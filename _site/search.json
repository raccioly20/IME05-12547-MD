[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre",
    "section": "",
    "text": "Esta Ã© a pÃ¡gina principal do site da disciplina MineraÃ§Ã£o de Dados IME05-12547.\nEste site foi construÃ­do usando Quarto e foi baseado em diversas fontes de informaÃ§Ã£o obtidas na internet.\nSeguem algumas referÃªncias Ãºteis para o Quarto:\nQuarto\nCurso da Duke University\nComo criar um blog com o Quarto\nPalestra do RStudio - Rmd para o Quarto"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IME05-12547 MineraÃ§Ã£o de Dados",
    "section": "",
    "text": "Aqui vocÃªs vÃ£o encontrar alguns dos exemplos apresentados em aula, com uso do R. O objetivo Ã© mostrar as possibilidades de aplicaÃ§Ã£o do R nesta disciplina.\nOs cÃ³digos apresentados em aula serÃ£o colocado por aqui tambÃ©m.\n[ðŸ“–] 1Âª Semana\n[ðŸ“–] 2Âª Semana\n[ðŸ“–] 3Âª Semana\n[ðŸ“–] 4Âª Semana\n[ðŸ“–] 5Âª Semana\n[ðŸ“–] 6Âª Semana\n[ðŸ“–] 7Âª Semana\n[ðŸ“–] 8Âª Semana\n[ðŸ“–] 9Âª Semana\n[ðŸ“–] 10Âª Semana\n[ðŸ“–] 11Âª Semana\n[ðŸ“–] 12Âª Semana\n[ðŸ“–] 13Âª Semana\n[ðŸ“–] 14Âª Semana\n[ðŸ“–] 15Âª Semana"
  },
  {
    "objectID": "slide01.html",
    "href": "slide01.html",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "",
    "text": "Carregando os dados\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.1 â”€â”€\n\n\nâœ” ggplot2 3.3.6     âœ” purrr   0.3.4\nâœ” tibble  3.1.7     âœ” dplyr   1.0.9\nâœ” tidyr   1.2.0     âœ” stringr 1.4.0\nâœ” readr   2.1.2     âœ” forcats 0.5.1\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\n\nlibrary(survival)\ntempo<- c(6,6,6,6,7,9,10,10,11,13,16,17,19,20,22,23,25,32,32,34,35)\nstatus<- c(1,1,1,0,1,0,1,0,0,1,1,0,0,0,1,1,0,0,0,0,0)\ndados <- data.frame(tempos=tempo, status=status)\najusteKM <- survfit(Surv(tempos, status) ~ 1, data=dados)\nplot(ajusteKM, xlab=\"Tempo (semanas)\",ylab=\"S(t)\", lty=2) \nlegend(\"topright\",\"6-MP\", lty = 2)\n\n\n\n\n\n\nSumÃ¡rio do ajuste\n\nsummary(ajusteKM)\n\nCall: survfit(formula = Surv(tempos, status) ~ 1, data = dados)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.720        1.000\n    7     17       1    0.807  0.0869        0.653        0.996\n   10     15       1    0.753  0.0963        0.586        0.968\n   13     12       1    0.690  0.1068        0.510        0.935\n   16     11       1    0.627  0.1141        0.439        0.896\n   22      7       1    0.538  0.1282        0.337        0.858\n   23      6       1    0.448  0.1346        0.249        0.807\n\n\n\n\nSegundo conjunto de dados\n\ntempo2<- c(1,1,2,2,3,4,4,5,5,8,8,8,8,11,11,12,12,15,17,22,23)\nstatus2<- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1) \ndados2 <- data.frame(tempos=tempo2, status=status2)\najusteKM2 <- survfit(Surv(tempos, status) ~ 1, data=dados2)\nplot(ajusteKM2, xlab=\"t(semanas)\",ylab=\"S(t)\", lty=3) \nlegend(\"topright\",\"Placebo\", lty = 3)\n\n\n\n\n\n\nSumÃ¡rio do 2Â° ajuste\n\nsummary(ajusteKM2)\n\nCall: survfit(formula = Surv(tempos, status) ~ 1, data = dados2)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1     21       2   0.9048  0.0641      0.78754        1.000\n    2     19       2   0.8095  0.0857      0.65785        0.996\n    3     17       1   0.7619  0.0929      0.59988        0.968\n    4     16       2   0.6667  0.1029      0.49268        0.902\n    5     14       2   0.5714  0.1080      0.39455        0.828\n    8     12       4   0.3810  0.1060      0.22085        0.657\n   11      8       2   0.2857  0.0986      0.14529        0.562\n   12      6       2   0.1905  0.0857      0.07887        0.460\n   15      4       1   0.1429  0.0764      0.05011        0.407\n   17      3       1   0.0952  0.0641      0.02549        0.356\n   22      2       1   0.0476  0.0465      0.00703        0.322\n   23      1       1   0.0000     NaN           NA           NA\n\n\n\n\nAnÃ¡lise conjunta\n\ntempo2g <- c(tempo,tempo2)\nstatus2g <- c(status,status2)\ngrupos <- c(rep(1,21),rep(2,21))\ndados3 <- data.frame(tempos=tempo2g, status=status2g, grupos=grupos)\najusteKM3 <- survfit(Surv(tempos, status) ~ grupos, data=dados3)\nplot(ajusteKM3, xlab=\"T(semanas)\",ylab=\"S(t)\", lty=1:2, \n     col=c(1,4), conf.int=0.95) \nlegend(\"topright\",c(\"6-MP\",\"Placebo\"), lty = 1:2, col=c(1,4))\n\n\n\n\n\n\nSumÃ¡rio do ajuste\n\nsummary(ajusteKM3)\n\nCall: survfit(formula = Surv(tempos, status) ~ grupos, data = dados3)\n\n                grupos=1 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.720        1.000\n    7     17       1    0.807  0.0869        0.653        0.996\n   10     15       1    0.753  0.0963        0.586        0.968\n   13     12       1    0.690  0.1068        0.510        0.935\n   16     11       1    0.627  0.1141        0.439        0.896\n   22      7       1    0.538  0.1282        0.337        0.858\n   23      6       1    0.448  0.1346        0.249        0.807\n\n                grupos=2 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1     21       2   0.9048  0.0641      0.78754        1.000\n    2     19       2   0.8095  0.0857      0.65785        0.996\n    3     17       1   0.7619  0.0929      0.59988        0.968\n    4     16       2   0.6667  0.1029      0.49268        0.902\n    5     14       2   0.5714  0.1080      0.39455        0.828\n    8     12       4   0.3810  0.1060      0.22085        0.657\n   11      8       2   0.2857  0.0986      0.14529        0.562\n   12      6       2   0.1905  0.0857      0.07887        0.460\n   15      4       1   0.1429  0.0764      0.05011        0.407\n   17      3       1   0.0952  0.0641      0.02549        0.356\n   22      2       1   0.0476  0.0465      0.00703        0.322\n   23      1       1   0.0000     NaN           NA           NA\n\n\n\n\nIntervalos de ConfianÃ§a - Normal\n\najusteKM4 <- survfit(Surv(tempos, status) ~ grupos, data=dados3,\n                     conf.type=\"plain\")\n# IC Pleno (AproximaÃ§Ã£o pela Normal)\nsummary(ajusteKM4)\n\nCall: survfit(formula = Surv(tempos, status) ~ grupos, data = dados3, \n    conf.type = \"plain\")\n\n                grupos=1 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.707        1.000\n    7     17       1    0.807  0.0869        0.636        0.977\n   10     15       1    0.753  0.0963        0.564        0.942\n   13     12       1    0.690  0.1068        0.481        0.900\n   16     11       1    0.627  0.1141        0.404        0.851\n   22      7       1    0.538  0.1282        0.286        0.789\n   23      6       1    0.448  0.1346        0.184        0.712\n\n                grupos=2 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1     21       2   0.9048  0.0641       0.7792        1.000\n    2     19       2   0.8095  0.0857       0.6416        0.977\n    3     17       1   0.7619  0.0929       0.5797        0.944\n    4     16       2   0.6667  0.1029       0.4650        0.868\n    5     14       2   0.5714  0.1080       0.3598        0.783\n    8     12       4   0.3810  0.1060       0.1733        0.589\n   11      8       2   0.2857  0.0986       0.0925        0.479\n   12      6       2   0.1905  0.0857       0.0225        0.358\n   15      4       1   0.1429  0.0764       0.0000        0.293\n   17      3       1   0.0952  0.0641       0.0000        0.221\n   22      2       1   0.0476  0.0465       0.0000        0.139\n   23      1       1   0.0000     NaN          NaN          NaN\n\n\n\n\nIntervalos de ConfianÃ§a - Log\n\najusteKM5 <- survfit(Surv(tempos, status) ~ grupos, data=dados3,\n                     conf.type=\"log\")\n# IC log - PadrÃ£o do R\nsummary(ajusteKM5)\n\nCall: survfit(formula = Surv(tempos, status) ~ grupos, data = dados3, \n    conf.type = \"log\")\n\n                grupos=1 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.720        1.000\n    7     17       1    0.807  0.0869        0.653        0.996\n   10     15       1    0.753  0.0963        0.586        0.968\n   13     12       1    0.690  0.1068        0.510        0.935\n   16     11       1    0.627  0.1141        0.439        0.896\n   22      7       1    0.538  0.1282        0.337        0.858\n   23      6       1    0.448  0.1346        0.249        0.807\n\n                grupos=2 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1     21       2   0.9048  0.0641      0.78754        1.000\n    2     19       2   0.8095  0.0857      0.65785        0.996\n    3     17       1   0.7619  0.0929      0.59988        0.968\n    4     16       2   0.6667  0.1029      0.49268        0.902\n    5     14       2   0.5714  0.1080      0.39455        0.828\n    8     12       4   0.3810  0.1060      0.22085        0.657\n   11      8       2   0.2857  0.0986      0.14529        0.562\n   12      6       2   0.1905  0.0857      0.07887        0.460\n   15      4       1   0.1429  0.0764      0.05011        0.407\n   17      3       1   0.0952  0.0641      0.02549        0.356\n   22      2       1   0.0476  0.0465      0.00703        0.322\n   23      1       1   0.0000     NaN           NA           NA\n\n\n\n\nIntervalos de ConfianÃ§a - Log-Log\n\n\nUsando o pacote survminer\n\nlibrary(survminer)\n\nCarregando pacotes exigidos: ggpubr\n\n\n\nAttaching package: 'survminer'\n\n\nThe following object is masked from 'package:survival':\n\n    myeloma\n\ndados <- data.frame(tempo=tempo2g, status=status2g, grupo= grupos)\najusteKM4 <- survfit(Surv(tempo2g, status2g) ~ grupo, data= dados, conf.type=\"log-log\")\nggsurvplot(ajusteKM4, data=dados)\n\n\n\n\n\n\nMelhorando a visualizaÃ§Ã£o\n\ndados <- data.frame(tempo=tempo2g, status=status2g, grupo= grupos)\nfit4 <- survfit(Surv(tempo2g, status2g) ~ grupo, data= dados, conf.type=\"log-log\")\nggsurvplot(\n  fit4,                   \n  data = dados,           \n  risk.table = TRUE,      \n  pval = FALSE,           \n  conf.int = TRUE,        \n  xlim = c(0,40),         \n  xlab = \"Tempo em meses\",  \n  ylab = \"S(t)\",\n  break.time.by = 10,     \n  ggtheme = theme_light(), \n  risk.table.y.text.col = T, \n  risk.table.y.text = FALSE  \n)"
  },
  {
    "objectID": "modregpar01.html",
    "href": "modregpar01.html",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "",
    "text": "Nesta etapa vamos comeÃ§ar a trabalhar com modelos de regressÃ£o paramÃ©tricos.\nOs modelos que vamos ver se denominam modelos de tempo de falha (vida) acelerado TFA (AFT).\nO conjunto de dados a seguir chamado â€œanderson.xlsxâ€ consiste em tempos de remissÃ£o (em semanas) em 42 pacientes com leucemia, metade dos quais recebem uma certa nova terapia de tratamento e a outra metade recebe uma terapia de tratamento padrÃ£o. A variÃ¡vel de exposiÃ§Ã£o de interesse Ã© o tratamento (Rx = 0 se novo tratamento, Rx = 1 se tratamento padrÃ£o).\nDuas outras variÃ¡veis para controle como potenciais confundidores sÃ£o a contagem de glÃ³bulos brancos (ou seja, logwbc) e sexo. O status de falha Ã© definido pela variÃ¡vel recaÃ­da (0 se censurado, 1 se falhar)."
  },
  {
    "objectID": "modregpar01.html#modelo-exponencial",
    "href": "modregpar01.html#modelo-exponencial",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Modelo Exponencial",
    "text": "Modelo Exponencial\n\nleuc.exp.comp <- survreg(Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, dist = \"exponential\")\nsummary(leuc.exp.comp)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, \n    dist = \"exponential\")\n              Value Std. Error     z      p\n(Intercept)  5.9741     0.6965  8.58 <2e-16\nsexo        -0.0859     0.3834 -0.22  0.823\nlogwbc      -0.8723     0.2212 -3.94  8e-05\nRx          -1.1156     0.4270 -2.61  0.009\n\nScale fixed at 1 \n\nExponential distribution\nLoglik(model)= -100.7   Loglik(intercept only)= -116.8\n    Chisq= 32.04 on 3 degrees of freedom, p= 5.1e-07 \nNumber of Newton-Raphson Iterations: 4 \nn= 42"
  },
  {
    "objectID": "modregpar01.html#automatizando-ajuste",
    "href": "modregpar01.html#automatizando-ajuste",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Automatizando ajuste",
    "text": "Automatizando ajuste\n\nlibrary(MASS)\nleuc.exp.sel <- stepAIC(leuc.exp.comp, direction=\"backward\", trace=FALSE)\nsummary(leuc.exp.sel)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"exponential\")\n             Value Std. Error     z       p\n(Intercept)  5.958      0.699  8.52 < 2e-16\nlogwbc      -0.884      0.216 -4.10 4.2e-05\nRx          -1.093      0.413 -2.65  0.0082\n\nScale fixed at 1 \n\nExponential distribution\nLoglik(model)= -100.8   Loglik(intercept only)= -116.8\n    Chisq= 31.99 on 2 degrees of freedom, p= 1.1e-07 \nNumber of Newton-Raphson Iterations: 4 \nn= 42"
  },
  {
    "objectID": "modregpar01.html#fazendo-previsÃµes",
    "href": "modregpar01.html#fazendo-previsÃµes",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Fazendo PrevisÃµes",
    "text": "Fazendo PrevisÃµes\n\nnovosdados <- data.frame(logwbc=c(2,2), Rx=c(0,1))\npredict(leuc.exp.sel, type=\"lp\", newdata=novosdados)\n\n       1        2 \n4.189084 3.096010"
  },
  {
    "objectID": "modregpar01.html#tempo-mediano",
    "href": "modregpar01.html#tempo-mediano",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Tempo Mediano",
    "text": "Tempo Mediano\n\nprev1 <-predict(leuc.exp.sel, type=\"quantile\", newdata=novosdados, p=0.5)\nprev1\n\n       1        2 \n45.72161 15.32518 \n\nprev1[1]/prev1[2]\n\n       1 \n2.983431"
  },
  {
    "objectID": "modregpar01.html#comparando-com-outro-quantil",
    "href": "modregpar01.html#comparando-com-outro-quantil",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Comparando com outro quantil",
    "text": "Comparando com outro quantil\n\nprev2 <-predict(leuc.exp.sel, type=\"quantile\", newdata=novosdados, p=0.7)\nprev2\n\n       1        2 \n79.41687 26.61931 \n\nprev2[1]/prev2[2]\n\n       1 \n2.983431"
  },
  {
    "objectID": "modregpar01.html#verificando-o-modelo",
    "href": "modregpar01.html#verificando-o-modelo",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Verificando o modelo",
    "text": "Verificando o modelo\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\npar(mfrow = c(1, 2), cex = 0.6)\npred.lin <- predict(leuc.exp.sel, type = \"lp\")[dados$status == 1]\nlog.resid <- log(dados$tempo[dados$status == 1]) - pred.lin\nplot(pred.lin, log.resid, main = \"Grafico TA\",\nxlab = \"log(valores ajustados)\", ylab = \"log(residuos)\")\nqqPlot(exp(log.resid), dist = \"weibull\",\nshape = 1,\nmain = \"Grafico Q-Q\", xlab = \"Quantis teoricos\", ylab = \"Quantis Empiricos\")\n\n\n\n\n[1] 11 16"
  },
  {
    "objectID": "modregpar01.html#modelo-weibull",
    "href": "modregpar01.html#modelo-weibull",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Modelo Weibull",
    "text": "Modelo Weibull\n\nleuc.wei.comp <- survreg(Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, dist = \"weibull\")\nsummary(leuc.wei.comp)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, \n    dist = \"weibull\")\n             Value Std. Error     z       p\n(Intercept)  5.462      0.351 15.58 < 2e-16\nsexo        -0.156      0.179 -0.87 0.38350\nlogwbc      -0.792      0.105 -7.54 4.8e-14\nRx          -0.722      0.201 -3.59 0.00034\nLog(scale)  -0.815      0.144 -5.65 1.6e-08\n\nScale= 0.443 \n\nWeibull distribution\nLoglik(model)= -89.7   Loglik(intercept only)= -116.4\n    Chisq= 53.42 on 3 degrees of freedom, p= 1.5e-11 \nNumber of Newton-Raphson Iterations: 7 \nn= 42 \n\n\n\nleuc.wei.sel <- stepAIC(leuc.wei.comp, direction=\"backward\", trace=FALSE)\nsummary(leuc.wei.sel)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"weibull\")\n             Value Std. Error     z       p\n(Intercept)  5.399      0.364 14.84 < 2e-16\nlogwbc      -0.807      0.108 -7.45 9.7e-14\nRx          -0.659      0.189 -3.49 0.00049\nLog(scale)  -0.793      0.142 -5.58 2.5e-08\n\nScale= 0.452 \n\nWeibull distribution\nLoglik(model)= -90.1   Loglik(intercept only)= -116.4\n    Chisq= 52.68 on 2 degrees of freedom, p= 3.6e-12 \nNumber of Newton-Raphson Iterations: 7 \nn= 42"
  },
  {
    "objectID": "modregpar01.html#anÃ¡lise-de-resÃ­duos",
    "href": "modregpar01.html#anÃ¡lise-de-resÃ­duos",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "AnÃ¡lise de resÃ­duos",
    "text": "AnÃ¡lise de resÃ­duos"
  },
  {
    "objectID": "modregpar01.html#fazendo-previsÃµes-1",
    "href": "modregpar01.html#fazendo-previsÃµes-1",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Fazendo PrevisÃµes",
    "text": "Fazendo PrevisÃµes\n\nnovosdados <- data.frame(logwbc=c(2,2), Rx=c(0,1))\npredict(leuc.wei.sel, type=\"lp\", newdata=novosdados)\n\n       1        2 \n3.784108 3.125137"
  },
  {
    "objectID": "modregpar01.html#tempo-mediano-1",
    "href": "modregpar01.html#tempo-mediano-1",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Tempo Mediano",
    "text": "Tempo Mediano\n\nprev1 <-predict(leuc.wei.sel, type=\"quantile\", newdata=novosdados, p=0.5)\nprev1\n\n       1        2 \n37.27311 19.28448 \n\nprev1[1]/prev1[2]\n\n       1 \n1.932804"
  },
  {
    "objectID": "modregpar01.html#comparando-com-outro-quantil-1",
    "href": "modregpar01.html#comparando-com-outro-quantil-1",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Comparando com outro quantil",
    "text": "Comparando com outro quantil\n\nprev2 <-predict(leuc.wei.sel, type=\"quantile\", newdata=novosdados, p=0.7)\nprev2\n\n       1        2 \n47.85133 24.75747 \n\nprev2[1]/prev2[2]\n\n       1 \n1.932804"
  },
  {
    "objectID": "modregpar01.html#verificando-o-modelo-1",
    "href": "modregpar01.html#verificando-o-modelo-1",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Verificando o modelo",
    "text": "Verificando o modelo\n\npar(mfrow = c(1, 2), cex = 0.6)\npred.lin <- predict(leuc.wei.sel, type = \"lp\")[dados$status == 1]\nlog.resid <- log(dados$tempo[dados$status == 1]) - pred.lin\nplot(pred.lin, log.resid, main = \"Grafico TA\",\nxlab = \"log(valores ajustados)\", ylab = \"log(residuos)\")\nqqPlot(exp(log.resid), dist = \"weibull\",\nshape = 1/leuc.wei.sel$scale,\nmain = \"Grafico Q-Q\", xlab = \"Quantis teoricos\", ylab = \"Quantis Empiricos\")\n\n\n\n\n[1] 11 16"
  },
  {
    "objectID": "modregpar01.html#modelo-lognormal",
    "href": "modregpar01.html#modelo-lognormal",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Modelo Lognormal",
    "text": "Modelo Lognormal\n\nleuc.logn.comp <- survreg(Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, dist = \"lognormal\")\nsummary(leuc.logn.comp)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, \n    dist = \"lognormal\")\n              Value Std. Error     z       p\n(Intercept)  4.9975     0.3924 12.74 < 2e-16\nsexo        -0.0947     0.2211 -0.43 0.66862\nlogwbc      -0.7051     0.1251 -5.64 1.7e-08\nRx          -0.8539     0.2311 -3.69 0.00022\nLog(scale)  -0.4424     0.1293 -3.42 0.00062\n\nScale= 0.642 \n\nLog Normal distribution\nLoglik(model)= -93.9   Loglik(intercept only)= -115.4\n    Chisq= 43.08 on 3 degrees of freedom, p= 2.4e-09 \nNumber of Newton-Raphson Iterations: 6 \nn= 42 \n\n\n\nleuc.logn.sel <- stepAIC(leuc.logn.comp, direction=\"backward\", trace=FALSE)\nsummary(leuc.logn.sel)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"lognormal\")\n             Value Std. Error     z       p\n(Intercept)  4.982      0.394 12.65 < 2e-16\nlogwbc      -0.716      0.123 -5.80 6.6e-09\nRx          -0.848      0.232 -3.66 0.00025\nLog(scale)  -0.437      0.129 -3.39 0.00070\n\nScale= 0.646 \n\nLog Normal distribution\nLoglik(model)= -93.9   Loglik(intercept only)= -115.4\n    Chisq= 42.9 on 2 degrees of freedom, p= 4.8e-10 \nNumber of Newton-Raphson Iterations: 6 \nn= 42"
  },
  {
    "objectID": "modregpar01.html#fazendo-previsÃµes-2",
    "href": "modregpar01.html#fazendo-previsÃµes-2",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Fazendo PrevisÃµes",
    "text": "Fazendo PrevisÃµes\n\nnovosdados <- data.frame(logwbc=c(2,2), Rx=c(0,1))\npredict(leuc.logn.sel, type=\"lp\", newdata=novosdados)\n\n       1        2 \n3.549821 2.702019"
  },
  {
    "objectID": "modregpar01.html#tempo-mediano-2",
    "href": "modregpar01.html#tempo-mediano-2",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Tempo Mediano",
    "text": "Tempo Mediano\n\nprev1 <-predict(leuc.logn.sel, type=\"quantile\", newdata=novosdados, p=0.5)\nprev1\n\n       1        2 \n34.80708 14.90980 \n\nprev1[1]/prev1[2]\n\n      1 \n2.33451"
  },
  {
    "objectID": "modregpar01.html#comparando-com-outro-quantil-2",
    "href": "modregpar01.html#comparando-com-outro-quantil-2",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Comparando com outro quantil",
    "text": "Comparando com outro quantil\n\nprev2 <-predict(leuc.logn.sel, type=\"quantile\", newdata=novosdados, p=0.7)\nprev2\n\n       1        2 \n48.83742 20.91977 \n\nprev2[1]/prev2[2]\n\n      1 \n2.33451"
  },
  {
    "objectID": "modregpar01.html#verificando-o-modelo-2",
    "href": "modregpar01.html#verificando-o-modelo-2",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Verificando o modelo",
    "text": "Verificando o modelo\n\npar(mfrow = c(1, 2), cex = 0.6)\npred.lin <- predict(leuc.logn.sel, type = \"lp\")[dados$status == 1]\nlog.resid <- log(dados$tempo[dados$status == 1]) - pred.lin\nplot(pred.lin, log.resid, main = \"Grafico TA\",\nxlab = \"log(valores ajustados)\", ylab = \"log(residuos)\")\nqqPlot(exp(log.resid), dist = \"norm\",\nsd = leuc.logn.sel$scale,\nmain = \"Grafico Q-Q\", xlab = \"Quantis teoricos\", ylab = \"Quantis Empiricos\")\n\n\n\n\n[1] 11 12"
  },
  {
    "objectID": "modregpar01.html#modelo-loglogistico",
    "href": "modregpar01.html#modelo-loglogistico",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Modelo Loglogistico",
    "text": "Modelo Loglogistico\n\nleuc.logl.comp <- survreg(Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, dist = \"loglogistic\")\nsummary(leuc.logl.comp)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ sexo + logwbc + Rx, data = dados, \n    dist = \"loglogistic\")\n              Value Std. Error     z       p\n(Intercept)  5.0190     0.3518 14.27 < 2e-16\nsexo        -0.0408     0.2027 -0.20 0.84065\nlogwbc      -0.7278     0.1098 -6.63 3.4e-11\nRx          -0.7494     0.2133 -3.51 0.00044\nLog(scale)  -1.0894     0.1509 -7.22 5.1e-13\n\nScale= 0.336 \n\nLog logistic distribution\nLoglik(model)= -92.3   Loglik(intercept only)= -115.4\n    Chisq= 46.08 on 3 degrees of freedom, p= 5.5e-10 \nNumber of Newton-Raphson Iterations: 6 \nn= 42 \n\n\n\nleuc.logl.sel <- stepAIC(leuc.logl.comp, direction=\"backward\", trace=FALSE)\nsummary(leuc.logl.sel)\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"loglogistic\")\n             Value Std. Error     z       p\n(Intercept)  5.008      0.348 14.40 < 2e-16\nlogwbc      -0.733      0.108 -6.81 9.8e-12\nRx          -0.743      0.210 -3.54   4e-04\nLog(scale)  -1.089      0.151 -7.22 5.3e-13\n\nScale= 0.337 \n\nLog logistic distribution\nLoglik(model)= -92.3   Loglik(intercept only)= -115.4\n    Chisq= 46.04 on 2 degrees of freedom, p= 1e-10 \nNumber of Newton-Raphson Iterations: 6 \nn= 42"
  },
  {
    "objectID": "modregpar01.html#fazendo-previsÃµes-3",
    "href": "modregpar01.html#fazendo-previsÃµes-3",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Fazendo PrevisÃµes",
    "text": "Fazendo PrevisÃµes\n\nnovosdados <- data.frame(logwbc=c(2,2), Rx=c(0,1))\npredict(leuc.logl.sel, type=\"lp\", newdata=novosdados)\n\n       1        2 \n3.542894 2.800346"
  },
  {
    "objectID": "modregpar01.html#tempo-mediano-3",
    "href": "modregpar01.html#tempo-mediano-3",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Tempo Mediano",
    "text": "Tempo Mediano\n\nprev1 <-predict(leuc.logl.sel, type=\"quantile\", newdata=novosdados, p=0.5)\nprev1\n\n       1        2 \n34.56680 16.45034 \n\nprev1[1]/prev1[2]\n\n       1 \n2.101282"
  },
  {
    "objectID": "modregpar01.html#comparando-com-outro-quantil-3",
    "href": "modregpar01.html#comparando-com-outro-quantil-3",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Comparando com outro quantil",
    "text": "Comparando com outro quantil\n\nprev2 <-predict(leuc.logl.sel, type=\"quantile\", newdata=novosdados, p=0.7)\nprev2\n\n       1        2 \n45.97221 21.87818 \n\nprev2[1]/prev2[2]\n\n       1 \n2.101282"
  },
  {
    "objectID": "modregpar01.html#verificando-o-modelo-3",
    "href": "modregpar01.html#verificando-o-modelo-3",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Verificando o modelo",
    "text": "Verificando o modelo\n\npar(mfrow = c(1, 2), cex = 0.6)\npred.lin <- predict(leuc.logl.sel, type = \"lp\")[dados$status == 1]\nlog.resid <- log(dados$tempo[dados$status == 1]) - pred.lin\nplot(pred.lin, log.resid, main = \"Grafico TA\",\nxlab = \"log(valores ajustados)\", ylab = \"log(residuos)\")\nqqPlot(exp(log.resid), dist = \"logis\",\nscale = leuc.logl.sel$scale,\nmain = \"Grafico Q-Q\", xlab = \"Quantis teoricos\", ylab = \"Quantis Empiricos\")\n\n\n\n\n[1] 11 12"
  },
  {
    "objectID": "modregpar01.html#comparaÃ§Ã£o-dos-modelos",
    "href": "modregpar01.html#comparaÃ§Ã£o-dos-modelos",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "ComparaÃ§Ã£o dos modelos",
    "text": "ComparaÃ§Ã£o dos modelos\n\ntab.exp <- summary(leuc.exp.sel)\ntab.exp\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"exponential\")\n             Value Std. Error     z       p\n(Intercept)  5.958      0.699  8.52 < 2e-16\nlogwbc      -0.884      0.216 -4.10 4.2e-05\nRx          -1.093      0.413 -2.65  0.0082\n\nScale fixed at 1 \n\nExponential distribution\nLoglik(model)= -100.8   Loglik(intercept only)= -116.8\n    Chisq= 31.99 on 2 degrees of freedom, p= 1.1e-07 \nNumber of Newton-Raphson Iterations: 4 \nn= 42 \n\ntab.wei <- summary(leuc.wei.sel)\ntab.wei\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"weibull\")\n             Value Std. Error     z       p\n(Intercept)  5.399      0.364 14.84 < 2e-16\nlogwbc      -0.807      0.108 -7.45 9.7e-14\nRx          -0.659      0.189 -3.49 0.00049\nLog(scale)  -0.793      0.142 -5.58 2.5e-08\n\nScale= 0.452 \n\nWeibull distribution\nLoglik(model)= -90.1   Loglik(intercept only)= -116.4\n    Chisq= 52.68 on 2 degrees of freedom, p= 3.6e-12 \nNumber of Newton-Raphson Iterations: 7 \nn= 42 \n\nTRV <- 2*(tab.wei$loglik[1] - tab.exp$loglik[1])\npchisq(TRV, 1, lower.tail = F)\n\n[1] 0.3953251\n\ntab.ln <- summary(leuc.logn.sel)\ntab.ln\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"lognormal\")\n             Value Std. Error     z       p\n(Intercept)  4.982      0.394 12.65 < 2e-16\nlogwbc      -0.716      0.123 -5.80 6.6e-09\nRx          -0.848      0.232 -3.66 0.00025\nLog(scale)  -0.437      0.129 -3.39 0.00070\n\nScale= 0.646 \n\nLog Normal distribution\nLoglik(model)= -93.9   Loglik(intercept only)= -115.4\n    Chisq= 42.9 on 2 degrees of freedom, p= 4.8e-10 \nNumber of Newton-Raphson Iterations: 6 \nn= 42 \n\ntab.ll <- summary(leuc.logl.sel)\ntab.ll\n\n\nCall:\nsurvreg(formula = Surv(tempo, status) ~ logwbc + Rx, data = dados, \n    dist = \"loglogistic\")\n             Value Std. Error     z       p\n(Intercept)  5.008      0.348 14.40 < 2e-16\nlogwbc      -0.733      0.108 -6.81 9.8e-12\nRx          -0.743      0.210 -3.54   4e-04\nLog(scale)  -1.089      0.151 -7.22 5.3e-13\n\nScale= 0.337 \n\nLog logistic distribution\nLoglik(model)= -92.3   Loglik(intercept only)= -115.4\n    Chisq= 46.04 on 2 degrees of freedom, p= 1e-10 \nNumber of Newton-Raphson Iterations: 6 \nn= 42 \n\naic.exp <- -2*tab.exp$loglik[1] + 2*3\naic.exp\n\n[1] 239.5333\n\naic.wei <- -2*tab.wei$loglik[1] + 2*4\naic.wei\n\n[1] 240.8108\n\naic.ln <- -2*tab.ln$loglik[1] + 2*4\naic.ln\n\n[1] 238.786\n\naic.ll <- -2*tab.ll$loglik[1] + 2*4\naic.ll\n\n[1] 238.7022\n\naic <- c(aic.exp, aic.wei, aic.ln, aic.ll)\ndelta.aic <- aic - min(aic)\ndelta.aic\n\n[1] 0.83108732 2.10858745 0.08373248 0.00000000\n\npeso.aic <- exp(-0.5*delta.aic)/sum(exp(-0.5*delta.aic))\nsum(peso.aic)\n\n[1] 1\n\nmodelos <- data.frame(modelos=c(\"Exponencial\", \"Weibull\",\n                                \"Lognormal\", \"Loglogistico\"),\n                      p_Akaike = peso.aic)\ngt::gt(modelos)\n\n\n\n\n\n  \n  \n    \n      modelos\n      p_Akaike\n    \n  \n  \n    Exponencial\n0.2224093\n    Weibull\n0.1174214\n    Lognormal\n0.3231759\n    Loglogistico\n0.3369933"
  },
  {
    "objectID": "modregpar01.html#usando-o-bic",
    "href": "modregpar01.html#usando-o-bic",
    "title": "AnÃ¡lise de SobrevivÃªncia",
    "section": "Usando o BIC",
    "text": "Usando o BIC\n\nbic.exp <- -2*tab.exp$loglik[1] + log(sum(dados$status == 1))*3\nbic.exp\n\n[1] 243.7369\n\nbic.wei <- -2*tab.wei$loglik[1] + log(sum(dados$status == 1))*4\nbic.wei\n\n[1] 246.4156\n\nbic.ln <- -2*tab.ln$loglik[1] + log(sum(dados$status == 1))*4\nbic.ln\n\n[1] 244.3907\n\nbic.ll <- -2*tab.ll$loglik[1] + log(sum(dados$status == 1))*4\nbic.ll\n\n[1] 244.307\n\nbic <- c(bic.exp, bic.wei, bic.ln, bic.ll)\ndelta.bic <- bic - min(bic)\ndelta.bic\n\n[1] 0.0000000 2.6786975 0.6538425 0.5701101\n\npeso.bic <- exp(-0.5*delta.bic)/sum(exp(-0.5*delta.bic))\nsum(peso.bic)\n\n[1] 1\n\nmodelos <- data.frame(modelos=c(\"Exponencial\", \"Weibull\",\n                                \"Lognormal\", \"Loglogistico\"),\n                      p_Akaike = peso.bic)\ngt::gt(modelos)\n\n\n\n\n\n  \n  \n    \n      modelos\n      p_Akaike\n    \n  \n  \n    Exponencial\n0.36561338\n    Weibull\n0.09579665\n    Lognormal\n0.26365862\n    Loglogistico\n0.27493135"
  },
  {
    "objectID": "acesso-rstudio.html",
    "href": "acesso-rstudio.html",
    "title": "RStudio Cloud",
    "section": "",
    "text": "RStudio"
  },
  {
    "objectID": "semanas/sem-1.html",
    "href": "semanas/sem-1.html",
    "title": "1Âª Semama",
    "section": "",
    "text": "Important\n\n\n\nAs aulas sÃ£o virtuais. Ache o link para o Teams aqui."
  },
  {
    "objectID": "semanas/sem-1.html#prepare",
    "href": "semanas/sem-1.html#prepare",
    "title": "1Âª Semama",
    "section": "Prepare",
    "text": "Prepare\nðŸ“– Leia sobre\n\nRetorne ao cronograma âŽ"
  },
  {
    "objectID": "semanas/sem-2.html",
    "href": "semanas/sem-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Important\n\n\n\n\nClasses are virtual this week. Find Zoom links here.\nDue dates:\n\nLab 1: Fri, Jan 14, 5pm ET\nAE 1: Sun, Jan 16, 11:59pm ET"
  },
  {
    "objectID": "semanas/sem-2.html#prepare",
    "href": "semanas/sem-2.html#prepare",
    "title": "Week 2",
    "section": "Prepare",
    "text": "Prepare\nðŸ“– Read Introduction to Modern Statistics, Chp 7: Linear regression with a single predictor"
  },
  {
    "objectID": "semanas/sem-2.html#participate",
    "href": "semanas/sem-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\nðŸ–¥ï¸ Lab 1 - Meet the toolkit\nðŸ–¥ï¸ Lecture 2 - Simple linear regression\nðŸ–¥ï¸ Lecture 3 - Model fitting in R with tidymodels"
  },
  {
    "objectID": "semanas/sem-2.html#practice",
    "href": "semanas/sem-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\nðŸ“‹ Application Exercise 1 - Bike rentals in DC (Post-class note: complete only Part 1 - Daily counts and temperature)"
  },
  {
    "objectID": "semanas/sem-2.html#perform",
    "href": "semanas/sem-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\nâŒ¨ï¸ Lab 1 - Meet the toolkit\n\n\nBack to course schedule âŽ"
  },
  {
    "objectID": "visao-do-curso.html",
    "href": "visao-do-curso.html",
    "title": "MineraÃ§Ã£o de Dados",
    "section": "",
    "text": "IntroduÃ§Ã£o a mineraÃ§Ã£o de dados\nVisualizaÃ§Ã£o e preparaÃ§Ã£o de Dados\nRegressÃ£o linear e seleÃ§Ã£o de modelos\nMÃ©todos de Reamostragem\nMÃ©todos de encolhimento (Ridge e Lasso)\nClassificaÃ§Ã£o (KNN, RegressÃ£o LogÃ­stica, LDA e QDA)\nMÃ©todos baseados em Ã¡rvores"
  },
  {
    "objectID": "IME-05-MD.html",
    "href": "IME-05-MD.html",
    "title": "IME-05-MD",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "semanas/Aula07.2.html",
    "href": "semanas/Aula07.2.html",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "semanas/Aula07.2.html#dados-de-propaganda",
    "href": "semanas/Aula07.2.html#dados-de-propaganda",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Dados de propaganda",
    "text": "Dados de propaganda\nO conjunto de dados contÃ©m estatÃ­sticas sobre as vendas de um produto em 200 diferentes mercados, juntamente com orÃ§amentos publicitÃ¡rios em cada um desses mercados, para diferentes canais de mÃ­dia: TV, rÃ¡dio e jornal. As vendas estÃ£o em milhares de unidades e o orÃ§amento estÃ¡ em milhares de dÃ³lares.\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nsummary(propaganda)\n\n       TV             Radio          Newspaper          Sales      \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00"
  },
  {
    "objectID": "semanas/Aula07.2.html#renomeando",
    "href": "semanas/Aula07.2.html#renomeando",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Renomeando",
    "text": "Renomeando\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)"
  },
  {
    "objectID": "semanas/Aula07.2.html#sumario",
    "href": "semanas/Aula07.2.html#sumario",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Sumario",
    "text": "Sumario\n\nsummary(propaganda)\n\n       TV             Radio            Jornal           Vendas     \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00  \n\nnrow(propaganda)\n\n[1] 200"
  },
  {
    "objectID": "semanas/Aula07.2.html#linhas-inicias",
    "href": "semanas/Aula07.2.html#linhas-inicias",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Linhas inicias",
    "text": "Linhas inicias\n\nlibrary(gt)\ngt(head(propaganda, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    44.5\n39.3\n45.1\n10.4\n    17.2\n45.9\n69.3\n9.3\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    8.7\n48.9\n75.0\n7.2\n    57.5\n32.8\n23.5\n11.8\n    120.2\n19.6\n11.6\n13.2\n    8.6\n2.1\n1.0\n4.8\n    199.8\n2.6\n21.2\n10.6"
  },
  {
    "objectID": "semanas/Aula07.2.html#criando-amostra-de-treino-e-teste",
    "href": "semanas/Aula07.2.html#criando-amostra-de-treino-e-teste",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Criando amostra de treino e teste",
    "text": "Criando amostra de treino e teste\n\nlibrary(caret)\nset.seed(21)\ny <- propaganda$Vendas\nindice_teste <- createDataPartition(y, times = 1, p = 0.40, list = FALSE)\n\nconj_treino <- propaganda %>% slice(-indice_teste)\nconj_teste <- propaganda %>% slice(indice_teste)\n\nstr(conj_treino)\n\ntibble [119 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:119] 230.1 151.5 180.8 199.8 66.1 ...\n $ Radio : num [1:119] 37.8 41.3 10.8 2.6 5.8 35.1 7.6 47.7 20.5 23.9 ...\n $ Jornal: num [1:119] 69.2 58.5 58.4 21.2 24.2 65.9 7.2 52.9 18.3 19.1 ...\n $ Vendas: num [1:119] 22.1 18.5 12.9 10.6 8.6 9.2 9.7 22.4 11.3 14.6 ...\n\nstr(conj_teste)\n\ntibble [81 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:81] 44.5 17.2 8.7 57.5 120.2 ...\n $ Radio : num [1:81] 39.3 45.9 48.9 32.8 19.6 2.1 24 32.9 36.6 39.6 ...\n $ Jornal: num [1:81] 45.1 69.3 75 23.5 11.6 1 4 46 114 55.8 ...\n $ Vendas: num [1:81] 10.4 9.3 7.2 11.8 13.2 4.8 17.4 19 12.5 24.4 ...\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6"
  },
  {
    "objectID": "semanas/Aula07.2.html#regressÃ£o-simples",
    "href": "semanas/Aula07.2.html#regressÃ£o-simples",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "RegressÃ£o Simples",
    "text": "RegressÃ£o Simples\n\nmod1 <- lm( Vendas ~ TV, data = conj_treino)\nmod2 <- lm( Vendas ~ Radio, data = conj_treino)\nmod3 <- lm( Vendas ~ Jornal, data = conj_treino)"
  },
  {
    "objectID": "semanas/Aula07.2.html#a-regressÃ£o-multipla",
    "href": "semanas/Aula07.2.html#a-regressÃ£o-multipla",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "1a RegressÃ£o Multipla",
    "text": "1a RegressÃ£o Multipla\n\nlibrary(car)\nscatterplotMatrix(conj_treino)\n\n\n\nmod4 <- lm( Vendas ~ TV + Radio + Jornal, data = conj_treino)\nsummary(mod4)\n\n\nCall:\nlm(formula = Vendas ~ TV + Radio + Jornal, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.1595 -0.6961  0.2676  1.0298  2.5871 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.268910   0.391828   8.343 1.81e-13 ***\nTV          0.042705   0.001776  24.039  < 2e-16 ***\nRadio       0.186439   0.011458  16.272  < 2e-16 ***\nJornal      0.008931   0.008292   1.077    0.284    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.606 on 115 degrees of freedom\nMultiple R-squared:  0.9002,    Adjusted R-squared:  0.8976 \nF-statistic: 345.9 on 3 and 115 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.2.html#a-regressao-multipla",
    "href": "semanas/Aula07.2.html#a-regressao-multipla",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "2a Regressao Multipla",
    "text": "2a Regressao Multipla\n\nmod5 <- lm( Vendas ~ TV + Radio, data = conj_treino)\nsummary(mod5)\n\n\nCall:\nlm(formula = Vendas ~ TV + Radio, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.4585 -0.6886  0.1687  1.0799  2.5529 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.441076   0.357985   9.612   <2e-16 ***\nTV          0.042575   0.001774  24.005   <2e-16 ***\nRadio       0.191607   0.010412  18.402   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.607 on 116 degrees of freedom\nMultiple R-squared:  0.8992,    Adjusted R-squared:  0.8975 \nF-statistic: 517.5 on 2 and 116 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.2.html#confirmando-o-teste-t-com-o-teste-f-anova",
    "href": "semanas/Aula07.2.html#confirmando-o-teste-t-com-o-teste-f-anova",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Confirmando o teste t com o teste F (ANOVA)",
    "text": "Confirmando o teste t com o teste F (ANOVA)\n\nanova(mod5, mod4)\n\nAnalysis of Variance Table\n\nModel 1: Vendas ~ TV + Radio\nModel 2: Vendas ~ TV + Radio + Jornal\n  Res.Df    RSS Df Sum of Sq    F Pr(>F)\n1    116 299.47                         \n2    115 296.48  1    2.9906 1.16 0.2837"
  },
  {
    "objectID": "semanas/Aula07.2.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste",
    "href": "semanas/Aula07.2.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste",
    "text": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod5, conj_teste)) ^ 2)) \n\n[1] 1.846764"
  },
  {
    "objectID": "semanas/Aula07.2.html#comparando-com-a-melhor-regressÃ£o-simples",
    "href": "semanas/Aula07.2.html#comparando-com-a-melhor-regressÃ£o-simples",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Comparando com a melhor regressÃ£o simples",
    "text": "Comparando com a melhor regressÃ£o simples\n\n## Modelo com somente TV\nsummary(mod1)$sigma\n\n[1] 3.167319\n\nsummary(mod1)$r.squared\n\n[1] 0.605027\n\nsqrt(mean((conj_teste$Vendas - predict(mod1, conj_teste)) ^ 2))\n\n[1] 3.41382\n\n## Modelo com TV e Jornal\nsummary(mod5)$sigma\n\n[1] 1.606744\n\nsummary(mod5)$adj.r.squared\n\n[1] 0.8974883\n\nsqrt(mean((conj_teste$Vendas - predict(mod5, conj_teste)) ^ 2))\n\n[1] 1.846764"
  },
  {
    "objectID": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-1",
    "href": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-1",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "AnÃ¡lise do Modelo 1",
    "text": "AnÃ¡lise do Modelo 1\n\nlibrary(performance)\ncheck_model(mod5)"
  },
  {
    "objectID": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-2",
    "href": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-2",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "AnÃ¡lise do Modelo 2",
    "text": "AnÃ¡lise do Modelo 2\n\nplot(mod5)"
  },
  {
    "objectID": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-3",
    "href": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-3",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "AnÃ¡lise do Modelo 3",
    "text": "AnÃ¡lise do Modelo 3\nPara o grÃ¡fico de resÃ­duos versus valores ajustados, podemos usar um teste chamado teste de Tukey de nÃ£o aditividade (Tukey, 1949), ele Ã© obtido adicionando os quadrados dos valores ajustados ao modelo e reajustando. O valor p para o teste de Tukey Ã© obtido comparando a estatÃ­stica de teste para a distribuiÃ§Ã£o padrÃ£o-normal. O teste confirma a visÃ­vel impressÃ£o de curvatura no grÃ¡fico residual, reforÃ§ando ainda mais a conclusÃ£o que o modelo nÃ£o Ã© adequado.\n\nlibrary(car)\nresidualPlots(mod5)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nTV           -4.8383        4.102e-06 ***\nRadio         1.9290           0.0562 .  \nTukey test    6.4114        1.442e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-com-car",
    "href": "semanas/Aula07.2.html#anÃ¡lise-do-modelo-com-car",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "AnÃ¡lise do Modelo com car",
    "text": "AnÃ¡lise do Modelo com car\n\nlibrary(car)\nvif(mod5)\n\n      TV    Radio \n1.014454 1.014454"
  },
  {
    "objectID": "semanas/Aula07.2.html#tentando-corrigir-o-problema",
    "href": "semanas/Aula07.2.html#tentando-corrigir-o-problema",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Tentando corrigir o problema",
    "text": "Tentando corrigir o problema\n\nsummary(p1 <- powerTransform(Vendas ~ TV + Radio, data=conj_treino))\n\nbcPower Transformation to Normality \n   Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nY1    0.9937           1       0.8018       1.1856\n\nLikelihood ratio test that transformation parameter is equal to 0\n (log transformation)\n                          LRT df       pval\nLR test, lambda = (0) 111.042  1 < 2.22e-16\n\nLikelihood ratio test that no transformation is needed\n                              LRT df    pval\nLR test, lambda = (1) 0.004149754  1 0.94864\n\nsummary(p2 <- powerTransform(cbind(TV, Radio) ~1 , data=conj_treino))\n\nbcPower Transformations to Multinormality \n      Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nTV       0.7692         1.0       0.5311       1.0073\nRadio    0.5349         0.5       0.3429       0.7269\n\nLikelihood ratio test that transformation parameters are equal to 0\n (all log transformations)\n                            LRT df       pval\nLR test, lambda = (0 0) 102.457  2 < 2.22e-16\n\nLikelihood ratio test that no transformations are needed\n                           LRT df       pval\nLR test, lambda = (1 1) 22.189  2 1.5196e-05\n\nmod6 <- lm( log(Vendas) ~ TV + Radio, data = conj_treino)\nsummary(mod6)\n\n\nCall:\nlm(formula = log(Vendas) ~ TV + Radio, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.77994 -0.05255  0.04368  0.10055  0.17353 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.791156   0.043994  40.713  < 2e-16 ***\nTV          0.003492   0.000218  16.022  < 2e-16 ***\nRadio       0.011524   0.001280   9.006 5.04e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1975 on 116 degrees of freedom\nMultiple R-squared:  0.765, Adjusted R-squared:  0.761 \nF-statistic: 188.8 on 2 and 116 DF,  p-value: < 2.2e-16\n\nresidualPlots(mod6)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nTV           -6.8943        3.092e-10 ***\nRadio        -0.2563           0.7982    \nTukey test   -0.5761           0.5646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.2.html#dado-que-parece-outlier-e-Ã©-um-valor-influente",
    "href": "semanas/Aula07.2.html#dado-que-parece-outlier-e-Ã©-um-valor-influente",
    "title": "RegressÃ£o Linear MÃºltipla",
    "section": "Dado que parece outlier e Ã© um valor influente",
    "text": "Dado que parece outlier e Ã© um valor influente\nA funÃ§Ã£o OutlierTest () no pacote do car localiza o maior resÃ­duo studentizado em valor absoluto e calcula o teste t com correÃ§Ã£o de Bonferroni. O testes de Outlier utiliza uma distribuiÃ§Ã£o t para testar se o maior valor do residuo studentizado do modelo Ã© estatisticamente diferente das outras observaÃ§Ãµes. Um valor p significativo indica um outlier extremo que merece um exame mais aprofundado.\n\noutlierTest(mod6)\n\n    rstudent unadjusted p-value Bonferroni p\n83 -18.13798         1.5879e-35   1.8896e-33\n\nconj_treino[83,]\n\n# A tibble: 1 Ã— 4\n     TV Radio Jornal Vendas\n  <dbl> <dbl>  <dbl>  <dbl>\n1   0.7  39.6    8.7    1.6"
  },
  {
    "objectID": "semanas/Aula07.3.html",
    "href": "semanas/Aula07.3.html",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)\nlibrary(leaps)"
  },
  {
    "objectID": "semanas/Aula07.3.html#carregando-os-dados",
    "href": "semanas/Aula07.3.html#carregando-os-dados",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\ndata(Boston)\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nsummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\nnrow(Boston)\n\n[1] 506"
  },
  {
    "objectID": "semanas/Aula07.3.html#explicaÃ§Ã£o-das-variÃ¡veis",
    "href": "semanas/Aula07.3.html#explicaÃ§Ã£o-das-variÃ¡veis",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "ExplicaÃ§Ã£o das variÃ¡veis",
    "text": "ExplicaÃ§Ã£o das variÃ¡veis\n\n# Boston Database\n# \n# 1) crim - taxa de criminalidade per capita por cidade.\n# \n# 2) zn - proporÃ§Ã£o de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n# 3) indus - proporÃ§Ã£o de negÃ³cios nÃ£o comerciais por acres e por cidade.\n# \n# 4) chas - variÃ¡vel dummy do Rio Charles (= 1 se prÃ³ximo do rio; 0 de outra forma).\n# \n# 5) nox - concentraÃ§Ã£o de Ã³xido de nitrogÃªnio (partes por 10 milhÃµes).\n# \n# 6) rm - nÃºmero mÃ©dio de cÃ´modos por habitaÃ§Ã£o\n# \n# 7) age - proporÃ§Ã£o da unidade ocupadas pelos proprietÃ¡rios construÃ­das antes 1940.\n# \n# 8) dis - mÃ©dia ponderada das distÃ¢ncias dos 5 pontos de emprego em Boston.\n# \n# 9) rad - indice de acessibilidade das avenidas radiais.\n# \n# 10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n# 11) ptratio - razÃ£o aluno-professor por cidade.\n# \n# 12) black - 1000(Bkâˆ’0.63)21000(Bkâˆ’0.63)2 proporÃ§Ã£o de negros por cidade.\n# \n# 13) lstat - percentual de baixo status da populaÃ§Ã£o.\n# \n# 14) medv - valor mediano das casas ocupadas pelos proprietÃ¡rio em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.3.html#conjunto-de-teste-e-treino",
    "href": "semanas/Aula07.3.html#conjunto-de-teste-e-treino",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Conjunto de teste e treino",
    "text": "Conjunto de teste e treino\n\nlibrary(caret)\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_teste <- Boston %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   403 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nstr(conj_teste)\n\n'data.frame':   103 obs. of  14 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ rad    : int  5 4 4 4 4 4 4 3 3 3 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ...\n\ngt::gt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      crim\n      zn\n      indus\n      chas\n      nox\n      rm\n      age\n      dis\n      rad\n      tax\n      ptratio\n      black\n      lstat\n      medv\n    \n  \n  \n    0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n    0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n    0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n    0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n    0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n    0.02985\n0.0\n2.18\n0\n0.458\n6.430\n58.7\n6.0622\n3\n222\n18.7\n394.12\n5.21\n28.7\n    0.08829\n12.5\n7.87\n0\n0.524\n6.012\n66.6\n5.5605\n5\n311\n15.2\n395.60\n12.43\n22.9\n    0.14455\n12.5\n7.87\n0\n0.524\n6.172\n96.1\n5.9505\n5\n311\n15.2\n396.90\n19.15\n27.1\n    0.17004\n12.5\n7.87\n0\n0.524\n6.004\n85.9\n6.5921\n5\n311\n15.2\n386.71\n17.10\n18.9\n    0.22489\n12.5\n7.87\n0\n0.524\n6.377\n94.3\n6.3467\n5\n311\n15.2\n392.52\n20.45\n15.0"
  },
  {
    "objectID": "semanas/Aula07.3.html#matriz-de-correlaÃ§Ã£o",
    "href": "semanas/Aula07.3.html#matriz-de-correlaÃ§Ã£o",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Matriz de correlaÃ§Ã£o",
    "text": "Matriz de correlaÃ§Ã£o\n\nlibrary(corrplot)\nmat_corr <- cor(conj_treino)\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula07.3.html#matriz-de-dispersÃ£o",
    "href": "semanas/Aula07.3.html#matriz-de-dispersÃ£o",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Matriz de dispersÃ£o",
    "text": "Matriz de dispersÃ£o\n\nlibrary(psych)\npairs.panels(conj_treino,\n             method = \"pearson\", # metodo de correlaÃ§Ã£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlaÃ§Ã£o\n             )"
  },
  {
    "objectID": "semanas/Aula07.3.html#mÃ©todos-de-seleÃ§Ã£o-de-modelo",
    "href": "semanas/Aula07.3.html#mÃ©todos-de-seleÃ§Ã£o-de-modelo",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "MÃ©todos de seleÃ§Ã£o de modelo",
    "text": "MÃ©todos de seleÃ§Ã£o de modelo\n\n## Best Subset sem definir o nÃºmero mÃ¡x de subsets a ser avaliado\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino)\nsummary(ajusreg.comp)\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 ) \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n\n## NÃ£o testou todas as combinaÃ§Ãµes possÃ­veis"
  },
  {
    "objectID": "semanas/Aula07.3.html#nvmax13",
    "href": "semanas/Aula07.3.html#nvmax13",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "nvmax=13",
    "text": "nvmax=13\n\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=13)\nsumario.reg <- summary(ajusreg.comp)\nsumario.reg\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: exhaustive\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nnames(sumario.reg)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\""
  },
  {
    "objectID": "semanas/Aula07.3.html#avaliando-os-modelos",
    "href": "semanas/Aula07.3.html#avaliando-os-modelos",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Avaliando os modelos",
    "text": "Avaliando os modelos\n\n## Os modelos vÃ£o ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 11\n\npoints(11,sumario.reg$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.comp,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#forward-stepwise-passo-a-passo-Ã -frente",
    "href": "semanas/Aula07.3.html#forward-stepwise-passo-a-passo-Ã -frente",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Forward Stepwise (passo a passo Ã  frente)",
    "text": "Forward Stepwise (passo a passo Ã  frente)\n\najusreg.fwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd <- summary(ajusreg.fwd)\nsumario.reg.fwd \n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"forward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: forward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nwhich.min(sumario.reg.fwd$cp)\n\n[1] 11\n\nplot(sumario.reg.fwd$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-1",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-1",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.fwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#backward-stepwise-passo-a-passo-atrÃ¡s",
    "href": "semanas/Aula07.3.html#backward-stepwise-passo-a-passo-atrÃ¡s",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Backward Stepwise (passo a passo atrÃ¡s)",
    "text": "Backward Stepwise (passo a passo atrÃ¡s)\n\najusreg.bwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"backward\")\nsumario.reg.bwd <- summary(ajusreg.bwd)\nsumario.reg.bwd\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"backward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: backward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nwhich.min(sumario.reg.bwd$cp)\n\n[1] 11\n\nplot(sumario.reg.bwd$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\npoints(11,sumario.reg.bwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-2",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-2",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.bwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#comportamento-dos-erros-de-treino-e-teste",
    "href": "semanas/Aula07.3.html#comportamento-dos-erros-de-treino-e-teste",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Comportamento dos erros de treino e teste",
    "text": "Comportamento dos erros de treino e teste\n\n## Codigo original de T. Hastie\nreg.fwd <- regsubsets(medv ~ . ,data=conj_treino,nvmax=13, method=\"forward\")\nval.erro <- rep(NA,13)\nx.teste <- model.matrix(medv~.,data=conj_teste)\nfor(i in 1:13){\n  coefi <- coef(reg.fwd,id=i)\n  pred <- x.teste[,names(coefi)]%*%coefi\n  val.erro[i] <- mean((conj_teste$medv - pred)^2)\n}\nplot(sqrt(val.erro),ylab=\"Raiz do EQM\",ylim=c(4,8),pch=19,type=\"b\")\npoints(sqrt(reg.fwd$rss[-1]/403),col=\"blue\",pch=19,type=\"b\")\nlegend(\"topright\",legend=c(\"Treino\",\"Teste\"),col=c(\"blue\",\"black\"),pch=19)"
  },
  {
    "objectID": "semanas/Aula07.3.html#testando-outra-estatÃ­stica-de-seleÃ§Ã£o-de-modelos---bic",
    "href": "semanas/Aula07.3.html#testando-outra-estatÃ­stica-de-seleÃ§Ã£o-de-modelos---bic",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Testando outra estatÃ­stica de seleÃ§Ã£o de modelos - BIC",
    "text": "Testando outra estatÃ­stica de seleÃ§Ã£o de modelos - BIC\n\najusreg.fwd1 <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd1 <- summary(ajusreg.fwd1)\nnames(sumario.reg.fwd1)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   \n\nwhich.min(sumario.reg.fwd1$bic)\n\n[1] 7\n\nplot(sumario.reg.fwd1$bic,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"BIC\")\npoints(7,sumario.reg.fwd1$bic[7],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.fwd1,7)  \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735"
  },
  {
    "objectID": "semanas/Aula07.3.html#usando-o-cp-novamente",
    "href": "semanas/Aula07.3.html#usando-o-cp-novamente",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Usando o Cp novamente",
    "text": "Usando o Cp novamente\n\nwhich.min(sumario.reg.fwd1$cp)\n\n[1] 11\n\nplot(sumario.reg.fwd1$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd1$cp[11],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.fwd1,11)\n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#comparando-os-dois-modelos-com-o-lm",
    "href": "semanas/Aula07.3.html#comparando-os-dois-modelos-com-o-lm",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Comparando os dois modelos com o lm()",
    "text": "Comparando os dois modelos com o lm()\n\n## Usando o lm para ajustar o modelo com as variÃ¡veis selecionadas pelo BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nmod_cp <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp)\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1857  -2.8830  -0.5641   1.8709  25.9074 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  24.119556   5.661887   4.260 2.56e-05 ***\ncrim         -0.059121   0.038751  -1.526 0.127902    \nzn            0.033951   0.015207   2.233 0.026139 *  \nchas          3.459703   0.995635   3.475 0.000568 ***\nnox         -17.228617   3.807289  -4.525 8.02e-06 ***\nrm            5.108916   0.466926  10.942  < 2e-16 ***\ndis          -1.272748   0.203301  -6.260 1.01e-09 ***\nrad           0.252036   0.067390   3.740 0.000212 ***\ntax          -0.010155   0.003556  -2.856 0.004525 ** \nptratio      -0.947329   0.141436  -6.698 7.38e-11 ***\nblack         0.012962   0.002822   4.593 5.90e-06 ***\nlstat        -0.396034   0.054069  -7.325 1.38e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.554 on 391 degrees of freedom\nMultiple R-squared:  0.7618,    Adjusted R-squared:  0.7551 \nF-statistic: 113.7 on 11 and 391 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3.html#eliminando-a-variÃ¡vel-nÃ£o-significativa",
    "href": "semanas/Aula07.3.html#eliminando-a-variÃ¡vel-nÃ£o-significativa",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Eliminando a variÃ¡vel nÃ£o significativa",
    "text": "Eliminando a variÃ¡vel nÃ£o significativa\n\nmod_cp2 <- lm(medv ~ zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp2)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + tax + \n    ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1471  -2.7317  -0.5389   1.9772  25.9698 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  22.884672   5.613214   4.077 5.53e-05 ***\nzn            0.031594   0.015154   2.085 0.037726 *  \nchas          3.524816   0.996402   3.538 0.000452 ***\nnox         -16.721605   3.799175  -4.401 1.39e-05 ***\nrm            5.183515   0.465145  11.144  < 2e-16 ***\ndis          -1.231499   0.201836  -6.101 2.52e-09 ***\nrad           0.218320   0.063772   3.423 0.000683 ***\ntax          -0.009827   0.003556  -2.764 0.005984 ** \nptratio      -0.938621   0.141560  -6.631 1.11e-10 ***\nblack         0.013799   0.002773   4.976 9.72e-07 ***\nlstat        -0.406190   0.053749  -7.557 2.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.562 on 392 degrees of freedom\nMultiple R-squared:  0.7604,    Adjusted R-squared:  0.7543 \nF-statistic: 124.4 on 10 and 392 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3.html#avaliando-colinearidade",
    "href": "semanas/Aula07.3.html#avaliando-colinearidade",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Avaliando Colinearidade",
    "text": "Avaliando Colinearidade\nUma investigaÃ§Ã£o minuciosa da multicollinearidade envolverÃ¡ a anÃ¡lise do valor do \\(R^2\\) que resulta da regressÃ£o de cada uma das variÃ¡veis explicativas contra todas as outras. A relaÃ§Ã£o entre as variÃ¡veis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacionÃ¡rio da variÃ¢ncia (FIV) ou Variance Inflation Factor (VIF). Seja \\(Rj~^{2}\\) o quadrado do coeficiente de correlaÃ§Ã£o mÃºltipla que resulta quando a variÃ¡vel explicativa \\(Xj~\\) Ã© ajustada contra todas as outras variÃ¡veis explicativas. EntÃ£o o vif para \\(Xj~\\) Ã© \\(VIFj = 1 / (1-Rj~^{2})\\)\nA regra geral Ã© que vifs superiores a 4 justificam novas investigaÃ§Ãµes, enquanto VIFs superiores a 10 sÃ£o sinais de multicollinearidade grave que requerem correÃ§Ã£o.\n\nlibrary(car)\nvif(mod_cp2)\n\n      zn     chas      nox       rm      dis      rad      tax  ptratio \n2.128862 1.076888 3.707463 2.032934 3.357506 6.005229 6.999822 1.796214 \n   black    lstat \n1.388299 3.010108 \n\n## Vamos eliminar tax e ver o que acontece\nmod_cp3 <- lm(medv ~ zn + chas + nox + rm + dis + rad + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp3)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.6480  -2.9158  -0.5013   1.9274  25.8537 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  21.606433   5.641174   3.830 0.000149 ***\nzn            0.021779   0.014856   1.466 0.143439    \nchas          3.623029   1.004143   3.608 0.000348 ***\nnox         -18.864099   3.750520  -5.030 7.48e-07 ***\nrm            5.337321   0.465687  11.461  < 2e-16 ***\ndis          -1.150869   0.201396  -5.714 2.18e-08 ***\nrad           0.079897   0.039806   2.007 0.045417 *  \nptratio      -1.016641   0.139883  -7.268 1.99e-12 ***\nblack         0.014071   0.002794   5.035 7.28e-07 ***\nlstat        -0.411503   0.054166  -7.597 2.24e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.6 on 393 degrees of freedom\nMultiple R-squared:  0.7557,    Adjusted R-squared:  0.7501 \nF-statistic: 135.1 on 9 and 393 DF,  p-value: < 2.2e-16\n\nvif(mod_cp3)\n\n      zn     chas      nox       rm      dis      rad  ptratio    black \n2.011936 1.075519 3.553096 2.003832 3.287355 2.300918 1.724780 1.386548 \n   lstat \n3.006257"
  },
  {
    "objectID": "semanas/Aula07.3.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "href": "semanas/Aula07.3.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Testando os dois modelos com o conjunto de teste",
    "text": "Testando os dois modelos com o conjunto de teste\n\n# Modelo com base no Cp\nsummary(mod_cp3)$sigma\n\n[1] 4.600016\n\nsummary(mod_cp3)$adj.r.squared\n\n[1] 0.7501409\n\nsqrt(mean((conj_teste$medv - predict(mod_cp3, conj_teste)) ^ 2))\n\n[1] 5.918251\n\n# Modelo com base no BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)$sigma\n\n[1] 4.630994\n\nsummary(mod_bic)$adj.r.squared\n\n[1] 0.7467643\n\nsqrt(mean((conj_teste$medv - predict(mod_bic, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula07.3A.html#carregando-bibliotecas",
    "href": "semanas/Aula07.3A.html#carregando-bibliotecas",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nCodelibrary(MASS)\nlibrary(tidyverse)\nlibrary(leaps)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#carregando-os-dados",
    "href": "semanas/Aula07.3A.html#carregando-os-dados",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\nCodedata(Boston)\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nCodesummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\nCodenrow(Boston)\n\n[1] 506"
  },
  {
    "objectID": "semanas/Aula07.3A.html#explicaÃ§Ã£o-das-variÃ¡veis",
    "href": "semanas/Aula07.3A.html#explicaÃ§Ã£o-das-variÃ¡veis",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "ExplicaÃ§Ã£o das variÃ¡veis",
    "text": "ExplicaÃ§Ã£o das variÃ¡veis\n\nCode# Boston Database\n# \n# 1) crim - taxa de criminalidade per capita por cidade.\n# \n# 2) zn - proporÃ§Ã£o de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n# 3) indus - proporÃ§Ã£o de negÃ³cios nÃ£o comerciais por acres e por cidade.\n# \n# 4) chas - variÃ¡vel dummy do Rio Charles (= 1 se prÃ³ximo do rio; 0 de outra forma).\n# \n# 5) nox - concentraÃ§Ã£o de Ã³xido de nitrogÃªnio (partes por 10 milhÃµes).\n# \n# 6) rm - nÃºmero mÃ©dio de cÃ´modos por habitaÃ§Ã£o\n# \n# 7) age - proporÃ§Ã£o da unidade ocupadas pelos proprietÃ¡rios construÃ­das antes 1940.\n# \n# 8) dis - mÃ©dia ponderada das distÃ¢ncias dos 5 pontos de emprego em Boston.\n# \n# 9) rad - indice de acessibilidade das avenidas radiais.\n# \n# 10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n# 11) ptratio - razÃ£o aluno-professor por cidade.\n# \n# 12) black - 1000(Bkâˆ’0.63)21000(Bkâˆ’0.63)2 proporÃ§Ã£o de negros por cidade.\n# \n# 13) lstat - percentual de baixo status da populaÃ§Ã£o.\n# \n# 14) medv - valor mediano das casas ocupadas pelos proprietÃ¡rio em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#conjunto-de-teste-e-treino",
    "href": "semanas/Aula07.3A.html#conjunto-de-teste-e-treino",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Conjunto de teste e treino",
    "text": "Conjunto de teste e treino\n\nCodelibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nCodeset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_teste <- Boston %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   403 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nCodestr(conj_teste)\n\n'data.frame':   103 obs. of  14 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ rad    : int  5 4 4 4 4 4 4 3 3 3 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ...\n\nCodegt::gt(head(conj_treino, 10))\n\n\n\n\n\n\ncrim\n      zn\n      indus\n      chas\n      nox\n      rm\n      age\n      dis\n      rad\n      tax\n      ptratio\n      black\n      lstat\n      medv\n    \n\n\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n0.02985\n0.0\n2.18\n0\n0.458\n6.430\n58.7\n6.0622\n3\n222\n18.7\n394.12\n5.21\n28.7\n\n\n0.08829\n12.5\n7.87\n0\n0.524\n6.012\n66.6\n5.5605\n5\n311\n15.2\n395.60\n12.43\n22.9\n\n\n0.14455\n12.5\n7.87\n0\n0.524\n6.172\n96.1\n5.9505\n5\n311\n15.2\n396.90\n19.15\n27.1\n\n\n0.17004\n12.5\n7.87\n0\n0.524\n6.004\n85.9\n6.5921\n5\n311\n15.2\n386.71\n17.10\n18.9\n\n\n0.22489\n12.5\n7.87\n0\n0.524\n6.377\n94.3\n6.3467\n5\n311\n15.2\n392.52\n20.45\n15.0"
  },
  {
    "objectID": "semanas/Aula07.3A.html#matriz-de-correlaÃ§Ã£o",
    "href": "semanas/Aula07.3A.html#matriz-de-correlaÃ§Ã£o",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Matriz de correlaÃ§Ã£o",
    "text": "Matriz de correlaÃ§Ã£o\n\nCodelibrary(corrplot)\nmat_corr <- cor(conj_treino)\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#matriz-de-dispersÃ£o",
    "href": "semanas/Aula07.3A.html#matriz-de-dispersÃ£o",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Matriz de dispersÃ£o",
    "text": "Matriz de dispersÃ£o\n\nCodelibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nCodepairs.panels(conj_treino,\n             method = \"pearson\", # metodo de correlaÃ§Ã£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlaÃ§Ã£o\n             )"
  },
  {
    "objectID": "semanas/Aula07.3A.html#mÃ©todos-de-seleÃ§Ã£o-de-modelo",
    "href": "semanas/Aula07.3A.html#mÃ©todos-de-seleÃ§Ã£o-de-modelo",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "MÃ©todos de seleÃ§Ã£o de modelo",
    "text": "MÃ©todos de seleÃ§Ã£o de modelo\n\nCode## Best Subset sem definir o nÃºmero mÃ¡x de subsets a ser avaliado\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino)\nsummary(ajusreg.comp)\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 ) \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n\nCode## NÃ£o testou todas as combinaÃ§Ãµes possÃ­veis"
  },
  {
    "objectID": "semanas/Aula07.3A.html#nvmax13",
    "href": "semanas/Aula07.3A.html#nvmax13",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "nvmax=13",
    "text": "nvmax=13\n\nCodeajusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=13)\nsumario.reg <- summary(ajusreg.comp)\nsumario.reg\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: exhaustive\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodenames(sumario.reg)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\""
  },
  {
    "objectID": "semanas/Aula07.3A.html#avaliando-os-modelos",
    "href": "semanas/Aula07.3A.html#avaliando-os-modelos",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Avaliando os modelos",
    "text": "Avaliando os modelos\n\nCode## Os modelos vÃ£o ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 11\n\nCodepoints(11,sumario.reg$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.comp,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#forward-stepwise-passo-a-passo-Ã -frente",
    "href": "semanas/Aula07.3A.html#forward-stepwise-passo-a-passo-Ã -frente",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Forward Stepwise (passo a passo Ã  frente)",
    "text": "Forward Stepwise (passo a passo Ã  frente)\n\nCodeajusreg.fwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd <- summary(ajusreg.fwd)\nsumario.reg.fwd \n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"forward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: forward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodewhich.min(sumario.reg.fwd$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.fwd$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-1",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-1",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.fwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#backward-stepwise-passo-a-passo-atrÃ¡s",
    "href": "semanas/Aula07.3A.html#backward-stepwise-passo-a-passo-atrÃ¡s",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Backward Stepwise (passo a passo atrÃ¡s)",
    "text": "Backward Stepwise (passo a passo atrÃ¡s)\n\nCodeajusreg.bwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"backward\")\nsumario.reg.bwd <- summary(ajusreg.bwd)\nsumario.reg.bwd\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"backward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: backward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodewhich.min(sumario.reg.bwd$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.bwd$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\npoints(11,sumario.reg.bwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-2",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-2",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.bwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#comportamento-dos-erros-de-treino-e-teste",
    "href": "semanas/Aula07.3A.html#comportamento-dos-erros-de-treino-e-teste",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Comportamento dos erros de treino e teste",
    "text": "Comportamento dos erros de treino e teste\n\nCode## Codigo original de T. Hastie\nreg.fwd <- regsubsets(medv ~ . ,data=conj_treino,nvmax=13, method=\"forward\")\nval.erro <- rep(NA,13)\nx.teste <- model.matrix(medv~.,data=conj_teste)\nfor(i in 1:13){\n  coefi <- coef(reg.fwd,id=i)\n  pred <- x.teste[,names(coefi)]%*%coefi\n  val.erro[i] <- mean((conj_teste$medv - pred)^2)\n}\nplot(sqrt(val.erro),ylab=\"Raiz do EQM\",ylim=c(4,8),pch=19,type=\"b\")\npoints(sqrt(reg.fwd$rss[-1]/403),col=\"blue\",pch=19,type=\"b\")\nlegend(\"topright\",legend=c(\"Treino\",\"Teste\"),col=c(\"blue\",\"black\"),pch=19)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#testando-outra-estatÃ­stica-de-seleÃ§Ã£o-de-modelos---bic",
    "href": "semanas/Aula07.3A.html#testando-outra-estatÃ­stica-de-seleÃ§Ã£o-de-modelos---bic",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Testando outra estatÃ­stica de seleÃ§Ã£o de modelos - BIC",
    "text": "Testando outra estatÃ­stica de seleÃ§Ã£o de modelos - BIC\n\nCodeajusreg.fwd1 <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd1 <- summary(ajusreg.fwd1)\nnames(sumario.reg.fwd1)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   \n\nCodewhich.min(sumario.reg.fwd1$bic)\n\n[1] 7\n\nCodeplot(sumario.reg.fwd1$bic,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"BIC\")\npoints(7,sumario.reg.fwd1$bic[7],pch=20,col=\"red\")\n\n\n\nCodecoef(ajusreg.fwd1,7)  \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735"
  },
  {
    "objectID": "semanas/Aula07.3A.html#usando-o-cp-novamente",
    "href": "semanas/Aula07.3A.html#usando-o-cp-novamente",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Usando o Cp novamente",
    "text": "Usando o Cp novamente\n\nCodewhich.min(sumario.reg.fwd1$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.fwd1$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd1$cp[11],pch=20,col=\"red\")\n\n\n\nCodecoef(ajusreg.fwd1,11)\n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#comparando-os-dois-modelos-com-o-lm",
    "href": "semanas/Aula07.3A.html#comparando-os-dois-modelos-com-o-lm",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Comparando os dois modelos com o lm()",
    "text": "Comparando os dois modelos com o lm()\n\nCode## Usando o lm para ajustar o modelo com as variÃ¡veis selecionadas pelo BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nCodemod_cp <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp)\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1857  -2.8830  -0.5641   1.8709  25.9074 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  24.119556   5.661887   4.260 2.56e-05 ***\ncrim         -0.059121   0.038751  -1.526 0.127902    \nzn            0.033951   0.015207   2.233 0.026139 *  \nchas          3.459703   0.995635   3.475 0.000568 ***\nnox         -17.228617   3.807289  -4.525 8.02e-06 ***\nrm            5.108916   0.466926  10.942  < 2e-16 ***\ndis          -1.272748   0.203301  -6.260 1.01e-09 ***\nrad           0.252036   0.067390   3.740 0.000212 ***\ntax          -0.010155   0.003556  -2.856 0.004525 ** \nptratio      -0.947329   0.141436  -6.698 7.38e-11 ***\nblack         0.012962   0.002822   4.593 5.90e-06 ***\nlstat        -0.396034   0.054069  -7.325 1.38e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.554 on 391 degrees of freedom\nMultiple R-squared:  0.7618,    Adjusted R-squared:  0.7551 \nF-statistic: 113.7 on 11 and 391 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3A.html#eliminando-a-variÃ¡vel-nÃ£o-significativa",
    "href": "semanas/Aula07.3A.html#eliminando-a-variÃ¡vel-nÃ£o-significativa",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Eliminando a variÃ¡vel nÃ£o significativa",
    "text": "Eliminando a variÃ¡vel nÃ£o significativa\n\nCodemod_cp2 <- lm(medv ~ zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp2)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + tax + \n    ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1471  -2.7317  -0.5389   1.9772  25.9698 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  22.884672   5.613214   4.077 5.53e-05 ***\nzn            0.031594   0.015154   2.085 0.037726 *  \nchas          3.524816   0.996402   3.538 0.000452 ***\nnox         -16.721605   3.799175  -4.401 1.39e-05 ***\nrm            5.183515   0.465145  11.144  < 2e-16 ***\ndis          -1.231499   0.201836  -6.101 2.52e-09 ***\nrad           0.218320   0.063772   3.423 0.000683 ***\ntax          -0.009827   0.003556  -2.764 0.005984 ** \nptratio      -0.938621   0.141560  -6.631 1.11e-10 ***\nblack         0.013799   0.002773   4.976 9.72e-07 ***\nlstat        -0.406190   0.053749  -7.557 2.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.562 on 392 degrees of freedom\nMultiple R-squared:  0.7604,    Adjusted R-squared:  0.7543 \nF-statistic: 124.4 on 10 and 392 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3A.html#avaliando-colinearidade",
    "href": "semanas/Aula07.3A.html#avaliando-colinearidade",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Avaliando Colinearidade",
    "text": "Avaliando Colinearidade\nUma investigaÃ§Ã£o minuciosa da multicollinearidade envolverÃ¡ a anÃ¡lise do valor do \\(R^2\\) que resulta da regressÃ£o de cada uma das variÃ¡veis explicativas contra todas as outras. A relaÃ§Ã£o entre as variÃ¡veis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacionÃ¡rio da variÃ¢ncia (FIV) ou Variance Inflation Factor (VIF). Seja \\(Rj~^{2}\\) o quadrado do coeficiente de correlaÃ§Ã£o mÃºltipla que resulta quando a variÃ¡vel explicativa \\(Xj~\\) Ã© ajustada contra todas as outras variÃ¡veis explicativas. EntÃ£o o vif para \\(Xj~\\) Ã© \\(VIFj = 1 / (1-Rj~^{2})\\)\nA regra geral Ã© que vifs superiores a 4 justificam novas investigaÃ§Ãµes, enquanto VIFs superiores a 10 sÃ£o sinais de multicollinearidade grave que requerem correÃ§Ã£o.\n\nCodelibrary(car)\nvif(mod_cp2)\n\n      zn     chas      nox       rm      dis      rad      tax  ptratio \n2.128862 1.076888 3.707463 2.032934 3.357506 6.005229 6.999822 1.796214 \n   black    lstat \n1.388299 3.010108 \n\nCode## Vamos eliminar tax e ver o que acontece\nmod_cp3 <- lm(medv ~ zn + chas + nox + rm + dis + rad + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp3)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.6480  -2.9158  -0.5013   1.9274  25.8537 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  21.606433   5.641174   3.830 0.000149 ***\nzn            0.021779   0.014856   1.466 0.143439    \nchas          3.623029   1.004143   3.608 0.000348 ***\nnox         -18.864099   3.750520  -5.030 7.48e-07 ***\nrm            5.337321   0.465687  11.461  < 2e-16 ***\ndis          -1.150869   0.201396  -5.714 2.18e-08 ***\nrad           0.079897   0.039806   2.007 0.045417 *  \nptratio      -1.016641   0.139883  -7.268 1.99e-12 ***\nblack         0.014071   0.002794   5.035 7.28e-07 ***\nlstat        -0.411503   0.054166  -7.597 2.24e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.6 on 393 degrees of freedom\nMultiple R-squared:  0.7557,    Adjusted R-squared:  0.7501 \nF-statistic: 135.1 on 9 and 393 DF,  p-value: < 2.2e-16\n\nCodevif(mod_cp3)\n\n      zn     chas      nox       rm      dis      rad  ptratio    black \n2.011936 1.075519 3.553096 2.003832 3.287355 2.300918 1.724780 1.386548 \n   lstat \n3.006257"
  },
  {
    "objectID": "semanas/Aula07.3A.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "href": "semanas/Aula07.3A.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "title": "SeleÃ§Ã£o de Modelos",
    "section": "Testando os dois modelos com o conjunto de teste",
    "text": "Testando os dois modelos com o conjunto de teste\n\nCode# Modelo com base no Cp\nsummary(mod_cp3)$sigma\n\n[1] 4.600016\n\nCodesummary(mod_cp3)$adj.r.squared\n\n[1] 0.7501409\n\nCodesqrt(mean((conj_teste$medv - predict(mod_cp3, conj_teste)) ^ 2))\n\n[1] 5.918251\n\nCode# Modelo com base no BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)$sigma\n\n[1] 4.630994\n\nCodesummary(mod_bic)$adj.r.squared\n\n[1] 0.7467643\n\nCodesqrt(mean((conj_teste$medv - predict(mod_bic, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula07.4.html#carregando-bibliotecas",
    "href": "semanas/Aula07.4.html#carregando-bibliotecas",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(glmnet)\ndata(Boston)"
  },
  {
    "objectID": "semanas/Aula07.4.html#carregando-os-dados",
    "href": "semanas/Aula07.4.html#carregando-os-dados",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nVamos utilizar neste exemplo os dados contidos na biblioteca MASS. A base de dados Boston tem 506 de valores preÃ§os medianos de casas na regiÃ£o de Boston com 13 outras variÃ¡veis explicativas (potencialmente). Vamos explorar os dados e ajustar modelos com penalizaÃ§Ã£o o Ridge e o LASSO e depois vamos comparar com os mÃ­nimos quadrados.\n\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nsummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\n\nObservamos acima que todas as variÃ¡veis sÃ£o quantitativas e que nÃ£o hÃ¡ necessidade de transformaÃ§Ãµes."
  },
  {
    "objectID": "semanas/Aula07.4.html#significado-das-variÃ¡veis",
    "href": "semanas/Aula07.4.html#significado-das-variÃ¡veis",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Significado das variÃ¡veis",
    "text": "Significado das variÃ¡veis\n\n# Boston Database\n# \n#1) crim - taxa de criminalidade per capita por cidade.\n# \n#2) zn - proporÃ§Ã£o de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n#3) indus - proporÃ§Ã£o de negÃ³cios nÃ£o comerciais por acres e por cidade.\n# \n#4) chas - variÃ¡vel dummy do Rio Charles(= 1 se prÃ³ximo do rio; 0 de outra forma).\n# \n#5) nox - concentraÃ§Ã£o de Ã³xido de nitrogÃªnio (partes por 10 milhÃµes).\n# \n#6) rm - nÃºmero mÃ©dio de quartos por habitaÃ§Ã£o\n# \n#7) age - proporÃ§Ã£o da unidade ocupadas pelos proprietÃ¡rios construÃ­das antes 1940.\n# \n#8) dis - mÃ©dia ponderada das distÃ¢ncias dos 5 pontos de emprego em Boston.\n# \n#9) rad - indice de acessibilidade das avenidas radiais.\n# \n#10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n#11) ptratio - razÃ£o aluno-professor por cidade.\n# \n#12) black - 1000(Bkâˆ’0.63)21000(Bkâˆ’0.63)2 proporÃ§Ã£o de negros por cidade.\n# \n#13) lstat - percentual de baixo status da populaÃ§Ã£o.\n# \n#14) medv - valor mediano das cas ocupadas pelos proprietÃ¡rio em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.4.html#conjunto-de-treino-e-de-teste",
    "href": "semanas/Aula07.4.html#conjunto-de-treino-e-de-teste",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Conjunto de treino e de teste",
    "text": "Conjunto de treino e de teste\n\nlibrary(caret)\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_treino <- conj_treino %>% select(-rad)\nconj_teste <- Boston %>% slice(indice_teste)\nconj_teste <- conj_teste %>% select(-rad)\nstr(conj_treino)\n\n'data.frame':   403 obs. of  13 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nstr(conj_teste)\n\n'data.frame':   103 obs. of  13 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ..."
  },
  {
    "objectID": "semanas/Aula07.4.html#mÃ©todos-de-regularizaÃ§Ã£o",
    "href": "semanas/Aula07.4.html#mÃ©todos-de-regularizaÃ§Ã£o",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "MÃ©todos de RegularizaÃ§Ã£o",
    "text": "MÃ©todos de RegularizaÃ§Ã£o\nO pacote glmnet nÃ£o usa a linguagem de formula, em particular nÃ³s devemos passar \\(x\\) como uma matriz e \\(y\\) como um vetor, pois nÃ£o se usa a sintaxe \\(y \\sim x\\). Com isso serÃ¡ necessÃ¡rio ajustar x e y. A funÃ§Ã£o model.matrix() Ã© particularmente Ãºtil para criar x; nÃ£o sÃ³ produz uma matriz correspondente as variÃ¡veis explicativas, mas tambÃ©m transforma automaticamente quaisquer variÃ¡veis qualitativas em variÃ¡veis dummy. Esta Ãºltima propriedade Ã© importante porque o glmnet() sÃ³ pode tomar insumos numÃ©ricos e quantitativos.\n\nx_treino <- model.matrix(medv ~ . , data = conj_treino)[, -1]\ny_treino <- conj_treino$medv\n\nx_teste <- model.matrix(medv ~ . , data = conj_teste)[, -1]\ny_teste = conj_teste$medv"
  },
  {
    "objectID": "semanas/Aula07.4.html#regressÃ£o-ridge",
    "href": "semanas/Aula07.4.html#regressÃ£o-ridge",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "RegressÃ£o Ridge",
    "text": "RegressÃ£o Ridge\nPrimeiro vamos ajustar um modelo de regressÃ£o Ridge. Isso Ã© conseguido chamando glmnet() com alpha=0, se alpha=1 entÃ£o glmnet() ajusta um lasso.(veja o arquivo de ajuda).\n\n## Estabelecendo um grid de valores para lambda\ngrid <- 10^seq(-2, 10, length = 100)\najusreg.ridge <- glmnet(x_treino, y_treino, alpha=0, lambda = grid)\n\nPor padrÃ£o, a funÃ§Ã£o glmnet() executa a regressÃ£o ridge automaticamente selecionando a faixa de valores de \\(\\lambda\\). No entanto, aqui nÃ³s escolhemos implementar usando uma grade de valores que variam de \\(\\lambda = 10^{-2}\\) a \\(\\lambda = 10^{10}\\), cobrindo toda a gama de cenÃ¡rios do modelo nulo contendo apenas o coeficiente linear atÃ© o ajuste dos mÃ­nimos quadrados.\nTambÃ©m podemos calcular o modelo para um valor particular de \\(\\lambda\\) que nÃ£o Ã© um dos valores de grade. Observe que, por padrÃ£o, a funÃ§Ã£o glmnet() padroniza as variÃ¡veis para que elas estejam na mesma escala. Esta padronizaÃ§Ã£o Ã© muito importante no caso da regressÃ£o Ridge, pois ela Ã© afetada pela mudanÃ§a de escala das variÃ¡veis explicativas.\nAssociado a cada valor de \\(\\lambda\\) existe um vetor de coeficientes de regressÃ£o de ridge, que Ã© armazenado em uma matriz que pode ser acessada por â€˜coef()â€™. Neste caso, Ã© uma matriz \\(14 \\times 100\\), com 14 linhas (uma para cada preditor, mais uma para o coeficiente linear) e 100 colunas (uma para cada valor de \\(\\lambda\\)).\n\ndim(coef(ajusreg.ridge))\n\n[1]  13 100\n\nplot(ajusreg.ridge, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n\n\n\n\nQuando \\(\\lambda\\) Ã© grande o esperado Ã© que os coeficentes sejam pequenos e quando \\(\\lambda\\) Ã© pequeno os coeficientes assumem valores maiores.\n\najusreg.ridge$lambda[1] # Mostra primeiro valor de lambda\n\n[1] 1e+10\n\ncoef(ajusreg.ridge)[,1] # Mostra os coeficientes associados com o primeiro valor\n\n  (Intercept)          crim            zn         indus          chas \n 2.247246e+01 -4.109894e-10  1.380771e-10 -6.245296e-10  6.798952e-09 \n          nox            rm           age           dis           tax \n-3.138930e-08  9.031398e-09 -1.154044e-10  1.094430e-09 -2.354379e-11 \n      ptratio         black         lstat \n-2.000167e-09  3.131126e-11 -8.446650e-10 \n\najusreg.ridge$lambda[100] # Mostra centÃ©simo valor de lambda\n\n[1] 0.01\n\ncoef(ajusreg.ridge)[,100] # Mostra os coeficientes associados com o centÃ©simo valor\n\n  (Intercept)          crim            zn         indus          chas \n 1.678767e+01 -1.657453e-02  2.307677e-02 -6.932521e-02  3.914065e+00 \n          nox            rm           age           dis           tax \n-1.315187e+01  5.586213e+00 -2.297883e-02 -1.312388e+00  6.917237e-04 \n      ptratio         black         lstat \n-8.347461e-01  1.262501e-02 -3.575121e-01 \n\n\n\nlibrary(plotmo)\nplot_glmnet(ajusreg.ridge)"
  },
  {
    "objectID": "semanas/Aula07.4.html#cross-validation-no-ridge",
    "href": "semanas/Aula07.4.html#cross-validation-no-ridge",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Cross-Validation no Ridge",
    "text": "Cross-Validation no Ridge\nNÃ³s podemos usar o k-fold cross validation para identificar o melhor valor de \\(\\lambda\\)\nA biblioteca glmnet jÃ¡ tem internamente uma funÃ§Ã£o para uso do crosss validation. O default sÃ£o 10 envelopes de dados nfold=10.\n\nset.seed(21)\nridge_cv <- cv.glmnet(x_treino,y_treino, alpha=0) ## por padrÃ£o k=10\nplot(ridge_cv)\n\n\n\nm_lamb <- ridge_cv$lambda.min  # Seleciona o lambda que minimiza o MSE (EQM) de treino\nm_lamb\n\n[1] 0.6844251\n\nlog(m_lamb)\n\n[1] -0.3791761\n\ncoef(ridge_cv, s=m_lamb)\n\n13 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept) 14.7144706557\ncrim        -0.0214927174\nzn           0.0200504882\nindus       -0.0735317662\nchas         3.8343862492\nnox         -9.4460044931\nrm           5.3120091904\nage         -0.0185326152\ndis         -1.0110801641\ntax         -0.0003434427\nptratio     -0.7785448609\nblack        0.0116393260\nlstat       -0.3465721929"
  },
  {
    "objectID": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste",
    "href": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Avaliando com conjunto de teste",
    "text": "Avaliando com conjunto de teste\nEm seguida avaliamos seu MSE no conjunto de teste, usando \\(\\lambda\\) = m_lamb. Observe o uso da funÃ§Ã£o â€˜predict()â€™: desta vez temos previsÃµes para um conjunto de teste, com o argumento newx.\n\najusreg.ridge2 <- glmnet(x_treino, y_treino, alpha=0, lambda = m_lamb)\ny_prev <- predict(ajusreg.ridge2, s = m_lamb, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n\n[1] 5.980257"
  },
  {
    "objectID": "semanas/Aula07.4.html#lasso",
    "href": "semanas/Aula07.4.html#lasso",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "LASSO",
    "text": "LASSO\nPrimeiro ajustamos com todos os dados como no caso do Ridge\n\najusreg.lasso <- glmnet(x_treino,y_treino, alpha = 1)\nplot(ajusreg.lasso, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n\n\n\nplot_glmnet(ajusreg.lasso)"
  },
  {
    "objectID": "semanas/Aula07.4.html#validaÃ§Ã£o-cruzada-no-lasso",
    "href": "semanas/Aula07.4.html#validaÃ§Ã£o-cruzada-no-lasso",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "ValidaÃ§Ã£o Cruzada no LASSO",
    "text": "ValidaÃ§Ã£o Cruzada no LASSO\n\nlasso_cv <- cv.glmnet(x_treino,y_treino, alpha = 1)\nplot(lasso_cv)\n\n\n\nm_lamb1 <- lasso_cv$lambda.min  # Seleciona o lambda que minimiza o MSE de treino\nm_lamb1\n\n[1] 0.0595278\n\nlog(m_lamb1)\n\n[1] -2.821312\n\ncoef(lasso_cv, s=m_lamb1)\n\n13 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  14.763435253\ncrim         -0.006217225\nzn            0.017479823\nindus        -0.050830256\nchas          3.644367387\nnox         -11.463040415\nrm            5.608066407\nage          -0.018352749\ndis          -1.107502465\ntax           .          \nptratio      -0.825247011\nblack         0.012263992\nlstat        -0.362939273"
  },
  {
    "objectID": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste-1",
    "href": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste-1",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Avaliando com conjunto de teste",
    "text": "Avaliando com conjunto de teste\n\najusreg.lasso2 <- glmnet(x_treino, y_treino, alpha=1, lambda = m_lamb1)\ny_prev <- predict(ajusreg.lasso2, s = m_lamb1, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n\n[1] 6.027343"
  },
  {
    "objectID": "semanas/Aula07.4.html#comparando-com-a-seleÃ§Ã£o-de-modelos-usando-o-cp",
    "href": "semanas/Aula07.4.html#comparando-com-a-seleÃ§Ã£o-de-modelos-usando-o-cp",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Comparando com a seleÃ§Ã£o de modelos usando o Cp",
    "text": "Comparando com a seleÃ§Ã£o de modelos usando o Cp\n\nlibrary(leaps)\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg <- summary(ajusreg.comp)\n## Os modelos vÃ£o ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 9\n\npoints(9,sumario.reg$cp[9],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.4.html#ajustando-no-lm-e-vendo-o-erro-no-conjunto-de-teste",
    "href": "semanas/Aula07.4.html#ajustando-no-lm-e-vendo-o-erro-no-conjunto-de-teste",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "Ajustando no lm() e vendo o erro no conjunto de teste",
    "text": "Ajustando no lm() e vendo o erro no conjunto de teste\nObservando so resultados de erro vemos que tanto a regressÃ£o Ridge como o LASSO apresentaram valores de erro maiores que o modelo definido atravÃ©s da melhor seleÃ§Ã£o de modelos (best subset regression). Aqui usamos o Cp de Mallows como critÃ©rio de deleÃ§Ã£o de variÃ¡veis.\n\ncoef(ajusreg.comp,9) \n\n (Intercept)           zn         chas          nox           rm          age \n 17.03537172   0.02326045   3.81378291 -14.60482205   5.66380782  -0.02328124 \n         dis      ptratio        black        lstat \n -1.26249225  -0.87101806   0.01301181  -0.36615078 \n\noutro_mod <- lm(medv ~ zn + chas + nox + rm + age + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + age + dis + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.9383  -2.6575  -0.5304   1.7899  27.0979 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.035372   5.393193   3.159 0.001707 ** \nzn            0.023260   0.014828   1.569 0.117534    \nchas          3.813783   1.008205   3.783 0.000179 ***\nnox         -14.604822   3.654556  -3.996 7.68e-05 ***\nrm            5.663808   0.473979  11.949  < 2e-16 ***\nage          -0.023281   0.014296  -1.629 0.104207    \ndis          -1.262492   0.209990  -6.012 4.19e-09 ***\nptratio      -0.871018   0.125529  -6.939 1.64e-11 ***\nblack         0.013012   0.002708   4.806 2.20e-06 ***\nlstat        -0.366151   0.057248  -6.396 4.54e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.608 on 393 degrees of freedom\nMultiple R-squared:  0.7549,    Adjusted R-squared:  0.7493 \nF-statistic: 134.5 on 9 and 393 DF,  p-value: < 2.2e-16\n\nsqrt(mean((conj_teste$medv - predict(outro_mod, conj_teste)) ^ 2)) \n\n[1] 6.032965"
  },
  {
    "objectID": "semanas/Aula07.4.html#e-o-bic",
    "href": "semanas/Aula07.4.html#e-o-bic",
    "title": "RegularizaÃ§Ã£o de Modelos",
    "section": "E o BIC?",
    "text": "E o BIC?\nE se escolhessemos o BIC como critÃ©rio de seleÃ§Ã£o de variÃ¡veis explicativas? Neste caso os resultados foram iguais ao Cp. Entretanto, dÃ¡ para perceber que o BIC apresentou uma certa estabilidade entre 7 e 9 variÃ¡veis. Se quisermos ter um modelo mais enxuto poderiamos optar por 7 variÃ¡veis.\n\najusreg.comp1 <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg1 <- summary(ajusreg.comp1)\n## Os modelos vÃ£o ser escolhidos com base no menor BIC\nplot(sumario.reg1$bic,xlab=\"NÃºmero de VariÃ¡veis\",ylab=\"BIC\")\nwhich.min(sumario.reg1$bic)\n\n[1] 7\n\npoints(7,sumario.reg1$bic[7],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.comp1,7) \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735 \n\noutro_mod1 <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod1)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nsqrt(mean((conj_teste$medv - predict(outro_mod1, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula08.html",
    "href": "semanas/Aula08.html",
    "title": "KNN",
    "section": "",
    "text": "O KNN Ã© um algoritmo muito simples no qual cada observaÃ§Ã£o Ã© prevista com base em sua â€œsemelhanÃ§aâ€ com outras observaÃ§Ãµes. Ao contrÃ¡rio da maioria dos mÃ©todos, KNN Ã© um algoritmo baseado na memÃ³ria e nÃ£o pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento sÃ£o necessÃ¡rias no tempo de execuÃ§Ã£o e as previsÃµes sÃ£o feitas diretamente das relaÃ§Ãµes amostrais. Consequentemente, os KNNs tambÃ©m sÃ£o conhecidos como aprendizes preguiÃ§osos"
  },
  {
    "objectID": "semanas/Aula08.html#carregando-bibliotecas",
    "href": "semanas/Aula08.html#carregando-bibliotecas",
    "title": "KNN",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula08.html#manipulando-os-dados",
    "href": "semanas/Aula08.html#manipulando-os-dados",
    "title": "KNN",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula08.html#normalizaÃ§Ã£o",
    "href": "semanas/Aula08.html#normalizaÃ§Ã£o",
    "title": "KNN",
    "section": "NormalizaÃ§Ã£o",
    "text": "NormalizaÃ§Ã£o\nAntes de iniciarmos Ã© fundamental fazermos a normalizaÃ§Ã£o (padronizaÃ§Ã£o) dos dados para que o KNN tenha um melhor desempenho.\n\ncredito_n <- credito\ncredito_n[,3:4] <- scale(credito_n[,3:4])"
  },
  {
    "objectID": "semanas/Aula08.html#treino-e-teste",
    "href": "semanas/Aula08.html#treino-e-teste",
    "title": "KNN",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nset.seed(21)\ny <- credito_n$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito_n %>% slice(-indice_teste)\nconj_teste <- credito_n %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco             receita         \n Nao:7733     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.455267  \n Sim: 266     1st Qu.:0.0000   1st Qu.:-0.732026   1st Qu.:-0.913102  \n              Median :0.0000   Median :-0.033621   Median : 0.076805  \n              Mean   :0.2953   Mean   :-0.005588   Mean   : 0.001763  \n              3rd Qu.:1.0000   3rd Qu.: 0.685798   3rd Qu.: 0.774041  \n              Max.   :1.0000   Max.   : 3.760371   Max.   : 3.002050  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco             receita         \n Nao:1934     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.156595  \n Sim:  67     1st Qu.:0.0000   1st Qu.:-0.727536   1st Qu.:-0.910738  \n              Median :0.0000   Median : 0.002479   Median : 0.080508  \n              Mean   :0.2909   Mean   : 0.022340   Mean   :-0.007049  \n              3rd Qu.:1.0000   3rd Qu.: 0.677484   3rd Qu.: 0.759484  \n              Max.   :1.0000   Max.   : 3.361757   Max.   : 2.828416"
  },
  {
    "objectID": "semanas/Aula08.html#matriz-de-dispersÃ£o",
    "href": "semanas/Aula08.html#matriz-de-dispersÃ£o",
    "title": "KNN",
    "section": "Matriz de dispersÃ£o",
    "text": "Matriz de dispersÃ£o\nVamos agora explorar os dados originais para termos algum visÃ£o do comportamento das variÃ¡veis explicativas e a variÃ¡vel dependente.\n\nlibrary(psych)\npairs.panels(credito, \n             method = \"pearson\", # metodo de correlaÃ§Ã£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlaÃ§Ã£o\n             )"
  },
  {
    "objectID": "semanas/Aula08.html#avaliando-o-comportamento-das-variÃ¡veis-em-funÃ§Ã£o-do-status-inadimplente-estudante",
    "href": "semanas/Aula08.html#avaliando-o-comportamento-das-variÃ¡veis-em-funÃ§Ã£o-do-status-inadimplente-estudante",
    "title": "KNN",
    "section": "Avaliando o comportamento das variÃ¡veis em funÃ§Ã£o do status (inadimplente / estudante)",
    "text": "Avaliando o comportamento das variÃ¡veis em funÃ§Ã£o do status (inadimplente / estudante)\n\nggplot(credito, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula08.html#explorando-um-pouco-mais-balanÃ§o-e-receita",
    "href": "semanas/Aula08.html#explorando-um-pouco-mais-balanÃ§o-e-receita",
    "title": "KNN",
    "section": "Explorando um pouco mais BalanÃ§o e Receita",
    "text": "Explorando um pouco mais BalanÃ§o e Receita\n\nggplot(credito, aes(x=balanco)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))\n\n\n\nggplot(credito, aes(x=receita)) +\n    geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))"
  },
  {
    "objectID": "semanas/Aula08.html#balanÃ§o-vs-receita",
    "href": "semanas/Aula08.html#balanÃ§o-vs-receita",
    "title": "KNN",
    "section": "BalanÃ§o vs Receita",
    "text": "BalanÃ§o vs Receita\n\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula08.html#knn-1",
    "href": "semanas/Aula08.html#knn-1",
    "title": "KNN",
    "section": "KNN",
    "text": "KNN\nVamos usar a funÃ§Ã£o knn da biblioteca caret que tem Ã³timas funcionalidades. Observem que a saÃ­da pode ser as classes ou as probabilidades de pertencer a uma classe\nComo o KNN usa as distancias entre os pontos ele Ã© afetado pela escala dos dados, portanto, Ã© necessÃ¡rio que os dados sejam normalizados (padronizados) para eliminar este efeito.\nQuando temos diversas variÃ¡veis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrÃ£o 1"
  },
  {
    "objectID": "semanas/Aula08.html#a-modelo",
    "href": "semanas/Aula08.html#a-modelo",
    "title": "KNN",
    "section": "1a Modelo",
    "text": "1a Modelo\n\n# Vamos usar a regra da raiz quadrada do tamnho da amostra\nsqrt(nrow(conj_treino)) ## ~90\n\n[1] 89.43713\n\nset.seed(21)\nt_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)\nt_knn1\n\n90-nearest neighbor model\nTraining set outcome distribution:\n\n Nao  Sim \n7733  266"
  },
  {
    "objectID": "semanas/Aula08.html#avaliando-o-modelo",
    "href": "semanas/Aula08.html#avaliando-o-modelo",
    "title": "KNN",
    "section": "Avaliando o modelo",
    "text": "Avaliando o modelo\nA acurÃ¡cia deu um valor alto, mas isto nÃ£o Ã© suficiente para considerarmo que temos um bom modelo. Veja que a sensibilidade estÃ¡ muito baixa e que o ideal Ã© que tenhamos valores altos de sensibilidade e especificidade.\nObservar que a prevalÃªncia Ã© muito baixa o que estÃ¡ afetando os resultados do modelo\n\n## \ny_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"class\")\n\n# Matriz de confusÃ£o para valiar os resultados\nconfusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1930   51\n       Sim    4   16\n                                          \n               Accuracy : 0.9725          \n                 95% CI : (0.9644, 0.9792)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.07329         \n                                          \n                  Kappa : 0.3579          \n                                          \n Mcnemar's Test P-Value : 5.552e-10       \n                                          \n            Sensitivity : 0.238806        \n            Specificity : 0.997932        \n         Pos Pred Value : 0.800000        \n         Neg Pred Value : 0.974255        \n             Prevalence : 0.033483        \n         Detection Rate : 0.007996        \n   Detection Prevalence : 0.009995        \n      Balanced Accuracy : 0.618369        \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula08.html#curva-roc",
    "href": "semanas/Aula08.html#curva-roc",
    "title": "KNN",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\n# Para a curva ROC preciso das probabilidades e nÃ£o das classes\np_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nhead(p_chapeu_knn1)\n\n           Nao        Sim\n[1,] 0.9777778 0.02222222\n[2,] 1.0000000 0.00000000\n[3,] 1.0000000 0.00000000\n[4,] 0.9888889 0.01111111\n[5,] 1.0000000 0.00000000\n[6,] 1.0000000 0.00000000\n\n# Aqui gera o curva e salvo numa variÃ¡vel\nroc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nlegend(\"bottomright\",legend=c(\"KNN1\"), \n       col=c(\"black\"),lwd=4)\n\n\n\n# Area abaixo da Curva (AUC)\nas.numeric(roc_knn1$auc)\n\n[1] 0.9276227"
  },
  {
    "objectID": "semanas/Aula08.html#variando-k",
    "href": "semanas/Aula08.html#variando-k",
    "title": "KNN",
    "section": "Variando K",
    "text": "Variando K\nAnteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a funÃ§Ã£o train da biblioteca caret \nObserve que a otimizaÃ§Ã£o de k Ã© feita atravÃ©s de acurÃ¡cia\n\nset.seed(21)\n\n# Usando validaÃ§Ã£o cruzada para obter o valor de k atravÃ©s da funÃ§Ã£o train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.\nctrl <- trainControl(method = \"cv\")\nt_knn2 <- train(inadimplente ~ balanco + receita + estudante,\n                method = \"knn\", trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                data = conj_treino)\n## Resultados do treino\nt_knn2\n\nk-Nearest Neighbors \n\n7999 samples\n   3 predictor\n   2 classes: 'Nao', 'Sim' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \nResampling results across tuning parameters:\n\n  k    Accuracy   Kappa     \n   10  0.9699953  0.37022050\n   20  0.9717451  0.37122371\n   30  0.9714948  0.34761685\n   40  0.9713698  0.32858918\n   50  0.9712448  0.30506559\n   60  0.9711200  0.29038841\n   70  0.9711204  0.28281374\n   80  0.9698700  0.22792293\n   90  0.9696197  0.20538564\n  100  0.9689948  0.15840977\n  110  0.9677454  0.09462220\n  120  0.9669959  0.03351642\n  130  0.9669961  0.01339042\n  140  0.9669961  0.01339042\n  150  0.9667464  0.00000000\n  160  0.9667464  0.00000000\n  170  0.9667464  0.00000000\n  180  0.9667464  0.00000000\n  190  0.9667464  0.00000000\n  200  0.9667464  0.00000000\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 20.\n\nplot(t_knn2)\n\n\n\n## PrevisÃµes com o resultaddos do treino\nprev_knn2 <- predict(t_knn2, conj_teste)\nconfusionMatrix(prev_knn2, conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1926   40\n       Sim    8   27\n                                          \n               Accuracy : 0.976           \n                 95% CI : (0.9683, 0.9823)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.008318        \n                                          \n                  Kappa : 0.5183          \n                                          \n Mcnemar's Test P-Value : 7.66e-06        \n                                          \n            Sensitivity : 0.40299         \n            Specificity : 0.99586         \n         Pos Pred Value : 0.77143         \n         Neg Pred Value : 0.97965         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01349         \n   Detection Prevalence : 0.01749         \n      Balanced Accuracy : 0.69942         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula08.html#variando-k-de-outra-forma",
    "href": "semanas/Aula08.html#variando-k-de-outra-forma",
    "title": "KNN",
    "section": "Variando K de outra forma",
    "text": "Variando K de outra forma\nVamos adicionar mais opÃ§Ãµes no trainControl\nAo colocar classProb = TRUE e summaryFunction ao invÃ©s da acurÃ¡cia a otimizaÃ§Ã£o passa a ser atravÃ©s o ROC\n\nset.seed(21)\n# ctrl <- trainControl(method = \"cv\", classProbs=TRUE, summaryFunction = twoClassSummary)\nctrl <- trainControl(method = \"repeatedcv\", \n                     number = 10,\n                     repeats = 5, \n                     classProbs = TRUE,\n                     summaryFunction = twoClassSummary)\n\nt_knn3 <- train(inadimplente ~ balanco + receita + estudante, \n                method = \"knn\", \n                trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                metric = \"ROC\",\n                data = conj_treino)\nt_knn3\n\nk-Nearest Neighbors \n\n7999 samples\n   3 predictor\n   2 classes: 'Nao', 'Sim' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 5 times) \nSummary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \nResampling results across tuning parameters:\n\n  k    ROC        Sens       Spec       \n   10  0.8532549  0.9936118  0.299230769\n   20  0.8962842  0.9957323  0.275897436\n   30  0.9129487  0.9965599  0.252507123\n   40  0.9223242  0.9972324  0.229401709\n   50  0.9260029  0.9976204  0.204558405\n   60  0.9275003  0.9978014  0.196239316\n   70  0.9283630  0.9979566  0.185014245\n   80  0.9324715  0.9981118  0.150284900\n   90  0.9335728  0.9986809  0.124643875\n  100  0.9390171  0.9991464  0.091566952\n  110  0.9401918  0.9994827  0.048062678\n  120  0.9405837  0.9998707  0.019515670\n  130  0.9416564  1.0000000  0.007492877\n  140  0.9429103  1.0000000  0.003703704\n  150  0.9434492  1.0000000  0.000000000\n  160  0.9432553  1.0000000  0.000000000\n  170  0.9444527  1.0000000  0.000000000\n  180  0.9452018  1.0000000  0.000000000\n  190  0.9450158  1.0000000  0.000000000\n  200  0.9447751  1.0000000  0.000000000\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was k = 180.\n\nplot(t_knn3)\n\n\n\nprev_knn3 <- predict(t_knn3, conj_teste)\nconfusionMatrix(prev_knn3, conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1934   66\n       Sim    0    1\n                                          \n               Accuracy : 0.967           \n                 95% CI : (0.9582, 0.9744)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.4829          \n                                          \n                  Kappa : 0.0285          \n                                          \n Mcnemar's Test P-Value : 1.235e-15       \n                                          \n            Sensitivity : 0.0149254       \n            Specificity : 1.0000000       \n         Pos Pred Value : 1.0000000       \n         Neg Pred Value : 0.9670000       \n             Prevalence : 0.0334833       \n         Detection Rate : 0.0004998       \n   Detection Prevalence : 0.0004998       \n      Balanced Accuracy : 0.5074627       \n                                          \n       'Positive' Class : Sim             \n                                          \n\n\nVeja que ao otimizar pela ROC o modelo escolhido tem sensibilidade zero! Isto obviamente nÃ£o Ã© um bom modelo! Neste caso a opÃ§Ã£o de otimizaÃ§Ã£o do parametro pela acurÃ¡cia dÃ¡ melhores resultados."
  },
  {
    "objectID": "semanas/Aula08.html#curva-roc-dos-2-melhores-modelos-k90-e-k20",
    "href": "semanas/Aula08.html#curva-roc-dos-2-melhores-modelos-k90-e-k20",
    "title": "KNN",
    "section": "Curva ROC dos 2 melhores modelos k=90 e k=20",
    "text": "Curva ROC dos 2 melhores modelos k=90 e k=20\n\nprev_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nprev_knn2 <- predict(t_knn2, conj_teste, type = \"prob\")\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\nroc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\nlegend(\"bottomright\",legend=c(\"KNN1\", \"KNN2\"), \n       col=c(\"black\",\"green\"),lwd=4)\n\n\n\n## Area embaixo das curvas\nas.numeric(roc_knn1$auc)\n\n[1] 0.9276227\n\nas.numeric(roc_knn2$auc)\n\n[1] 0.9032436\n\n\nObserve que os resultados de Ã¡rea abaixo da ROC nÃ£o sÃ£o suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!\nOs resultados encontrados apontam k=20 como a melhor opÃ§Ã£o"
  },
  {
    "objectID": "semanas/Aula09.html",
    "href": "semanas/Aula09.html",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula09.html#manipulando-os-dados",
    "href": "semanas/Aula09.html#manipulando-os-dados",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09.html#treino-e-teste",
    "href": "semanas/Aula09.html#treino-e-teste",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula09.html#matriz-de-dispersÃ£o",
    "href": "semanas/Aula09.html#matriz-de-dispersÃ£o",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Matriz de dispersÃ£o",
    "text": "Matriz de dispersÃ£o\n\nlibrary(psych)\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correlaÃ§Ã£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlaÃ§Ã£o\n             )"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-comportamento-das-variÃ¡veis-em-funÃ§Ã£o-do-status-inadimplente-estudante",
    "href": "semanas/Aula09.html#avaliando-o-comportamento-das-variÃ¡veis-em-funÃ§Ã£o-do-status-inadimplente-estudante",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Avaliando o comportamento das variÃ¡veis em funÃ§Ã£o do status (inadimplente / estudante)",
    "text": "Avaliando o comportamento das variÃ¡veis em funÃ§Ã£o do status (inadimplente / estudante)\n\nggplot(conj_treino, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula09.html#balanÃ§o-vs-receita",
    "href": "semanas/Aula09.html#balanÃ§o-vs-receita",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "BalanÃ§o vs Receita",
    "text": "BalanÃ§o vs Receita\n\nggplot(data = conj_treino, aes(x=balanco,  y = receita, col = inadimplente)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula09.html#regressÃ£o-linear",
    "href": "semanas/Aula09.html#regressÃ£o-linear",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "RegressÃ£o Linear?",
    "text": "RegressÃ£o Linear?\n\n## Primeiro precisa transformar qualitativa em numÃ©rica\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nmodelo_linear <- lm(inadimpl ~ balanco, data = conj_treino)\nplot(inadimpl ~ balanco, data = conj_treino, \n     col = \"darkorange\", pch = \"|\", ylim = c(-0.2, 1),\n     main = \"RegressÃ£o Linear - ClassificaÃ§Ã£o\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\nabline(modelo_linear, lwd = 3, col = \"dodgerblue\")"
  },
  {
    "objectID": "semanas/Aula09.html#outras-avaliaÃ§Ãµes",
    "href": "semanas/Aula09.html#outras-avaliaÃ§Ãµes",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Outras avaliaÃ§Ãµes",
    "text": "Outras avaliaÃ§Ãµes\n\n# proporÃ§Ã£o de inadimplentes\nconj_treino %>% select(inadimplente, balanco) %>% summarize(prop = mean(inadimplente == \"Sim\")) \n\n# A tibble: 1 Ã— 1\n    prop\n   <dbl>\n1 0.0333\n\n# media do balanÃ§o dos inadimplentes \nconj_treino %>% filter(inadimplente == \"Sim\") %>% summarize(valor= mean(balanco))   \n\n# A tibble: 1 Ã— 1\n  valor\n  <dbl>\n1 1745.\n\nquantis <- quantile(conj_treino$balanco, probs = c(.1,.25, .50, .75, .9, .95, 0.97, 0.99))\nquantis\n\n      10%       25%       50%       75%       90%       95%       97%       99% \n 176.9895  481.2830  819.1118 1167.1059 1468.8300 1660.1834 1786.5132 1991.6971 \n\nconj_treino %>% \n            mutate(grupo_balanco = case_when(\n               balanco<=quantis[1] ~ quantis[1],\n               balanco>quantis[1] & balanco<=quantis[2] ~ quantis[2],\n               balanco>quantis[2] & balanco<=quantis[3]  ~ quantis[3],\n               balanco>quantis[3] & balanco<=quantis[4]  ~ quantis[4],\n               balanco>quantis[4] & balanco<=quantis[5]  ~ quantis[5],\n               balanco>quantis[5] & balanco<=quantis[6]  ~ quantis[6],\n               balanco>quantis[6] & balanco<=quantis[7]  ~ quantis[7],\n               balanco>quantis[7] ~ quantis[8])) %>%\n           group_by(grupo_balanco) %>%\n           summarize(prop = mean(inadimplente == \"Sim\")) %>%\n           ggplot(aes(grupo_balanco, prop)) +\n           geom_point() +\n           geom_line()"
  },
  {
    "objectID": "semanas/Aula09.html#a-regressÃ£o-logÃ­stica-sÃ³-balanÃ§o",
    "href": "semanas/Aula09.html#a-regressÃ£o-logÃ­stica-sÃ³-balanÃ§o",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "1a RegressÃ£o logÃ­stica: sÃ³ balanÃ§o",
    "text": "1a RegressÃ£o logÃ­stica: sÃ³ balanÃ§o\n\nmod1 <- glm(inadimplente ~ balanco,data=conj_treino,family=binomial)\nsummary(mod1)\n\n\nCall:\nglm(formula = inadimplente ~ balanco, family = binomial, data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3119  -0.1453  -0.0568  -0.0211   3.7748  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.077e+01  4.119e-01  -26.16   <2e-16 ***\nbalanco      5.593e-03  2.521e-04   22.18   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1268.0  on 7997  degrees of freedom\nAIC: 1272\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod1)\n\n  (Intercept)       balanco \n-10.772870680   0.005593346 \n\nsummary(mod1)$coef\n\n                 Estimate   Std. Error   z value      Pr(>|z|)\n(Intercept) -10.772870680 0.4118820840 -26.15523 8.593630e-151\nbalanco       0.005593346 0.0002521341  22.18401 4.901112e-109"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-modelo",
    "href": "semanas/Aula09.html#avaliando-o-modelo",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Avaliando o modelo",
    "text": "Avaliando o modelo\n\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1922   41\n       Sim   12   26\n                                          \n               Accuracy : 0.9735          \n                 95% CI : (0.9655, 0.9801)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.04298         \n                                          \n                  Kappa : 0.4827          \n                                          \n Mcnemar's Test P-Value : 0.00012         \n                                          \n            Sensitivity : 0.38806         \n            Specificity : 0.99380         \n         Pos Pred Value : 0.68421         \n         Neg Pred Value : 0.97911         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01299         \n   Detection Prevalence : 0.01899         \n      Balanced Accuracy : 0.69093         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#veja-as-probabilidade-de-inadimplencia-para-balanÃ§os-de-1000-2000-e-3000",
    "href": "semanas/Aula09.html#veja-as-probabilidade-de-inadimplencia-para-balanÃ§os-de-1000-2000-e-3000",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Veja as probabilidade de inadimplencia para balanÃ§os de 1000, 2000 e 3000",
    "text": "Veja as probabilidade de inadimplencia para balanÃ§os de 1000, 2000 e 3000\n\npredict(mod1, newdata = data.frame(balanco = c(1000,2000,3000)), type=\"response\")\n\n          1           2           3 \n0.005599153 0.602003608 0.997544989"
  },
  {
    "objectID": "semanas/Aula09.html#curva-s",
    "href": "semanas/Aula09.html#curva-s",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Curva S",
    "text": "Curva S\n\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nplot(inadimpl ~ balanco, data = conj_treino, \n     col = \"darkorange\", pch = \"|\", ylim = c(0, 1),\n     main = \"RegressÃ£o Logistica - ClassificacÃ£o\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\ncurve(predict(mod1, data.frame(balanco = x),\n        type = \"response\"), add = TRUE, lwd = 3, col = \"dodgerblue\")\nabline(v = -coef(mod1)[1] / coef(mod1)[2], lwd = 2)"
  },
  {
    "objectID": "semanas/Aula09.html#valor-de-balanÃ§o-com-probabilidade-de-50",
    "href": "semanas/Aula09.html#valor-de-balanÃ§o-com-probabilidade-de-50",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Valor de balanÃ§o com probabilidade de 50%",
    "text": "Valor de balanÃ§o com probabilidade de 50%\n-\\(\\beta_0\\)/\\(\\beta_1\\)\n\n-coef(mod1)[1] / coef(mod1)[2]\n\n(Intercept) \n   1926.016"
  },
  {
    "objectID": "semanas/Aula09.html#a-regressÃ£o-logÃ­stica-todas-as-variÃ¡veis",
    "href": "semanas/Aula09.html#a-regressÃ£o-logÃ­stica-todas-as-variÃ¡veis",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "2a RegressÃ£o logÃ­stica: todas as variÃ¡veis",
    "text": "2a RegressÃ£o logÃ­stica: todas as variÃ¡veis\n\nmod2 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treino,family=binomial)\nsummary(mod2)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n    data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.5314  -0.1409  -0.0535  -0.0192   3.7500  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.123e+01  5.684e-01 -19.763   <2e-16 ***\nbalanco      5.842e-03  2.661e-04  21.955   <2e-16 ***\nreceita      8.476e-06  9.253e-06   0.916   0.3597    \nestudante   -5.106e-01  2.671e-01  -1.912   0.0559 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1248.2  on 7995  degrees of freedom\nAIC: 1256.2\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod2)\n\n  (Intercept)       balanco       receita     estudante \n-1.123321e+01  5.842417e-03  8.475971e-06 -5.106360e-01 \n\nsummary(mod2)$coef\n\n                 Estimate   Std. Error     z value      Pr(>|z|)\n(Intercept) -1.123321e+01 5.683883e-01 -19.7632675  6.167980e-87\nbalanco      5.842417e-03 2.661065e-04  21.9551820 7.727138e-107\nreceita      8.475971e-06 9.253027e-06   0.9160214  3.596557e-01\nestudante   -5.106360e-01 2.671246e-01  -1.9116025  5.592720e-02"
  },
  {
    "objectID": "semanas/Aula09.html#Ã©-possÃ­vel-se-ver-que-receita-nÃ£o-Ã©-significativa",
    "href": "semanas/Aula09.html#Ã©-possÃ­vel-se-ver-que-receita-nÃ£o-Ã©-significativa",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Ã‰ possÃ­vel se ver que receita nÃ£o Ã© significativa",
    "text": "Ã‰ possÃ­vel se ver que receita nÃ£o Ã© significativa"
  },
  {
    "objectID": "semanas/Aula09.html#a-regressÃ£o-logÃ­stica-sem-receita",
    "href": "semanas/Aula09.html#a-regressÃ£o-logÃ­stica-sem-receita",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "3a RegressÃ£o LogÃ­stica (sem receita)",
    "text": "3a RegressÃ£o LogÃ­stica (sem receita)\n\nmod3 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\nsummary(mod3)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + estudante, family = binomial, \n    data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4991  -0.1410  -0.0535  -0.0192   3.7631  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.089e+01  4.220e-01  -25.81  < 2e-16 ***\nbalanco      5.842e-03  2.658e-04   21.98  < 2e-16 ***\nestudante   -7.016e-01  1.655e-01   -4.24 2.23e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1249.1  on 7996  degrees of freedom\nAIC: 1255.1\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod3)\n\n  (Intercept)       balanco     estudante \n-10.891361318   0.005842385  -0.701581567 \n\nsummary(mod3)$coef\n\n                 Estimate   Std. Error    z value      Pr(>|z|)\n(Intercept) -10.891361318 0.4220005414 -25.808880 7.048822e-147\nbalanco       0.005842385 0.0002658371  21.977315 4.747239e-107\nestudante    -0.701581567 0.1654530947  -4.240365  2.231563e-05"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-modelo-novamente",
    "href": "semanas/Aula09.html#avaliando-o-modelo-novamente",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Avaliando o modelo novamente",
    "text": "Avaliando o modelo novamente\n\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1924   37\n       Sim   10   30\n                                          \n               Accuracy : 0.9765          \n                 95% CI : (0.9689, 0.9827)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.0056579       \n                                          \n                  Kappa : 0.5495          \n                                          \n Mcnemar's Test P-Value : 0.0001491       \n                                          \n            Sensitivity : 0.44776         \n            Specificity : 0.99483         \n         Pos Pred Value : 0.75000         \n         Neg Pred Value : 0.98113         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01499         \n   Detection Prevalence : 0.01999         \n      Balanced Accuracy : 0.72130         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#mudando-a-probabilidade-limite-para-aumentar-a-sensibilidade",
    "href": "semanas/Aula09.html#mudando-a-probabilidade-limite-para-aumentar-a-sensibilidade",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Mudando a probabilidade (limite) para aumentar a sensibilidade",
    "text": "Mudando a probabilidade (limite) para aumentar a sensibilidade\n\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.1, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1809   18\n       Sim  125   49\n                                          \n               Accuracy : 0.9285          \n                 95% CI : (0.9164, 0.9394)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3765          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.73134         \n            Specificity : 0.93537         \n         Pos Pred Value : 0.28161         \n         Neg Pred Value : 0.99015         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02449         \n   Detection Prevalence : 0.08696         \n      Balanced Accuracy : 0.83336         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-modelo-sÃ³-com-balanÃ§o",
    "href": "semanas/Aula09.html#curva-roc-modelo-sÃ³-com-balanÃ§o",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Curva ROC modelo sÃ³ com balanÃ§o",
    "text": "Curva ROC modelo sÃ³ com balanÃ§o\n\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.897038e-02 7.892012e-05 2.096006e-05 1.087093e-02 3.336139e-04 2.580431e-04 \n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n\n\n\n# Area debaixo da curva\nas.numeric(roc_log$auc)\n\n[1] 0.9389557"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-2-modelo-com-balanÃ§o-estudante",
    "href": "semanas/Aula09.html#curva-roc-2-modelo-com-balanÃ§o-estudante",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Curva ROC 2: Modelo com balanÃ§o + estudante",
    "text": "Curva ROC 2: Modelo com balanÃ§o + estudante\n\np_chapeu_log <- predict(mod3, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.140962e-02 7.436487e-05 1.861803e-05 6.355948e-03 3.351978e-04 1.271000e-04 \n\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n\n\n\n# Area debaixo da curva\nas.numeric(roc_log2$auc)\n\n[1] 0.9415487"
  },
  {
    "objectID": "semanas/Aula09.html#duas-rocs-juntas",
    "href": "semanas/Aula09.html#duas-rocs-juntas",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Duas ROCs juntas",
    "text": "Duas ROCs juntas\n\nplot(roc_log)\nplot(roc_log2, add=TRUE, col=\"blue\")\nlegend(\"bottomright\", legend=c(\"Mod 1\", \"Mod2\"),\n       col=c(par(\"fg\"), \"blue\"), lwd=2)"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-3-com-o-knn",
    "href": "semanas/Aula09.html#curva-roc-3-com-o-knn",
    "title": "RegressÃ£o LogÃ­stica",
    "section": "Curva ROC 3 com o KNN",
    "text": "Curva ROC 3 com o KNN\n\n# Ajustando KNN \nset.seed(21)\nctrl <- trainControl(method = \"cv\")\ntreina_knn <- train(inadimplente ~ scale(balanco) + scale(estudante), method = \"knn\", trControl= ctrl, tuneGrid = data.frame(k = seq(5,140, by=4)), data = conj_treino)\n# treina_knn\nplot(treina_knn)\n\n\n\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n## ROC\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, col= \"black\", legacy.axes=TRUE) \nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg. Log\", \"KNN\"), \n       col=c(\"black\",\"green\"),lwd=4)\n\n\n\n# Area abaixo da curva\n# RegressÃ£o LogÃ­stica\nas.numeric(roc_log2$auc)\n\n[1] 0.9415487\n\n## KNN\nas.numeric(roc_knn1$auc)\n\n[1] 0.9388361"
  },
  {
    "objectID": "semanas/Aula09A.html",
    "href": "semanas/Aula09A.html",
    "title": "RegressÃ£o LogÃ­stica - SMOTE",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula09A.html#manipulando-os-dados",
    "href": "semanas/Aula09A.html#manipulando-os-dados",
    "title": "RegressÃ£o LogÃ­stica - SMOTE",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          ))\n\nstr(credito)\n\ntibble [10,000 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09A.html#treino-e-teste",
    "href": "semanas/Aula09A.html#treino-e-teste",
    "title": "RegressÃ£o LogÃ­stica - SMOTE",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula09A.html#smote",
    "href": "semanas/Aula09A.html#smote",
    "title": "RegressÃ£o LogÃ­stica - SMOTE",
    "section": "SMOTE",
    "text": "SMOTE\n\nlibrary(smotefamily)\nset.seed(123)\nteste <- SMOTE(conj_treino[,-1], target = conj_treino$inadimplente, K=5)\nconj_treinoS <- teste$data\nconj_treinoS$class <- as.factor(conj_treinoS$class)\nconj_treinoS <- conj_treinoS %>% rename( inadimplente = class)\nprop.table(table(conj_treinoS$inadimplente))\n\n\n     Nao      Sim \n0.500615 0.499385 \n\nsummary(conj_treinoS)\n\n   estudante         balanco          receita      inadimplente\n Min.   :0.0000   Min.   :   0.0   Min.   :  772   Nao:7733    \n 1st Qu.:0.0000   1st Qu.: 795.5   1st Qu.:20166   Sim:7714    \n Median :0.0000   Median :1392.3   Median :33703               \n Mean   :0.3394   Mean   :1272.9   Mean   :32841               \n 3rd Qu.:1.0000   3rd Qu.:1769.2   3rd Qu.:43745               \n Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09A.html#a-regressÃ£o-logÃ­stica",
    "href": "semanas/Aula09A.html#a-regressÃ£o-logÃ­stica",
    "title": "RegressÃ£o LogÃ­stica - SMOTE",
    "section": "1a RegressÃ£o logÃ­stica",
    "text": "1a RegressÃ£o logÃ­stica\n\nmod1 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treinoS,family=binomial)\nsummary(mod1)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n    data = conj_treinoS)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.9262  -0.1967  -0.0084   0.3402   3.0696  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -9.778e+00  2.279e-01 -42.898  < 2e-16 ***\nbalanco      7.115e-03  1.199e-04  59.356  < 2e-16 ***\nreceita      9.409e-06  3.645e-06   2.582  0.00984 ** \nestudante   -6.092e-01  1.071e-01  -5.688 1.28e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 21414.1  on 15446  degrees of freedom\nResidual deviance:  7490.3  on 15443  degrees of freedom\nAIC: 7498.3\n\nNumber of Fisher Scoring iterations: 7\n\ncoef(mod1)\n\n  (Intercept)       balanco       receita     estudante \n-9.778189e+00  7.114940e-03  9.409475e-06 -6.092070e-01 \n\nsummary(mod1)$coef\n\n                 Estimate   Std. Error    z value     Pr(>|z|)\n(Intercept) -9.778189e+00 2.279388e-01 -42.898311 0.000000e+00\nbalanco      7.114940e-03 1.198694e-04  59.355775 0.000000e+00\nreceita      9.409475e-06 3.644856e-06   2.581576 9.835023e-03\nestudante   -6.092070e-01 1.070945e-01  -5.688499 1.281605e-08"
  },
  {
    "objectID": "semanas/Aula09A.html#avaliando-o-modelo-novamente",
    "href": "semanas/Aula09A.html#avaliando-o-modelo-novamente",
    "title": "RegressÃ£o LogÃ­stica - SMOTE",
    "section": "Avaliando o modelo novamente",
    "text": "Avaliando o modelo novamente\n\nprop.table(table(conj_teste$inadimplente))\n\n\n       Nao        Sim \n0.96651674 0.03348326 \n\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1696   11\n       Sim  238   56\n                                          \n               Accuracy : 0.8756          \n                 95% CI : (0.8603, 0.8897)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.2705          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.83582         \n            Specificity : 0.87694         \n         Pos Pred Value : 0.19048         \n         Neg Pred Value : 0.99356         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02799         \n   Detection Prevalence : 0.14693         \n      Balanced Accuracy : 0.85638         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09A.html#curva-roc",
    "href": "semanas/Aula09A.html#curva-roc",
    "title": "RegressÃ£o LogÃ­stica - SMOTE",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.710555e-01 3.991424e-04 9.094011e-05 9.398313e-02 3.185776e-03 8.710220e-04 \n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=TRUE,\n                 legacy.axes=TRUE) \n\n\n\nas.numeric(roc_log$auc)\n\n[1] 0.941186"
  },
  {
    "objectID": "semanas/Aula10.html#carregando-bibliotecas",
    "href": "semanas/Aula10.html#carregando-bibliotecas",
    "title": "LDA e QDA",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula10.html#manipulando-os-dados",
    "href": "semanas/Aula10.html#manipulando-os-dados",
    "title": "LDA e QDA",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula10.html#treino-e-teste",
    "href": "semanas/Aula10.html#treino-e-teste",
    "title": "LDA e QDA",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula10.html#balanÃ§o-e-receita",
    "href": "semanas/Aula10.html#balanÃ§o-e-receita",
    "title": "LDA e QDA",
    "section": "BalanÃ§o e receita",
    "text": "BalanÃ§o e receita\n\nfeaturePlot(x = conj_treino[, c(\"balanco\", \"receita\")], \n            y = conj_treino$inadimplente,\n            plot = \"density\", \n            scales = list(x = list(relation = \"free\"), \n                          y = list(relation = \"free\")), \n            adjust = 1.5, \n            pch = \"|\", \n            layout = c(2, 1), \n            auto.key = list(columns = 2))"
  },
  {
    "objectID": "semanas/Aula10.html#bayes-ingÃªnuo-naive-bayes",
    "href": "semanas/Aula10.html#bayes-ingÃªnuo-naive-bayes",
    "title": "LDA e QDA",
    "section": "Bayes IngÃªnuo (Naive Bayes)",
    "text": "Bayes IngÃªnuo (Naive Bayes)\n\nparams <- conj_treino %>% \n     group_by(inadimplente) %>% \n     summarize(media = mean(balanco), desvpad = sd(balanco))\nparams\n\n# A tibble: 2 Ã— 3\n  inadimplente media desvpad\n  <fct>        <dbl>   <dbl>\n1 Nao           801.    456.\n2 Sim          1745.    332.\n\npi <- conj_treino %>% summarize(pi=mean(inadimplente==\"Sim\")) %>% pull(pi)\npi\n\n[1] 0.03325416\n\nx <- conj_teste$balanco\n\nf0 <- dnorm(x, params$media[1], params$desvpad[1])\nf1 <- dnorm(x, params$media[2], params$desvpad[2])\n\np_chapeu_bayes <- f1*pi / (f1*pi + f0*(1 - pi))\ny_chapeu_bayes <- ifelse(p_chapeu_bayes > 0.5, \"Sim\", \"Nao\")\n\nconfusionMatrix(factor(y_chapeu_bayes), conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1927   44\n       Sim    7   23\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.4631         \n                                         \n Mcnemar's Test P-Value : 4.631e-07      \n                                         \n            Sensitivity : 0.34328        \n            Specificity : 0.99638        \n         Pos Pred Value : 0.76667        \n         Neg Pred Value : 0.97768        \n             Prevalence : 0.03348        \n         Detection Rate : 0.01149        \n   Detection Prevalence : 0.01499        \n      Balanced Accuracy : 0.66983        \n                                         \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#calcula-erro",
    "href": "semanas/Aula10.html#calcula-erro",
    "title": "LDA e QDA",
    "section": "Calcula Erro",
    "text": "Calcula Erro\n\ncalc_erro_class <- function(real, previsto) {\n  mean(real != previsto)\n}\n# Este valor Ã© igual a 1 - Accuracy da matriz de confusÃ£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu_bayes)\n\n[1] 0.02548726"
  },
  {
    "objectID": "semanas/Aula10.html#alterando-o-valor-da-priori",
    "href": "semanas/Aula10.html#alterando-o-valor-da-priori",
    "title": "LDA e QDA",
    "section": "Alterando o valor da priori",
    "text": "Alterando o valor da priori\n\np_chapeu_bayes <- f1*0.15 / (f1*0.15 + f0*(1 - 0.15))\ny_chapeu_bayes <- ifelse(p_chapeu_bayes > 0.5, \"Sim\", \"Nao\")\n\n\nconfusionMatrix(factor(y_chapeu_bayes), conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1839   22\n       Sim   95   45\n                                          \n               Accuracy : 0.9415          \n                 95% CI : (0.9303, 0.9514)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.408           \n                                          \n Mcnemar's Test P-Value : 2.806e-11       \n                                          \n            Sensitivity : 0.67164         \n            Specificity : 0.95088         \n         Pos Pred Value : 0.32143         \n         Neg Pred Value : 0.98818         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02249         \n   Detection Prevalence : 0.06997         \n      Balanced Accuracy : 0.81126         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor Ã© igual a 1 - Accuracy da matriz de confusÃ£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu_bayes)\n\n[1] 0.05847076"
  },
  {
    "objectID": "semanas/Aula10.html#lda",
    "href": "semanas/Aula10.html#lda",
    "title": "LDA e QDA",
    "section": "LDA",
    "text": "LDA\n\nlibrary(MASS)\n\ntreina_lda <- lda(inadimplente ~ balanco + estudante, data = conj_treino)\ntreina_lda\n\nCall:\nlda(inadimplente ~ balanco + estudante, data = conj_treino)\n\nPrior probabilities of groups:\n       Nao        Sim \n0.96674584 0.03325416 \n\nGroup means:\n      balanco estudante\nNao  801.3012 0.2919953\nSim 1744.6575 0.3909774\n\nCoefficients of linear discriminants:\n                   LD1\nbalanco    0.002242096\nestudante -0.216603545\n\nplot(treina_lda)\n\n\n\nnames(predict(treina_lda, conj_treino))\n\n[1] \"class\"     \"posterior\" \"x\"        \n\ny_chapeu <- predict(treina_lda, conj_teste)$class %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1928   45\n       Sim    6   22\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.4523         \n                                         \n Mcnemar's Test P-Value : 1.032e-07      \n                                         \n            Sensitivity : 0.32836        \n            Specificity : 0.99690        \n         Pos Pred Value : 0.78571        \n         Neg Pred Value : 0.97719        \n             Prevalence : 0.03348        \n         Detection Rate : 0.01099        \n   Detection Prevalence : 0.01399        \n      Balanced Accuracy : 0.66263        \n                                         \n       'Positive' Class : Sim            \n                                         \n\n# Este valor Ã© igual a 1 - Accuracy da matriz de confusÃ£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu)\n\n[1] 0.02548726"
  },
  {
    "objectID": "semanas/Aula10.html#lda---ajustes",
    "href": "semanas/Aula10.html#lda---ajustes",
    "title": "LDA e QDA",
    "section": "LDA - ajustes",
    "text": "LDA - ajustes\n\np_chapeu <- predict(treina_lda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9804367 0.0195633263\n2 0.9996897 0.0003102714\n3 0.9998980 0.0001019950\n4 0.9877333 0.0122667438\n5 0.9989602 0.0010397555\n6 0.9994672 0.0005327889\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1818   19\n       Sim  116   48\n                                          \n               Accuracy : 0.9325          \n                 95% CI : (0.9206, 0.9431)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3864          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.71642         \n            Specificity : 0.94002         \n         Pos Pred Value : 0.29268         \n         Neg Pred Value : 0.98966         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02399         \n   Detection Prevalence : 0.08196         \n      Balanced Accuracy : 0.82822         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor Ã© igual a 1 - Accuracy da matriz de confusÃ£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu)\n\n[1] 0.06746627"
  },
  {
    "objectID": "semanas/Aula10.html#qda",
    "href": "semanas/Aula10.html#qda",
    "title": "LDA e QDA",
    "section": "QDA",
    "text": "QDA\n\ntreina_qda <- qda(inadimplente ~ balanco + estudante, data = conj_treino)\ntreina_qda\n\nCall:\nqda(inadimplente ~ balanco + estudante, data = conj_treino)\n\nPrior probabilities of groups:\n       Nao        Sim \n0.96674584 0.03325416 \n\nGroup means:\n      balanco estudante\nNao  801.3012 0.2919953\nSim 1744.6575 0.3909774\n\ny_chapeu <- predict(treina_qda, conj_teste)$class %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1927   41\n       Sim    7   26\n                                          \n               Accuracy : 0.976           \n                 95% CI : (0.9683, 0.9823)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.008318        \n                                          \n                  Kappa : 0.5092          \n                                          \n Mcnemar's Test P-Value : 1.906e-06       \n                                          \n            Sensitivity : 0.38806         \n            Specificity : 0.99638         \n         Pos Pred Value : 0.78788         \n         Neg Pred Value : 0.97917         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01299         \n   Detection Prevalence : 0.01649         \n      Balanced Accuracy : 0.69222         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#qda-ajustes",
    "href": "semanas/Aula10.html#qda-ajustes",
    "title": "LDA e QDA",
    "section": "QDA ajustes",
    "text": "QDA ajustes\n\np_chapeu <- predict(treina_qda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9882876 1.171241e-02\n2 0.9999968 3.209822e-06\n3 0.9999998 1.848443e-07\n4 0.9946442 5.355842e-03\n5 0.9999472 5.284669e-05\n6 0.9999916 8.371285e-06\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1798   18\n       Sim  136   49\n                                          \n               Accuracy : 0.923           \n                 95% CI : (0.9105, 0.9343)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3573          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.73134         \n            Specificity : 0.92968         \n         Pos Pred Value : 0.26486         \n         Neg Pred Value : 0.99009         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02449         \n   Detection Prevalence : 0.09245         \n      Balanced Accuracy : 0.83051         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#curva-roc",
    "href": "semanas/Aula10.html#curva-roc",
    "title": "LDA e QDA",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\n# KNN\nset.seed(21)\nctrl <- trainControl(method = \"cv\")\ntreina_knn <- train(inadimplente ~ balanco + estudante, method = \"knn\", trControl= ctrl, preProcess=c(\"center\", \"scale\"), tuneGrid = data.frame(k = seq(21,140, by=4)), data = conj_treino)\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n# Reg Log\nmod2 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\np_chapeu_log <- predict(mod2, newdata = conj_teste, type = \"response\")\n\n# LDA e QDA\np_chapeu_lda <- predict(treina_lda, conj_teste)$posterior\np_chapeu_qda <- predict(treina_qda, conj_teste)$posterior\n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE,\n                 col=\"black\", legacy.axes=TRUE)\nroc_lda <- roc(conj_teste$inadimplente ~ p_chapeu_lda[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\nroc_qda <- roc(conj_teste$inadimplente ~ p_chapeu_qda[,2], plot = TRUE, print.auc=FALSE, col=\"blue\", legacy.axes=TRUE, add=TRUE)\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"red\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg Log\",\"LDA\",\"QDA\", \"KNN\"), \n       col=c(\"black\", \"green\",\"blue\", \"red\"),lwd=4)\n\n\n\nas.numeric(roc_log$auc)\n\n[1] 0.9415487\n\nas.numeric(roc_lda$auc)\n\n[1] 0.9412709\n\nas.numeric(roc_qda$auc)\n\n[1] 0.9414715\n\nas.numeric(roc_knn1$auc)\n\n[1] 0.9388361"
  },
  {
    "objectID": "semanas/Aula01.html#lendo-dados-de-arquivos-csv",
    "href": "semanas/Aula01.html#lendo-dados-de-arquivos-csv",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de arquivos csv",
    "text": "Lendo dados de arquivos csv\n\nlibrary(readr)\nurl <- \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-acervo-de-dados-tecnicos/tabela-pocos.csv\"\n## O read_delim permite que seja definido o tipo de delimitador dos dados\npocos <- read_delim(url, delim = \";\", locale= locale(decimal_mark = \",\"), col_names = TRUE)\n\nRows: 30255 Columns: 60\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \";\"\nchr (51): POCO, CADASTRO, OPERADOR, POCO_OPERADOR, ESTADO, BACIA, BLOCO, SIG...\ndbl  (8): LATITUDE_BASE_DD, LONGITUDE_BASE_DD, PROFUNDIDADE_VERTICAL_M, PROF...\nlgl  (1): UNIDADE_ESTRATIGRAFICA\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(pocos)\n\n# A tibble: 6 Ã— 60\n  POCO  CADASâ€¦Â¹ OPERAâ€¦Â² POCO_â€¦Â³ ESTADO BACIA BLOCO SIG_Câ€¦â´ CAMPO TERRAâ€¦âµ POCO_â€¦â¶\n  <chr> <chr>   <chr>   <chr>   <chr>  <chr> <chr> <chr>   <chr> <chr>   <chr>  \n1 7-PCâ€¦ 721000â€¦ 3R Macâ€¦ 7PC  0â€¦ RN     Potiâ€¦ PC    \"PC   \" PORTâ€¦ T       N      \n2 7-COâ€¦ 742810â€¦ Petrobâ€¦ 7CO  0â€¦ RJ     Campâ€¦ CO    \"CO   \" CORVâ€¦ M       N      \n3 7-BAâ€¦ 202400â€¦ Petrobâ€¦ 7BA  0â€¦ BA     RecÃ´â€¦ BA    \"BA   \" BURAâ€¦ T       N      \n4 7-ETâ€¦ 721000â€¦ Petrobâ€¦ 7ET  0â€¦ RN     Potiâ€¦ ET    \"ET   \" ESTRâ€¦ T       N      \n5 4-FSâ€¦ 342700â€¦ Petrobâ€¦ 4FSL 0â€¦ ES     EspÃ­â€¦ FSL   \"FSL  \" FAZEâ€¦ T       N      \n6 7-CAâ€¦ 721000â€¦ Petrobâ€¦ 7CAM 0â€¦ RN     Potiâ€¦ CAM   \"CAM  \" CANTâ€¦ T       N      \n# â€¦ with 49 more variables: TIPO <chr>, CATEGORIA <chr>, RECLASSIFICACAO <chr>,\n#   SITUACAO <chr>, INICIO <chr>, TERMINO <chr>, CONCLUSAO <chr>,\n#   TITULARIDADE <chr>, LATITUDE_BASE_4C <chr>, LONGITUDE_BASE_4C <chr>,\n#   LATITUDE_BASE_DD <dbl>, LONGITUDE_BASE_DD <dbl>, DATUM_HORIZONTAL <chr>,\n#   TIPO_DE_COORDENADA_DE_BASE <chr>, DIRECAO <chr>,\n#   PROFUNDIDADE_VERTICAL_M <dbl>, PROFUNDIDADE_SONDADOR_M <dbl>,\n#   PROFUNDIDADE_MEDIDA_M <dbl>, REFERENCIA_DE_PROFUNDIDADE <chr>, â€¦\n# â„¹ Use `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula01.html#bibliotecas",
    "href": "semanas/Aula01.html#bibliotecas",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Bibliotecas",
    "text": "Bibliotecas\nVamos carregar as bibliotecas que serÃ£o usadas na manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados.\nO pacote tidyverse carrega diversos pacotes muito uteis na manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados\n\nlibrary(\"tidyverse\")\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.2 â”€â”€\nâœ” ggplot2 3.3.6     âœ” dplyr   1.0.9\nâœ” tibble  3.1.8     âœ” stringr 1.4.0\nâœ” tidyr   1.2.0     âœ” forcats 0.5.1\nâœ” purrr   0.3.4     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\n\n\nVamos primeiro conhecer o que tem na base de dados pocos. A base de dados possui 30255 linhas\n\nclass(pocos)  # Tipo de base de dados\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nsummary(pocos) # Sumario da base de dados\n\n     POCO             CADASTRO           OPERADOR         POCO_OPERADOR     \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    ESTADO             BACIA              BLOCO            SIG_CAMPO        \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    CAMPO            TERRA_MAR         POCO_POS_ANP           TIPO          \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  CATEGORIA         RECLASSIFICACAO      SITUACAO            INICIO         \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   TERMINO           CONCLUSAO         TITULARIDADE       LATITUDE_BASE_4C  \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n LONGITUDE_BASE_4C  LATITUDE_BASE_DD  LONGITUDE_BASE_DD DATUM_HORIZONTAL  \n Length:30255       Min.   :-32.927   Min.   :-73.38    Length:30255      \n Class :character   1st Qu.:-12.691   1st Qu.:-39.61    Class :character  \n Mode  :character   Median :-10.710   Median :-37.83    Mode  :character  \n                    Mean   :-11.480   Mean   :-38.83                      \n                    3rd Qu.: -5.327   3rd Qu.:-36.98                      \n                    Max.   :  4.528   Max.   :-34.83                      \n                                                                          \n TIPO_DE_COORDENADA_DE_BASE   DIRECAO          PROFUNDIDADE_VERTICAL_M\n Length:30255               Length:30255       Min.   :-62550.0       \n Class :character           Class :character   1st Qu.:  -772.4       \n Mode  :character           Mode  :character   Median :     0.0       \n                                               Mean   :  -254.4       \n                                               3rd Qu.:   138.0       \n                                               Max.   :528084.0       \n                                               NA's   :19336          \n PROFUNDIDADE_SONDADOR_M PROFUNDIDADE_MEDIDA_M REFERENCIA_DE_PROFUNDIDADE\n Min.   :    0           Min.   :    0.0       Length:30255              \n 1st Qu.:  485           1st Qu.:  347.5       Class :character          \n Median :  999           Median :  870.2       Mode  :character          \n Mean   : 1507           Mean   : 1583.9                                 \n 3rd Qu.: 2230           3rd Qu.: 2644.0                                 \n Max.   :62750           Max.   :62800.0                                 \n NA's   :1043            NA's   :17787                                   \n MESA_ROTATIVA     COTA_ALTIMETRICA_M LAMINA_D_AGUA_M   DATUM_VERTICAL    \n Min.   :   0.00   Min.   :    0.00   Min.   :    0.0   Length:30255      \n 1st Qu.:  19.00   1st Qu.:    0.00   1st Qu.:    0.0   Class :character  \n Median :  32.40   Median :   12.30   Median :    0.0   Mode  :character  \n Mean   :  57.34   Mean   :   41.00   Mean   :  284.2                     \n 3rd Qu.:  75.68   3rd Qu.:   56.99   3rd Qu.:  116.0                     \n Max.   :2220.00   Max.   :30940.00   Max.   :30940.0                     \n                   NA's   :17225      NA's   :14761                       \n UNIDADE_ESTRATIGRAFICA GEOLOGIA_GRUPO_FINAL GEOLOGIA_FORMACAO_FINAL\n Mode:logical           Length:30255         Length:30255           \n NA's:30255             Class :character     Class :character       \n                        Mode  :character     Mode  :character       \n                                                                    \n                                                                    \n                                                                    \n                                                                    \n GEOLOGIA_MEMBRO_FINAL     CDPE               AGP                 PC           \n Length:30255          Length:30255       Length:30255       Length:30255      \n Class :character      Class :character   Class :character   Class :character  \n Mode  :character      Mode  :character   Mode  :character   Mode  :character  \n                                                                               \n                                                                               \n                                                                               \n                                                                               \n     PAG            PERFIS_CONVENCIONAIS DURANTE_PERFURACAO PERFIS_DIGITAIS   \n Length:30255       Length:30255         Length:30255       Length:30255      \n Class :character   Class :character     Class :character   Class :character  \n Mode  :character   Mode  :character     Mode  :character   Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n PERFIS_PROCESSADOS PERFIS_ESPECIAIS   AMOSTRA_LATERAL      SISMICA         \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n TABELA_TEMPO_PROFUNDIDADE DADOS_DIRECIONAIS  TESTE_A_CABO      \n Length:30255              Length:30255       Length:30255      \n Class :character          Class :character   Class :character  \n Mode  :character          Mode  :character   Mode  :character  \n                                                                \n                                                                \n                                                                \n                                                                \n TESTE_DE_FORMACAO   CANHONEIO          TESTEMUNHO         GEOQUIMICA       \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  SIG_SONDA          NOM_SONDA         DHA_ATUALIZACAO    ATINGIU_PRESAL    \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "semanas/Aula01.html#dados-de-poÃ§os",
    "href": "semanas/Aula01.html#dados-de-poÃ§os",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Dados de poÃ§os",
    "text": "Dados de poÃ§os\nOs dados da tabela poÃ§os tem 60 colunas.\nVamos inicialmente selecionar algumas colunas para podermos trabalhar com os dados.\nAs colunas que vamos trabalhar sÃ£o:\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\nPara selecionar colunas usamos a funÃ§Ã£o select\n\n## Vamos selecionar as colunas listadas acima\npocos_01 <- pocos %>% select(POCO,OPERADOR,ESTADO,BACIA,BLOCO, CAMPO,TERRA_MAR,CATEGORIA,SITUACAO, INICIO, TERMINO, PROFUNDIDADE_MEDIDA_M)\nhead(pocos_01)\n\n# A tibble: 6 Ã— 12\n  POCO   OPERAâ€¦Â¹ ESTADO BACIA BLOCO CAMPO TERRAâ€¦Â² CATEGâ€¦Â³ SITUAâ€¦â´ INICIO TERMINO\n  <chr>  <chr>   <chr>  <chr> <chr> <chr> <chr>   <chr>   <chr>   <chr>  <chr>  \n1 7-PC-â€¦ 3R Macâ€¦ RN     Potiâ€¦ PC    PORTâ€¦ T       Desenvâ€¦ ARRASAâ€¦ 25/08â€¦ 27/08/â€¦\n2 7-CO-â€¦ Petrobâ€¦ RJ     Campâ€¦ CO    CORVâ€¦ M       Desenvâ€¦ ABANDOâ€¦ 26/08â€¦ 11/10/â€¦\n3 7-BA-â€¦ Petrobâ€¦ BA     RecÃ´â€¦ BA    BURAâ€¦ T       Desenvâ€¦ ABANDOâ€¦ 28/08â€¦ 06/09/â€¦\n4 7-ET-â€¦ Petrobâ€¦ RN     Potiâ€¦ ET    ESTRâ€¦ T       Desenvâ€¦ PRODUZâ€¦ 30/05â€¦ 31/05/â€¦\n5 4-FSLâ€¦ Petrobâ€¦ ES     EspÃ­â€¦ FSL   FAZEâ€¦ T       Pioneiâ€¦ ABANDOâ€¦ 31/05â€¦ 30/06/â€¦\n6 7-CAMâ€¦ Petrobâ€¦ RN     Potiâ€¦ CAM   CANTâ€¦ T       Desenvâ€¦ INJETAâ€¦ 01/06â€¦ 04/06/â€¦\n# â€¦ with 1 more variable: PROFUNDIDADE_MEDIDA_M <dbl>, and abbreviated variable\n#   names Â¹â€‹OPERADOR, Â²â€‹TERRA_MAR, Â³â€‹CATEGORIA, â´â€‹SITUACAO\n# â„¹ Use `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula01.html#manipulaÃ§Ã£o-de-dados",
    "href": "semanas/Aula01.html#manipulaÃ§Ã£o-de-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "ManipulaÃ§Ã£o de dados",
    "text": "ManipulaÃ§Ã£o de dados\nVamos eliminar as linhas de dados que apresenta dados ausentes â€œNAâ€ nas colunas TERMINO e PROFUNDIDADE_MEDIDA_M.\n\nsum(is.na(pocos_01))\n\n[1] 30235\n\nsum(is.na(pocos_01$INICIO))\n\n[1] 0\n\nsum(is.na(pocos_01$TERMINO))\n\n[1] 1861\n\nsum(is.na(pocos_01$PROFUNDIDADE_MEDIDA_M))\n\n[1] 17787\n\npocos_01 <- pocos_01 %>% drop_na(any_of(c(\"TERMINO\",\n                                          \"PROFUNDIDADE_MEDIDA_M\")))\n# melhorando a visualizaÃ§Ã£o dos dados\nknitr::kable(\n  head(pocos_01, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_01.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_01.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n1-MOR-1-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nPioneiro\nFECHADO\n12/06/1994 00:00\n28/06/1994 00:00\n0.0\n\n\n7-REP-28-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nDesenvolvimento\nINJETANDO\n12/04/1995 00:00\n18/04/1995 00:00\n0.0\n\n\n7-ET-647-RN\nPetrobras\nRN\nPotiguar\nET\nESTREITO\nT\nDesenvolvimento\nINJETANDO\n16/04/1995 00:00\n18/04/1995 00:00\n277.2\n\n\n7-MRL-54-RJS\nPetrobras\nRJ\nCampos\nMRL\nMARLIM\nM\nDesenvolvimento\nFECHADO\n30/05/1996 00:00\n13/06/1996 00:00\n0.0\n\n\n7-BVS-13-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nDesenvolvimento\nFECHADO\n06/06/1996 00:00\n15/06/1996 00:00\n0.0\n\n\n9-LUC-31D-AM\nPetrobras\nAM\nSolimÃµes\nLUC\nLESTE DO URUCU\nT\nEspecial\nABANDONADO PERMANENTEMENTE\n10/06/1996 00:00\n15/08/1996 00:00\n0.0\n\n\n1-RJS-500-RJS\nPetrobras\nRJ\nCampos\nESP\nESPADARTE\nM\nPioneiro\nABANDONADO PERMANENTEMENTE\n10/06/1996 00:00\n19/07/1996 00:00\n0.0\n\n\n8-MRL-36D-RJS\nPetrobras\nRJ\nCampos\nMRL\nMARLIM\nM\nInjeÃ§Ã£o\nFECHADO\n27/10/1993 00:00\n15/11/1993 00:00\n0.0\n\n\n3-ESP-2-RJS\nPetrobras\nRJ\nCampos\nESP\nESPADARTE\nM\nExtensÃ£o\nABANDONADO PERMANENTEMENTE\n09/05/1995 00:00\n19/06/1995 00:00\n0.0\n\n\n8-AB-49D-RJS\nPetrobras\nRJ\nCampos\nAB\nALBACORA\nM\nInjeÃ§Ã£o\nFECHADO\n15/04/1996 00:00\n30/07/1996 00:00\n0.0\n\n\n\n\nsum(is.na(pocos_01))\n\n[1] 4328\n\n\nVeja que existia um grande nÃºmero de dados ausentes\nAntes: 30255 linhas Depois: 10715 linhas"
  },
  {
    "objectID": "semanas/Aula01.html#corrigindo-tipo-de-dados",
    "href": "semanas/Aula01.html#corrigindo-tipo-de-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Corrigindo tipo de dados",
    "text": "Corrigindo tipo de dados\nAs colunas INICIO e TERMINO sÃ£o datas, mas foram lidas como caracter, vamos corrigir isto!\nPara trabalhar com datas vamos usar o pacote lubridate\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\npocos_01$INICIO <- as_date(pocos_01$INICIO, format=\"%d/%m/%Y\")\npocos_01$TERMINO <- as_date(pocos_01$TERMINO, format=\"%d/%m/%Y\")"
  },
  {
    "objectID": "semanas/Aula01.html#filtrando-dados",
    "href": "semanas/Aula01.html#filtrando-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Filtrando dados",
    "text": "Filtrando dados\nVamos analisar os poÃ§os de uma detreminada regiÃ£o, para isto podemos fltrar os poÃ§os de um bloco. Vamos filtrar somente os poÃ§os do CAMPO PEREGRINO usando a funÃ§Ã£o filter.\n\npocos_02 <- pocos_01 %>% filter(CAMPO==\"PEREGRINO\") ##  \nsummary(pocos_02)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:94          Length:94          Length:94          Length:94         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:94          Length:94          Length:94          Length:94         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:94          Min.   :1994-07-07   Min.   :1994-08-17  \n Class :character   1st Qu.:2011-12-16   1st Qu.:2012-01-27  \n Mode  :character   Median :2013-07-02   Median :2013-08-31  \n                    Mean   :2013-11-27   Mean   :2013-12-27  \n                    3rd Qu.:2015-10-06   3rd Qu.:2015-10-29  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M\n Min.   :   0         \n 1st Qu.:4457         \n Median :4925         \n Mean   :5136         \n 3rd Qu.:6213         \n Max.   :8613         \n\nknitr::kable(\n  head(pocos_02, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_02.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_02.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n1-RJS-498-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nPioneiro\nABANDONADO PERMANENTEMENTE\n1994-07-07\n1994-08-17\n0.00\n\n\n7-PRG-2HB-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2011-01-16\n2011-02-03\n4676.00\n\n\n7-PRG-64HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2018-11-11\n2018-12-05\n5790.00\n\n\n7-PRG-65HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2019-01-05\n2019-01-20\n4386.00\n\n\n7-PRG-73HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2022-02-25\n2022-03-09\n5694.00\n\n\n8-PRG-68H-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nInjeÃ§Ã£o\nEM AVALIAÃ‡ÃƒO\n2019-08-16\n2019-09-12\n4133.00\n\n\n7-PRG-66HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2019-02-11\n2019-03-07\n6529.00\n\n\n7-PRG-71HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2020-12-08\n2020-12-11\n3646.00\n\n\n7-PRG-71HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2020-12-18\n2020-01-06\n5404.00\n\n\n7-PRG-40HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2014-07-27\n2014-08-03\n4797.74\n\n\n\n\n\n\nAvaliando os dados\nOs poÃ§os possuem diversas categorias, vamos ver que categorias existem nestes poÃ§os do bloco BES-100.\n\nunique(pocos_02$CATEGORIA)\n\n[1] \"Pioneiro\"        \"Desenvolvimento\" \"InjeÃ§Ã£o\"         \"Especial\"       \n[5] \"ExtensÃ£o\"       \n\n\n\n\nFiltrando poÃ§os de desenvolvimento\n\npocos_03 <- pocos_02 %>% filter(CATEGORIA==\"Desenvolvimento\") ##  \nsummary(pocos_03)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:73          Min.   :2010-11-10   Min.   :2010-11-11  \n Class :character   1st Qu.:2012-02-04   1st Qu.:2012-04-06  \n Mode  :character   Median :2013-10-20   Median :2013-11-15  \n                    Mean   :2014-07-23   Mean   :2014-08-21  \n                    3rd Qu.:2016-06-23   3rd Qu.:2016-08-27  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M\n Min.   : 742         \n 1st Qu.:4543         \n Median :5066         \n Mean   :5385         \n 3rd Qu.:6383         \n Max.   :8613         \n\nknitr::kable(\n  head(pocos_03, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_03.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_03.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n7-PRG-2HB-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2011-01-16\n2011-02-03\n4676.00\n\n\n7-PRG-64HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2018-11-11\n2018-12-05\n5790.00\n\n\n7-PRG-65HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2019-01-05\n2019-01-20\n4386.00\n\n\n7-PRG-73HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2022-02-25\n2022-03-09\n5694.00\n\n\n7-PRG-66HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2019-02-11\n2019-03-07\n6529.00\n\n\n7-PRG-71HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2020-12-08\n2020-12-11\n3646.00\n\n\n7-PRG-71HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2020-12-18\n2020-01-06\n5404.00\n\n\n7-PRG-40HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2014-07-27\n2014-08-03\n4797.74\n\n\n7-PRG-8HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2011-11-07\n2011-12-02\n4959.87\n\n\n7-PRG-72HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2021-11-17\n2021-12-08\n5302.00"
  },
  {
    "objectID": "semanas/Aula01.html#criando-uma-coluna-com-mutate",
    "href": "semanas/Aula01.html#criando-uma-coluna-com-mutate",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Criando uma coluna com mutate",
    "text": "Criando uma coluna com mutate\nVamos criar uma coluna que nos darÃ¡ a duraÃ§Ã£o da perfuraÃ§Ã£o dos poÃ§os.\n\npocos_03$INICIO[1]\n\n[1] \"2011-01-16\"\n\npocos_03$TERMINO[1]\n\n[1] \"2011-02-03\"\n\npocos_03$TERMINO[1] - pocos_03$INICIO[1]\n\nTime difference of 18 days\n\ndifftime(pocos_03$TERMINO[1], pocos_03$INICIO[1], units = \"days\")\n\nTime difference of 18 days\n\ntempo <- difftime(pocos_03$TERMINO[1], pocos_03$INICIO[1], units = \"days\")\nstr(tempo)\n\n 'difftime' num 18\n - attr(*, \"units\")= chr \"days\"\n\n(pocos_03$INICIO[1] %--% pocos_03$TERMINO[1])/ddays(1)\n\n[1] 18\n\npocos_03 <- pocos_03 %>% mutate(TPERF = (INICIO %--% TERMINO)/ddays(1))\nsummary(pocos_03)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:73          Min.   :2010-11-10   Min.   :2010-11-11  \n Class :character   1st Qu.:2012-02-04   1st Qu.:2012-04-06  \n Mode  :character   Median :2013-10-20   Median :2013-11-15  \n                    Mean   :2014-07-23   Mean   :2014-08-21  \n                    3rd Qu.:2016-06-23   3rd Qu.:2016-08-27  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M     TPERF       \n Min.   : 742          Min.   :-347.0  \n 1st Qu.:4543          1st Qu.:  16.0  \n Median :5066          Median :  24.0  \n Mean   :5385          Mean   :  28.9  \n 3rd Qu.:6383          3rd Qu.:  37.0  \n Max.   :8613          Max.   : 260.0  \n\n\n\nEliminando colunas com tempos negativos\n\npocos_03 <- pocos_03 %>% filter(TPERF > 0)"
  },
  {
    "objectID": "semanas/Aula01.html#visualizando-os-dados-de-peregrino",
    "href": "semanas/Aula01.html#visualizando-os-dados-de-peregrino",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Visualizando os dados de PEREGRINO",
    "text": "Visualizando os dados de PEREGRINO\n\nBox-Plot\n\nggplot(pocos_03, aes(x=CAMPO, y=TPERF)) +\n  geom_boxplot()\n\n\n\n\nVeja que existem alguns tempos bem elevados que estÃ£o representados por pontos no box-plot. Eles podem ser considerados pontos afastados (outliers), que neste caso vamos eliminar.\n\npocos_04 <- pocos_03 %>% filter(TPERF < 100)\nggplot(pocos_04, aes(x=CAMPO, y=TPERF)) +\n  geom_boxplot()\n\n\n\n\n\n\nHistograma\n\nggplot(pocos_04, aes(x=TPERF)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nVeja que desta forma o ggplot usa o seu padrÃ£o de 30 faixas de dados, que geralmente nÃ£o Ã© o mais adequado.\nVamos usar uma regra adequada para definiÃ§Ã£o de nÃºmero de faixas.\n\n\nCriando um histograma usando a regra de Sturges\nA regra de Sturges indica 7 faixas enquanto que o padrÃ£o do ggplot2 Ã© 30.\n\nggplot(pocos_04, aes(x = TPERF)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(pocos_04)),0))\n\n\n\n\nVeja que agora temos um histograma mais suave.\n\n\nGrÃ¡fico de DispersÃ£o\n\nggplot(pocos_04, aes(x=PROFUNDIDADE_MEDIDA_M, y=TPERF)) + \n  geom_point()\n\n\n\n\nPodemos perceber que hÃ¡ uma relaÃ§Ã£o entre o tempo de perfuraÃ§Ã£o e a profundidade do poÃ§o.\nTambÃ©m Ã© possÃ­vel se perceber que ainda existem dados com comportamentos estranhos. PoÃ§os rasos com profundidade muito diferente dos demais, alÃ©m disso um poÃ§o muito profundo com duraÃ§Ã£o muito pequena.\nSe fossemos construir um modelo certamente terÃ­mos que investigar o porque destes comportamentos.\n\n\nAlterando nome das colunas\n\nnames(pocos_04)\n\n [1] \"POCO\"                  \"OPERADOR\"              \"ESTADO\"               \n [4] \"BACIA\"                 \"BLOCO\"                 \"CAMPO\"                \n [7] \"TERRA_MAR\"             \"CATEGORIA\"             \"SITUACAO\"             \n[10] \"INICIO\"                \"TERMINO\"               \"PROFUNDIDADE_MEDIDA_M\"\n[13] \"TPERF\"                \n\nnames(pocos_04) <- tolower(names(pocos_04))\nnames(pocos_04)\n\n [1] \"poco\"                  \"operador\"              \"estado\"               \n [4] \"bacia\"                 \"bloco\"                 \"campo\"                \n [7] \"terra_mar\"             \"categoria\"             \"situacao\"             \n[10] \"inicio\"                \"termino\"               \"profundidade_medida_m\"\n[13] \"tperf\""
  },
  {
    "objectID": "semanas/Aula02.html",
    "href": "semanas/Aula02.html",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "",
    "text": "Vamos trabalhar de novo com os dados do gapminder para fazer algumas manipulaÃ§Ãµes de dados que sÃ£o muito Ãºteis no dia a dia.\nEste material foi em parte adaptado do curso Data Visualization in R with ggplot2 de Kara Woo\n\nlibrary(\"gapminder\")\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")"
  },
  {
    "objectID": "semanas/Aula02.html#filtrando-2007",
    "href": "semanas/Aula02.html#filtrando-2007",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Filtrando 2007",
    "text": "Filtrando 2007\n\n## Cria um extrato do ano de 2007\ndata(gapminder)\nsummary(gapminder)\n\n        country        continent        year         lifeExp     \n Afghanistan:  12   Africa  :624   Min.   :1952   Min.   :23.60  \n Albania    :  12   Americas:300   1st Qu.:1966   1st Qu.:48.20  \n Algeria    :  12   Asia    :396   Median :1980   Median :60.71  \n Angola     :  12   Europe  :360   Mean   :1980   Mean   :59.47  \n Argentina  :  12   Oceania : 24   3rd Qu.:1993   3rd Qu.:70.85  \n Australia  :  12                  Max.   :2007   Max.   :82.60  \n (Other)    :1632                                                \n      pop              gdpPercap       \n Min.   :6.001e+04   Min.   :   241.2  \n 1st Qu.:2.794e+06   1st Qu.:  1202.1  \n Median :7.024e+06   Median :  3531.8  \n Mean   :2.960e+07   Mean   :  7215.3  \n 3rd Qu.:1.959e+07   3rd Qu.:  9325.5  \n Max.   :1.319e+09   Max.   :113523.1  \n                                       \n\ngap_07 <- filter(gapminder, year == 2007)"
  },
  {
    "objectID": "semanas/Aula02.html#vendo-primeiras-e-Ãºltimas-10-linhas",
    "href": "semanas/Aula02.html#vendo-primeiras-e-Ãºltimas-10-linhas",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Vendo primeiras e Ãºltimas 10 linhas",
    "text": "Vendo primeiras e Ãºltimas 10 linhas\n\nhead(gap_07, n=10) %>% knitr::kable(booktabs = TRUE) # primeiros dez paises da base de dados\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nAfghanistan\nAsia\n2007\n43.828\n31889923\n974.5803\n\n\nAlbania\nEurope\n2007\n76.423\n3600523\n5937.0295\n\n\nAlgeria\nAfrica\n2007\n72.301\n33333216\n6223.3675\n\n\nAngola\nAfrica\n2007\n42.731\n12420476\n4797.2313\n\n\nArgentina\nAmericas\n2007\n75.320\n40301927\n12779.3796\n\n\nAustralia\nOceania\n2007\n81.235\n20434176\n34435.3674\n\n\nAustria\nEurope\n2007\n79.829\n8199783\n36126.4927\n\n\nBahrain\nAsia\n2007\n75.635\n708573\n29796.0483\n\n\nBangladesh\nAsia\n2007\n64.062\n150448339\n1391.2538\n\n\nBelgium\nEurope\n2007\n79.441\n10392226\n33692.6051\n\n\n\n\ntail(gap_07, n=10) %>% knitr::kable(booktabs = TRUE) # Ãºltimos 10 paÃ­ses \n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nUganda\nAfrica\n2007\n51.542\n29170398\n1056.3801\n\n\nUnited Kingdom\nEurope\n2007\n79.425\n60776238\n33203.2613\n\n\nUnited States\nAmericas\n2007\n78.242\n301139947\n42951.6531\n\n\nUruguay\nAmericas\n2007\n76.384\n3447496\n10611.4630\n\n\nVenezuela\nAmericas\n2007\n73.747\n26084662\n11415.8057\n\n\nVietnam\nAsia\n2007\n74.249\n85262356\n2441.5764\n\n\nWest Bank and Gaza\nAsia\n2007\n73.422\n4018332\n3025.3498\n\n\nYemen, Rep.\nAsia\n2007\n62.698\n22211743\n2280.7699\n\n\nZambia\nAfrica\n2007\n42.384\n11746035\n1271.2116\n\n\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.7093"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-1",
    "href": "semanas/Aula02.html#manipulando-1",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Manipulando 1",
    "text": "Manipulando 1\nSelecionando dados por paÃ­s\n\nfilter(gap_07, country %in% c(\"Brazil\", \"Chile\"))\n\n# A tibble: 2 Ã— 6\n  country continent  year lifeExp       pop gdpPercap\n  <fct>   <fct>     <int>   <dbl>     <int>     <dbl>\n1 Brazil  Americas   2007    72.4 190010647     9066.\n2 Chile   Americas   2007    78.6  16284741    13172."
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-2",
    "href": "semanas/Aula02.html#manipulando-2",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Manipulando 2",
    "text": "Manipulando 2\nSelecionando dados para 2007 excluindo a Oceania\n\nfilter(gapminder, year == 2007 & continent != \"Oceania\")\n\n# A tibble: 140 Ã— 6\n   country     continent  year lifeExp       pop gdpPercap\n   <fct>       <fct>     <int>   <dbl>     <int>     <dbl>\n 1 Afghanistan Asia       2007    43.8  31889923      975.\n 2 Albania     Europe     2007    76.4   3600523     5937.\n 3 Algeria     Africa     2007    72.3  33333216     6223.\n 4 Angola      Africa     2007    42.7  12420476     4797.\n 5 Argentina   Americas   2007    75.3  40301927    12779.\n 6 Austria     Europe     2007    79.8   8199783    36126.\n 7 Bahrain     Asia       2007    75.6    708573    29796.\n 8 Bangladesh  Asia       2007    64.1 150448339     1391.\n 9 Belgium     Europe     2007    79.4  10392226    33693.\n10 Benin       Africa     2007    56.7   8078314     1441.\n# â€¦ with 130 more rows\n# â„¹ Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-3",
    "href": "semanas/Aula02.html#manipulando-3",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Manipulando 3",
    "text": "Manipulando 3\nSelecionando dados de 2007, agrupando por continente e sumarizando para achar a mÃ©dia da populaÃ§Ã£o por continente\n\ngapminder %>%\n  filter(year == 2007) %>% \n  group_by(continent) %>% \n  summarize(mediapop = mean(pop))\n\n# A tibble: 5 Ã— 2\n  continent   mediapop\n  <fct>          <dbl>\n1 Africa     17875763.\n2 Americas   35954847.\n3 Asia      115513752.\n4 Europe     19536618.\n5 Oceania    12274974."
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-1",
    "href": "semanas/Aula02.html#visualizando-1",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Visualizando 1",
    "text": "Visualizando 1\nMostrar linhas e pontos do PIB ao longo do tempo para Brasil e Chile\n\ngap_brachi <- filter(gapminder, country %in% c(\"Brazil\", \"Chile\"))\np <- ggplot(gap_brachi, aes(x = year, y = gdpPercap, color=country))\np1 <- p + geom_point()\np1"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-2",
    "href": "semanas/Aula02.html#visualizando-2",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Visualizando 2",
    "text": "Visualizando 2\n\np2 <- p + geom_line()\np2"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-3",
    "href": "semanas/Aula02.html#visualizando-3",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Visualizando 3",
    "text": "Visualizando 3\n\np3 <- p + geom_point() + geom_line()\np3"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-4---usando-o-pacote-patchwork",
    "href": "semanas/Aula02.html#visualizando-4---usando-o-pacote-patchwork",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Visualizando 4 - Usando o pacote patchwork",
    "text": "Visualizando 4 - Usando o pacote patchwork\n\n(p1 + p2) /\n  p3"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-4",
    "href": "semanas/Aula02.html#manipulando-4",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Manipulando 4",
    "text": "Manipulando 4\nContando nÃºmero de paÃ­ses e continentes com distinct\n\nnrow(gapminder) ## Esta nÃ£o Ã© a informaÃ§Ã£o que eu quero\n\n[1] 1704\n\nhead(gapminder)\n\n# A tibble: 6 Ã— 6\n  country     continent  year lifeExp      pop gdpPercap\n  <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\nnrow(distinct(gapminder,country))\n\n[1] 142\n\nnrow(distinct(gapminder, continent))\n\n[1] 5"
  },
  {
    "objectID": "semanas/Aula02.html#fazendo-contagens-de-dados",
    "href": "semanas/Aula02.html#fazendo-contagens-de-dados",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Fazendo contagens de dados",
    "text": "Fazendo contagens de dados\n\ngapminder %>% filter(year == 2007) %>% \n  group_by(continent) %>% summarise(n = n())\n\n# A tibble: 5 Ã— 2\n  continent     n\n  <fct>     <int>\n1 Africa       52\n2 Americas     25\n3 Asia         33\n4 Europe       30\n5 Oceania       2"
  },
  {
    "objectID": "semanas/Aula02.html#mudando-orientaÃ§Ã£o-dos-dados",
    "href": "semanas/Aula02.html#mudando-orientaÃ§Ã£o-dos-dados",
    "title": "ManipulaÃ§Ã£o dos dados",
    "section": "Mudando orientaÃ§Ã£o dos dados",
    "text": "Mudando orientaÃ§Ã£o dos dados\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nhead(propaganda)\n\n# A tibble: 6 Ã— 4\n     TV Radio Newspaper Sales\n  <dbl> <dbl>     <dbl> <dbl>\n1 230.   37.8      69.2  22.1\n2  44.5  39.3      45.1  10.4\n3  17.2  45.9      69.3   9.3\n4 152.   41.3      58.5  18.5\n5 181.   10.8      58.4  12.9\n6   8.7  48.9      75     7.2\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)\npropaganda %>% tidyr::pivot_longer(!Vendas, names_to=\"Midia\", values_to=\"Orcamento\")\n\n# A tibble: 600 Ã— 3\n   Vendas Midia  Orcamento\n    <dbl> <chr>      <dbl>\n 1   22.1 TV         230. \n 2   22.1 Radio       37.8\n 3   22.1 Jornal      69.2\n 4   10.4 TV          44.5\n 5   10.4 Radio       39.3\n 6   10.4 Jornal      45.1\n 7    9.3 TV          17.2\n 8    9.3 Radio       45.9\n 9    9.3 Jornal      69.3\n10   18.5 TV         152. \n# â€¦ with 590 more rows\n# â„¹ Use `print(n = ...)` to see more rows\n\n\n\n\nlibrary(readr)\npesquisa <- read.csv(\"data_joined.csv\", header = T)\nhead(pesquisa)\n\n  record_id month day year plot_id species_id sex hindfoot_length weight\n1         1     7  16 1977       2         NL   M              32     NA\n2        72     8  19 1977       2         NL   M              31     NA\n3       224     9  13 1977       2         NL                  NA     NA\n4       266    10  16 1977       2         NL                  NA     NA\n5       349    11  12 1977       2         NL                  NA     NA\n6       363    11  12 1977       2         NL                  NA     NA\n    genus  species   taxa plot_type\n1 Neotoma albigula Rodent   Control\n2 Neotoma albigula Rodent   Control\n3 Neotoma albigula Rodent   Control\n4 Neotoma albigula Rodent   Control\n5 Neotoma albigula Rodent   Control\n6 Neotoma albigula Rodent   Control\n\npesquisa_gw <- pesquisa %>% filter(!is.na(weight)) %>%\n  group_by(year, genus) %>%\n  summarize(peso_medio = mean(weight))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\nhead(pesquisa_gw)\n\n# A tibble: 6 Ã— 3\n# Groups:   year [1]\n   year genus           peso_medio\n  <int> <chr>                <dbl>\n1  1977 Chaetodipus          15.3 \n2  1977 Dipodomys            52.5 \n3  1977 Onychomys            21.4 \n4  1977 Perognathus           7.17\n5  1977 Peromyscus           19.5 \n6  1977 Reithrodontomys      10   \n\npesquisa_gw %>% tidyr::pivot_wider(names_from=\"genus\", values_from=\"peso_medio\")\n\n# A tibble: 26 Ã— 11\n# Groups:   year [26]\n    year Chaetâ€¦Â¹ Dipodâ€¦Â² Onychâ€¦Â³ Perogâ€¦â´ Peromâ€¦âµ Reithâ€¦â¶ Neotoma Sigmoâ€¦â· Spermâ€¦â¸\n   <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  1977    15.3    52.5    21.4    7.17    19.5   10        NA       NA      NA\n 2  1978    14.9    73.9    26.5    7.09    20.5    7.5     185.      89     130\n 3  1979    15.1    74.9    27.4    7.53    21.3    8.33    138       NA      NA\n 4  1980    14.2    73.1    28.3    7.46    22.4   10.2     159.      NA      NA\n 5  1981    14.0    72.7    28.4    7.15    20.4   11.2     166.      NA      57\n 6  1982    16.1    66.3    29.9    6.92    21.3   10.5     161.      79      NA\n 7  1983    15.5    65.0    29.0    6.83    21.5    9.87    157.      NA      NA\n 8  1984    15.3    52.8    28.3   16.9     20.0   11.2     150.      NA      NA\n 9  1985    15.8    51.1    28.1   32.7     20.0    8.37    149.      NA      NA\n10  1986    16.8    56.4    27.5   18.3     22.1   10.8     160.      55      NA\n# â€¦ with 16 more rows, 1 more variable: Baiomys <dbl>, and abbreviated variable\n#   names Â¹â€‹Chaetodipus, Â²â€‹Dipodomys, Â³â€‹Onychomys, â´â€‹Perognathus, âµâ€‹Peromyscus,\n#   â¶â€‹Reithrodontomys, â·â€‹Sigmodon, â¸â€‹Spermophilus\n# â„¹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula03.html",
    "href": "semanas/Aula03.html",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "",
    "text": "Vamos trabalhar de novo com os dados do gapminder para fazer algumas visualizaÃ§Ãµes de dados que sÃ£o muito Ãºteis no dia a dia.\nEste material foi adaptado do curso Data Visualization in R with ggplot2 de Kara Woo\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"gapminder\")"
  },
  {
    "objectID": "semanas/Aula03.html#selecionando-dados",
    "href": "semanas/Aula03.html#selecionando-dados",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Selecionando dados",
    "text": "Selecionando dados\n\ngap_07 <- filter(gapminder, year == 2007)"
  },
  {
    "objectID": "semanas/Aula03.html#vendo-a-distribuiÃ§Ã£o",
    "href": "semanas/Aula03.html#vendo-a-distribuiÃ§Ã£o",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Vendo a distribuiÃ§Ã£o",
    "text": "Vendo a distribuiÃ§Ã£o\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_histogram()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-histograma-usando-a-regra-de-sturges",
    "href": "semanas/Aula03.html#criando-um-histograma-usando-a-regra-de-sturges",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Criando um histograma usando a regra de Sturges",
    "text": "Criando um histograma usando a regra de Sturges\nA regra de Sturges indica 8 faixas enquanto que o padrÃ£o do ggplot2 Ã© 30.\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(gap_07)),0))"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-grÃ¡fico-de-densidade",
    "href": "semanas/Aula03.html#criando-um-grÃ¡fico-de-densidade",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Criando um grÃ¡fico de densidade",
    "text": "Criando um grÃ¡fico de densidade\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_density()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-box-plot",
    "href": "semanas/Aula03.html#criando-um-box-plot",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Criando um box-plot",
    "text": "Criando um box-plot\n\nggplot(gap_07, aes(x = continent, y = lifeExp)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-box-plot-com-visÃ£o-dos-dados",
    "href": "semanas/Aula03.html#criando-um-box-plot-com-visÃ£o-dos-dados",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Criando um box-plot com visÃ£o dos dados",
    "text": "Criando um box-plot com visÃ£o dos dados\n\nggplot(gap_07, aes(x = continent, y = lifeExp)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.5, alpha = 0.2)"
  },
  {
    "objectID": "semanas/Aula03.html#matriz-de-correlaÃ§Ãµes",
    "href": "semanas/Aula03.html#matriz-de-correlaÃ§Ãµes",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Matriz de CorrelaÃ§Ãµes",
    "text": "Matriz de CorrelaÃ§Ãµes\n\nlibrary(corrplot)\ngap_07_s <- gap_07 %>% select(lifeExp, pop, gdpPercap)\nmat_corr <- cor(gap_07_s)\ncorrplot(mat_corr, method = \"number\", col = \"black\", cl.pos = \"n\")\n\n\n\ncorrplot(mat_corr, method = \"number\")\n\n\n\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula03.html#splom",
    "href": "semanas/Aula03.html#splom",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "SPLOM",
    "text": "SPLOM\n\nlibrary(psych)\npairs.panels(gap_07_s)\n\n\n\n\n\n\nlibrary(GGally)\nggpairs(gap_07_s)"
  },
  {
    "objectID": "semanas/Aula03.html#descrevendo-a-distribuiÃ§Ã£o",
    "href": "semanas/Aula03.html#descrevendo-a-distribuiÃ§Ã£o",
    "title": "Visualizando as distribuiÃ§Ãµes",
    "section": "Descrevendo a distribuiÃ§Ã£o",
    "text": "Descrevendo a distribuiÃ§Ã£o\n\nlibrary(datawizard)\ndescribe_distribution(gap_07_s)\n\nVariable  |     Mean |       SD |      IQR |                Range | Skewness | Kurtosis |   n | n_Missing\n---------------------------------------------------------------------------------------------------------\nlifeExp   |    67.01 |    12.07 |    19.59 |       [39.61, 82.60] |    -0.69 |    -0.83 | 142 |         0\npop       | 4.40e+07 | 1.48e+08 | 2.78e+07 | [2.00e+05, 1.32e+09] |     7.40 |    58.33 | 142 |         0\ngdpPercap | 11680.07 | 12859.94 | 16579.19 |   [277.55, 49357.19] |     1.22 |     0.35 | 142 |         0"
  },
  {
    "objectID": "semanas/Aula05.html",
    "href": "semanas/Aula05.html",
    "title": "SuavizaÃ§Ã£o",
    "section": "",
    "text": "library(\"ggplot2\")\nlibrary(\"gapminder\")\nlibrary(\"dplyr\")"
  },
  {
    "objectID": "semanas/Aula05.html#suavizaÃ§Ã£o",
    "href": "semanas/Aula05.html#suavizaÃ§Ã£o",
    "title": "SuavizaÃ§Ã£o",
    "section": "SuavizaÃ§Ã£o",
    "text": "SuavizaÃ§Ã£o\n(locally estimated scatterplot smoothing/Local Polynomial Regression Fitting)\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#fazendo-o-suavizador-mais-nervoso",
    "href": "semanas/Aula05.html#fazendo-o-suavizador-mais-nervoso",
    "title": "SuavizaÃ§Ã£o",
    "section": "Fazendo o suavizador mais nervoso",
    "text": "Fazendo o suavizador mais nervoso\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(span = 0.2)"
  },
  {
    "objectID": "semanas/Aula05.html#fazendo-o-suavizador-menos-nervoso",
    "href": "semanas/Aula05.html#fazendo-o-suavizador-menos-nervoso",
    "title": "SuavizaÃ§Ã£o",
    "section": "Fazendo o suavizador menos nervoso",
    "text": "Fazendo o suavizador menos nervoso\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(span = 0.9)"
  },
  {
    "objectID": "semanas/Aula05.html#removendo-intervalos-de-confianÃ§a",
    "href": "semanas/Aula05.html#removendo-intervalos-de-confianÃ§a",
    "title": "SuavizaÃ§Ã£o",
    "section": "Removendo intervalos de confianÃ§a",
    "text": "Removendo intervalos de confianÃ§a\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(se = FALSE)"
  },
  {
    "objectID": "semanas/Aula05.html#usando-ic-de-90",
    "href": "semanas/Aula05.html#usando-ic-de-90",
    "title": "SuavizaÃ§Ã£o",
    "section": "Usando IC de 90%",
    "text": "Usando IC de 90%\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(level = 0.90)"
  },
  {
    "objectID": "semanas/Aula05.html#usando-um-modelo-linear-ao-invÃ©s-do-loess",
    "href": "semanas/Aula05.html#usando-um-modelo-linear-ao-invÃ©s-do-loess",
    "title": "SuavizaÃ§Ã£o",
    "section": "Usando um modelo linear ao invÃ©s do loess",
    "text": "Usando um modelo linear ao invÃ©s do loess\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "semanas/Aula05.html#usando-basic-splines-para-melhorar-o-ajuste",
    "href": "semanas/Aula05.html#usando-basic-splines-para-melhorar-o-ajuste",
    "title": "SuavizaÃ§Ã£o",
    "section": "Usando basic splines para melhorar o ajuste",
    "text": "Usando basic splines para melhorar o ajuste\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ splines::bs(x, df = 3))"
  },
  {
    "objectID": "semanas/Aula05.html#usando-o-gam-general-addtive-models-com-regressÃ£o-spline",
    "href": "semanas/Aula05.html#usando-o-gam-general-addtive-models-com-regressÃ£o-spline",
    "title": "SuavizaÃ§Ã£o",
    "section": "Usando o gam (general addtive models) com regressÃ£o spline",
    "text": "Usando o gam (general addtive models) com regressÃ£o spline\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"gam\", formula = y ~ s(x))"
  },
  {
    "objectID": "semanas/Aula05.html#comeÃ§ando-a-construir-um-grÃ¡fico-do-tipo-facet-com-suavizaÃ§Ãµes",
    "href": "semanas/Aula05.html#comeÃ§ando-a-construir-um-grÃ¡fico-do-tipo-facet-com-suavizaÃ§Ãµes",
    "title": "SuavizaÃ§Ã£o",
    "section": "ComeÃ§ando a construir um grÃ¡fico do tipo facet com suavizaÃ§Ãµes",
    "text": "ComeÃ§ando a construir um grÃ¡fico do tipo facet com suavizaÃ§Ãµes\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula05.html#dividindo-por-continente",
    "href": "semanas/Aula05.html#dividindo-por-continente",
    "title": "SuavizaÃ§Ã£o",
    "section": "Dividindo por continente",
    "text": "Dividindo por continente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent)"
  },
  {
    "objectID": "semanas/Aula05.html#adicionando-suavizadores",
    "href": "semanas/Aula05.html#adicionando-suavizadores",
    "title": "SuavizaÃ§Ã£o",
    "section": "Adicionando suavizadores",
    "text": "Adicionando suavizadores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#colorindo-por-continente",
    "href": "semanas/Aula05.html#colorindo-por-continente",
    "title": "SuavizaÃ§Ã£o",
    "section": "Colorindo por continente",
    "text": "Colorindo por continente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#colorindo-somente-a-curva",
    "href": "semanas/Aula05.html#colorindo-somente-a-curva",
    "title": "SuavizaÃ§Ã£o",
    "section": "Colorindo somente a curva",
    "text": "Colorindo somente a curva\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth(aes(color = continent))"
  },
  {
    "objectID": "semanas/Aula04.html",
    "href": "semanas/Aula04.html",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "",
    "text": "library(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"gapminder\")"
  },
  {
    "objectID": "semanas/Aula04.html#cores-por-continente",
    "href": "semanas/Aula04.html#cores-por-continente",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Cores por continente",
    "text": "Cores por continente\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#usando-formas-e-cores-diferentes",
    "href": "semanas/Aula04.html#usando-formas-e-cores-diferentes",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Usando formas e cores diferentes",
    "text": "Usando formas e cores diferentes\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   shape = continent, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#cores-e-tamanho",
    "href": "semanas/Aula04.html#cores-e-tamanho",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Cores e tamanho",
    "text": "Cores e tamanho\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   size = pop, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#sumario-dos-dados-para-obter-pop-mÃ©dia-por-continente",
    "href": "semanas/Aula04.html#sumario-dos-dados-para-obter-pop-mÃ©dia-por-continente",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Sumario dos dados para obter pop mÃ©dia por continente",
    "text": "Sumario dos dados para obter pop mÃ©dia por continente\n\ngap_pop <- gapminder %>% \n  group_by(continent, year) %>% \n  summarize(pop = mean(pop))\nhead(gap_pop)\n\n# A tibble: 6 Ã— 3\n# Groups:   continent [1]\n  continent  year      pop\n  <fct>     <int>    <dbl>\n1 Africa     1952 4570010.\n2 Africa     1957 5093033.\n3 Africa     1962 5702247.\n4 Africa     1967 6447875.\n5 Africa     1972 7305376.\n6 Africa     1977 8328097."
  },
  {
    "objectID": "semanas/Aula04.html#grafico-de-linha-com-cores",
    "href": "semanas/Aula04.html#grafico-de-linha-com-cores",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Grafico de linha com cores",
    "text": "Grafico de linha com cores\n\nggplot(gap_pop, aes(x = year, y = pop, color = continent)) +\n  geom_line() + geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#criando-grids-entre-os-anos-de-2002-e-2007",
    "href": "semanas/Aula04.html#criando-grids-entre-os-anos-de-2002-e-2007",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Criando grids entre os anos de 2002 e 2007",
    "text": "Criando grids entre os anos de 2002 e 2007\n\ngap_0207 <- gapminder %>% filter(between(year, 2002, 2007))\nggplot(gap_0207, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_grid(continent ~ year)"
  },
  {
    "objectID": "semanas/Aula04.html#outro-tipo-de-apresentaÃ§Ãµes-de-grid",
    "href": "semanas/Aula04.html#outro-tipo-de-apresentaÃ§Ãµes-de-grid",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Outro tipo de apresentaÃ§Ãµes de grid",
    "text": "Outro tipo de apresentaÃ§Ãµes de grid\n\ngap_life <- gapminder %>% \n  group_by(continent, year) %>% \n  summarize(lifeExp = mean(lifeExp))\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_grid(continent ~ .)"
  },
  {
    "objectID": "semanas/Aula04.html#grid-em-outra-direÃ§Ã£o",
    "href": "semanas/Aula04.html#grid-em-outra-direÃ§Ã£o",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Grid em outra direÃ§Ã£o",
    "text": "Grid em outra direÃ§Ã£o\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_grid(. ~ continent)"
  },
  {
    "objectID": "semanas/Aula04.html#usando-o-wrap",
    "href": "semanas/Aula04.html#usando-o-wrap",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Usando o wrap",
    "text": "Usando o wrap\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_wrap( ~ continent)"
  },
  {
    "objectID": "semanas/Aula04.html#filtrando-dados-e-fazendo-grafico-de-dispersÃ£o-padrÃ£o",
    "href": "semanas/Aula04.html#filtrando-dados-e-fazendo-grafico-de-dispersÃ£o-padrÃ£o",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Filtrando dados e fazendo grafico de dispersÃ£o padrÃ£o",
    "text": "Filtrando dados e fazendo grafico de dispersÃ£o padrÃ£o\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#transformando-o-eixo-x-para-escala-logarÃ­timica",
    "href": "semanas/Aula04.html#transformando-o-eixo-x-para-escala-logarÃ­timica",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Transformando o eixo x para escala logarÃ­timica",
    "text": "Transformando o eixo x para escala logarÃ­timica\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_continuous(trans = \"log10\")"
  },
  {
    "objectID": "semanas/Aula04.html#outra-forma-de-transformaÃ§Ã£o-do-eixo-x",
    "href": "semanas/Aula04.html#outra-forma-de-transformaÃ§Ã£o-do-eixo-x",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Outra forma de transformaÃ§Ã£o do eixo x",
    "text": "Outra forma de transformaÃ§Ã£o do eixo x\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#definindo-limites-para-o-eixo-y",
    "href": "semanas/Aula04.html#definindo-limites-para-o-eixo-y",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Definindo limites para o eixo y",
    "text": "Definindo limites para o eixo y\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 95))"
  },
  {
    "objectID": "semanas/Aula04.html#grafico-com-cores-normais",
    "href": "semanas/Aula04.html#grafico-com-cores-normais",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Grafico com cores normais",
    "text": "Grafico com cores normais\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#grafico-usando-outra-paleta-de-cores",
    "href": "semanas/Aula04.html#grafico-usando-outra-paleta-de-cores",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Grafico usando outra paleta de cores",
    "text": "Grafico usando outra paleta de cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "semanas/Aula04.html#usando-codigos-manuais-para-as-cores",
    "href": "semanas/Aula04.html#usando-codigos-manuais-para-as-cores",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Usando codigos manuais para as cores",
    "text": "Usando codigos manuais para as cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_manual(values = c(\"#FF0000\", \"#00A08A\", \"#F2AD00\",\n                                \"#F98400\", \"#5BBCD6\"))"
  },
  {
    "objectID": "semanas/Aula04.html#definindo-as-cores-e-tamanho-dos-pontos",
    "href": "semanas/Aula04.html#definindo-as-cores-e-tamanho-dos-pontos",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Definindo as cores e tamanho dos pontos",
    "text": "Definindo as cores e tamanho dos pontos\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(color = \"darkblue\", size = 3) +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#customizando-tÃ­tulos-rÃ³tulos-de-eixo-e-legendas",
    "href": "semanas/Aula04.html#customizando-tÃ­tulos-rÃ³tulos-de-eixo-e-legendas",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Customizando tÃ­tulos, rÃ³tulos de eixo e legendas",
    "text": "Customizando tÃ­tulos, rÃ³tulos de eixo e legendas\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "semanas/Aula04.html#sem-legenda",
    "href": "semanas/Aula04.html#sem-legenda",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Sem legenda",
    "text": "Sem legenda\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "semanas/Aula04.html#legenda-dentro-do-grÃ¡fico",
    "href": "semanas/Aula04.html#legenda-dentro-do-grÃ¡fico",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Legenda dentro do grÃ¡fico",
    "text": "Legenda dentro do grÃ¡fico\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))"
  },
  {
    "objectID": "semanas/Aula04.html#salvando-o-grÃ¡fico",
    "href": "semanas/Aula04.html#salvando-o-grÃ¡fico",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Salvando o grÃ¡fico",
    "text": "Salvando o grÃ¡fico\n\ngraf1 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))\n\ngraf1"
  },
  {
    "objectID": "semanas/Aula04.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "href": "semanas/Aula04.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "title": "Melhorando a visualizaÃ§Ã£o",
    "section": "Aumentando o tamanho do texto e mudando para portugues",
    "text": "Aumentando o tamanho do texto e mudando para portugues\n\ngraf2 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.80),\n        legend.key = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14)) +\n  labs(x = \"PIB Per capita (US$)\", \n       y = \"Expectativa de Vida (anos)\", \n       title = \"Expectativa de Vida vs PIB em 2007\",\n       color = \"Continente\")\n\ngraf2"
  },
  {
    "objectID": "semanas/Aula06.html",
    "href": "semanas/Aula06.html",
    "title": "Eixos - Escalas - Cores",
    "section": "",
    "text": "library(tidyverse)\nlibrary(gapminder)"
  },
  {
    "objectID": "semanas/Aula06.html#filtrando-dados-e-fazendo-grafico-de-dispersÃ£o-padrÃ£o",
    "href": "semanas/Aula06.html#filtrando-dados-e-fazendo-grafico-de-dispersÃ£o-padrÃ£o",
    "title": "Eixos - Escalas - Cores",
    "section": "Filtrando dados e fazendo grafico de dispersÃ£o padrÃ£o",
    "text": "Filtrando dados e fazendo grafico de dispersÃ£o padrÃ£o\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula06.html#transformando-o-eixo-x-para-escala-logarÃ­timica",
    "href": "semanas/Aula06.html#transformando-o-eixo-x-para-escala-logarÃ­timica",
    "title": "Eixos - Escalas - Cores",
    "section": "Transformando o eixo x para escala logarÃ­timica",
    "text": "Transformando o eixo x para escala logarÃ­timica\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_continuous(trans = \"log10\")"
  },
  {
    "objectID": "semanas/Aula06.html#outra-forma-de-transformaÃ§Ã£o-do-eixo-x",
    "href": "semanas/Aula06.html#outra-forma-de-transformaÃ§Ã£o-do-eixo-x",
    "title": "Eixos - Escalas - Cores",
    "section": "Outra forma de transformaÃ§Ã£o do eixo x",
    "text": "Outra forma de transformaÃ§Ã£o do eixo x\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#definindo-limites-para-o-eixo-y",
    "href": "semanas/Aula06.html#definindo-limites-para-o-eixo-y",
    "title": "Eixos - Escalas - Cores",
    "section": "Definindo limites para o eixo y",
    "text": "Definindo limites para o eixo y\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 95))"
  },
  {
    "objectID": "semanas/Aula06.html#grafico-com-cores-normais",
    "href": "semanas/Aula06.html#grafico-com-cores-normais",
    "title": "Eixos - Escalas - Cores",
    "section": "Grafico com cores normais",
    "text": "Grafico com cores normais\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#grafico-usando-uma-paleta-de-cores-diferente",
    "href": "semanas/Aula06.html#grafico-usando-uma-paleta-de-cores-diferente",
    "title": "Eixos - Escalas - Cores",
    "section": "Grafico usando uma paleta de cores diferente",
    "text": "Grafico usando uma paleta de cores diferente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "semanas/Aula06.html#usando-codigos-manuais-para-as-cores",
    "href": "semanas/Aula06.html#usando-codigos-manuais-para-as-cores",
    "title": "Eixos - Escalas - Cores",
    "section": "Usando codigos manuais para as cores",
    "text": "Usando codigos manuais para as cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_manual(values = c(\"#FF0000\", \"#00A08A\", \"#F2AD00\",\n                                \"#F98400\", \"#5BBCD6\"))"
  },
  {
    "objectID": "semanas/Aula06.html#definindo-as-cores-e-tamanho-dos-pontos",
    "href": "semanas/Aula06.html#definindo-as-cores-e-tamanho-dos-pontos",
    "title": "Eixos - Escalas - Cores",
    "section": "Definindo as cores e tamanho dos pontos",
    "text": "Definindo as cores e tamanho dos pontos\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(color = \"darkblue\", size = 3) +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#customizando-tÃ­tulos-rÃ³tulos-de-eixo-e-legendas",
    "href": "semanas/Aula06.html#customizando-tÃ­tulos-rÃ³tulos-de-eixo-e-legendas",
    "title": "Eixos - Escalas - Cores",
    "section": "Customizando tÃ­tulos, rÃ³tulos de eixo e legendas",
    "text": "Customizando tÃ­tulos, rÃ³tulos de eixo e legendas\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "semanas/Aula06.html#sem-legenda",
    "href": "semanas/Aula06.html#sem-legenda",
    "title": "Eixos - Escalas - Cores",
    "section": "Sem legenda",
    "text": "Sem legenda\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "semanas/Aula06.html#legenda-dentro-do-grÃ¡fico",
    "href": "semanas/Aula06.html#legenda-dentro-do-grÃ¡fico",
    "title": "Eixos - Escalas - Cores",
    "section": "Legenda dentro do grÃ¡fico",
    "text": "Legenda dentro do grÃ¡fico\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))"
  },
  {
    "objectID": "semanas/Aula06.html#salvando-o-grÃ¡fico",
    "href": "semanas/Aula06.html#salvando-o-grÃ¡fico",
    "title": "Eixos - Escalas - Cores",
    "section": "Salvando o grÃ¡fico",
    "text": "Salvando o grÃ¡fico\n\ngraf1 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))\n\ngraf1\n\n\n\nggsave(\"Exp_vida_pib_2007_1.png\", plot=graf1, width = 7, height = 7)"
  },
  {
    "objectID": "semanas/Aula06.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "href": "semanas/Aula06.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "title": "Eixos - Escalas - Cores",
    "section": "Aumentando o tamanho do texto e mudando para portugues",
    "text": "Aumentando o tamanho do texto e mudando para portugues\n\ngraf2 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85),\n        legend.key = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14)) +\n  labs(x = \"PIB Per capita (US$)\", \n       y = \"Expectativa de Vida (anos)\", \n       title = \"Expectativa de Vida vs PIB em 2007\",\n       color = \"Continente\")\n\ngraf2\n\n\n\nggsave(\"Exp_vida_pib_2007_2.png\", plot = graf2, width = 7, height = 7)"
  },
  {
    "objectID": "semanas/Aula07.1.html",
    "href": "semanas/Aula07.1.html",
    "title": "RegressÃ£o Linear",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "semanas/Aula07.1.html#dados-de-propaganda",
    "href": "semanas/Aula07.1.html#dados-de-propaganda",
    "title": "RegressÃ£o Linear",
    "section": "Dados de propaganda",
    "text": "Dados de propaganda\nO conjunto de dados contÃ©m estatÃ­sticas sobre as vendas de um produto em 200 diferentes mercados, juntamente com orÃ§amentos publicitÃ¡rios em cada um desses mercados, para diferentes canais de mÃ­dia: TV, rÃ¡dio e jornal. As vendas estÃ£o em milhares de unidades e o orÃ§amento estÃ¡ em milhares de dÃ³lares.\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nsummary(propaganda)\n\n       TV             Radio          Newspaper          Sales      \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00"
  },
  {
    "objectID": "semanas/Aula07.1.html#renomeando",
    "href": "semanas/Aula07.1.html#renomeando",
    "title": "RegressÃ£o Linear",
    "section": "Renomeando",
    "text": "Renomeando\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)"
  },
  {
    "objectID": "semanas/Aula07.1.html#sumario",
    "href": "semanas/Aula07.1.html#sumario",
    "title": "RegressÃ£o Linear",
    "section": "Sumario",
    "text": "Sumario\n\nsummary(propaganda)\n\n       TV             Radio            Jornal           Vendas     \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00  \n\nnrow(propaganda)\n\n[1] 200"
  },
  {
    "objectID": "semanas/Aula07.1.html#linhas-inicias",
    "href": "semanas/Aula07.1.html#linhas-inicias",
    "title": "RegressÃ£o Linear",
    "section": "Linhas inicias",
    "text": "Linhas inicias\n\nlibrary(gt)\ngt(head(propaganda, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    44.5\n39.3\n45.1\n10.4\n    17.2\n45.9\n69.3\n9.3\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    8.7\n48.9\n75.0\n7.2\n    57.5\n32.8\n23.5\n11.8\n    120.2\n19.6\n11.6\n13.2\n    8.6\n2.1\n1.0\n4.8\n    199.8\n2.6\n21.2\n10.6"
  },
  {
    "objectID": "semanas/Aula07.1.html#criando-amostra-de-treino-e-teste",
    "href": "semanas/Aula07.1.html#criando-amostra-de-treino-e-teste",
    "title": "RegressÃ£o Linear",
    "section": "Criando amostra de treino e teste",
    "text": "Criando amostra de treino e teste\n\nlibrary(caret)\nset.seed(21)\ny <- propaganda$Vendas\nindice_teste <- createDataPartition(y, times = 1, p = 0.40, list = FALSE)\n\nconj_treino <- propaganda %>% slice(-indice_teste)\nconj_teste <- propaganda %>% slice(indice_teste)\n\nstr(conj_treino)\n\ntibble [119 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:119] 230.1 151.5 180.8 199.8 66.1 ...\n $ Radio : num [1:119] 37.8 41.3 10.8 2.6 5.8 35.1 7.6 47.7 20.5 23.9 ...\n $ Jornal: num [1:119] 69.2 58.5 58.4 21.2 24.2 65.9 7.2 52.9 18.3 19.1 ...\n $ Vendas: num [1:119] 22.1 18.5 12.9 10.6 8.6 9.2 9.7 22.4 11.3 14.6 ...\n\nstr(conj_teste)\n\ntibble [81 Ã— 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:81] 44.5 17.2 8.7 57.5 120.2 ...\n $ Radio : num [1:81] 39.3 45.9 48.9 32.8 19.6 2.1 24 32.9 36.6 39.6 ...\n $ Jornal: num [1:81] 45.1 69.3 75 23.5 11.6 1 4 46 114 55.8 ...\n $ Vendas: num [1:81] 10.4 9.3 7.2 11.8 13.2 4.8 17.4 19 12.5 24.4 ...\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6"
  },
  {
    "objectID": "semanas/Aula07.1.html#primeira-visualizaÃ§Ã£o-dos-dados",
    "href": "semanas/Aula07.1.html#primeira-visualizaÃ§Ã£o-dos-dados",
    "title": "RegressÃ£o Linear",
    "section": "Primeira visualizaÃ§Ã£o dos dados",
    "text": "Primeira visualizaÃ§Ã£o dos dados\nAqui estou usando uma funÃ§Ã£o do pacote caret que de uma maneira simples apresenta a relaÃ§Ã£o entre a variÃ¡vel resposta e suas possÃ­veis variÃ¡veis explicativas\n\nfeaturePlot(x = conj_treino[ , c(\"TV\", \"Radio\", \"Jornal\")], y = conj_treino$Vendas)"
  },
  {
    "objectID": "semanas/Aula07.1.html#usando-o-ggplot",
    "href": "semanas/Aula07.1.html#usando-o-ggplot",
    "title": "RegressÃ£o Linear",
    "section": "Usando o ggplot",
    "text": "Usando o ggplot\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6\n  \n  \n  \n\n\n\nc_treino_pivot <- conj_treino %>% pivot_longer(!Vendas, names_to=\"Tipo\", values_to=\"OrÃ§amento\" ) \ngt(head(c_treino_pivot, 10))\n\n\n\n\n\n  \n  \n    \n      Vendas\n      Tipo\n      OrÃ§amento\n    \n  \n  \n    22.1\nTV\n230.1\n    22.1\nRadio\n37.8\n    22.1\nJornal\n69.2\n    18.5\nTV\n151.5\n    18.5\nRadio\n41.3\n    18.5\nJornal\n58.5\n    12.9\nTV\n180.8\n    12.9\nRadio\n10.8\n    12.9\nJornal\n58.4\n    10.6\nTV\n199.8\n  \n  \n  \n\n\n\nconj_treino %>% pivot_longer(!Vendas, names_to=\"Tipo\", values_to=\"OrÃ§amento\" ) %>%\n            ggplot() + \n            geom_point(aes(x=OrÃ§amento, y=Vendas)) +\n            facet_wrap( ~ Tipo, scales = \"free_x\") +\n            labs(x = \"OrÃ§amento (1000 US$)\", \n                 y = \"Vendas (em 1000 unidades vendidas)\", \n                 title = \"Vendas vs Propaganda\"\n                 )"
  },
  {
    "objectID": "semanas/Aula07.1.html#matriz-de-dispersÃ£o",
    "href": "semanas/Aula07.1.html#matriz-de-dispersÃ£o",
    "title": "RegressÃ£o Linear",
    "section": "Matriz de dispersÃ£o",
    "text": "Matriz de dispersÃ£o\n\nlibrary(psych)\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correlaÃ§Ã£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlaÃ§Ã£o\n             )"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-mod-regressÃ£o",
    "href": "semanas/Aula07.1.html#o-mod-regressÃ£o",
    "title": "RegressÃ£o Linear",
    "section": "1o Mod RegressÃ£o",
    "text": "1o Mod RegressÃ£o\n\nmod1 <- lm( Vendas ~ TV, data = conj_treino)\nnames(mod1)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoeflinear <- mod1$coefficients[1]\ncoefang <- mod1$coefficients[2]\nsummary(mod1)\n\n\nCall:\nlm(formula = Vendas ~ TV, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6383 -1.9426 -0.0565  1.7033  7.5277 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.929269   0.598642   11.57   <2e-16 ***\nTV          0.046471   0.003471   13.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.167 on 117 degrees of freedom\nMultiple R-squared:  0.605, Adjusted R-squared:  0.6017 \nF-statistic: 179.2 on 1 and 117 DF,  p-value: < 2.2e-16\n\nggplot(conj_treino, aes(x=TV, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representaÃ§Ã£o-do-1o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representaÃ§Ã£o-do-1o-modelo",
    "title": "RegressÃ£o Linear",
    "section": "Outra forma de representaÃ§Ã£o do 1o Modelo",
    "text": "Outra forma de representaÃ§Ã£o do 1o Modelo\n\nlibrary(car)\nscatterplot(Vendas ~ TV, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#extraindo-informaÃ§Ãµes-do-1o-ajuste",
    "href": "semanas/Aula07.1.html#extraindo-informaÃ§Ãµes-do-1o-ajuste",
    "title": "RegressÃ£o Linear",
    "section": "Extraindo informaÃ§Ãµes do 1o ajuste",
    "text": "Extraindo informaÃ§Ãµes do 1o ajuste\n\nsummary(mod1)$sigma\n\n[1] 3.167319\n\nsummary(mod1)$r.squared\n\n[1] 0.605027"
  },
  {
    "objectID": "semanas/Aula07.1.html#intervalo-de-confianÃ§a",
    "href": "semanas/Aula07.1.html#intervalo-de-confianÃ§a",
    "title": "RegressÃ£o Linear",
    "section": "Intervalo de ConfianÃ§a",
    "text": "Intervalo de ConfianÃ§a\n\nsummary(mod1)\n\n\nCall:\nlm(formula = Vendas ~ TV, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6383 -1.9426 -0.0565  1.7033  7.5277 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.929269   0.598642   11.57   <2e-16 ***\nTV          0.046471   0.003471   13.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.167 on 117 degrees of freedom\nMultiple R-squared:  0.605, Adjusted R-squared:  0.6017 \nF-statistic: 179.2 on 1 and 117 DF,  p-value: < 2.2e-16\n\nconfint(mod1)\n\n                 2.5 %     97.5 %\n(Intercept) 5.74368904 8.11484821\nTV          0.03959625 0.05334545"
  },
  {
    "objectID": "semanas/Aula07.1.html#anova",
    "href": "semanas/Aula07.1.html#anova",
    "title": "RegressÃ£o Linear",
    "section": "Anova",
    "text": "Anova\n\nanova(mod1)\n\nAnalysis of Variance Table\n\nResponse: Vendas\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nTV          1 1798.0 1797.95  179.22 < 2.2e-16 ***\nResiduals 117 1173.7   10.03                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.1.html#previsÃµes",
    "href": "semanas/Aula07.1.html#previsÃµes",
    "title": "RegressÃ£o Linear",
    "section": "PrevisÃµes",
    "text": "PrevisÃµes\n\n#?predict\npredict(mod1, data.frame(TV=c(50, 150, 250)), interval = \"prediction\")\n\n        fit       lwr      upr\n1  9.252811  2.915787 15.58983\n2 13.899896  7.600884 20.19891\n3 18.546982 12.211175 24.88279"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste",
    "title": "RegressÃ£o Linear",
    "section": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste",
    "text": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod1, conj_teste)) ^ 2)) \n\n[1] 3.41382"
  },
  {
    "objectID": "semanas/Aula07.1.html#anÃ¡lise-do-modelo",
    "href": "semanas/Aula07.1.html#anÃ¡lise-do-modelo",
    "title": "RegressÃ£o Linear",
    "section": "AnÃ¡lise do modelo",
    "text": "AnÃ¡lise do modelo\n\nplot(mod1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#anÃ¡lise-do-modelo-2",
    "href": "semanas/Aula07.1.html#anÃ¡lise-do-modelo-2",
    "title": "RegressÃ£o Linear",
    "section": "AnÃ¡lise do modelo 2",
    "text": "AnÃ¡lise do modelo 2\n\nlibrary(performance)\ncheck_model(mod1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-modelo-de-regressÃ£o",
    "href": "semanas/Aula07.1.html#o-modelo-de-regressÃ£o",
    "title": "RegressÃ£o Linear",
    "section": "2o Modelo de RegressÃ£o",
    "text": "2o Modelo de RegressÃ£o\n\nmod2 <- lm( Vendas ~ Radio, data = conj_treino)\ncoeflinear <- mod2$coefficients[1]\ncoefang <- mod2$coefficients[2]\nsummary(mod2)\n\n\nCall:\nlm(formula = Vendas ~ Radio, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.396  -1.851   0.675   2.522   7.451 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  9.22746    0.64377  14.333  < 2e-16 ***\nRadio        0.22144    0.02515   8.806 1.38e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.908 on 117 degrees of freedom\nMultiple R-squared:  0.3986,    Adjusted R-squared:  0.3935 \nF-statistic: 77.55 on 1 and 117 DF,  p-value: 1.384e-14\n\nggplot(propaganda, aes(x=Radio, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representaÃ§Ã£o-do-2o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representaÃ§Ã£o-do-2o-modelo",
    "title": "RegressÃ£o Linear",
    "section": "Outra forma de representaÃ§Ã£o do 2o Modelo",
    "text": "Outra forma de representaÃ§Ã£o do 2o Modelo\n\nscatterplot(Vendas ~ Radio, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste-1",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste-1",
    "title": "RegressÃ£o Linear",
    "section": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste",
    "text": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod2, conj_teste)) ^ 2)) \n\n[1] 4.808117"
  },
  {
    "objectID": "semanas/Aula07.1.html#anÃ¡lise-de-resÃ­duos",
    "href": "semanas/Aula07.1.html#anÃ¡lise-de-resÃ­duos",
    "title": "RegressÃ£o Linear",
    "section": "AnÃ¡lise de ResÃ­duos",
    "text": "AnÃ¡lise de ResÃ­duos\n\ncheck_model(mod2)"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-modelo-de-regressÃ£o-1",
    "href": "semanas/Aula07.1.html#o-modelo-de-regressÃ£o-1",
    "title": "RegressÃ£o Linear",
    "section": "3o Modelo de RegressÃ£o",
    "text": "3o Modelo de RegressÃ£o\n\nmod3 <- lm( Vendas ~ Jornal, data = conj_treino)\ncoeflinear <- mod3$coefficients[1]\ncoefang <- mod3$coefficients[2]\nsummary(mod3)\n\n\nCall:\nlm(formula = Vendas ~ Jornal, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.0331  -3.2104  -0.8491   3.0389  13.0002 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 12.08457    0.80845  14.948  < 2e-16 ***\nJornal       0.06305    0.02290   2.753  0.00685 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.884 on 117 degrees of freedom\nMultiple R-squared:  0.06084,   Adjusted R-squared:  0.05281 \nF-statistic: 7.579 on 1 and 117 DF,  p-value: 0.006847\n\nggplot(propaganda, aes(x=Jornal, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representaÃ§Ã£o-do-3o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representaÃ§Ã£o-do-3o-modelo",
    "title": "RegressÃ£o Linear",
    "section": "Outra forma de representaÃ§Ã£o do 3o Modelo",
    "text": "Outra forma de representaÃ§Ã£o do 3o Modelo\n\nscatterplot(Vendas ~ Jornal, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste-2",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padrÃ£o-do-resÃ­duo-com-amostra-de-teste-2",
    "title": "RegressÃ£o Linear",
    "section": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste",
    "text": "Calculando o erro padrÃ£o do resÃ­duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod3, conj_teste)) ^ 2)) \n\n[1] 5.38693"
  },
  {
    "objectID": "semanas/Aula07.1.html#anÃ¡lise-de-resÃ­duos-1",
    "href": "semanas/Aula07.1.html#anÃ¡lise-de-resÃ­duos-1",
    "title": "RegressÃ£o Linear",
    "section": "AnÃ¡lise de ResÃ­duos",
    "text": "AnÃ¡lise de ResÃ­duos\n\ncheck_model(mod3)"
  },
  {
    "objectID": "semanas/Aula01A.html#lendo-dados-de-arquivos-xlsx",
    "href": "semanas/Aula01A.html#lendo-dados-de-arquivos-xlsx",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de arquivos xlsx",
    "text": "Lendo dados de arquivos xlsx\n\nlibrary(readxl)\ndados_seg <- read_xlsx(\"C:/Users/ricar/OneDrive/Documents/GitHub/IME05-12547/indicadoressegurancapublicauf.xlsx\", col_names = TRUE, sheet = \"OcorrÃªncias\")\nhead(dados_seg)\n\n# A tibble: 6 Ã— 5\n  UF    `Tipo Crime`                      Ano MÃªs     OcorrÃªncias\n  <chr> <chr>                           <dbl> <chr>         <dbl>\n1 Acre  Estupro                          2022 janeiro          31\n2 Acre  Furto de veÃ­culo                 2022 janeiro          50\n3 Acre  HomicÃ­dio doloso                 2022 janeiro          10\n4 Acre  LesÃ£o corporal seguida de morte  2022 janeiro           0\n5 Acre  Roubo a instituiÃ§Ã£o financeira   2022 janeiro           0\n6 Acre  Roubo de carga                   2022 janeiro           0\n\nstr(dados_seg)\n\ntibble [20,686 Ã— 5] (S3: tbl_df/tbl/data.frame)\n $ UF         : chr [1:20686] \"Acre\" \"Acre\" \"Acre\" \"Acre\" ...\n $ Tipo Crime : chr [1:20686] \"Estupro\" \"Furto de veÃ­culo\" \"HomicÃ­dio doloso\" \"LesÃ£o corporal seguida de morte\" ...\n $ Ano        : num [1:20686] 2022 2022 2022 2022 2022 ...\n $ MÃªs        : chr [1:20686] \"janeiro\" \"janeiro\" \"janeiro\" \"janeiro\" ...\n $ OcorrÃªncias: num [1:20686] 31 50 10 0 0 0 72 0 22 34 ..."
  },
  {
    "objectID": "semanas/Aula01A.html#lendo-dados-de-atravÃ©s-de-uma-url",
    "href": "semanas/Aula01A.html#lendo-dados-de-atravÃ©s-de-uma-url",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de atravÃ©s de uma url",
    "text": "Lendo dados de atravÃ©s de uma url\n\nlibrary(readxl)\nlibrary(httr)\nurl <- \"http://dados.mj.gov.br/dataset/210b9ae2-21fc-4986-89c6-2006eb4db247/resource/feeae05e-faba-406c-8a4a-512aec91a9d1/download/indicadoressegurancapublicauf.xlsx\"\nGET(url, write_disk(tf <- tempfile(fileext = \".xlsx\")))\n\nResponse [https://dados.mj.gov.br/dataset/210b9ae2-21fc-4986-89c6-2006eb4db247/resource/feeae05e-faba-406c-8a4a-512aec91a9d1/download/indicadoressegurancapublicauf.xlsx]\n  Date: 2022-08-12 18:33\n  Status: 200\n  Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n  Size: 1.02 MB\n<ON DISK>  C:\\Users\\ricar\\AppData\\Local\\Temp\\Rtmp4wadjp\\file2d6462e33ec0.xlsx\n\nsegur <- read_xlsx(tf, sheet = \"OcorrÃªncias\")\nstr(segur)\n\ntibble [20,957 Ã— 5] (S3: tbl_df/tbl/data.frame)\n $ UF         : chr [1:20957] \"Acre\" \"Acre\" \"Acre\" \"Acre\" ...\n $ Tipo Crime : chr [1:20957] \"Estupro\" \"Furto de veÃ­culo\" \"HomicÃ­dio doloso\" \"LesÃ£o corporal seguida de morte\" ...\n $ Ano        : num [1:20957] 2022 2022 2022 2022 2022 ...\n $ MÃªs        : chr [1:20957] \"janeiro\" \"janeiro\" \"janeiro\" \"janeiro\" ...\n $ OcorrÃªncias: num [1:20957] 31 50 10 0 0 0 72 0 22 34 ...\n\nhead(segur)\n\n# A tibble: 6 Ã— 5\n  UF    `Tipo Crime`                      Ano MÃªs     OcorrÃªncias\n  <chr> <chr>                           <dbl> <chr>         <dbl>\n1 Acre  Estupro                          2022 janeiro          31\n2 Acre  Furto de veÃ­culo                 2022 janeiro          50\n3 Acre  HomicÃ­dio doloso                 2022 janeiro          10\n4 Acre  LesÃ£o corporal seguida de morte  2022 janeiro           0\n5 Acre  Roubo a instituiÃ§Ã£o financeira   2022 janeiro           0\n6 Acre  Roubo de carga                   2022 janeiro           0"
  },
  {
    "objectID": "semanas/Aula01A.html#bibliotecas",
    "href": "semanas/Aula01A.html#bibliotecas",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Bibliotecas",
    "text": "Bibliotecas\nVamos carregar as bibliotecas que serÃ£o usadas na manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados.\nO pacote tidyverse carrega diversos pacotes muito uteis na manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados\n\nlibrary(\"tidyverse\")\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.2 â”€â”€\nâœ” ggplot2 3.3.6     âœ” purrr   0.3.4\nâœ” tibble  3.1.8     âœ” dplyr   1.0.9\nâœ” tidyr   1.2.0     âœ” stringr 1.4.0\nâœ” readr   2.1.2     âœ” forcats 0.5.1\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\n\n\n\nglimpse(dados_seg)\n\nRows: 20,686\nColumns: 5\n$ UF           <chr> \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"â€¦\n$ `Tipo Crime` <chr> \"Estupro\", \"Furto de veÃ­culo\", \"HomicÃ­dio doloso\", \"LesÃ£oâ€¦\n$ Ano          <dbl> 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 202â€¦\n$ MÃªs          <chr> \"janeiro\", \"janeiro\", \"janeiro\", \"janeiro\", \"janeiro\", \"jâ€¦\n$ OcorrÃªncias  <dbl> 31, 50, 10, 0, 0, 0, 72, 0, 22, 34, 55, 10, 0, 0, 0, 48, â€¦\n\nunique(dados_seg$UF)\n\n [1] \"Acre\"                \"Alagoas\"             \"AmapÃ¡\"              \n [4] \"Amazonas\"            \"Bahia\"               \"CearÃ¡\"              \n [7] \"Distrito Federal\"    \"EspÃ­rito Santo\"      \"GoiÃ¡s\"              \n[10] \"MaranhÃ£o\"            \"Mato Grosso\"         \"Mato Grosso do Sul\" \n[13] \"Minas Gerais\"        \"ParÃ¡\"                \"ParaÃ­ba\"            \n[16] \"ParanÃ¡\"              \"Pernambuco\"          \"PiauÃ­\"              \n[19] \"Rio Grande do Norte\" \"Rio Grande do Sul\"   \"RondÃ´nia\"           \n[22] \"Roraima\"             \"Santa Catarina\"      \"SÃ£o Paulo\"          \n[25] \"Sergipe\"             \"Tocantins\"           \"Rio de Janeiro\"     \n\ndados_segRJ <- dados_seg %>% filter(UF==\"Rio de Janeiro\")\nsummary(dados_segRJ)\n\n      UF             Tipo Crime             Ano           MÃªs           \n Length:756         Length:756         Min.   :2015   Length:756        \n Class :character   Class :character   1st Qu.:2016   Class :character  \n Mode  :character   Mode  :character   Median :2018   Mode  :character  \n                                       Mean   :2018                     \n                                       3rd Qu.:2020                     \n                                       Max.   :2021                     \n  OcorrÃªncias    \n Min.   :   0.0  \n 1st Qu.:  10.0  \n Median : 335.0  \n Mean   : 683.3  \n 3rd Qu.: 744.5  \n Max.   :5358.0  \n\n\n\nunique(dados_segRJ$`Tipo Crime`)\n\n[1] \"Estupro\"                             \"Furto de veÃ­culo\"                   \n[3] \"HomicÃ­dio doloso\"                    \"LesÃ£o corporal seguida de morte\"    \n[5] \"Roubo a instituiÃ§Ã£o financeira\"      \"Roubo de carga\"                     \n[7] \"Roubo de veÃ­culo\"                    \"Roubo seguido de morte (latrocÃ­nio)\"\n[9] \"Tentativa de homicÃ­dio\"             \n\ndados_segRJ$`Tipo Crime` <- as.factor(dados_segRJ$`Tipo Crime`)\ndados_segRJ %>% filter(`Tipo Crime`==\"HomicÃ­dio doloso\" ) %>% ggplot(aes(x=as.factor(Ano), y=OcorrÃªncias)) + geom_boxplot()\n\n\n\ndados_segRJ %>% filter(`Tipo Crime`==\"Roubo de veÃ­culo\" ) %>% ggplot(aes(x=as.factor(Ano), y=OcorrÃªncias)) + geom_boxplot()\n\n\n\n\n\nsintese_RJ <- dados_segRJ %>% group_by(Ano,`Tipo Crime`) %>% summarise(total = sum(OcorrÃªncias))\n\n`summarise()` has grouped output by 'Ano'. You can override using the `.groups`\nargument.\n\nsintese_RJ %>% ggplot(aes(x=Ano, y=total, color=`Tipo Crime`)) + geom_point() + geom_line()"
  },
  {
    "objectID": "semanas/Aula10.html#alterando-o-valor-da-probabilidade-priori",
    "href": "semanas/Aula10.html#alterando-o-valor-da-probabilidade-priori",
    "title": "LDA e QDA",
    "section": "Alterando o valor da probabilidade priori",
    "text": "Alterando o valor da probabilidade priori\n\np_chapeu_bayes <- f1*0.15 / (f1*0.15 + f0*(1 - 0.15))\ny_chapeu_bayes <- ifelse(p_chapeu_bayes > 0.5, \"Sim\", \"Nao\")\n\n\nconfusionMatrix(factor(y_chapeu_bayes), conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1839   22\n       Sim   95   45\n                                          \n               Accuracy : 0.9415          \n                 95% CI : (0.9303, 0.9514)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.408           \n                                          \n Mcnemar's Test P-Value : 2.806e-11       \n                                          \n            Sensitivity : 0.67164         \n            Specificity : 0.95088         \n         Pos Pred Value : 0.32143         \n         Neg Pred Value : 0.98818         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02249         \n   Detection Prevalence : 0.06997         \n      Balanced Accuracy : 0.81126         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor Ã© igual a 1 - Accuracy da matriz de confusÃ£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu_bayes)\n\n[1] 0.05847076"
  },
  {
    "objectID": "semanas/Aula10.html#lda---ajustando-probabilidade-limite",
    "href": "semanas/Aula10.html#lda---ajustando-probabilidade-limite",
    "title": "LDA e QDA",
    "section": "LDA - Ajustando probabilidade limite",
    "text": "LDA - Ajustando probabilidade limite\n\np_chapeu <- predict(treina_lda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9804367 0.0195633263\n2 0.9996897 0.0003102714\n3 0.9998980 0.0001019950\n4 0.9877333 0.0122667438\n5 0.9989602 0.0010397555\n6 0.9994672 0.0005327889\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1818   19\n       Sim  116   48\n                                          \n               Accuracy : 0.9325          \n                 95% CI : (0.9206, 0.9431)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3864          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.71642         \n            Specificity : 0.94002         \n         Pos Pred Value : 0.29268         \n         Neg Pred Value : 0.98966         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02399         \n   Detection Prevalence : 0.08196         \n      Balanced Accuracy : 0.82822         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor Ã© igual a 1 - Accuracy da matriz de confusÃ£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu)\n\n[1] 0.06746627"
  },
  {
    "objectID": "semanas/Aula10.html#qda---ajustando-probabilidade-limite",
    "href": "semanas/Aula10.html#qda---ajustando-probabilidade-limite",
    "title": "LDA e QDA",
    "section": "QDA - Ajustando probabilidade limite",
    "text": "QDA - Ajustando probabilidade limite\n\np_chapeu <- predict(treina_qda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9882876 1.171241e-02\n2 0.9999968 3.209822e-06\n3 0.9999998 1.848443e-07\n4 0.9946442 5.355842e-03\n5 0.9999472 5.284669e-05\n6 0.9999916 8.371285e-06\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1798   18\n       Sim  136   49\n                                          \n               Accuracy : 0.923           \n                 95% CI : (0.9105, 0.9343)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3573          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.73134         \n            Specificity : 0.92968         \n         Pos Pred Value : 0.26486         \n         Neg Pred Value : 0.99009         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02449         \n   Detection Prevalence : 0.09245         \n      Balanced Accuracy : 0.83051         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula06A.html",
    "href": "semanas/Aula06A.html",
    "title": "Explorando Dados",
    "section": "",
    "text": "library(tidyverse)\ndata(iris)"
  },
  {
    "objectID": "semanas/Aula06A.html#o-que-temos-aqui",
    "href": "semanas/Aula06A.html#o-que-temos-aqui",
    "title": "Explorando Dados",
    "section": "O que temos aqui?",
    "text": "O que temos aqui?\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\niris %>% count(Species)\n\n     Species  n\n1     setosa 50\n2 versicolor 50\n3  virginica 50"
  },
  {
    "objectID": "semanas/Aula06A.html#quais-sÃ£o-as-mÃ©dias",
    "href": "semanas/Aula06A.html#quais-sÃ£o-as-mÃ©dias",
    "title": "Explorando Dados",
    "section": "Quais sÃ£o as mÃ©dias?",
    "text": "Quais sÃ£o as mÃ©dias?\n\niris %>% \n  group_by(Species) %>% \n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 3 Ã— 5\n  Species    Sepal.Length Sepal.Width Petal.Length Petal.Width\n  <fct>             <dbl>       <dbl>        <dbl>       <dbl>\n1 setosa             5.01        3.43         1.46       0.246\n2 versicolor         5.94        2.77         4.26       1.33 \n3 virginica          6.59        2.97         5.55       2.03"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis",
    "text": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Sepal.Width, y=Sepal.Length, \n                                   color=Species)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis-2",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis-2",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis 2",
    "text": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis 2\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Sepal.Width, y=Sepal.Length, color=Species)) +\n  geom_point() + geom_smooth(method = \"lm\", se=FALSE)"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis-3",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis-3",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis 3",
    "text": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis 3\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Petal.Width, y=Petal.Length, \n                                   color=Species)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis-4",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relaÃ§Ã£o-entre-as-variÃ¡veis-4",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis 4",
    "text": "Vamos ver se temos alguma relaÃ§Ã£o entre as variÃ¡veis 4\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Petal.Width, y=Petal.Length, color=Species)) +\n  geom_point() + geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.width",
    "href": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.width",
    "title": "Explorando Dados",
    "section": "Vamos ver como se distribui o Petal.Width",
    "text": "Vamos ver como se distribui o Petal.Width\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Petal.Width, \n                                   fill=Species)) + \n                                   geom_histogram()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.length",
    "href": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.length",
    "title": "Explorando Dados",
    "section": "Vamos ver como se distribui o Petal.Length",
    "text": "Vamos ver como se distribui o Petal.Length\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Petal.Length, fill=Species)) + \n  geom_histogram()"
  }
]