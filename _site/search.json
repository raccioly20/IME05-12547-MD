[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre",
    "section": "",
    "text": "Esta √© a p√°gina principal do site da disciplina Minera√ß√£o de Dados IME05-12547.\nEste site foi constru√≠do usando Quarto e foi baseado em diversas fontes de informa√ß√£o obtidas na internet.\nSeguem algumas refer√™ncias √∫teis para o Quarto:\nQuarto\nCurso da Duke University\nComo criar um blog com o Quarto\nWebnar do Quarto"
  },
  {
    "objectID": "acesso-rstudio.html",
    "href": "acesso-rstudio.html",
    "title": "RStudio Cloud",
    "section": "",
    "text": "RStudio"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IME05-12547 Minera√ß√£o de Dados",
    "section": "",
    "text": "Aqui voc√™s v√£o encontrar alguns dos exemplos apresentados em aula, com uso do R. O objetivo √© mostrar as possibilidades de aplica√ß√£o do R nesta disciplina.\nOs c√≥digos apresentados em aula ser√£o colocado por aqui tamb√©m.\n[üìñ] Aula 01\n[üìñ] Aula01A\n[üìñ] Aula02\n[üìñ] Aula03\n[üìñ] Aula04\n[üìñ] Aula05\n[üìñ] Aula06\n[üìñ] Aula7.1\n[üìñ] Aula7.2\n[üìñ] Aula7.3\n[üìñ] Aula7.4\n[üìñ] Aula08\n[üìñ] Aula09\n[üìñ] Aula09A\n[üìñ] Aula10\n[üìñ] Aula11\n[üìñ] Aula12"
  },
  {
    "objectID": "semanas/Aula01.html#lendo-dados-de-arquivos-csv",
    "href": "semanas/Aula01.html#lendo-dados-de-arquivos-csv",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de arquivos csv",
    "text": "Lendo dados de arquivos csv\n\nlibrary(readr)\nurl <- \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-acervo-de-dados-tecnicos/tabela-pocos.csv\"\n## O read_delim permite que seja definido o tipo de delimitador dos dados\npocos <- read_delim(url, delim = \";\", locale= locale(decimal_mark = \",\"), col_names = TRUE)\n\nRows: 30255 Columns: 60\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \";\"\nchr (51): POCO, CADASTRO, OPERADOR, POCO_OPERADOR, ESTADO, BACIA, BLOCO, SIG...\ndbl  (8): LATITUDE_BASE_DD, LONGITUDE_BASE_DD, PROFUNDIDADE_VERTICAL_M, PROF...\nlgl  (1): UNIDADE_ESTRATIGRAFICA\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(pocos)\n\n# A tibble: 6 √ó 60\n  POCO  CADAS‚Ä¶¬π OPERA‚Ä¶¬≤ POCO_‚Ä¶¬≥ ESTADO BACIA BLOCO SIG_C‚Ä¶‚Å¥ CAMPO TERRA‚Ä¶‚Åµ POCO_‚Ä¶‚Å∂\n  <chr> <chr>   <chr>   <chr>   <chr>  <chr> <chr> <chr>   <chr> <chr>   <chr>  \n1 7-PC‚Ä¶ 721000‚Ä¶ 3R Mac‚Ä¶ 7PC  0‚Ä¶ RN     Poti‚Ä¶ PC    \"PC   \" PORT‚Ä¶ T       N      \n2 7-CO‚Ä¶ 742810‚Ä¶ Petrob‚Ä¶ 7CO  0‚Ä¶ RJ     Camp‚Ä¶ CO    \"CO   \" CORV‚Ä¶ M       N      \n3 7-BA‚Ä¶ 202400‚Ä¶ Petrob‚Ä¶ 7BA  0‚Ä¶ BA     Rec√¥‚Ä¶ BA    \"BA   \" BURA‚Ä¶ T       N      \n4 7-ET‚Ä¶ 721000‚Ä¶ Petrob‚Ä¶ 7ET  0‚Ä¶ RN     Poti‚Ä¶ ET    \"ET   \" ESTR‚Ä¶ T       N      \n5 4-FS‚Ä¶ 342700‚Ä¶ Petrob‚Ä¶ 4FSL 0‚Ä¶ ES     Esp√≠‚Ä¶ FSL   \"FSL  \" FAZE‚Ä¶ T       N      \n6 7-CA‚Ä¶ 721000‚Ä¶ Petrob‚Ä¶ 7CAM 0‚Ä¶ RN     Poti‚Ä¶ CAM   \"CAM  \" CANT‚Ä¶ T       N      \n# ‚Ä¶ with 49 more variables: TIPO <chr>, CATEGORIA <chr>, RECLASSIFICACAO <chr>,\n#   SITUACAO <chr>, INICIO <chr>, TERMINO <chr>, CONCLUSAO <chr>,\n#   TITULARIDADE <chr>, LATITUDE_BASE_4C <chr>, LONGITUDE_BASE_4C <chr>,\n#   LATITUDE_BASE_DD <dbl>, LONGITUDE_BASE_DD <dbl>, DATUM_HORIZONTAL <chr>,\n#   TIPO_DE_COORDENADA_DE_BASE <chr>, DIRECAO <chr>,\n#   PROFUNDIDADE_VERTICAL_M <dbl>, PROFUNDIDADE_SONDADOR_M <dbl>,\n#   PROFUNDIDADE_MEDIDA_M <dbl>, REFERENCIA_DE_PROFUNDIDADE <chr>, ‚Ä¶\n# ‚Ñπ Use `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula01.html#bibliotecas",
    "href": "semanas/Aula01.html#bibliotecas",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Bibliotecas",
    "text": "Bibliotecas\nVamos carregar as bibliotecas que ser√£o usadas na manipula√ß√£o e visualiza√ß√£o de dados.\nO pacote tidyverse carrega diversos pacotes muito uteis na manipula√ß√£o e visualiza√ß√£o de dados\n\nlibrary(\"tidyverse\")\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.3.6     ‚úî dplyr   1.0.9\n‚úî tibble  3.1.8     ‚úî stringr 1.4.0\n‚úî tidyr   1.2.0     ‚úî forcats 0.5.1\n‚úî purrr   0.3.4     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\n\nVamos primeiro conhecer o que tem na base de dados pocos. A base de dados possui 30255 linhas\n\nclass(pocos)  # Tipo de base de dados\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nsummary(pocos) # Sumario da base de dados\n\n     POCO             CADASTRO           OPERADOR         POCO_OPERADOR     \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    ESTADO             BACIA              BLOCO            SIG_CAMPO        \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    CAMPO            TERRA_MAR         POCO_POS_ANP           TIPO          \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  CATEGORIA         RECLASSIFICACAO      SITUACAO            INICIO         \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   TERMINO           CONCLUSAO         TITULARIDADE       LATITUDE_BASE_4C  \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n LONGITUDE_BASE_4C  LATITUDE_BASE_DD  LONGITUDE_BASE_DD DATUM_HORIZONTAL  \n Length:30255       Min.   :-32.927   Min.   :-73.38    Length:30255      \n Class :character   1st Qu.:-12.691   1st Qu.:-39.61    Class :character  \n Mode  :character   Median :-10.710   Median :-37.83    Mode  :character  \n                    Mean   :-11.480   Mean   :-38.83                      \n                    3rd Qu.: -5.327   3rd Qu.:-36.98                      \n                    Max.   :  4.528   Max.   :-34.83                      \n                                                                          \n TIPO_DE_COORDENADA_DE_BASE   DIRECAO          PROFUNDIDADE_VERTICAL_M\n Length:30255               Length:30255       Min.   :-62550.0       \n Class :character           Class :character   1st Qu.:  -772.4       \n Mode  :character           Mode  :character   Median :     0.0       \n                                               Mean   :  -254.4       \n                                               3rd Qu.:   138.0       \n                                               Max.   :528084.0       \n                                               NA's   :19336          \n PROFUNDIDADE_SONDADOR_M PROFUNDIDADE_MEDIDA_M REFERENCIA_DE_PROFUNDIDADE\n Min.   :    0           Min.   :    0.0       Length:30255              \n 1st Qu.:  485           1st Qu.:  347.5       Class :character          \n Median :  999           Median :  870.2       Mode  :character          \n Mean   : 1507           Mean   : 1583.9                                 \n 3rd Qu.: 2230           3rd Qu.: 2644.0                                 \n Max.   :62750           Max.   :62800.0                                 \n NA's   :1043            NA's   :17787                                   \n MESA_ROTATIVA     COTA_ALTIMETRICA_M LAMINA_D_AGUA_M   DATUM_VERTICAL    \n Min.   :   0.00   Min.   :    0.00   Min.   :    0.0   Length:30255      \n 1st Qu.:  19.00   1st Qu.:    0.00   1st Qu.:    0.0   Class :character  \n Median :  32.40   Median :   12.30   Median :    0.0   Mode  :character  \n Mean   :  57.34   Mean   :   41.00   Mean   :  284.2                     \n 3rd Qu.:  75.68   3rd Qu.:   56.99   3rd Qu.:  116.0                     \n Max.   :2220.00   Max.   :30940.00   Max.   :30940.0                     \n                   NA's   :17225      NA's   :14761                       \n UNIDADE_ESTRATIGRAFICA GEOLOGIA_GRUPO_FINAL GEOLOGIA_FORMACAO_FINAL\n Mode:logical           Length:30255         Length:30255           \n NA's:30255             Class :character     Class :character       \n                        Mode  :character     Mode  :character       \n                                                                    \n                                                                    \n                                                                    \n                                                                    \n GEOLOGIA_MEMBRO_FINAL     CDPE               AGP                 PC           \n Length:30255          Length:30255       Length:30255       Length:30255      \n Class :character      Class :character   Class :character   Class :character  \n Mode  :character      Mode  :character   Mode  :character   Mode  :character  \n                                                                               \n                                                                               \n                                                                               \n                                                                               \n     PAG            PERFIS_CONVENCIONAIS DURANTE_PERFURACAO PERFIS_DIGITAIS   \n Length:30255       Length:30255         Length:30255       Length:30255      \n Class :character   Class :character     Class :character   Class :character  \n Mode  :character   Mode  :character     Mode  :character   Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n PERFIS_PROCESSADOS PERFIS_ESPECIAIS   AMOSTRA_LATERAL      SISMICA         \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n TABELA_TEMPO_PROFUNDIDADE DADOS_DIRECIONAIS  TESTE_A_CABO      \n Length:30255              Length:30255       Length:30255      \n Class :character          Class :character   Class :character  \n Mode  :character          Mode  :character   Mode  :character  \n                                                                \n                                                                \n                                                                \n                                                                \n TESTE_DE_FORMACAO   CANHONEIO          TESTEMUNHO         GEOQUIMICA       \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  SIG_SONDA          NOM_SONDA         DHA_ATUALIZACAO    ATINGIU_PRESAL    \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "semanas/Aula01.html#dados-de-po√ßos",
    "href": "semanas/Aula01.html#dados-de-po√ßos",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Dados de po√ßos",
    "text": "Dados de po√ßos\nOs dados da tabela po√ßos tem 60 colunas.\nVamos inicialmente selecionar algumas colunas para podermos trabalhar com os dados.\nAs colunas que vamos trabalhar s√£o:\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\nPara selecionar colunas usamos a fun√ß√£o select\n\n## Vamos selecionar as colunas listadas acima\npocos_01 <- pocos %>% select(POCO,OPERADOR,ESTADO,BACIA,BLOCO, CAMPO,TERRA_MAR,CATEGORIA,SITUACAO, INICIO, TERMINO, PROFUNDIDADE_MEDIDA_M)\nhead(pocos_01)\n\n# A tibble: 6 √ó 12\n  POCO   OPERA‚Ä¶¬π ESTADO BACIA BLOCO CAMPO TERRA‚Ä¶¬≤ CATEG‚Ä¶¬≥ SITUA‚Ä¶‚Å¥ INICIO TERMINO\n  <chr>  <chr>   <chr>  <chr> <chr> <chr> <chr>   <chr>   <chr>   <chr>  <chr>  \n1 7-PC-‚Ä¶ 3R Mac‚Ä¶ RN     Poti‚Ä¶ PC    PORT‚Ä¶ T       Desenv‚Ä¶ ARRASA‚Ä¶ 25/08‚Ä¶ 27/08/‚Ä¶\n2 7-CO-‚Ä¶ Petrob‚Ä¶ RJ     Camp‚Ä¶ CO    CORV‚Ä¶ M       Desenv‚Ä¶ ABANDO‚Ä¶ 26/08‚Ä¶ 11/10/‚Ä¶\n3 7-BA-‚Ä¶ Petrob‚Ä¶ BA     Rec√¥‚Ä¶ BA    BURA‚Ä¶ T       Desenv‚Ä¶ ABANDO‚Ä¶ 28/08‚Ä¶ 06/09/‚Ä¶\n4 7-ET-‚Ä¶ Petrob‚Ä¶ RN     Poti‚Ä¶ ET    ESTR‚Ä¶ T       Desenv‚Ä¶ PRODUZ‚Ä¶ 30/05‚Ä¶ 31/05/‚Ä¶\n5 4-FSL‚Ä¶ Petrob‚Ä¶ ES     Esp√≠‚Ä¶ FSL   FAZE‚Ä¶ T       Pionei‚Ä¶ ABANDO‚Ä¶ 31/05‚Ä¶ 30/06/‚Ä¶\n6 7-CAM‚Ä¶ Petrob‚Ä¶ RN     Poti‚Ä¶ CAM   CANT‚Ä¶ T       Desenv‚Ä¶ INJETA‚Ä¶ 01/06‚Ä¶ 04/06/‚Ä¶\n# ‚Ä¶ with 1 more variable: PROFUNDIDADE_MEDIDA_M <dbl>, and abbreviated variable\n#   names ¬π‚ÄãOPERADOR, ¬≤‚ÄãTERRA_MAR, ¬≥‚ÄãCATEGORIA, ‚Å¥‚ÄãSITUACAO\n# ‚Ñπ Use `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula01.html#manipula√ß√£o-de-dados",
    "href": "semanas/Aula01.html#manipula√ß√£o-de-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Manipula√ß√£o de dados",
    "text": "Manipula√ß√£o de dados\nVamos eliminar as linhas de dados que apresenta dados ausentes ‚ÄúNA‚Äù nas colunas TERMINO e PROFUNDIDADE_MEDIDA_M.\n\nsum(is.na(pocos_01))\n\n[1] 30235\n\nsum(is.na(pocos_01$INICIO))\n\n[1] 0\n\nsum(is.na(pocos_01$TERMINO))\n\n[1] 1861\n\nsum(is.na(pocos_01$PROFUNDIDADE_MEDIDA_M))\n\n[1] 17787\n\npocos_01 <- pocos_01 %>% drop_na(any_of(c(\"TERMINO\",\n                                          \"PROFUNDIDADE_MEDIDA_M\")))\n# melhorando a visualiza√ß√£o dos dados\nknitr::kable(\n  head(pocos_01, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_01.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_01.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n1-MOR-1-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nPioneiro\nFECHADO\n12/06/1994 00:00\n28/06/1994 00:00\n0.0\n\n\n7-REP-28-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nDesenvolvimento\nINJETANDO\n12/04/1995 00:00\n18/04/1995 00:00\n0.0\n\n\n7-ET-647-RN\nPetrobras\nRN\nPotiguar\nET\nESTREITO\nT\nDesenvolvimento\nINJETANDO\n16/04/1995 00:00\n18/04/1995 00:00\n277.2\n\n\n7-MRL-54-RJS\nPetrobras\nRJ\nCampos\nMRL\nMARLIM\nM\nDesenvolvimento\nFECHADO\n30/05/1996 00:00\n13/06/1996 00:00\n0.0\n\n\n7-BVS-13-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nDesenvolvimento\nFECHADO\n06/06/1996 00:00\n15/06/1996 00:00\n0.0\n\n\n9-LUC-31D-AM\nPetrobras\nAM\nSolim√µes\nLUC\nLESTE DO URUCU\nT\nEspecial\nABANDONADO PERMANENTEMENTE\n10/06/1996 00:00\n15/08/1996 00:00\n0.0\n\n\n1-RJS-500-RJS\nPetrobras\nRJ\nCampos\nESP\nESPADARTE\nM\nPioneiro\nABANDONADO PERMANENTEMENTE\n10/06/1996 00:00\n19/07/1996 00:00\n0.0\n\n\n8-MRL-36D-RJS\nPetrobras\nRJ\nCampos\nMRL\nMARLIM\nM\nInje√ß√£o\nFECHADO\n27/10/1993 00:00\n15/11/1993 00:00\n0.0\n\n\n3-ESP-2-RJS\nPetrobras\nRJ\nCampos\nESP\nESPADARTE\nM\nExtens√£o\nABANDONADO PERMANENTEMENTE\n09/05/1995 00:00\n19/06/1995 00:00\n0.0\n\n\n8-AB-49D-RJS\nPetrobras\nRJ\nCampos\nAB\nALBACORA\nM\nInje√ß√£o\nFECHADO\n15/04/1996 00:00\n30/07/1996 00:00\n0.0\n\n\n\n\nsum(is.na(pocos_01))\n\n[1] 4328\n\n\nVeja que existia um grande n√∫mero de dados ausentes\nAntes: 30255 linhas Depois: 10715 linhas"
  },
  {
    "objectID": "semanas/Aula01.html#corrigindo-tipo-de-dados",
    "href": "semanas/Aula01.html#corrigindo-tipo-de-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Corrigindo tipo de dados",
    "text": "Corrigindo tipo de dados\nAs colunas INICIO e TERMINO s√£o datas, mas foram lidas como caracter, vamos corrigir isto!\nPara trabalhar com datas vamos usar o pacote lubridate\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\npocos_01$INICIO <- as_date(pocos_01$INICIO, format=\"%d/%m/%Y\")\npocos_01$TERMINO <- as_date(pocos_01$TERMINO, format=\"%d/%m/%Y\")"
  },
  {
    "objectID": "semanas/Aula01.html#filtrando-dados",
    "href": "semanas/Aula01.html#filtrando-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Filtrando dados",
    "text": "Filtrando dados\nVamos analisar os po√ßos de uma detreminada regi√£o, para isto podemos fltrar os po√ßos de um bloco. Vamos filtrar somente os po√ßos do CAMPO PEREGRINO usando a fun√ß√£o filter.\n\npocos_02 <- pocos_01 %>% filter(CAMPO==\"PEREGRINO\") ##  \nsummary(pocos_02)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:94          Length:94          Length:94          Length:94         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:94          Length:94          Length:94          Length:94         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:94          Min.   :1994-07-07   Min.   :1994-08-17  \n Class :character   1st Qu.:2011-12-16   1st Qu.:2012-01-27  \n Mode  :character   Median :2013-07-02   Median :2013-08-31  \n                    Mean   :2013-11-27   Mean   :2013-12-27  \n                    3rd Qu.:2015-10-06   3rd Qu.:2015-10-29  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M\n Min.   :   0         \n 1st Qu.:4457         \n Median :4925         \n Mean   :5136         \n 3rd Qu.:6213         \n Max.   :8613         \n\nknitr::kable(\n  head(pocos_02, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_02.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_02.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n1-RJS-498-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nPioneiro\nABANDONADO PERMANENTEMENTE\n1994-07-07\n1994-08-17\n0.00\n\n\n7-PRG-2HB-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2011-01-16\n2011-02-03\n4676.00\n\n\n7-PRG-64HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2018-11-11\n2018-12-05\n5790.00\n\n\n7-PRG-65HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2019-01-05\n2019-01-20\n4386.00\n\n\n7-PRG-73HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2022-02-25\n2022-03-09\n5694.00\n\n\n8-PRG-68H-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nInje√ß√£o\nEM AVALIA√á√ÉO\n2019-08-16\n2019-09-12\n4133.00\n\n\n7-PRG-66HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2019-02-11\n2019-03-07\n6529.00\n\n\n7-PRG-71HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2020-12-08\n2020-12-11\n3646.00\n\n\n7-PRG-71HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2020-12-18\n2020-01-06\n5404.00\n\n\n7-PRG-40HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2014-07-27\n2014-08-03\n4797.74\n\n\n\n\n\n\nAvaliando os dados\nOs po√ßos possuem diversas categorias, vamos ver que categorias existem nestes po√ßos do bloco BES-100.\n\nunique(pocos_02$CATEGORIA)\n\n[1] \"Pioneiro\"        \"Desenvolvimento\" \"Inje√ß√£o\"         \"Especial\"       \n[5] \"Extens√£o\"       \n\n\n\n\nFiltrando po√ßos de desenvolvimento\n\npocos_03 <- pocos_02 %>% filter(CATEGORIA==\"Desenvolvimento\") ##  \nsummary(pocos_03)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:73          Min.   :2010-11-10   Min.   :2010-11-11  \n Class :character   1st Qu.:2012-02-04   1st Qu.:2012-04-06  \n Mode  :character   Median :2013-10-20   Median :2013-11-15  \n                    Mean   :2014-07-23   Mean   :2014-08-21  \n                    3rd Qu.:2016-06-23   3rd Qu.:2016-08-27  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M\n Min.   : 742         \n 1st Qu.:4543         \n Median :5066         \n Mean   :5385         \n 3rd Qu.:6383         \n Max.   :8613         \n\nknitr::kable(\n  head(pocos_03, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_03.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_03.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n7-PRG-2HB-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2011-01-16\n2011-02-03\n4676.00\n\n\n7-PRG-64HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2018-11-11\n2018-12-05\n5790.00\n\n\n7-PRG-65HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2019-01-05\n2019-01-20\n4386.00\n\n\n7-PRG-73HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2022-02-25\n2022-03-09\n5694.00\n\n\n7-PRG-66HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2019-02-11\n2019-03-07\n6529.00\n\n\n7-PRG-71HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2020-12-08\n2020-12-11\n3646.00\n\n\n7-PRG-71HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2020-12-18\n2020-01-06\n5404.00\n\n\n7-PRG-40HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2014-07-27\n2014-08-03\n4797.74\n\n\n7-PRG-8HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2011-11-07\n2011-12-02\n4959.87\n\n\n7-PRG-72HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2021-11-17\n2021-12-08\n5302.00"
  },
  {
    "objectID": "semanas/Aula01.html#criando-uma-coluna-com-mutate",
    "href": "semanas/Aula01.html#criando-uma-coluna-com-mutate",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Criando uma coluna com mutate",
    "text": "Criando uma coluna com mutate\nVamos criar uma coluna que nos dar√° a dura√ß√£o da perfura√ß√£o dos po√ßos.\n\npocos_03$INICIO[1]\n\n[1] \"2011-01-16\"\n\npocos_03$TERMINO[1]\n\n[1] \"2011-02-03\"\n\npocos_03$TERMINO[1] - pocos_03$INICIO[1]\n\nTime difference of 18 days\n\ndifftime(pocos_03$TERMINO[1], pocos_03$INICIO[1], units = \"days\")\n\nTime difference of 18 days\n\ntempo <- difftime(pocos_03$TERMINO[1], pocos_03$INICIO[1], units = \"days\")\nstr(tempo)\n\n 'difftime' num 18\n - attr(*, \"units\")= chr \"days\"\n\n(pocos_03$INICIO[1] %--% pocos_03$TERMINO[1])/ddays(1)\n\n[1] 18\n\npocos_03 <- pocos_03 %>% mutate(TPERF = (INICIO %--% TERMINO)/ddays(1))\nsummary(pocos_03)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:73          Min.   :2010-11-10   Min.   :2010-11-11  \n Class :character   1st Qu.:2012-02-04   1st Qu.:2012-04-06  \n Mode  :character   Median :2013-10-20   Median :2013-11-15  \n                    Mean   :2014-07-23   Mean   :2014-08-21  \n                    3rd Qu.:2016-06-23   3rd Qu.:2016-08-27  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M     TPERF       \n Min.   : 742          Min.   :-347.0  \n 1st Qu.:4543          1st Qu.:  16.0  \n Median :5066          Median :  24.0  \n Mean   :5385          Mean   :  28.9  \n 3rd Qu.:6383          3rd Qu.:  37.0  \n Max.   :8613          Max.   : 260.0  \n\n\n\nEliminando colunas com tempos negativos\n\npocos_03 <- pocos_03 %>% filter(TPERF > 0)"
  },
  {
    "objectID": "semanas/Aula01.html#visualizando-os-dados-de-peregrino",
    "href": "semanas/Aula01.html#visualizando-os-dados-de-peregrino",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Visualizando os dados de PEREGRINO",
    "text": "Visualizando os dados de PEREGRINO\n\nBox-Plot\n\nggplot(pocos_03, aes(x=CAMPO, y=TPERF)) +\n  geom_boxplot()\n\n\n\n\nVeja que existem alguns tempos bem elevados que est√£o representados por pontos no box-plot. Eles podem ser considerados pontos afastados (outliers), que neste caso vamos eliminar.\n\npocos_04 <- pocos_03 %>% filter(TPERF < 100)\nggplot(pocos_04, aes(x=CAMPO, y=TPERF)) +\n  geom_boxplot()\n\n\n\n\n\n\nHistograma\n\nggplot(pocos_04, aes(x=TPERF)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nVeja que desta forma o ggplot usa o seu padr√£o de 30 faixas de dados, que geralmente n√£o √© o mais adequado.\nVamos usar uma regra adequada para defini√ß√£o de n√∫mero de faixas.\n\n\nCriando um histograma usando a regra de Sturges\nA regra de Sturges indica 7 faixas enquanto que o padr√£o do ggplot2 √© 30.\n\nggplot(pocos_04, aes(x = TPERF)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(pocos_04)),0))\n\n\n\n\nVeja que agora temos um histograma mais suave.\n\n\nGr√°fico de Dispers√£o\n\nggplot(pocos_04, aes(x=PROFUNDIDADE_MEDIDA_M, y=TPERF)) + \n  geom_point()\n\n\n\n\nPodemos perceber que h√° uma rela√ß√£o entre o tempo de perfura√ß√£o e a profundidade do po√ßo.\nTamb√©m √© poss√≠vel se perceber que ainda existem dados com comportamentos estranhos. Po√ßos rasos com profundidade muito diferente dos demais, al√©m disso um po√ßo muito profundo com dura√ß√£o muito pequena.\nSe fossemos construir um modelo certamente ter√≠mos que investigar o porque destes comportamentos.\n\n\nAlterando nome das colunas\n\nnames(pocos_04)\n\n [1] \"POCO\"                  \"OPERADOR\"              \"ESTADO\"               \n [4] \"BACIA\"                 \"BLOCO\"                 \"CAMPO\"                \n [7] \"TERRA_MAR\"             \"CATEGORIA\"             \"SITUACAO\"             \n[10] \"INICIO\"                \"TERMINO\"               \"PROFUNDIDADE_MEDIDA_M\"\n[13] \"TPERF\"                \n\nnames(pocos_04) <- tolower(names(pocos_04))\nnames(pocos_04)\n\n [1] \"poco\"                  \"operador\"              \"estado\"               \n [4] \"bacia\"                 \"bloco\"                 \"campo\"                \n [7] \"terra_mar\"             \"categoria\"             \"situacao\"             \n[10] \"inicio\"                \"termino\"               \"profundidade_medida_m\"\n[13] \"tperf\""
  },
  {
    "objectID": "semanas/Aula01A.html#lendo-dados-de-arquivos-xlsx",
    "href": "semanas/Aula01A.html#lendo-dados-de-arquivos-xlsx",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de arquivos xlsx",
    "text": "Lendo dados de arquivos xlsx\n\nlibrary(readxl)\ndados_seg <- read_xlsx(\"C:/Users/ricar/OneDrive/Documents/GitHub/IME05-12547/indicadoressegurancapublicauf.xlsx\", col_names = TRUE, sheet = \"Ocorr√™ncias\")\nhead(dados_seg)\n\n# A tibble: 6 √ó 5\n  UF    `Tipo Crime`                      Ano M√™s     Ocorr√™ncias\n  <chr> <chr>                           <dbl> <chr>         <dbl>\n1 Acre  Estupro                          2022 janeiro          31\n2 Acre  Furto de ve√≠culo                 2022 janeiro          50\n3 Acre  Homic√≠dio doloso                 2022 janeiro          10\n4 Acre  Les√£o corporal seguida de morte  2022 janeiro           0\n5 Acre  Roubo a institui√ß√£o financeira   2022 janeiro           0\n6 Acre  Roubo de carga                   2022 janeiro           0\n\nstr(dados_seg)\n\ntibble [20,686 √ó 5] (S3: tbl_df/tbl/data.frame)\n $ UF         : chr [1:20686] \"Acre\" \"Acre\" \"Acre\" \"Acre\" ...\n $ Tipo Crime : chr [1:20686] \"Estupro\" \"Furto de ve√≠culo\" \"Homic√≠dio doloso\" \"Les√£o corporal seguida de morte\" ...\n $ Ano        : num [1:20686] 2022 2022 2022 2022 2022 ...\n $ M√™s        : chr [1:20686] \"janeiro\" \"janeiro\" \"janeiro\" \"janeiro\" ...\n $ Ocorr√™ncias: num [1:20686] 31 50 10 0 0 0 72 0 22 34 ..."
  },
  {
    "objectID": "semanas/Aula01A.html#lendo-dados-de-atrav√©s-de-uma-url",
    "href": "semanas/Aula01A.html#lendo-dados-de-atrav√©s-de-uma-url",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de atrav√©s de uma url",
    "text": "Lendo dados de atrav√©s de uma url\n\nlibrary(readxl)\nlibrary(httr)\nurl <- \"http://dados.mj.gov.br/dataset/210b9ae2-21fc-4986-89c6-2006eb4db247/resource/feeae05e-faba-406c-8a4a-512aec91a9d1/download/indicadoressegurancapublicauf.xlsx\"\nGET(url, write_disk(tf <- tempfile(fileext = \".xlsx\")))\n\nResponse [https://dados.mj.gov.br/dataset/210b9ae2-21fc-4986-89c6-2006eb4db247/resource/feeae05e-faba-406c-8a4a-512aec91a9d1/download/indicadoressegurancapublicauf.xlsx]\n  Date: 2022-08-12 18:33\n  Status: 200\n  Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n  Size: 1.02 MB\n<ON DISK>  C:\\Users\\ricar\\AppData\\Local\\Temp\\Rtmp4wadjp\\file2d6462e33ec0.xlsx\n\nsegur <- read_xlsx(tf, sheet = \"Ocorr√™ncias\")\nstr(segur)\n\ntibble [20,957 √ó 5] (S3: tbl_df/tbl/data.frame)\n $ UF         : chr [1:20957] \"Acre\" \"Acre\" \"Acre\" \"Acre\" ...\n $ Tipo Crime : chr [1:20957] \"Estupro\" \"Furto de ve√≠culo\" \"Homic√≠dio doloso\" \"Les√£o corporal seguida de morte\" ...\n $ Ano        : num [1:20957] 2022 2022 2022 2022 2022 ...\n $ M√™s        : chr [1:20957] \"janeiro\" \"janeiro\" \"janeiro\" \"janeiro\" ...\n $ Ocorr√™ncias: num [1:20957] 31 50 10 0 0 0 72 0 22 34 ...\n\nhead(segur)\n\n# A tibble: 6 √ó 5\n  UF    `Tipo Crime`                      Ano M√™s     Ocorr√™ncias\n  <chr> <chr>                           <dbl> <chr>         <dbl>\n1 Acre  Estupro                          2022 janeiro          31\n2 Acre  Furto de ve√≠culo                 2022 janeiro          50\n3 Acre  Homic√≠dio doloso                 2022 janeiro          10\n4 Acre  Les√£o corporal seguida de morte  2022 janeiro           0\n5 Acre  Roubo a institui√ß√£o financeira   2022 janeiro           0\n6 Acre  Roubo de carga                   2022 janeiro           0"
  },
  {
    "objectID": "semanas/Aula01A.html#bibliotecas",
    "href": "semanas/Aula01A.html#bibliotecas",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Bibliotecas",
    "text": "Bibliotecas\nVamos carregar as bibliotecas que ser√£o usadas na manipula√ß√£o e visualiza√ß√£o de dados.\nO pacote tidyverse carrega diversos pacotes muito uteis na manipula√ß√£o e visualiza√ß√£o de dados\n\nlibrary(\"tidyverse\")\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.3.6     ‚úî purrr   0.3.4\n‚úî tibble  3.1.8     ‚úî dplyr   1.0.9\n‚úî tidyr   1.2.0     ‚úî stringr 1.4.0\n‚úî readr   2.1.2     ‚úî forcats 0.5.1\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\n\n\nglimpse(dados_seg)\n\nRows: 20,686\nColumns: 5\n$ UF           <chr> \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"‚Ä¶\n$ `Tipo Crime` <chr> \"Estupro\", \"Furto de ve√≠culo\", \"Homic√≠dio doloso\", \"Les√£o‚Ä¶\n$ Ano          <dbl> 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 202‚Ä¶\n$ M√™s          <chr> \"janeiro\", \"janeiro\", \"janeiro\", \"janeiro\", \"janeiro\", \"j‚Ä¶\n$ Ocorr√™ncias  <dbl> 31, 50, 10, 0, 0, 0, 72, 0, 22, 34, 55, 10, 0, 0, 0, 48, ‚Ä¶\n\nunique(dados_seg$UF)\n\n [1] \"Acre\"                \"Alagoas\"             \"Amap√°\"              \n [4] \"Amazonas\"            \"Bahia\"               \"Cear√°\"              \n [7] \"Distrito Federal\"    \"Esp√≠rito Santo\"      \"Goi√°s\"              \n[10] \"Maranh√£o\"            \"Mato Grosso\"         \"Mato Grosso do Sul\" \n[13] \"Minas Gerais\"        \"Par√°\"                \"Para√≠ba\"            \n[16] \"Paran√°\"              \"Pernambuco\"          \"Piau√≠\"              \n[19] \"Rio Grande do Norte\" \"Rio Grande do Sul\"   \"Rond√¥nia\"           \n[22] \"Roraima\"             \"Santa Catarina\"      \"S√£o Paulo\"          \n[25] \"Sergipe\"             \"Tocantins\"           \"Rio de Janeiro\"     \n\ndados_segRJ <- dados_seg %>% filter(UF==\"Rio de Janeiro\")\nsummary(dados_segRJ)\n\n      UF             Tipo Crime             Ano           M√™s           \n Length:756         Length:756         Min.   :2015   Length:756        \n Class :character   Class :character   1st Qu.:2016   Class :character  \n Mode  :character   Mode  :character   Median :2018   Mode  :character  \n                                       Mean   :2018                     \n                                       3rd Qu.:2020                     \n                                       Max.   :2021                     \n  Ocorr√™ncias    \n Min.   :   0.0  \n 1st Qu.:  10.0  \n Median : 335.0  \n Mean   : 683.3  \n 3rd Qu.: 744.5  \n Max.   :5358.0  \n\n\n\nunique(dados_segRJ$`Tipo Crime`)\n\n[1] \"Estupro\"                             \"Furto de ve√≠culo\"                   \n[3] \"Homic√≠dio doloso\"                    \"Les√£o corporal seguida de morte\"    \n[5] \"Roubo a institui√ß√£o financeira\"      \"Roubo de carga\"                     \n[7] \"Roubo de ve√≠culo\"                    \"Roubo seguido de morte (latroc√≠nio)\"\n[9] \"Tentativa de homic√≠dio\"             \n\ndados_segRJ$`Tipo Crime` <- as.factor(dados_segRJ$`Tipo Crime`)\ndados_segRJ %>% filter(`Tipo Crime`==\"Homic√≠dio doloso\" ) %>% ggplot(aes(x=as.factor(Ano), y=Ocorr√™ncias)) + geom_boxplot()\n\n\n\ndados_segRJ %>% filter(`Tipo Crime`==\"Roubo de ve√≠culo\" ) %>% ggplot(aes(x=as.factor(Ano), y=Ocorr√™ncias)) + geom_boxplot()\n\n\n\n\n\nsintese_RJ <- dados_segRJ %>% group_by(Ano,`Tipo Crime`) %>% summarise(total = sum(Ocorr√™ncias))\n\n`summarise()` has grouped output by 'Ano'. You can override using the `.groups`\nargument.\n\nsintese_RJ %>% ggplot(aes(x=Ano, y=total, color=`Tipo Crime`)) + geom_point() + geom_line()"
  },
  {
    "objectID": "semanas/Aula02.html",
    "href": "semanas/Aula02.html",
    "title": "Manipula√ß√£o dos dados",
    "section": "",
    "text": "Vamos trabalhar de novo com os dados do gapminder para fazer algumas manipula√ß√µes de dados que s√£o muito √∫teis no dia a dia.\nEste material foi em parte adaptado do curso Data Visualization in R with ggplot2 de Kara Woo\n\nlibrary(\"gapminder\")\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")"
  },
  {
    "objectID": "semanas/Aula02.html#filtrando-2007",
    "href": "semanas/Aula02.html#filtrando-2007",
    "title": "Manipula√ß√£o dos dados",
    "section": "Filtrando 2007",
    "text": "Filtrando 2007\n\n## Cria um extrato do ano de 2007\ndata(gapminder)\nsummary(gapminder)\n\n        country        continent        year         lifeExp     \n Afghanistan:  12   Africa  :624   Min.   :1952   Min.   :23.60  \n Albania    :  12   Americas:300   1st Qu.:1966   1st Qu.:48.20  \n Algeria    :  12   Asia    :396   Median :1980   Median :60.71  \n Angola     :  12   Europe  :360   Mean   :1980   Mean   :59.47  \n Argentina  :  12   Oceania : 24   3rd Qu.:1993   3rd Qu.:70.85  \n Australia  :  12                  Max.   :2007   Max.   :82.60  \n (Other)    :1632                                                \n      pop              gdpPercap       \n Min.   :6.001e+04   Min.   :   241.2  \n 1st Qu.:2.794e+06   1st Qu.:  1202.1  \n Median :7.024e+06   Median :  3531.8  \n Mean   :2.960e+07   Mean   :  7215.3  \n 3rd Qu.:1.959e+07   3rd Qu.:  9325.5  \n Max.   :1.319e+09   Max.   :113523.1  \n                                       \n\ngap_07 <- filter(gapminder, year == 2007)"
  },
  {
    "objectID": "semanas/Aula02.html#vendo-primeiras-e-√∫ltimas-10-linhas",
    "href": "semanas/Aula02.html#vendo-primeiras-e-√∫ltimas-10-linhas",
    "title": "Manipula√ß√£o dos dados",
    "section": "Vendo primeiras e √∫ltimas 10 linhas",
    "text": "Vendo primeiras e √∫ltimas 10 linhas\n\nhead(gap_07, n=10) %>% knitr::kable(booktabs = TRUE) # primeiros dez paises da base de dados\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nAfghanistan\nAsia\n2007\n43.828\n31889923\n974.5803\n\n\nAlbania\nEurope\n2007\n76.423\n3600523\n5937.0295\n\n\nAlgeria\nAfrica\n2007\n72.301\n33333216\n6223.3675\n\n\nAngola\nAfrica\n2007\n42.731\n12420476\n4797.2313\n\n\nArgentina\nAmericas\n2007\n75.320\n40301927\n12779.3796\n\n\nAustralia\nOceania\n2007\n81.235\n20434176\n34435.3674\n\n\nAustria\nEurope\n2007\n79.829\n8199783\n36126.4927\n\n\nBahrain\nAsia\n2007\n75.635\n708573\n29796.0483\n\n\nBangladesh\nAsia\n2007\n64.062\n150448339\n1391.2538\n\n\nBelgium\nEurope\n2007\n79.441\n10392226\n33692.6051\n\n\n\n\ntail(gap_07, n=10) %>% knitr::kable(booktabs = TRUE) # √∫ltimos 10 pa√≠ses \n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nUganda\nAfrica\n2007\n51.542\n29170398\n1056.3801\n\n\nUnited Kingdom\nEurope\n2007\n79.425\n60776238\n33203.2613\n\n\nUnited States\nAmericas\n2007\n78.242\n301139947\n42951.6531\n\n\nUruguay\nAmericas\n2007\n76.384\n3447496\n10611.4630\n\n\nVenezuela\nAmericas\n2007\n73.747\n26084662\n11415.8057\n\n\nVietnam\nAsia\n2007\n74.249\n85262356\n2441.5764\n\n\nWest Bank and Gaza\nAsia\n2007\n73.422\n4018332\n3025.3498\n\n\nYemen, Rep.\nAsia\n2007\n62.698\n22211743\n2280.7699\n\n\nZambia\nAfrica\n2007\n42.384\n11746035\n1271.2116\n\n\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.7093"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-1",
    "href": "semanas/Aula02.html#manipulando-1",
    "title": "Manipula√ß√£o dos dados",
    "section": "Manipulando 1",
    "text": "Manipulando 1\nSelecionando dados por pa√≠s\n\nfilter(gap_07, country %in% c(\"Brazil\", \"Chile\"))\n\n# A tibble: 2 √ó 6\n  country continent  year lifeExp       pop gdpPercap\n  <fct>   <fct>     <int>   <dbl>     <int>     <dbl>\n1 Brazil  Americas   2007    72.4 190010647     9066.\n2 Chile   Americas   2007    78.6  16284741    13172."
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-2",
    "href": "semanas/Aula02.html#manipulando-2",
    "title": "Manipula√ß√£o dos dados",
    "section": "Manipulando 2",
    "text": "Manipulando 2\nSelecionando dados para 2007 excluindo a Oceania\n\nfilter(gapminder, year == 2007 & continent != \"Oceania\")\n\n# A tibble: 140 √ó 6\n   country     continent  year lifeExp       pop gdpPercap\n   <fct>       <fct>     <int>   <dbl>     <int>     <dbl>\n 1 Afghanistan Asia       2007    43.8  31889923      975.\n 2 Albania     Europe     2007    76.4   3600523     5937.\n 3 Algeria     Africa     2007    72.3  33333216     6223.\n 4 Angola      Africa     2007    42.7  12420476     4797.\n 5 Argentina   Americas   2007    75.3  40301927    12779.\n 6 Austria     Europe     2007    79.8   8199783    36126.\n 7 Bahrain     Asia       2007    75.6    708573    29796.\n 8 Bangladesh  Asia       2007    64.1 150448339     1391.\n 9 Belgium     Europe     2007    79.4  10392226    33693.\n10 Benin       Africa     2007    56.7   8078314     1441.\n# ‚Ä¶ with 130 more rows\n# ‚Ñπ Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-3",
    "href": "semanas/Aula02.html#manipulando-3",
    "title": "Manipula√ß√£o dos dados",
    "section": "Manipulando 3",
    "text": "Manipulando 3\nSelecionando dados de 2007, agrupando por continente e sumarizando para achar a m√©dia da popula√ß√£o por continente\n\ngapminder %>%\n  filter(year == 2007) %>% \n  group_by(continent) %>% \n  summarize(mediapop = mean(pop))\n\n# A tibble: 5 √ó 2\n  continent   mediapop\n  <fct>          <dbl>\n1 Africa     17875763.\n2 Americas   35954847.\n3 Asia      115513752.\n4 Europe     19536618.\n5 Oceania    12274974."
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-1",
    "href": "semanas/Aula02.html#visualizando-1",
    "title": "Manipula√ß√£o dos dados",
    "section": "Visualizando 1",
    "text": "Visualizando 1\nMostrar linhas e pontos do PIB ao longo do tempo para Brasil e Chile\n\ngap_brachi <- filter(gapminder, country %in% c(\"Brazil\", \"Chile\"))\np <- ggplot(gap_brachi, aes(x = year, y = gdpPercap, color=country))\np1 <- p + geom_point()\np1"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-2",
    "href": "semanas/Aula02.html#visualizando-2",
    "title": "Manipula√ß√£o dos dados",
    "section": "Visualizando 2",
    "text": "Visualizando 2\n\np2 <- p + geom_line()\np2"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-3",
    "href": "semanas/Aula02.html#visualizando-3",
    "title": "Manipula√ß√£o dos dados",
    "section": "Visualizando 3",
    "text": "Visualizando 3\n\np3 <- p + geom_point() + geom_line()\np3"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-4---usando-o-pacote-patchwork",
    "href": "semanas/Aula02.html#visualizando-4---usando-o-pacote-patchwork",
    "title": "Manipula√ß√£o dos dados",
    "section": "Visualizando 4 - Usando o pacote patchwork",
    "text": "Visualizando 4 - Usando o pacote patchwork\n\n(p1 + p2) /\n  p3"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-4",
    "href": "semanas/Aula02.html#manipulando-4",
    "title": "Manipula√ß√£o dos dados",
    "section": "Manipulando 4",
    "text": "Manipulando 4\nContando n√∫mero de pa√≠ses e continentes com distinct\n\nnrow(gapminder) ## Esta n√£o √© a informa√ß√£o que eu quero\n\n[1] 1704\n\nhead(gapminder)\n\n# A tibble: 6 √ó 6\n  country     continent  year lifeExp      pop gdpPercap\n  <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\nnrow(distinct(gapminder,country))\n\n[1] 142\n\nnrow(distinct(gapminder, continent))\n\n[1] 5"
  },
  {
    "objectID": "semanas/Aula02.html#fazendo-contagens-de-dados",
    "href": "semanas/Aula02.html#fazendo-contagens-de-dados",
    "title": "Manipula√ß√£o dos dados",
    "section": "Fazendo contagens de dados",
    "text": "Fazendo contagens de dados\n\ngapminder %>% filter(year == 2007) %>% \n  group_by(continent) %>% summarise(n = n())\n\n# A tibble: 5 √ó 2\n  continent     n\n  <fct>     <int>\n1 Africa       52\n2 Americas     25\n3 Asia         33\n4 Europe       30\n5 Oceania       2"
  },
  {
    "objectID": "semanas/Aula02.html#mudando-orienta√ß√£o-dos-dados",
    "href": "semanas/Aula02.html#mudando-orienta√ß√£o-dos-dados",
    "title": "Manipula√ß√£o dos dados",
    "section": "Mudando orienta√ß√£o dos dados",
    "text": "Mudando orienta√ß√£o dos dados\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nhead(propaganda)\n\n# A tibble: 6 √ó 4\n     TV Radio Newspaper Sales\n  <dbl> <dbl>     <dbl> <dbl>\n1 230.   37.8      69.2  22.1\n2  44.5  39.3      45.1  10.4\n3  17.2  45.9      69.3   9.3\n4 152.   41.3      58.5  18.5\n5 181.   10.8      58.4  12.9\n6   8.7  48.9      75     7.2\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)\npropaganda %>% tidyr::pivot_longer(!Vendas, names_to=\"Midia\", values_to=\"Orcamento\")\n\n# A tibble: 600 √ó 3\n   Vendas Midia  Orcamento\n    <dbl> <chr>      <dbl>\n 1   22.1 TV         230. \n 2   22.1 Radio       37.8\n 3   22.1 Jornal      69.2\n 4   10.4 TV          44.5\n 5   10.4 Radio       39.3\n 6   10.4 Jornal      45.1\n 7    9.3 TV          17.2\n 8    9.3 Radio       45.9\n 9    9.3 Jornal      69.3\n10   18.5 TV         152. \n# ‚Ä¶ with 590 more rows\n# ‚Ñπ Use `print(n = ...)` to see more rows\n\n\n\n\nlibrary(readr)\npesquisa <- read.csv(\"data_joined.csv\", header = T)\nhead(pesquisa)\n\n  record_id month day year plot_id species_id sex hindfoot_length weight\n1         1     7  16 1977       2         NL   M              32     NA\n2        72     8  19 1977       2         NL   M              31     NA\n3       224     9  13 1977       2         NL                  NA     NA\n4       266    10  16 1977       2         NL                  NA     NA\n5       349    11  12 1977       2         NL                  NA     NA\n6       363    11  12 1977       2         NL                  NA     NA\n    genus  species   taxa plot_type\n1 Neotoma albigula Rodent   Control\n2 Neotoma albigula Rodent   Control\n3 Neotoma albigula Rodent   Control\n4 Neotoma albigula Rodent   Control\n5 Neotoma albigula Rodent   Control\n6 Neotoma albigula Rodent   Control\n\npesquisa_gw <- pesquisa %>% filter(!is.na(weight)) %>%\n  group_by(year, genus) %>%\n  summarize(peso_medio = mean(weight))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\nhead(pesquisa_gw)\n\n# A tibble: 6 √ó 3\n# Groups:   year [1]\n   year genus           peso_medio\n  <int> <chr>                <dbl>\n1  1977 Chaetodipus          15.3 \n2  1977 Dipodomys            52.5 \n3  1977 Onychomys            21.4 \n4  1977 Perognathus           7.17\n5  1977 Peromyscus           19.5 \n6  1977 Reithrodontomys      10   \n\npesquisa_gw %>% tidyr::pivot_wider(names_from=\"genus\", values_from=\"peso_medio\")\n\n# A tibble: 26 √ó 11\n# Groups:   year [26]\n    year Chaet‚Ä¶¬π Dipod‚Ä¶¬≤ Onych‚Ä¶¬≥ Perog‚Ä¶‚Å¥ Perom‚Ä¶‚Åµ Reith‚Ä¶‚Å∂ Neotoma Sigmo‚Ä¶‚Å∑ Sperm‚Ä¶‚Å∏\n   <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  1977    15.3    52.5    21.4    7.17    19.5   10        NA       NA      NA\n 2  1978    14.9    73.9    26.5    7.09    20.5    7.5     185.      89     130\n 3  1979    15.1    74.9    27.4    7.53    21.3    8.33    138       NA      NA\n 4  1980    14.2    73.1    28.3    7.46    22.4   10.2     159.      NA      NA\n 5  1981    14.0    72.7    28.4    7.15    20.4   11.2     166.      NA      57\n 6  1982    16.1    66.3    29.9    6.92    21.3   10.5     161.      79      NA\n 7  1983    15.5    65.0    29.0    6.83    21.5    9.87    157.      NA      NA\n 8  1984    15.3    52.8    28.3   16.9     20.0   11.2     150.      NA      NA\n 9  1985    15.8    51.1    28.1   32.7     20.0    8.37    149.      NA      NA\n10  1986    16.8    56.4    27.5   18.3     22.1   10.8     160.      55      NA\n# ‚Ä¶ with 16 more rows, 1 more variable: Baiomys <dbl>, and abbreviated variable\n#   names ¬π‚ÄãChaetodipus, ¬≤‚ÄãDipodomys, ¬≥‚ÄãOnychomys, ‚Å¥‚ÄãPerognathus, ‚Åµ‚ÄãPeromyscus,\n#   ‚Å∂‚ÄãReithrodontomys, ‚Å∑‚ÄãSigmodon, ‚Å∏‚ÄãSpermophilus\n# ‚Ñπ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula03.html",
    "href": "semanas/Aula03.html",
    "title": "Visualizando as distribui√ß√µes",
    "section": "",
    "text": "Vamos trabalhar de novo com os dados do gapminder para fazer algumas visualiza√ß√µes de dados que s√£o muito √∫teis no dia a dia.\nEste material foi adaptado do curso Data Visualization in R with ggplot2 de Kara Woo\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"gapminder\")"
  },
  {
    "objectID": "semanas/Aula03.html#selecionando-dados",
    "href": "semanas/Aula03.html#selecionando-dados",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Selecionando dados",
    "text": "Selecionando dados\n\ngap_07 <- filter(gapminder, year == 2007)"
  },
  {
    "objectID": "semanas/Aula03.html#vendo-a-distribui√ß√£o",
    "href": "semanas/Aula03.html#vendo-a-distribui√ß√£o",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Vendo a distribui√ß√£o",
    "text": "Vendo a distribui√ß√£o\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_histogram()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-histograma-usando-a-regra-de-sturges",
    "href": "semanas/Aula03.html#criando-um-histograma-usando-a-regra-de-sturges",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Criando um histograma usando a regra de Sturges",
    "text": "Criando um histograma usando a regra de Sturges\nA regra de Sturges indica 8 faixas enquanto que o padr√£o do ggplot2 √© 30.\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(gap_07)),0))"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-gr√°fico-de-densidade",
    "href": "semanas/Aula03.html#criando-um-gr√°fico-de-densidade",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Criando um gr√°fico de densidade",
    "text": "Criando um gr√°fico de densidade\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_density()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-box-plot",
    "href": "semanas/Aula03.html#criando-um-box-plot",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Criando um box-plot",
    "text": "Criando um box-plot\n\nggplot(gap_07, aes(x = continent, y = lifeExp)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-box-plot-com-vis√£o-dos-dados",
    "href": "semanas/Aula03.html#criando-um-box-plot-com-vis√£o-dos-dados",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Criando um box-plot com vis√£o dos dados",
    "text": "Criando um box-plot com vis√£o dos dados\n\nggplot(gap_07, aes(x = continent, y = lifeExp)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.5, alpha = 0.2)"
  },
  {
    "objectID": "semanas/Aula03.html#matriz-de-correla√ß√µes",
    "href": "semanas/Aula03.html#matriz-de-correla√ß√µes",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Matriz de Correla√ß√µes",
    "text": "Matriz de Correla√ß√µes\n\nlibrary(corrplot)\ngap_07_s <- gap_07 %>% select(lifeExp, pop, gdpPercap)\nmat_corr <- cor(gap_07_s)\ncorrplot(mat_corr, method = \"number\", col = \"black\", cl.pos = \"n\")\n\n\n\ncorrplot(mat_corr, method = \"number\")\n\n\n\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula03.html#splom",
    "href": "semanas/Aula03.html#splom",
    "title": "Visualizando as distribui√ß√µes",
    "section": "SPLOM",
    "text": "SPLOM\n\nlibrary(psych)\npairs.panels(gap_07_s)\n\n\n\n\n\n\nlibrary(GGally)\nggpairs(gap_07_s)"
  },
  {
    "objectID": "semanas/Aula03.html#descrevendo-a-distribui√ß√£o",
    "href": "semanas/Aula03.html#descrevendo-a-distribui√ß√£o",
    "title": "Visualizando as distribui√ß√µes",
    "section": "Descrevendo a distribui√ß√£o",
    "text": "Descrevendo a distribui√ß√£o\n\nlibrary(datawizard)\ndescribe_distribution(gap_07_s)\n\nVariable  |     Mean |       SD |      IQR |                Range | Skewness | Kurtosis |   n | n_Missing\n---------------------------------------------------------------------------------------------------------\nlifeExp   |    67.01 |    12.07 |    19.59 |       [39.61, 82.60] |    -0.69 |    -0.83 | 142 |         0\npop       | 4.40e+07 | 1.48e+08 | 2.78e+07 | [2.00e+05, 1.32e+09] |     7.40 |    58.33 | 142 |         0\ngdpPercap | 11680.07 | 12859.94 | 16579.19 |   [277.55, 49357.19] |     1.22 |     0.35 | 142 |         0"
  },
  {
    "objectID": "semanas/Aula04.html",
    "href": "semanas/Aula04.html",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "",
    "text": "library(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"gapminder\")"
  },
  {
    "objectID": "semanas/Aula04.html#cores-por-continente",
    "href": "semanas/Aula04.html#cores-por-continente",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Cores por continente",
    "text": "Cores por continente\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#usando-formas-e-cores-diferentes",
    "href": "semanas/Aula04.html#usando-formas-e-cores-diferentes",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Usando formas e cores diferentes",
    "text": "Usando formas e cores diferentes\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   shape = continent, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#cores-e-tamanho",
    "href": "semanas/Aula04.html#cores-e-tamanho",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Cores e tamanho",
    "text": "Cores e tamanho\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   size = pop, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#sumario-dos-dados-para-obter-pop-m√©dia-por-continente",
    "href": "semanas/Aula04.html#sumario-dos-dados-para-obter-pop-m√©dia-por-continente",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Sumario dos dados para obter pop m√©dia por continente",
    "text": "Sumario dos dados para obter pop m√©dia por continente\n\ngap_pop <- gapminder %>% \n  group_by(continent, year) %>% \n  summarize(pop = mean(pop))\nhead(gap_pop)\n\n# A tibble: 6 √ó 3\n# Groups:   continent [1]\n  continent  year      pop\n  <fct>     <int>    <dbl>\n1 Africa     1952 4570010.\n2 Africa     1957 5093033.\n3 Africa     1962 5702247.\n4 Africa     1967 6447875.\n5 Africa     1972 7305376.\n6 Africa     1977 8328097."
  },
  {
    "objectID": "semanas/Aula04.html#grafico-de-linha-com-cores",
    "href": "semanas/Aula04.html#grafico-de-linha-com-cores",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Grafico de linha com cores",
    "text": "Grafico de linha com cores\n\nggplot(gap_pop, aes(x = year, y = pop, color = continent)) +\n  geom_line() + geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#criando-grids-entre-os-anos-de-2002-e-2007",
    "href": "semanas/Aula04.html#criando-grids-entre-os-anos-de-2002-e-2007",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Criando grids entre os anos de 2002 e 2007",
    "text": "Criando grids entre os anos de 2002 e 2007\n\ngap_0207 <- gapminder %>% filter(between(year, 2002, 2007))\nggplot(gap_0207, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_grid(continent ~ year)"
  },
  {
    "objectID": "semanas/Aula04.html#outro-tipo-de-apresenta√ß√µes-de-grid",
    "href": "semanas/Aula04.html#outro-tipo-de-apresenta√ß√µes-de-grid",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Outro tipo de apresenta√ß√µes de grid",
    "text": "Outro tipo de apresenta√ß√µes de grid\n\ngap_life <- gapminder %>% \n  group_by(continent, year) %>% \n  summarize(lifeExp = mean(lifeExp))\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_grid(continent ~ .)"
  },
  {
    "objectID": "semanas/Aula04.html#grid-em-outra-dire√ß√£o",
    "href": "semanas/Aula04.html#grid-em-outra-dire√ß√£o",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Grid em outra dire√ß√£o",
    "text": "Grid em outra dire√ß√£o\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_grid(. ~ continent)"
  },
  {
    "objectID": "semanas/Aula04.html#usando-o-wrap",
    "href": "semanas/Aula04.html#usando-o-wrap",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Usando o wrap",
    "text": "Usando o wrap\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_wrap( ~ continent)"
  },
  {
    "objectID": "semanas/Aula04.html#filtrando-dados-e-fazendo-grafico-de-dispers√£o-padr√£o",
    "href": "semanas/Aula04.html#filtrando-dados-e-fazendo-grafico-de-dispers√£o-padr√£o",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Filtrando dados e fazendo grafico de dispers√£o padr√£o",
    "text": "Filtrando dados e fazendo grafico de dispers√£o padr√£o\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#transformando-o-eixo-x-para-escala-logar√≠timica",
    "href": "semanas/Aula04.html#transformando-o-eixo-x-para-escala-logar√≠timica",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Transformando o eixo x para escala logar√≠timica",
    "text": "Transformando o eixo x para escala logar√≠timica\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_continuous(trans = \"log10\")"
  },
  {
    "objectID": "semanas/Aula04.html#outra-forma-de-transforma√ß√£o-do-eixo-x",
    "href": "semanas/Aula04.html#outra-forma-de-transforma√ß√£o-do-eixo-x",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Outra forma de transforma√ß√£o do eixo x",
    "text": "Outra forma de transforma√ß√£o do eixo x\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#definindo-limites-para-o-eixo-y",
    "href": "semanas/Aula04.html#definindo-limites-para-o-eixo-y",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Definindo limites para o eixo y",
    "text": "Definindo limites para o eixo y\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 95))"
  },
  {
    "objectID": "semanas/Aula04.html#grafico-com-cores-normais",
    "href": "semanas/Aula04.html#grafico-com-cores-normais",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Grafico com cores normais",
    "text": "Grafico com cores normais\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#grafico-usando-outra-paleta-de-cores",
    "href": "semanas/Aula04.html#grafico-usando-outra-paleta-de-cores",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Grafico usando outra paleta de cores",
    "text": "Grafico usando outra paleta de cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "semanas/Aula04.html#usando-codigos-manuais-para-as-cores",
    "href": "semanas/Aula04.html#usando-codigos-manuais-para-as-cores",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Usando codigos manuais para as cores",
    "text": "Usando codigos manuais para as cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_manual(values = c(\"#FF0000\", \"#00A08A\", \"#F2AD00\",\n                                \"#F98400\", \"#5BBCD6\"))"
  },
  {
    "objectID": "semanas/Aula04.html#definindo-as-cores-e-tamanho-dos-pontos",
    "href": "semanas/Aula04.html#definindo-as-cores-e-tamanho-dos-pontos",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Definindo as cores e tamanho dos pontos",
    "text": "Definindo as cores e tamanho dos pontos\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(color = \"darkblue\", size = 3) +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#customizando-t√≠tulos-r√≥tulos-de-eixo-e-legendas",
    "href": "semanas/Aula04.html#customizando-t√≠tulos-r√≥tulos-de-eixo-e-legendas",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Customizando t√≠tulos, r√≥tulos de eixo e legendas",
    "text": "Customizando t√≠tulos, r√≥tulos de eixo e legendas\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "semanas/Aula04.html#sem-legenda",
    "href": "semanas/Aula04.html#sem-legenda",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Sem legenda",
    "text": "Sem legenda\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "semanas/Aula04.html#legenda-dentro-do-gr√°fico",
    "href": "semanas/Aula04.html#legenda-dentro-do-gr√°fico",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Legenda dentro do gr√°fico",
    "text": "Legenda dentro do gr√°fico\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))"
  },
  {
    "objectID": "semanas/Aula04.html#salvando-o-gr√°fico",
    "href": "semanas/Aula04.html#salvando-o-gr√°fico",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Salvando o gr√°fico",
    "text": "Salvando o gr√°fico\n\ngraf1 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))\n\ngraf1"
  },
  {
    "objectID": "semanas/Aula04.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "href": "semanas/Aula04.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "title": "Melhorando a visualiza√ß√£o",
    "section": "Aumentando o tamanho do texto e mudando para portugues",
    "text": "Aumentando o tamanho do texto e mudando para portugues\n\ngraf2 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.80),\n        legend.key = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14)) +\n  labs(x = \"PIB Per capita (US$)\", \n       y = \"Expectativa de Vida (anos)\", \n       title = \"Expectativa de Vida vs PIB em 2007\",\n       color = \"Continente\")\n\ngraf2"
  },
  {
    "objectID": "semanas/Aula05.html",
    "href": "semanas/Aula05.html",
    "title": "Suaviza√ß√£o",
    "section": "",
    "text": "library(\"ggplot2\")\nlibrary(\"gapminder\")\nlibrary(\"dplyr\")"
  },
  {
    "objectID": "semanas/Aula05.html#suaviza√ß√£o",
    "href": "semanas/Aula05.html#suaviza√ß√£o",
    "title": "Suaviza√ß√£o",
    "section": "Suaviza√ß√£o",
    "text": "Suaviza√ß√£o\n(locally estimated scatterplot smoothing/Local Polynomial Regression Fitting)\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#fazendo-o-suavizador-mais-nervoso",
    "href": "semanas/Aula05.html#fazendo-o-suavizador-mais-nervoso",
    "title": "Suaviza√ß√£o",
    "section": "Fazendo o suavizador mais nervoso",
    "text": "Fazendo o suavizador mais nervoso\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(span = 0.2)"
  },
  {
    "objectID": "semanas/Aula05.html#fazendo-o-suavizador-menos-nervoso",
    "href": "semanas/Aula05.html#fazendo-o-suavizador-menos-nervoso",
    "title": "Suaviza√ß√£o",
    "section": "Fazendo o suavizador menos nervoso",
    "text": "Fazendo o suavizador menos nervoso\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(span = 0.9)"
  },
  {
    "objectID": "semanas/Aula05.html#removendo-intervalos-de-confian√ßa",
    "href": "semanas/Aula05.html#removendo-intervalos-de-confian√ßa",
    "title": "Suaviza√ß√£o",
    "section": "Removendo intervalos de confian√ßa",
    "text": "Removendo intervalos de confian√ßa\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(se = FALSE)"
  },
  {
    "objectID": "semanas/Aula05.html#usando-ic-de-90",
    "href": "semanas/Aula05.html#usando-ic-de-90",
    "title": "Suaviza√ß√£o",
    "section": "Usando IC de 90%",
    "text": "Usando IC de 90%\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(level = 0.90)"
  },
  {
    "objectID": "semanas/Aula05.html#usando-um-modelo-linear-ao-inv√©s-do-loess",
    "href": "semanas/Aula05.html#usando-um-modelo-linear-ao-inv√©s-do-loess",
    "title": "Suaviza√ß√£o",
    "section": "Usando um modelo linear ao inv√©s do loess",
    "text": "Usando um modelo linear ao inv√©s do loess\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "semanas/Aula05.html#usando-basic-splines-para-melhorar-o-ajuste",
    "href": "semanas/Aula05.html#usando-basic-splines-para-melhorar-o-ajuste",
    "title": "Suaviza√ß√£o",
    "section": "Usando basic splines para melhorar o ajuste",
    "text": "Usando basic splines para melhorar o ajuste\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ splines::bs(x, df = 3))"
  },
  {
    "objectID": "semanas/Aula05.html#usando-o-gam-general-addtive-models-com-regress√£o-spline",
    "href": "semanas/Aula05.html#usando-o-gam-general-addtive-models-com-regress√£o-spline",
    "title": "Suaviza√ß√£o",
    "section": "Usando o gam (general addtive models) com regress√£o spline",
    "text": "Usando o gam (general addtive models) com regress√£o spline\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"gam\", formula = y ~ s(x))"
  },
  {
    "objectID": "semanas/Aula05.html#come√ßando-a-construir-um-gr√°fico-do-tipo-facet-com-suaviza√ß√µes",
    "href": "semanas/Aula05.html#come√ßando-a-construir-um-gr√°fico-do-tipo-facet-com-suaviza√ß√µes",
    "title": "Suaviza√ß√£o",
    "section": "Come√ßando a construir um gr√°fico do tipo facet com suaviza√ß√µes",
    "text": "Come√ßando a construir um gr√°fico do tipo facet com suaviza√ß√µes\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula05.html#dividindo-por-continente",
    "href": "semanas/Aula05.html#dividindo-por-continente",
    "title": "Suaviza√ß√£o",
    "section": "Dividindo por continente",
    "text": "Dividindo por continente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent)"
  },
  {
    "objectID": "semanas/Aula05.html#adicionando-suavizadores",
    "href": "semanas/Aula05.html#adicionando-suavizadores",
    "title": "Suaviza√ß√£o",
    "section": "Adicionando suavizadores",
    "text": "Adicionando suavizadores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#colorindo-por-continente",
    "href": "semanas/Aula05.html#colorindo-por-continente",
    "title": "Suaviza√ß√£o",
    "section": "Colorindo por continente",
    "text": "Colorindo por continente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#colorindo-somente-a-curva",
    "href": "semanas/Aula05.html#colorindo-somente-a-curva",
    "title": "Suaviza√ß√£o",
    "section": "Colorindo somente a curva",
    "text": "Colorindo somente a curva\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth(aes(color = continent))"
  },
  {
    "objectID": "semanas/Aula06.html",
    "href": "semanas/Aula06.html",
    "title": "Eixos - Escalas - Cores",
    "section": "",
    "text": "library(tidyverse)\nlibrary(gapminder)"
  },
  {
    "objectID": "semanas/Aula06.html#filtrando-dados-e-fazendo-grafico-de-dispers√£o-padr√£o",
    "href": "semanas/Aula06.html#filtrando-dados-e-fazendo-grafico-de-dispers√£o-padr√£o",
    "title": "Eixos - Escalas - Cores",
    "section": "Filtrando dados e fazendo grafico de dispers√£o padr√£o",
    "text": "Filtrando dados e fazendo grafico de dispers√£o padr√£o\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula06.html#transformando-o-eixo-x-para-escala-logar√≠timica",
    "href": "semanas/Aula06.html#transformando-o-eixo-x-para-escala-logar√≠timica",
    "title": "Eixos - Escalas - Cores",
    "section": "Transformando o eixo x para escala logar√≠timica",
    "text": "Transformando o eixo x para escala logar√≠timica\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_continuous(trans = \"log10\")"
  },
  {
    "objectID": "semanas/Aula06.html#outra-forma-de-transforma√ß√£o-do-eixo-x",
    "href": "semanas/Aula06.html#outra-forma-de-transforma√ß√£o-do-eixo-x",
    "title": "Eixos - Escalas - Cores",
    "section": "Outra forma de transforma√ß√£o do eixo x",
    "text": "Outra forma de transforma√ß√£o do eixo x\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#definindo-limites-para-o-eixo-y",
    "href": "semanas/Aula06.html#definindo-limites-para-o-eixo-y",
    "title": "Eixos - Escalas - Cores",
    "section": "Definindo limites para o eixo y",
    "text": "Definindo limites para o eixo y\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 95))"
  },
  {
    "objectID": "semanas/Aula06.html#grafico-com-cores-normais",
    "href": "semanas/Aula06.html#grafico-com-cores-normais",
    "title": "Eixos - Escalas - Cores",
    "section": "Grafico com cores normais",
    "text": "Grafico com cores normais\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#grafico-usando-uma-paleta-de-cores-diferente",
    "href": "semanas/Aula06.html#grafico-usando-uma-paleta-de-cores-diferente",
    "title": "Eixos - Escalas - Cores",
    "section": "Grafico usando uma paleta de cores diferente",
    "text": "Grafico usando uma paleta de cores diferente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "semanas/Aula06.html#usando-codigos-manuais-para-as-cores",
    "href": "semanas/Aula06.html#usando-codigos-manuais-para-as-cores",
    "title": "Eixos - Escalas - Cores",
    "section": "Usando codigos manuais para as cores",
    "text": "Usando codigos manuais para as cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_manual(values = c(\"#FF0000\", \"#00A08A\", \"#F2AD00\",\n                                \"#F98400\", \"#5BBCD6\"))"
  },
  {
    "objectID": "semanas/Aula06.html#definindo-as-cores-e-tamanho-dos-pontos",
    "href": "semanas/Aula06.html#definindo-as-cores-e-tamanho-dos-pontos",
    "title": "Eixos - Escalas - Cores",
    "section": "Definindo as cores e tamanho dos pontos",
    "text": "Definindo as cores e tamanho dos pontos\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(color = \"darkblue\", size = 3) +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#customizando-t√≠tulos-r√≥tulos-de-eixo-e-legendas",
    "href": "semanas/Aula06.html#customizando-t√≠tulos-r√≥tulos-de-eixo-e-legendas",
    "title": "Eixos - Escalas - Cores",
    "section": "Customizando t√≠tulos, r√≥tulos de eixo e legendas",
    "text": "Customizando t√≠tulos, r√≥tulos de eixo e legendas\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "semanas/Aula06.html#sem-legenda",
    "href": "semanas/Aula06.html#sem-legenda",
    "title": "Eixos - Escalas - Cores",
    "section": "Sem legenda",
    "text": "Sem legenda\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "semanas/Aula06.html#legenda-dentro-do-gr√°fico",
    "href": "semanas/Aula06.html#legenda-dentro-do-gr√°fico",
    "title": "Eixos - Escalas - Cores",
    "section": "Legenda dentro do gr√°fico",
    "text": "Legenda dentro do gr√°fico\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))"
  },
  {
    "objectID": "semanas/Aula06.html#salvando-o-gr√°fico",
    "href": "semanas/Aula06.html#salvando-o-gr√°fico",
    "title": "Eixos - Escalas - Cores",
    "section": "Salvando o gr√°fico",
    "text": "Salvando o gr√°fico\n\ngraf1 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))\n\ngraf1\n\n\n\nggsave(\"Exp_vida_pib_2007_1.png\", plot=graf1, width = 7, height = 7)"
  },
  {
    "objectID": "semanas/Aula06.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "href": "semanas/Aula06.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "title": "Eixos - Escalas - Cores",
    "section": "Aumentando o tamanho do texto e mudando para portugues",
    "text": "Aumentando o tamanho do texto e mudando para portugues\n\ngraf2 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85),\n        legend.key = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14)) +\n  labs(x = \"PIB Per capita (US$)\", \n       y = \"Expectativa de Vida (anos)\", \n       title = \"Expectativa de Vida vs PIB em 2007\",\n       color = \"Continente\")\n\ngraf2\n\n\n\nggsave(\"Exp_vida_pib_2007_2.png\", plot = graf2, width = 7, height = 7)"
  },
  {
    "objectID": "semanas/Aula06A.html",
    "href": "semanas/Aula06A.html",
    "title": "Explorando Dados",
    "section": "",
    "text": "library(tidyverse)\ndata(iris)"
  },
  {
    "objectID": "semanas/Aula06A.html#o-que-temos-aqui",
    "href": "semanas/Aula06A.html#o-que-temos-aqui",
    "title": "Explorando Dados",
    "section": "O que temos aqui?",
    "text": "O que temos aqui?\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\niris %>% count(Species)\n\n     Species  n\n1     setosa 50\n2 versicolor 50\n3  virginica 50"
  },
  {
    "objectID": "semanas/Aula06A.html#quais-s√£o-as-m√©dias",
    "href": "semanas/Aula06A.html#quais-s√£o-as-m√©dias",
    "title": "Explorando Dados",
    "section": "Quais s√£o as m√©dias?",
    "text": "Quais s√£o as m√©dias?\n\niris %>% \n  group_by(Species) %>% \n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 3 √ó 5\n  Species    Sepal.Length Sepal.Width Petal.Length Petal.Width\n  <fct>             <dbl>       <dbl>        <dbl>       <dbl>\n1 setosa             5.01        3.43         1.46       0.246\n2 versicolor         5.94        2.77         4.26       1.33 \n3 virginica          6.59        2.97         5.55       2.03"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis",
    "text": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Sepal.Width, y=Sepal.Length, \n                                   color=Species)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis-2",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis-2",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis 2",
    "text": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis 2\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Sepal.Width, y=Sepal.Length, color=Species)) +\n  geom_point() + geom_smooth(method = \"lm\", se=FALSE)"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis-3",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis-3",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis 3",
    "text": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis 3\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Petal.Width, y=Petal.Length, \n                                   color=Species)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis-4",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-rela√ß√£o-entre-as-vari√°veis-4",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis 4",
    "text": "Vamos ver se temos alguma rela√ß√£o entre as vari√°veis 4\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Petal.Width, y=Petal.Length, color=Species)) +\n  geom_point() + geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.width",
    "href": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.width",
    "title": "Explorando Dados",
    "section": "Vamos ver como se distribui o Petal.Width",
    "text": "Vamos ver como se distribui o Petal.Width\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Petal.Width, \n                                   fill=Species)) + \n                                   geom_histogram()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.length",
    "href": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.length",
    "title": "Explorando Dados",
    "section": "Vamos ver como se distribui o Petal.Length",
    "text": "Vamos ver como se distribui o Petal.Length\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Petal.Length, fill=Species)) + \n  geom_histogram()"
  },
  {
    "objectID": "semanas/Aula07.1.html",
    "href": "semanas/Aula07.1.html",
    "title": "Regress√£o Linear",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "semanas/Aula07.1.html#dados-de-propaganda",
    "href": "semanas/Aula07.1.html#dados-de-propaganda",
    "title": "Regress√£o Linear",
    "section": "Dados de propaganda",
    "text": "Dados de propaganda\nO conjunto de dados cont√©m estat√≠sticas sobre as vendas de um produto em 200 diferentes mercados, juntamente com or√ßamentos publicit√°rios em cada um desses mercados, para diferentes canais de m√≠dia: TV, r√°dio e jornal. As vendas est√£o em milhares de unidades e o or√ßamento est√° em milhares de d√≥lares.\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nsummary(propaganda)\n\n       TV             Radio          Newspaper          Sales      \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00"
  },
  {
    "objectID": "semanas/Aula07.1.html#renomeando",
    "href": "semanas/Aula07.1.html#renomeando",
    "title": "Regress√£o Linear",
    "section": "Renomeando",
    "text": "Renomeando\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)"
  },
  {
    "objectID": "semanas/Aula07.1.html#sumario",
    "href": "semanas/Aula07.1.html#sumario",
    "title": "Regress√£o Linear",
    "section": "Sumario",
    "text": "Sumario\n\nsummary(propaganda)\n\n       TV             Radio            Jornal           Vendas     \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00  \n\nnrow(propaganda)\n\n[1] 200"
  },
  {
    "objectID": "semanas/Aula07.1.html#linhas-inicias",
    "href": "semanas/Aula07.1.html#linhas-inicias",
    "title": "Regress√£o Linear",
    "section": "Linhas inicias",
    "text": "Linhas inicias\n\nlibrary(gt)\ngt(head(propaganda, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    44.5\n39.3\n45.1\n10.4\n    17.2\n45.9\n69.3\n9.3\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    8.7\n48.9\n75.0\n7.2\n    57.5\n32.8\n23.5\n11.8\n    120.2\n19.6\n11.6\n13.2\n    8.6\n2.1\n1.0\n4.8\n    199.8\n2.6\n21.2\n10.6"
  },
  {
    "objectID": "semanas/Aula07.1.html#criando-amostra-de-treino-e-teste",
    "href": "semanas/Aula07.1.html#criando-amostra-de-treino-e-teste",
    "title": "Regress√£o Linear",
    "section": "Criando amostra de treino e teste",
    "text": "Criando amostra de treino e teste\n\nlibrary(caret)\nset.seed(21)\ny <- propaganda$Vendas\nindice_teste <- createDataPartition(y, times = 1, p = 0.40, list = FALSE)\n\nconj_treino <- propaganda %>% slice(-indice_teste)\nconj_teste <- propaganda %>% slice(indice_teste)\n\nstr(conj_treino)\n\ntibble [119 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:119] 230.1 151.5 180.8 199.8 66.1 ...\n $ Radio : num [1:119] 37.8 41.3 10.8 2.6 5.8 35.1 7.6 47.7 20.5 23.9 ...\n $ Jornal: num [1:119] 69.2 58.5 58.4 21.2 24.2 65.9 7.2 52.9 18.3 19.1 ...\n $ Vendas: num [1:119] 22.1 18.5 12.9 10.6 8.6 9.2 9.7 22.4 11.3 14.6 ...\n\nstr(conj_teste)\n\ntibble [81 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:81] 44.5 17.2 8.7 57.5 120.2 ...\n $ Radio : num [1:81] 39.3 45.9 48.9 32.8 19.6 2.1 24 32.9 36.6 39.6 ...\n $ Jornal: num [1:81] 45.1 69.3 75 23.5 11.6 1 4 46 114 55.8 ...\n $ Vendas: num [1:81] 10.4 9.3 7.2 11.8 13.2 4.8 17.4 19 12.5 24.4 ...\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6"
  },
  {
    "objectID": "semanas/Aula07.1.html#primeira-visualiza√ß√£o-dos-dados",
    "href": "semanas/Aula07.1.html#primeira-visualiza√ß√£o-dos-dados",
    "title": "Regress√£o Linear",
    "section": "Primeira visualiza√ß√£o dos dados",
    "text": "Primeira visualiza√ß√£o dos dados\nAqui estou usando uma fun√ß√£o do pacote caret que de uma maneira simples apresenta a rela√ß√£o entre a vari√°vel resposta e suas poss√≠veis vari√°veis explicativas\n\nfeaturePlot(x = conj_treino[ , c(\"TV\", \"Radio\", \"Jornal\")], y = conj_treino$Vendas)"
  },
  {
    "objectID": "semanas/Aula07.1.html#usando-o-ggplot",
    "href": "semanas/Aula07.1.html#usando-o-ggplot",
    "title": "Regress√£o Linear",
    "section": "Usando o ggplot",
    "text": "Usando o ggplot\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6\n  \n  \n  \n\n\n\nc_treino_pivot <- conj_treino %>% pivot_longer(!Vendas, names_to=\"Tipo\", values_to=\"Or√ßamento\" ) \ngt(head(c_treino_pivot, 10))\n\n\n\n\n\n  \n  \n    \n      Vendas\n      Tipo\n      Or√ßamento\n    \n  \n  \n    22.1\nTV\n230.1\n    22.1\nRadio\n37.8\n    22.1\nJornal\n69.2\n    18.5\nTV\n151.5\n    18.5\nRadio\n41.3\n    18.5\nJornal\n58.5\n    12.9\nTV\n180.8\n    12.9\nRadio\n10.8\n    12.9\nJornal\n58.4\n    10.6\nTV\n199.8\n  \n  \n  \n\n\n\nconj_treino %>% pivot_longer(!Vendas, names_to=\"Tipo\", values_to=\"Or√ßamento\" ) %>%\n            ggplot() + \n            geom_point(aes(x=Or√ßamento, y=Vendas)) +\n            facet_wrap( ~ Tipo, scales = \"free_x\") +\n            labs(x = \"Or√ßamento (1000 US$)\", \n                 y = \"Vendas (em 1000 unidades vendidas)\", \n                 title = \"Vendas vs Propaganda\"\n                 )"
  },
  {
    "objectID": "semanas/Aula07.1.html#matriz-de-dispers√£o",
    "href": "semanas/Aula07.1.html#matriz-de-dispers√£o",
    "title": "Regress√£o Linear",
    "section": "Matriz de dispers√£o",
    "text": "Matriz de dispers√£o\n\nlibrary(psych)\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correla√ß√£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correla√ß√£o\n             )"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-mod-regress√£o",
    "href": "semanas/Aula07.1.html#o-mod-regress√£o",
    "title": "Regress√£o Linear",
    "section": "1o Mod Regress√£o",
    "text": "1o Mod Regress√£o\n\nmod1 <- lm( Vendas ~ TV, data = conj_treino)\nnames(mod1)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoeflinear <- mod1$coefficients[1]\ncoefang <- mod1$coefficients[2]\nsummary(mod1)\n\n\nCall:\nlm(formula = Vendas ~ TV, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6383 -1.9426 -0.0565  1.7033  7.5277 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.929269   0.598642   11.57   <2e-16 ***\nTV          0.046471   0.003471   13.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.167 on 117 degrees of freedom\nMultiple R-squared:  0.605, Adjusted R-squared:  0.6017 \nF-statistic: 179.2 on 1 and 117 DF,  p-value: < 2.2e-16\n\nggplot(conj_treino, aes(x=TV, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representa√ß√£o-do-1o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representa√ß√£o-do-1o-modelo",
    "title": "Regress√£o Linear",
    "section": "Outra forma de representa√ß√£o do 1o Modelo",
    "text": "Outra forma de representa√ß√£o do 1o Modelo\n\nlibrary(car)\nscatterplot(Vendas ~ TV, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#extraindo-informa√ß√µes-do-1o-ajuste",
    "href": "semanas/Aula07.1.html#extraindo-informa√ß√µes-do-1o-ajuste",
    "title": "Regress√£o Linear",
    "section": "Extraindo informa√ß√µes do 1o ajuste",
    "text": "Extraindo informa√ß√µes do 1o ajuste\n\nsummary(mod1)$sigma\n\n[1] 3.167319\n\nsummary(mod1)$r.squared\n\n[1] 0.605027"
  },
  {
    "objectID": "semanas/Aula07.1.html#intervalo-de-confian√ßa",
    "href": "semanas/Aula07.1.html#intervalo-de-confian√ßa",
    "title": "Regress√£o Linear",
    "section": "Intervalo de Confian√ßa",
    "text": "Intervalo de Confian√ßa\n\nsummary(mod1)\n\n\nCall:\nlm(formula = Vendas ~ TV, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6383 -1.9426 -0.0565  1.7033  7.5277 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.929269   0.598642   11.57   <2e-16 ***\nTV          0.046471   0.003471   13.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.167 on 117 degrees of freedom\nMultiple R-squared:  0.605, Adjusted R-squared:  0.6017 \nF-statistic: 179.2 on 1 and 117 DF,  p-value: < 2.2e-16\n\nconfint(mod1)\n\n                 2.5 %     97.5 %\n(Intercept) 5.74368904 8.11484821\nTV          0.03959625 0.05334545"
  },
  {
    "objectID": "semanas/Aula07.1.html#anova",
    "href": "semanas/Aula07.1.html#anova",
    "title": "Regress√£o Linear",
    "section": "Anova",
    "text": "Anova\n\nanova(mod1)\n\nAnalysis of Variance Table\n\nResponse: Vendas\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nTV          1 1798.0 1797.95  179.22 < 2.2e-16 ***\nResiduals 117 1173.7   10.03                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.1.html#previs√µes",
    "href": "semanas/Aula07.1.html#previs√µes",
    "title": "Regress√£o Linear",
    "section": "Previs√µes",
    "text": "Previs√µes\n\n#?predict\npredict(mod1, data.frame(TV=c(50, 150, 250)), interval = \"prediction\")\n\n        fit       lwr      upr\n1  9.252811  2.915787 15.58983\n2 13.899896  7.600884 20.19891\n3 18.546982 12.211175 24.88279"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste",
    "title": "Regress√£o Linear",
    "section": "Calculando o erro padr√£o do res√≠duo com amostra de teste",
    "text": "Calculando o erro padr√£o do res√≠duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod1, conj_teste)) ^ 2)) \n\n[1] 3.41382"
  },
  {
    "objectID": "semanas/Aula07.1.html#an√°lise-do-modelo",
    "href": "semanas/Aula07.1.html#an√°lise-do-modelo",
    "title": "Regress√£o Linear",
    "section": "An√°lise do modelo",
    "text": "An√°lise do modelo\n\nplot(mod1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#an√°lise-do-modelo-2",
    "href": "semanas/Aula07.1.html#an√°lise-do-modelo-2",
    "title": "Regress√£o Linear",
    "section": "An√°lise do modelo 2",
    "text": "An√°lise do modelo 2\n\nlibrary(performance)\ncheck_model(mod1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-modelo-de-regress√£o",
    "href": "semanas/Aula07.1.html#o-modelo-de-regress√£o",
    "title": "Regress√£o Linear",
    "section": "2o Modelo de Regress√£o",
    "text": "2o Modelo de Regress√£o\n\nmod2 <- lm( Vendas ~ Radio, data = conj_treino)\ncoeflinear <- mod2$coefficients[1]\ncoefang <- mod2$coefficients[2]\nsummary(mod2)\n\n\nCall:\nlm(formula = Vendas ~ Radio, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.396  -1.851   0.675   2.522   7.451 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  9.22746    0.64377  14.333  < 2e-16 ***\nRadio        0.22144    0.02515   8.806 1.38e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.908 on 117 degrees of freedom\nMultiple R-squared:  0.3986,    Adjusted R-squared:  0.3935 \nF-statistic: 77.55 on 1 and 117 DF,  p-value: 1.384e-14\n\nggplot(propaganda, aes(x=Radio, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representa√ß√£o-do-2o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representa√ß√£o-do-2o-modelo",
    "title": "Regress√£o Linear",
    "section": "Outra forma de representa√ß√£o do 2o Modelo",
    "text": "Outra forma de representa√ß√£o do 2o Modelo\n\nscatterplot(Vendas ~ Radio, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste-1",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste-1",
    "title": "Regress√£o Linear",
    "section": "Calculando o erro padr√£o do res√≠duo com amostra de teste",
    "text": "Calculando o erro padr√£o do res√≠duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod2, conj_teste)) ^ 2)) \n\n[1] 4.808117"
  },
  {
    "objectID": "semanas/Aula07.1.html#an√°lise-de-res√≠duos",
    "href": "semanas/Aula07.1.html#an√°lise-de-res√≠duos",
    "title": "Regress√£o Linear",
    "section": "An√°lise de Res√≠duos",
    "text": "An√°lise de Res√≠duos\n\ncheck_model(mod2)"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-modelo-de-regress√£o-1",
    "href": "semanas/Aula07.1.html#o-modelo-de-regress√£o-1",
    "title": "Regress√£o Linear",
    "section": "3o Modelo de Regress√£o",
    "text": "3o Modelo de Regress√£o\n\nmod3 <- lm( Vendas ~ Jornal, data = conj_treino)\ncoeflinear <- mod3$coefficients[1]\ncoefang <- mod3$coefficients[2]\nsummary(mod3)\n\n\nCall:\nlm(formula = Vendas ~ Jornal, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.0331  -3.2104  -0.8491   3.0389  13.0002 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 12.08457    0.80845  14.948  < 2e-16 ***\nJornal       0.06305    0.02290   2.753  0.00685 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.884 on 117 degrees of freedom\nMultiple R-squared:  0.06084,   Adjusted R-squared:  0.05281 \nF-statistic: 7.579 on 1 and 117 DF,  p-value: 0.006847\n\nggplot(propaganda, aes(x=Jornal, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representa√ß√£o-do-3o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representa√ß√£o-do-3o-modelo",
    "title": "Regress√£o Linear",
    "section": "Outra forma de representa√ß√£o do 3o Modelo",
    "text": "Outra forma de representa√ß√£o do 3o Modelo\n\nscatterplot(Vendas ~ Jornal, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste-2",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste-2",
    "title": "Regress√£o Linear",
    "section": "Calculando o erro padr√£o do res√≠duo com amostra de teste",
    "text": "Calculando o erro padr√£o do res√≠duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod3, conj_teste)) ^ 2)) \n\n[1] 5.38693"
  },
  {
    "objectID": "semanas/Aula07.1.html#an√°lise-de-res√≠duos-1",
    "href": "semanas/Aula07.1.html#an√°lise-de-res√≠duos-1",
    "title": "Regress√£o Linear",
    "section": "An√°lise de Res√≠duos",
    "text": "An√°lise de Res√≠duos\n\ncheck_model(mod3)"
  },
  {
    "objectID": "semanas/Aula07.2.html",
    "href": "semanas/Aula07.2.html",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "semanas/Aula07.2.html#dados-de-propaganda",
    "href": "semanas/Aula07.2.html#dados-de-propaganda",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Dados de propaganda",
    "text": "Dados de propaganda\nO conjunto de dados cont√©m estat√≠sticas sobre as vendas de um produto em 200 diferentes mercados, juntamente com or√ßamentos publicit√°rios em cada um desses mercados, para diferentes canais de m√≠dia: TV, r√°dio e jornal. As vendas est√£o em milhares de unidades e o or√ßamento est√° em milhares de d√≥lares.\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nsummary(propaganda)\n\n       TV             Radio          Newspaper          Sales      \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00"
  },
  {
    "objectID": "semanas/Aula07.2.html#renomeando",
    "href": "semanas/Aula07.2.html#renomeando",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Renomeando",
    "text": "Renomeando\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)"
  },
  {
    "objectID": "semanas/Aula07.2.html#sumario",
    "href": "semanas/Aula07.2.html#sumario",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Sumario",
    "text": "Sumario\n\nsummary(propaganda)\n\n       TV             Radio            Jornal           Vendas     \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00  \n\nnrow(propaganda)\n\n[1] 200"
  },
  {
    "objectID": "semanas/Aula07.2.html#linhas-inicias",
    "href": "semanas/Aula07.2.html#linhas-inicias",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Linhas inicias",
    "text": "Linhas inicias\n\nlibrary(gt)\ngt(head(propaganda, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    44.5\n39.3\n45.1\n10.4\n    17.2\n45.9\n69.3\n9.3\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    8.7\n48.9\n75.0\n7.2\n    57.5\n32.8\n23.5\n11.8\n    120.2\n19.6\n11.6\n13.2\n    8.6\n2.1\n1.0\n4.8\n    199.8\n2.6\n21.2\n10.6"
  },
  {
    "objectID": "semanas/Aula07.2.html#criando-amostra-de-treino-e-teste",
    "href": "semanas/Aula07.2.html#criando-amostra-de-treino-e-teste",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Criando amostra de treino e teste",
    "text": "Criando amostra de treino e teste\n\nlibrary(caret)\nset.seed(21)\ny <- propaganda$Vendas\nindice_teste <- createDataPartition(y, times = 1, p = 0.40, list = FALSE)\n\nconj_treino <- propaganda %>% slice(-indice_teste)\nconj_teste <- propaganda %>% slice(indice_teste)\n\nstr(conj_treino)\n\ntibble [119 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:119] 230.1 151.5 180.8 199.8 66.1 ...\n $ Radio : num [1:119] 37.8 41.3 10.8 2.6 5.8 35.1 7.6 47.7 20.5 23.9 ...\n $ Jornal: num [1:119] 69.2 58.5 58.4 21.2 24.2 65.9 7.2 52.9 18.3 19.1 ...\n $ Vendas: num [1:119] 22.1 18.5 12.9 10.6 8.6 9.2 9.7 22.4 11.3 14.6 ...\n\nstr(conj_teste)\n\ntibble [81 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:81] 44.5 17.2 8.7 57.5 120.2 ...\n $ Radio : num [1:81] 39.3 45.9 48.9 32.8 19.6 2.1 24 32.9 36.6 39.6 ...\n $ Jornal: num [1:81] 45.1 69.3 75 23.5 11.6 1 4 46 114 55.8 ...\n $ Vendas: num [1:81] 10.4 9.3 7.2 11.8 13.2 4.8 17.4 19 12.5 24.4 ...\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6"
  },
  {
    "objectID": "semanas/Aula07.2.html#regress√£o-simples",
    "href": "semanas/Aula07.2.html#regress√£o-simples",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Regress√£o Simples",
    "text": "Regress√£o Simples\n\nmod1 <- lm( Vendas ~ TV, data = conj_treino)\nmod2 <- lm( Vendas ~ Radio, data = conj_treino)\nmod3 <- lm( Vendas ~ Jornal, data = conj_treino)"
  },
  {
    "objectID": "semanas/Aula07.2.html#a-regress√£o-multipla",
    "href": "semanas/Aula07.2.html#a-regress√£o-multipla",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "1a Regress√£o Multipla",
    "text": "1a Regress√£o Multipla\n\nlibrary(car)\nscatterplotMatrix(conj_treino)\n\n\n\nmod4 <- lm( Vendas ~ TV + Radio + Jornal, data = conj_treino)\nsummary(mod4)\n\n\nCall:\nlm(formula = Vendas ~ TV + Radio + Jornal, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.1595 -0.6961  0.2676  1.0298  2.5871 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.268910   0.391828   8.343 1.81e-13 ***\nTV          0.042705   0.001776  24.039  < 2e-16 ***\nRadio       0.186439   0.011458  16.272  < 2e-16 ***\nJornal      0.008931   0.008292   1.077    0.284    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.606 on 115 degrees of freedom\nMultiple R-squared:  0.9002,    Adjusted R-squared:  0.8976 \nF-statistic: 345.9 on 3 and 115 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.2.html#a-regressao-multipla",
    "href": "semanas/Aula07.2.html#a-regressao-multipla",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "2a Regressao Multipla",
    "text": "2a Regressao Multipla\n\nmod5 <- lm( Vendas ~ TV + Radio, data = conj_treino)\nsummary(mod5)\n\n\nCall:\nlm(formula = Vendas ~ TV + Radio, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.4585 -0.6886  0.1687  1.0799  2.5529 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.441076   0.357985   9.612   <2e-16 ***\nTV          0.042575   0.001774  24.005   <2e-16 ***\nRadio       0.191607   0.010412  18.402   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.607 on 116 degrees of freedom\nMultiple R-squared:  0.8992,    Adjusted R-squared:  0.8975 \nF-statistic: 517.5 on 2 and 116 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.2.html#confirmando-o-teste-t-com-o-teste-f-anova",
    "href": "semanas/Aula07.2.html#confirmando-o-teste-t-com-o-teste-f-anova",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Confirmando o teste t com o teste F (ANOVA)",
    "text": "Confirmando o teste t com o teste F (ANOVA)\n\nanova(mod5, mod4)\n\nAnalysis of Variance Table\n\nModel 1: Vendas ~ TV + Radio\nModel 2: Vendas ~ TV + Radio + Jornal\n  Res.Df    RSS Df Sum of Sq    F Pr(>F)\n1    116 299.47                         \n2    115 296.48  1    2.9906 1.16 0.2837"
  },
  {
    "objectID": "semanas/Aula07.2.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste",
    "href": "semanas/Aula07.2.html#calculando-o-erro-padr√£o-do-res√≠duo-com-amostra-de-teste",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Calculando o erro padr√£o do res√≠duo com amostra de teste",
    "text": "Calculando o erro padr√£o do res√≠duo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod5, conj_teste)) ^ 2)) \n\n[1] 1.846764"
  },
  {
    "objectID": "semanas/Aula07.2.html#comparando-com-a-melhor-regress√£o-simples",
    "href": "semanas/Aula07.2.html#comparando-com-a-melhor-regress√£o-simples",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Comparando com a melhor regress√£o simples",
    "text": "Comparando com a melhor regress√£o simples\n\n## Modelo com somente TV\nsummary(mod1)$sigma\n\n[1] 3.167319\n\nsummary(mod1)$r.squared\n\n[1] 0.605027\n\nsqrt(mean((conj_teste$Vendas - predict(mod1, conj_teste)) ^ 2))\n\n[1] 3.41382\n\n## Modelo com TV e Jornal\nsummary(mod5)$sigma\n\n[1] 1.606744\n\nsummary(mod5)$adj.r.squared\n\n[1] 0.8974883\n\nsqrt(mean((conj_teste$Vendas - predict(mod5, conj_teste)) ^ 2))\n\n[1] 1.846764"
  },
  {
    "objectID": "semanas/Aula07.2.html#an√°lise-do-modelo-1",
    "href": "semanas/Aula07.2.html#an√°lise-do-modelo-1",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "An√°lise do Modelo 1",
    "text": "An√°lise do Modelo 1\n\nlibrary(performance)\ncheck_model(mod5)"
  },
  {
    "objectID": "semanas/Aula07.2.html#an√°lise-do-modelo-2",
    "href": "semanas/Aula07.2.html#an√°lise-do-modelo-2",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "An√°lise do Modelo 2",
    "text": "An√°lise do Modelo 2\n\nplot(mod5)"
  },
  {
    "objectID": "semanas/Aula07.2.html#an√°lise-do-modelo-3",
    "href": "semanas/Aula07.2.html#an√°lise-do-modelo-3",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "An√°lise do Modelo 3",
    "text": "An√°lise do Modelo 3\nPara o gr√°fico de res√≠duos versus valores ajustados, podemos usar um teste chamado teste de Tukey de n√£o aditividade (Tukey, 1949), ele √© obtido adicionando os quadrados dos valores ajustados ao modelo e reajustando. O valor p para o teste de Tukey √© obtido comparando a estat√≠stica de teste para a distribui√ß√£o padr√£o-normal. O teste confirma a vis√≠vel impress√£o de curvatura no gr√°fico residual, refor√ßando ainda mais a conclus√£o que o modelo n√£o √© adequado.\n\nlibrary(car)\nresidualPlots(mod5)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nTV           -4.8383        4.102e-06 ***\nRadio         1.9290           0.0562 .  \nTukey test    6.4114        1.442e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.2.html#an√°lise-do-modelo-com-car",
    "href": "semanas/Aula07.2.html#an√°lise-do-modelo-com-car",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "An√°lise do Modelo com car",
    "text": "An√°lise do Modelo com car\n\nlibrary(car)\nvif(mod5)\n\n      TV    Radio \n1.014454 1.014454"
  },
  {
    "objectID": "semanas/Aula07.2.html#tentando-corrigir-o-problema",
    "href": "semanas/Aula07.2.html#tentando-corrigir-o-problema",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Tentando corrigir o problema",
    "text": "Tentando corrigir o problema\n\nsummary(p1 <- powerTransform(Vendas ~ TV + Radio, data=conj_treino))\n\nbcPower Transformation to Normality \n   Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nY1    0.9937           1       0.8018       1.1856\n\nLikelihood ratio test that transformation parameter is equal to 0\n (log transformation)\n                          LRT df       pval\nLR test, lambda = (0) 111.042  1 < 2.22e-16\n\nLikelihood ratio test that no transformation is needed\n                              LRT df    pval\nLR test, lambda = (1) 0.004149754  1 0.94864\n\nsummary(p2 <- powerTransform(cbind(TV, Radio) ~1 , data=conj_treino))\n\nbcPower Transformations to Multinormality \n      Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nTV       0.7692         1.0       0.5311       1.0073\nRadio    0.5349         0.5       0.3429       0.7269\n\nLikelihood ratio test that transformation parameters are equal to 0\n (all log transformations)\n                            LRT df       pval\nLR test, lambda = (0 0) 102.457  2 < 2.22e-16\n\nLikelihood ratio test that no transformations are needed\n                           LRT df       pval\nLR test, lambda = (1 1) 22.189  2 1.5196e-05\n\nmod6 <- lm( log(Vendas) ~ TV + Radio, data = conj_treino)\nsummary(mod6)\n\n\nCall:\nlm(formula = log(Vendas) ~ TV + Radio, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.77994 -0.05255  0.04368  0.10055  0.17353 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.791156   0.043994  40.713  < 2e-16 ***\nTV          0.003492   0.000218  16.022  < 2e-16 ***\nRadio       0.011524   0.001280   9.006 5.04e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1975 on 116 degrees of freedom\nMultiple R-squared:  0.765, Adjusted R-squared:  0.761 \nF-statistic: 188.8 on 2 and 116 DF,  p-value: < 2.2e-16\n\nresidualPlots(mod6)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nTV           -6.8943        3.092e-10 ***\nRadio        -0.2563           0.7982    \nTukey test   -0.5761           0.5646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.2.html#dado-que-parece-outlier-e-√©-um-valor-influente",
    "href": "semanas/Aula07.2.html#dado-que-parece-outlier-e-√©-um-valor-influente",
    "title": "Regress√£o Linear M√∫ltipla",
    "section": "Dado que parece outlier e √© um valor influente",
    "text": "Dado que parece outlier e √© um valor influente\nA fun√ß√£o OutlierTest () no pacote do car localiza o maior res√≠duo studentizado em valor absoluto e calcula o teste t com corre√ß√£o de Bonferroni. O testes de Outlier utiliza uma distribui√ß√£o t para testar se o maior valor do residuo studentizado do modelo √© estatisticamente diferente das outras observa√ß√µes. Um valor p significativo indica um outlier extremo que merece um exame mais aprofundado.\n\noutlierTest(mod6)\n\n    rstudent unadjusted p-value Bonferroni p\n83 -18.13798         1.5879e-35   1.8896e-33\n\nconj_treino[83,]\n\n# A tibble: 1 √ó 4\n     TV Radio Jornal Vendas\n  <dbl> <dbl>  <dbl>  <dbl>\n1   0.7  39.6    8.7    1.6"
  },
  {
    "objectID": "semanas/Aula07.3.html",
    "href": "semanas/Aula07.3.html",
    "title": "Sele√ß√£o de Modelos",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)\nlibrary(leaps)"
  },
  {
    "objectID": "semanas/Aula07.3.html#carregando-os-dados",
    "href": "semanas/Aula07.3.html#carregando-os-dados",
    "title": "Sele√ß√£o de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\ndata(Boston)\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nsummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\nnrow(Boston)\n\n[1] 506"
  },
  {
    "objectID": "semanas/Aula07.3.html#explica√ß√£o-das-vari√°veis",
    "href": "semanas/Aula07.3.html#explica√ß√£o-das-vari√°veis",
    "title": "Sele√ß√£o de Modelos",
    "section": "Explica√ß√£o das vari√°veis",
    "text": "Explica√ß√£o das vari√°veis\n\n# Boston Database\n# \n# 1) crim - taxa de criminalidade per capita por cidade.\n# \n# 2) zn - propor√ß√£o de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n# 3) indus - propor√ß√£o de neg√≥cios n√£o comerciais por acres e por cidade.\n# \n# 4) chas - vari√°vel dummy do Rio Charles (= 1 se pr√≥ximo do rio; 0 de outra forma).\n# \n# 5) nox - concentra√ß√£o de √≥xido de nitrog√™nio (partes por 10 milh√µes).\n# \n# 6) rm - n√∫mero m√©dio de c√¥modos por habita√ß√£o\n# \n# 7) age - propor√ß√£o da unidade ocupadas pelos propriet√°rios constru√≠das antes 1940.\n# \n# 8) dis - m√©dia ponderada das dist√¢ncias dos 5 pontos de emprego em Boston.\n# \n# 9) rad - indice de acessibilidade das avenidas radiais.\n# \n# 10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n# 11) ptratio - raz√£o aluno-professor por cidade.\n# \n# 12) black - 1000(Bk‚àí0.63)21000(Bk‚àí0.63)2 propor√ß√£o de negros por cidade.\n# \n# 13) lstat - percentual de baixo status da popula√ß√£o.\n# \n# 14) medv - valor mediano das casas ocupadas pelos propriet√°rio em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.3.html#conjunto-de-teste-e-treino",
    "href": "semanas/Aula07.3.html#conjunto-de-teste-e-treino",
    "title": "Sele√ß√£o de Modelos",
    "section": "Conjunto de teste e treino",
    "text": "Conjunto de teste e treino\n\nlibrary(caret)\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_teste <- Boston %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   403 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nstr(conj_teste)\n\n'data.frame':   103 obs. of  14 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ rad    : int  5 4 4 4 4 4 4 3 3 3 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ...\n\ngt::gt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      crim\n      zn\n      indus\n      chas\n      nox\n      rm\n      age\n      dis\n      rad\n      tax\n      ptratio\n      black\n      lstat\n      medv\n    \n  \n  \n    0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n    0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n    0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n    0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n    0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n    0.02985\n0.0\n2.18\n0\n0.458\n6.430\n58.7\n6.0622\n3\n222\n18.7\n394.12\n5.21\n28.7\n    0.08829\n12.5\n7.87\n0\n0.524\n6.012\n66.6\n5.5605\n5\n311\n15.2\n395.60\n12.43\n22.9\n    0.14455\n12.5\n7.87\n0\n0.524\n6.172\n96.1\n5.9505\n5\n311\n15.2\n396.90\n19.15\n27.1\n    0.17004\n12.5\n7.87\n0\n0.524\n6.004\n85.9\n6.5921\n5\n311\n15.2\n386.71\n17.10\n18.9\n    0.22489\n12.5\n7.87\n0\n0.524\n6.377\n94.3\n6.3467\n5\n311\n15.2\n392.52\n20.45\n15.0"
  },
  {
    "objectID": "semanas/Aula07.3.html#matriz-de-correla√ß√£o",
    "href": "semanas/Aula07.3.html#matriz-de-correla√ß√£o",
    "title": "Sele√ß√£o de Modelos",
    "section": "Matriz de correla√ß√£o",
    "text": "Matriz de correla√ß√£o\n\nlibrary(corrplot)\nmat_corr <- cor(conj_treino)\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula07.3.html#matriz-de-dispers√£o",
    "href": "semanas/Aula07.3.html#matriz-de-dispers√£o",
    "title": "Sele√ß√£o de Modelos",
    "section": "Matriz de dispers√£o",
    "text": "Matriz de dispers√£o\n\nlibrary(psych)\npairs.panels(conj_treino,\n             method = \"pearson\", # metodo de correla√ß√£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correla√ß√£o\n             )"
  },
  {
    "objectID": "semanas/Aula07.3.html#m√©todos-de-sele√ß√£o-de-modelo",
    "href": "semanas/Aula07.3.html#m√©todos-de-sele√ß√£o-de-modelo",
    "title": "Sele√ß√£o de Modelos",
    "section": "M√©todos de sele√ß√£o de modelo",
    "text": "M√©todos de sele√ß√£o de modelo\n\n## Best Subset sem definir o n√∫mero m√°x de subsets a ser avaliado\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino)\nsummary(ajusreg.comp)\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 ) \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n\n## N√£o testou todas as combina√ß√µes poss√≠veis"
  },
  {
    "objectID": "semanas/Aula07.3.html#nvmax13",
    "href": "semanas/Aula07.3.html#nvmax13",
    "title": "Sele√ß√£o de Modelos",
    "section": "nvmax=13",
    "text": "nvmax=13\n\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=13)\nsumario.reg <- summary(ajusreg.comp)\nsumario.reg\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: exhaustive\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nnames(sumario.reg)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\""
  },
  {
    "objectID": "semanas/Aula07.3.html#avaliando-os-modelos",
    "href": "semanas/Aula07.3.html#avaliando-os-modelos",
    "title": "Sele√ß√£o de Modelos",
    "section": "Avaliando os modelos",
    "text": "Avaliando os modelos\n\n## Os modelos v√£o ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 11\n\npoints(11,sumario.reg$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste",
    "title": "Sele√ß√£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.comp,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#forward-stepwise-passo-a-passo-√†-frente",
    "href": "semanas/Aula07.3.html#forward-stepwise-passo-a-passo-√†-frente",
    "title": "Sele√ß√£o de Modelos",
    "section": "Forward Stepwise (passo a passo √† frente)",
    "text": "Forward Stepwise (passo a passo √† frente)\n\najusreg.fwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd <- summary(ajusreg.fwd)\nsumario.reg.fwd \n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"forward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: forward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nwhich.min(sumario.reg.fwd$cp)\n\n[1] 11\n\nplot(sumario.reg.fwd$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-1",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-1",
    "title": "Sele√ß√£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.fwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#backward-stepwise-passo-a-passo-atr√°s",
    "href": "semanas/Aula07.3.html#backward-stepwise-passo-a-passo-atr√°s",
    "title": "Sele√ß√£o de Modelos",
    "section": "Backward Stepwise (passo a passo atr√°s)",
    "text": "Backward Stepwise (passo a passo atr√°s)\n\najusreg.bwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"backward\")\nsumario.reg.bwd <- summary(ajusreg.bwd)\nsumario.reg.bwd\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"backward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: backward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nwhich.min(sumario.reg.bwd$cp)\n\n[1] 11\n\nplot(sumario.reg.bwd$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\npoints(11,sumario.reg.bwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-2",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-2",
    "title": "Sele√ß√£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.bwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#comportamento-dos-erros-de-treino-e-teste",
    "href": "semanas/Aula07.3.html#comportamento-dos-erros-de-treino-e-teste",
    "title": "Sele√ß√£o de Modelos",
    "section": "Comportamento dos erros de treino e teste",
    "text": "Comportamento dos erros de treino e teste\n\n## Codigo original de T. Hastie\nreg.fwd <- regsubsets(medv ~ . ,data=conj_treino,nvmax=13, method=\"forward\")\nval.erro <- rep(NA,13)\nx.teste <- model.matrix(medv~.,data=conj_teste)\nfor(i in 1:13){\n  coefi <- coef(reg.fwd,id=i)\n  pred <- x.teste[,names(coefi)]%*%coefi\n  val.erro[i] <- mean((conj_teste$medv - pred)^2)\n}\nplot(sqrt(val.erro),ylab=\"Raiz do EQM\",ylim=c(4,8),pch=19,type=\"b\")\npoints(sqrt(reg.fwd$rss[-1]/403),col=\"blue\",pch=19,type=\"b\")\nlegend(\"topright\",legend=c(\"Treino\",\"Teste\"),col=c(\"blue\",\"black\"),pch=19)"
  },
  {
    "objectID": "semanas/Aula07.3.html#testando-outra-estat√≠stica-de-sele√ß√£o-de-modelos---bic",
    "href": "semanas/Aula07.3.html#testando-outra-estat√≠stica-de-sele√ß√£o-de-modelos---bic",
    "title": "Sele√ß√£o de Modelos",
    "section": "Testando outra estat√≠stica de sele√ß√£o de modelos - BIC",
    "text": "Testando outra estat√≠stica de sele√ß√£o de modelos - BIC\n\najusreg.fwd1 <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd1 <- summary(ajusreg.fwd1)\nnames(sumario.reg.fwd1)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   \n\nwhich.min(sumario.reg.fwd1$bic)\n\n[1] 7\n\nplot(sumario.reg.fwd1$bic,xlab=\"N√∫mero de Vari√°veis\",ylab=\"BIC\")\npoints(7,sumario.reg.fwd1$bic[7],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.fwd1,7)  \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735"
  },
  {
    "objectID": "semanas/Aula07.3.html#usando-o-cp-novamente",
    "href": "semanas/Aula07.3.html#usando-o-cp-novamente",
    "title": "Sele√ß√£o de Modelos",
    "section": "Usando o Cp novamente",
    "text": "Usando o Cp novamente\n\nwhich.min(sumario.reg.fwd1$cp)\n\n[1] 11\n\nplot(sumario.reg.fwd1$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd1$cp[11],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.fwd1,11)\n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#comparando-os-dois-modelos-com-o-lm",
    "href": "semanas/Aula07.3.html#comparando-os-dois-modelos-com-o-lm",
    "title": "Sele√ß√£o de Modelos",
    "section": "Comparando os dois modelos com o lm()",
    "text": "Comparando os dois modelos com o lm()\n\n## Usando o lm para ajustar o modelo com as vari√°veis selecionadas pelo BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nmod_cp <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp)\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1857  -2.8830  -0.5641   1.8709  25.9074 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  24.119556   5.661887   4.260 2.56e-05 ***\ncrim         -0.059121   0.038751  -1.526 0.127902    \nzn            0.033951   0.015207   2.233 0.026139 *  \nchas          3.459703   0.995635   3.475 0.000568 ***\nnox         -17.228617   3.807289  -4.525 8.02e-06 ***\nrm            5.108916   0.466926  10.942  < 2e-16 ***\ndis          -1.272748   0.203301  -6.260 1.01e-09 ***\nrad           0.252036   0.067390   3.740 0.000212 ***\ntax          -0.010155   0.003556  -2.856 0.004525 ** \nptratio      -0.947329   0.141436  -6.698 7.38e-11 ***\nblack         0.012962   0.002822   4.593 5.90e-06 ***\nlstat        -0.396034   0.054069  -7.325 1.38e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.554 on 391 degrees of freedom\nMultiple R-squared:  0.7618,    Adjusted R-squared:  0.7551 \nF-statistic: 113.7 on 11 and 391 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3.html#eliminando-a-vari√°vel-n√£o-significativa",
    "href": "semanas/Aula07.3.html#eliminando-a-vari√°vel-n√£o-significativa",
    "title": "Sele√ß√£o de Modelos",
    "section": "Eliminando a vari√°vel n√£o significativa",
    "text": "Eliminando a vari√°vel n√£o significativa\n\nmod_cp2 <- lm(medv ~ zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp2)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + tax + \n    ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1471  -2.7317  -0.5389   1.9772  25.9698 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  22.884672   5.613214   4.077 5.53e-05 ***\nzn            0.031594   0.015154   2.085 0.037726 *  \nchas          3.524816   0.996402   3.538 0.000452 ***\nnox         -16.721605   3.799175  -4.401 1.39e-05 ***\nrm            5.183515   0.465145  11.144  < 2e-16 ***\ndis          -1.231499   0.201836  -6.101 2.52e-09 ***\nrad           0.218320   0.063772   3.423 0.000683 ***\ntax          -0.009827   0.003556  -2.764 0.005984 ** \nptratio      -0.938621   0.141560  -6.631 1.11e-10 ***\nblack         0.013799   0.002773   4.976 9.72e-07 ***\nlstat        -0.406190   0.053749  -7.557 2.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.562 on 392 degrees of freedom\nMultiple R-squared:  0.7604,    Adjusted R-squared:  0.7543 \nF-statistic: 124.4 on 10 and 392 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3.html#avaliando-colinearidade",
    "href": "semanas/Aula07.3.html#avaliando-colinearidade",
    "title": "Sele√ß√£o de Modelos",
    "section": "Avaliando Colinearidade",
    "text": "Avaliando Colinearidade\nUma investiga√ß√£o minuciosa da multicollinearidade envolver√° a an√°lise do valor do \\(R^2\\) que resulta da regress√£o de cada uma das vari√°veis explicativas contra todas as outras. A rela√ß√£o entre as vari√°veis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacion√°rio da vari√¢ncia (FIV) ou Variance Inflation Factor (VIF). Seja \\(Rj~^{2}\\) o quadrado do coeficiente de correla√ß√£o m√∫ltipla que resulta quando a vari√°vel explicativa \\(Xj~\\) √© ajustada contra todas as outras vari√°veis explicativas. Ent√£o o vif para \\(Xj~\\) √© \\(VIFj = 1 / (1-Rj~^{2})\\)\nA regra geral √© que vifs superiores a 4 justificam novas investiga√ß√µes, enquanto VIFs superiores a 10 s√£o sinais de multicollinearidade grave que requerem corre√ß√£o.\n\nlibrary(car)\nvif(mod_cp2)\n\n      zn     chas      nox       rm      dis      rad      tax  ptratio \n2.128862 1.076888 3.707463 2.032934 3.357506 6.005229 6.999822 1.796214 \n   black    lstat \n1.388299 3.010108 \n\n## Vamos eliminar tax e ver o que acontece\nmod_cp3 <- lm(medv ~ zn + chas + nox + rm + dis + rad + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp3)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.6480  -2.9158  -0.5013   1.9274  25.8537 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  21.606433   5.641174   3.830 0.000149 ***\nzn            0.021779   0.014856   1.466 0.143439    \nchas          3.623029   1.004143   3.608 0.000348 ***\nnox         -18.864099   3.750520  -5.030 7.48e-07 ***\nrm            5.337321   0.465687  11.461  < 2e-16 ***\ndis          -1.150869   0.201396  -5.714 2.18e-08 ***\nrad           0.079897   0.039806   2.007 0.045417 *  \nptratio      -1.016641   0.139883  -7.268 1.99e-12 ***\nblack         0.014071   0.002794   5.035 7.28e-07 ***\nlstat        -0.411503   0.054166  -7.597 2.24e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.6 on 393 degrees of freedom\nMultiple R-squared:  0.7557,    Adjusted R-squared:  0.7501 \nF-statistic: 135.1 on 9 and 393 DF,  p-value: < 2.2e-16\n\nvif(mod_cp3)\n\n      zn     chas      nox       rm      dis      rad  ptratio    black \n2.011936 1.075519 3.553096 2.003832 3.287355 2.300918 1.724780 1.386548 \n   lstat \n3.006257"
  },
  {
    "objectID": "semanas/Aula07.3.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "href": "semanas/Aula07.3.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "title": "Sele√ß√£o de Modelos",
    "section": "Testando os dois modelos com o conjunto de teste",
    "text": "Testando os dois modelos com o conjunto de teste\n\n# Modelo com base no Cp\nsummary(mod_cp3)$sigma\n\n[1] 4.600016\n\nsummary(mod_cp3)$adj.r.squared\n\n[1] 0.7501409\n\nsqrt(mean((conj_teste$medv - predict(mod_cp3, conj_teste)) ^ 2))\n\n[1] 5.918251\n\n# Modelo com base no BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)$sigma\n\n[1] 4.630994\n\nsummary(mod_bic)$adj.r.squared\n\n[1] 0.7467643\n\nsqrt(mean((conj_teste$medv - predict(mod_bic, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula07.3A.html#carregando-bibliotecas",
    "href": "semanas/Aula07.3A.html#carregando-bibliotecas",
    "title": "Sele√ß√£o de Modelos",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nCodelibrary(MASS)\nlibrary(tidyverse)\nlibrary(leaps)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#carregando-os-dados",
    "href": "semanas/Aula07.3A.html#carregando-os-dados",
    "title": "Sele√ß√£o de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\nCodedata(Boston)\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nCodesummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\nCodenrow(Boston)\n\n[1] 506"
  },
  {
    "objectID": "semanas/Aula07.3A.html#explica√ß√£o-das-vari√°veis",
    "href": "semanas/Aula07.3A.html#explica√ß√£o-das-vari√°veis",
    "title": "Sele√ß√£o de Modelos",
    "section": "Explica√ß√£o das vari√°veis",
    "text": "Explica√ß√£o das vari√°veis\n\nCode# Boston Database\n# \n# 1) crim - taxa de criminalidade per capita por cidade.\n# \n# 2) zn - propor√ß√£o de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n# 3) indus - propor√ß√£o de neg√≥cios n√£o comerciais por acres e por cidade.\n# \n# 4) chas - vari√°vel dummy do Rio Charles (= 1 se pr√≥ximo do rio; 0 de outra forma).\n# \n# 5) nox - concentra√ß√£o de √≥xido de nitrog√™nio (partes por 10 milh√µes).\n# \n# 6) rm - n√∫mero m√©dio de c√¥modos por habita√ß√£o\n# \n# 7) age - propor√ß√£o da unidade ocupadas pelos propriet√°rios constru√≠das antes 1940.\n# \n# 8) dis - m√©dia ponderada das dist√¢ncias dos 5 pontos de emprego em Boston.\n# \n# 9) rad - indice de acessibilidade das avenidas radiais.\n# \n# 10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n# 11) ptratio - raz√£o aluno-professor por cidade.\n# \n# 12) black - 1000(Bk‚àí0.63)21000(Bk‚àí0.63)2 propor√ß√£o de negros por cidade.\n# \n# 13) lstat - percentual de baixo status da popula√ß√£o.\n# \n# 14) medv - valor mediano das casas ocupadas pelos propriet√°rio em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#conjunto-de-teste-e-treino",
    "href": "semanas/Aula07.3A.html#conjunto-de-teste-e-treino",
    "title": "Sele√ß√£o de Modelos",
    "section": "Conjunto de teste e treino",
    "text": "Conjunto de teste e treino\n\nCodelibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nCodeset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_teste <- Boston %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   403 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nCodestr(conj_teste)\n\n'data.frame':   103 obs. of  14 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ rad    : int  5 4 4 4 4 4 4 3 3 3 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ...\n\nCodegt::gt(head(conj_treino, 10))\n\n\n\n\n\n\ncrim\n      zn\n      indus\n      chas\n      nox\n      rm\n      age\n      dis\n      rad\n      tax\n      ptratio\n      black\n      lstat\n      medv\n    \n\n\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n0.02985\n0.0\n2.18\n0\n0.458\n6.430\n58.7\n6.0622\n3\n222\n18.7\n394.12\n5.21\n28.7\n\n\n0.08829\n12.5\n7.87\n0\n0.524\n6.012\n66.6\n5.5605\n5\n311\n15.2\n395.60\n12.43\n22.9\n\n\n0.14455\n12.5\n7.87\n0\n0.524\n6.172\n96.1\n5.9505\n5\n311\n15.2\n396.90\n19.15\n27.1\n\n\n0.17004\n12.5\n7.87\n0\n0.524\n6.004\n85.9\n6.5921\n5\n311\n15.2\n386.71\n17.10\n18.9\n\n\n0.22489\n12.5\n7.87\n0\n0.524\n6.377\n94.3\n6.3467\n5\n311\n15.2\n392.52\n20.45\n15.0"
  },
  {
    "objectID": "semanas/Aula07.3A.html#matriz-de-correla√ß√£o",
    "href": "semanas/Aula07.3A.html#matriz-de-correla√ß√£o",
    "title": "Sele√ß√£o de Modelos",
    "section": "Matriz de correla√ß√£o",
    "text": "Matriz de correla√ß√£o\n\nCodelibrary(corrplot)\nmat_corr <- cor(conj_treino)\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#matriz-de-dispers√£o",
    "href": "semanas/Aula07.3A.html#matriz-de-dispers√£o",
    "title": "Sele√ß√£o de Modelos",
    "section": "Matriz de dispers√£o",
    "text": "Matriz de dispers√£o\n\nCodelibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nCodepairs.panels(conj_treino,\n             method = \"pearson\", # metodo de correla√ß√£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correla√ß√£o\n             )"
  },
  {
    "objectID": "semanas/Aula07.3A.html#m√©todos-de-sele√ß√£o-de-modelo",
    "href": "semanas/Aula07.3A.html#m√©todos-de-sele√ß√£o-de-modelo",
    "title": "Sele√ß√£o de Modelos",
    "section": "M√©todos de sele√ß√£o de modelo",
    "text": "M√©todos de sele√ß√£o de modelo\n\nCode## Best Subset sem definir o n√∫mero m√°x de subsets a ser avaliado\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino)\nsummary(ajusreg.comp)\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 ) \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n\nCode## N√£o testou todas as combina√ß√µes poss√≠veis"
  },
  {
    "objectID": "semanas/Aula07.3A.html#nvmax13",
    "href": "semanas/Aula07.3A.html#nvmax13",
    "title": "Sele√ß√£o de Modelos",
    "section": "nvmax=13",
    "text": "nvmax=13\n\nCodeajusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=13)\nsumario.reg <- summary(ajusreg.comp)\nsumario.reg\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: exhaustive\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodenames(sumario.reg)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\""
  },
  {
    "objectID": "semanas/Aula07.3A.html#avaliando-os-modelos",
    "href": "semanas/Aula07.3A.html#avaliando-os-modelos",
    "title": "Sele√ß√£o de Modelos",
    "section": "Avaliando os modelos",
    "text": "Avaliando os modelos\n\nCode## Os modelos v√£o ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 11\n\nCodepoints(11,sumario.reg$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste",
    "title": "Sele√ß√£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.comp,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#forward-stepwise-passo-a-passo-√†-frente",
    "href": "semanas/Aula07.3A.html#forward-stepwise-passo-a-passo-√†-frente",
    "title": "Sele√ß√£o de Modelos",
    "section": "Forward Stepwise (passo a passo √† frente)",
    "text": "Forward Stepwise (passo a passo √† frente)\n\nCodeajusreg.fwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd <- summary(ajusreg.fwd)\nsumario.reg.fwd \n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"forward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: forward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodewhich.min(sumario.reg.fwd$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.fwd$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-1",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-1",
    "title": "Sele√ß√£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.fwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#backward-stepwise-passo-a-passo-atr√°s",
    "href": "semanas/Aula07.3A.html#backward-stepwise-passo-a-passo-atr√°s",
    "title": "Sele√ß√£o de Modelos",
    "section": "Backward Stepwise (passo a passo atr√°s)",
    "text": "Backward Stepwise (passo a passo atr√°s)\n\nCodeajusreg.bwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"backward\")\nsumario.reg.bwd <- summary(ajusreg.bwd)\nsumario.reg.bwd\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"backward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: backward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodewhich.min(sumario.reg.bwd$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.bwd$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\npoints(11,sumario.reg.bwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-2",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-2",
    "title": "Sele√ß√£o de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.bwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#comportamento-dos-erros-de-treino-e-teste",
    "href": "semanas/Aula07.3A.html#comportamento-dos-erros-de-treino-e-teste",
    "title": "Sele√ß√£o de Modelos",
    "section": "Comportamento dos erros de treino e teste",
    "text": "Comportamento dos erros de treino e teste\n\nCode## Codigo original de T. Hastie\nreg.fwd <- regsubsets(medv ~ . ,data=conj_treino,nvmax=13, method=\"forward\")\nval.erro <- rep(NA,13)\nx.teste <- model.matrix(medv~.,data=conj_teste)\nfor(i in 1:13){\n  coefi <- coef(reg.fwd,id=i)\n  pred <- x.teste[,names(coefi)]%*%coefi\n  val.erro[i] <- mean((conj_teste$medv - pred)^2)\n}\nplot(sqrt(val.erro),ylab=\"Raiz do EQM\",ylim=c(4,8),pch=19,type=\"b\")\npoints(sqrt(reg.fwd$rss[-1]/403),col=\"blue\",pch=19,type=\"b\")\nlegend(\"topright\",legend=c(\"Treino\",\"Teste\"),col=c(\"blue\",\"black\"),pch=19)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#testando-outra-estat√≠stica-de-sele√ß√£o-de-modelos---bic",
    "href": "semanas/Aula07.3A.html#testando-outra-estat√≠stica-de-sele√ß√£o-de-modelos---bic",
    "title": "Sele√ß√£o de Modelos",
    "section": "Testando outra estat√≠stica de sele√ß√£o de modelos - BIC",
    "text": "Testando outra estat√≠stica de sele√ß√£o de modelos - BIC\n\nCodeajusreg.fwd1 <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd1 <- summary(ajusreg.fwd1)\nnames(sumario.reg.fwd1)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   \n\nCodewhich.min(sumario.reg.fwd1$bic)\n\n[1] 7\n\nCodeplot(sumario.reg.fwd1$bic,xlab=\"N√∫mero de Vari√°veis\",ylab=\"BIC\")\npoints(7,sumario.reg.fwd1$bic[7],pch=20,col=\"red\")\n\n\n\nCodecoef(ajusreg.fwd1,7)  \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735"
  },
  {
    "objectID": "semanas/Aula07.3A.html#usando-o-cp-novamente",
    "href": "semanas/Aula07.3A.html#usando-o-cp-novamente",
    "title": "Sele√ß√£o de Modelos",
    "section": "Usando o Cp novamente",
    "text": "Usando o Cp novamente\n\nCodewhich.min(sumario.reg.fwd1$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.fwd1$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd1$cp[11],pch=20,col=\"red\")\n\n\n\nCodecoef(ajusreg.fwd1,11)\n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#comparando-os-dois-modelos-com-o-lm",
    "href": "semanas/Aula07.3A.html#comparando-os-dois-modelos-com-o-lm",
    "title": "Sele√ß√£o de Modelos",
    "section": "Comparando os dois modelos com o lm()",
    "text": "Comparando os dois modelos com o lm()\n\nCode## Usando o lm para ajustar o modelo com as vari√°veis selecionadas pelo BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nCodemod_cp <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp)\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1857  -2.8830  -0.5641   1.8709  25.9074 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  24.119556   5.661887   4.260 2.56e-05 ***\ncrim         -0.059121   0.038751  -1.526 0.127902    \nzn            0.033951   0.015207   2.233 0.026139 *  \nchas          3.459703   0.995635   3.475 0.000568 ***\nnox         -17.228617   3.807289  -4.525 8.02e-06 ***\nrm            5.108916   0.466926  10.942  < 2e-16 ***\ndis          -1.272748   0.203301  -6.260 1.01e-09 ***\nrad           0.252036   0.067390   3.740 0.000212 ***\ntax          -0.010155   0.003556  -2.856 0.004525 ** \nptratio      -0.947329   0.141436  -6.698 7.38e-11 ***\nblack         0.012962   0.002822   4.593 5.90e-06 ***\nlstat        -0.396034   0.054069  -7.325 1.38e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.554 on 391 degrees of freedom\nMultiple R-squared:  0.7618,    Adjusted R-squared:  0.7551 \nF-statistic: 113.7 on 11 and 391 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3A.html#eliminando-a-vari√°vel-n√£o-significativa",
    "href": "semanas/Aula07.3A.html#eliminando-a-vari√°vel-n√£o-significativa",
    "title": "Sele√ß√£o de Modelos",
    "section": "Eliminando a vari√°vel n√£o significativa",
    "text": "Eliminando a vari√°vel n√£o significativa\n\nCodemod_cp2 <- lm(medv ~ zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp2)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + tax + \n    ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1471  -2.7317  -0.5389   1.9772  25.9698 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  22.884672   5.613214   4.077 5.53e-05 ***\nzn            0.031594   0.015154   2.085 0.037726 *  \nchas          3.524816   0.996402   3.538 0.000452 ***\nnox         -16.721605   3.799175  -4.401 1.39e-05 ***\nrm            5.183515   0.465145  11.144  < 2e-16 ***\ndis          -1.231499   0.201836  -6.101 2.52e-09 ***\nrad           0.218320   0.063772   3.423 0.000683 ***\ntax          -0.009827   0.003556  -2.764 0.005984 ** \nptratio      -0.938621   0.141560  -6.631 1.11e-10 ***\nblack         0.013799   0.002773   4.976 9.72e-07 ***\nlstat        -0.406190   0.053749  -7.557 2.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.562 on 392 degrees of freedom\nMultiple R-squared:  0.7604,    Adjusted R-squared:  0.7543 \nF-statistic: 124.4 on 10 and 392 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3A.html#avaliando-colinearidade",
    "href": "semanas/Aula07.3A.html#avaliando-colinearidade",
    "title": "Sele√ß√£o de Modelos",
    "section": "Avaliando Colinearidade",
    "text": "Avaliando Colinearidade\nUma investiga√ß√£o minuciosa da multicollinearidade envolver√° a an√°lise do valor do \\(R^2\\) que resulta da regress√£o de cada uma das vari√°veis explicativas contra todas as outras. A rela√ß√£o entre as vari√°veis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacion√°rio da vari√¢ncia (FIV) ou Variance Inflation Factor (VIF). Seja \\(Rj~^{2}\\) o quadrado do coeficiente de correla√ß√£o m√∫ltipla que resulta quando a vari√°vel explicativa \\(Xj~\\) √© ajustada contra todas as outras vari√°veis explicativas. Ent√£o o vif para \\(Xj~\\) √© \\(VIFj = 1 / (1-Rj~^{2})\\)\nA regra geral √© que vifs superiores a 4 justificam novas investiga√ß√µes, enquanto VIFs superiores a 10 s√£o sinais de multicollinearidade grave que requerem corre√ß√£o.\n\nCodelibrary(car)\nvif(mod_cp2)\n\n      zn     chas      nox       rm      dis      rad      tax  ptratio \n2.128862 1.076888 3.707463 2.032934 3.357506 6.005229 6.999822 1.796214 \n   black    lstat \n1.388299 3.010108 \n\nCode## Vamos eliminar tax e ver o que acontece\nmod_cp3 <- lm(medv ~ zn + chas + nox + rm + dis + rad + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp3)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.6480  -2.9158  -0.5013   1.9274  25.8537 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  21.606433   5.641174   3.830 0.000149 ***\nzn            0.021779   0.014856   1.466 0.143439    \nchas          3.623029   1.004143   3.608 0.000348 ***\nnox         -18.864099   3.750520  -5.030 7.48e-07 ***\nrm            5.337321   0.465687  11.461  < 2e-16 ***\ndis          -1.150869   0.201396  -5.714 2.18e-08 ***\nrad           0.079897   0.039806   2.007 0.045417 *  \nptratio      -1.016641   0.139883  -7.268 1.99e-12 ***\nblack         0.014071   0.002794   5.035 7.28e-07 ***\nlstat        -0.411503   0.054166  -7.597 2.24e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.6 on 393 degrees of freedom\nMultiple R-squared:  0.7557,    Adjusted R-squared:  0.7501 \nF-statistic: 135.1 on 9 and 393 DF,  p-value: < 2.2e-16\n\nCodevif(mod_cp3)\n\n      zn     chas      nox       rm      dis      rad  ptratio    black \n2.011936 1.075519 3.553096 2.003832 3.287355 2.300918 1.724780 1.386548 \n   lstat \n3.006257"
  },
  {
    "objectID": "semanas/Aula07.3A.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "href": "semanas/Aula07.3A.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "title": "Sele√ß√£o de Modelos",
    "section": "Testando os dois modelos com o conjunto de teste",
    "text": "Testando os dois modelos com o conjunto de teste\n\nCode# Modelo com base no Cp\nsummary(mod_cp3)$sigma\n\n[1] 4.600016\n\nCodesummary(mod_cp3)$adj.r.squared\n\n[1] 0.7501409\n\nCodesqrt(mean((conj_teste$medv - predict(mod_cp3, conj_teste)) ^ 2))\n\n[1] 5.918251\n\nCode# Modelo com base no BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)$sigma\n\n[1] 4.630994\n\nCodesummary(mod_bic)$adj.r.squared\n\n[1] 0.7467643\n\nCodesqrt(mean((conj_teste$medv - predict(mod_bic, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula07.4.html#carregando-bibliotecas",
    "href": "semanas/Aula07.4.html#carregando-bibliotecas",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(glmnet)\ndata(Boston)"
  },
  {
    "objectID": "semanas/Aula07.4.html#carregando-os-dados",
    "href": "semanas/Aula07.4.html#carregando-os-dados",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nVamos utilizar neste exemplo os dados contidos na biblioteca MASS. A base de dados Boston tem 506 de valores pre√ßos medianos de casas na regi√£o de Boston com 13 outras vari√°veis explicativas (potencialmente). Vamos explorar os dados e ajustar modelos com penaliza√ß√£o o Ridge e o LASSO e depois vamos comparar com os m√≠nimos quadrados.\n\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nsummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\n\nObservamos acima que todas as vari√°veis s√£o quantitativas e que n√£o h√° necessidade de transforma√ß√µes."
  },
  {
    "objectID": "semanas/Aula07.4.html#significado-das-vari√°veis",
    "href": "semanas/Aula07.4.html#significado-das-vari√°veis",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Significado das vari√°veis",
    "text": "Significado das vari√°veis\n\n# Boston Database\n# \n#1) crim - taxa de criminalidade per capita por cidade.\n# \n#2) zn - propor√ß√£o de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n#3) indus - propor√ß√£o de neg√≥cios n√£o comerciais por acres e por cidade.\n# \n#4) chas - vari√°vel dummy do Rio Charles(= 1 se pr√≥ximo do rio; 0 de outra forma).\n# \n#5) nox - concentra√ß√£o de √≥xido de nitrog√™nio (partes por 10 milh√µes).\n# \n#6) rm - n√∫mero m√©dio de quartos por habita√ß√£o\n# \n#7) age - propor√ß√£o da unidade ocupadas pelos propriet√°rios constru√≠das antes 1940.\n# \n#8) dis - m√©dia ponderada das dist√¢ncias dos 5 pontos de emprego em Boston.\n# \n#9) rad - indice de acessibilidade das avenidas radiais.\n# \n#10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n#11) ptratio - raz√£o aluno-professor por cidade.\n# \n#12) black - 1000(Bk‚àí0.63)21000(Bk‚àí0.63)2 propor√ß√£o de negros por cidade.\n# \n#13) lstat - percentual de baixo status da popula√ß√£o.\n# \n#14) medv - valor mediano das cas ocupadas pelos propriet√°rio em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.4.html#conjunto-de-treino-e-de-teste",
    "href": "semanas/Aula07.4.html#conjunto-de-treino-e-de-teste",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Conjunto de treino e de teste",
    "text": "Conjunto de treino e de teste\n\nlibrary(caret)\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_treino <- conj_treino %>% select(-rad)\nconj_teste <- Boston %>% slice(indice_teste)\nconj_teste <- conj_teste %>% select(-rad)\nstr(conj_treino)\n\n'data.frame':   403 obs. of  13 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nstr(conj_teste)\n\n'data.frame':   103 obs. of  13 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ..."
  },
  {
    "objectID": "semanas/Aula07.4.html#m√©todos-de-regulariza√ß√£o",
    "href": "semanas/Aula07.4.html#m√©todos-de-regulariza√ß√£o",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "M√©todos de Regulariza√ß√£o",
    "text": "M√©todos de Regulariza√ß√£o\nO pacote glmnet n√£o usa a linguagem de formula, em particular n√≥s devemos passar \\(x\\) como uma matriz e \\(y\\) como um vetor, pois n√£o se usa a sintaxe \\(y \\sim x\\). Com isso ser√° necess√°rio ajustar x e y. A fun√ß√£o model.matrix() √© particularmente √∫til para criar x; n√£o s√≥ produz uma matriz correspondente as vari√°veis explicativas, mas tamb√©m transforma automaticamente quaisquer vari√°veis qualitativas em vari√°veis dummy. Esta √∫ltima propriedade √© importante porque o glmnet() s√≥ pode tomar insumos num√©ricos e quantitativos.\n\nx_treino <- model.matrix(medv ~ . , data = conj_treino)[, -1]\ny_treino <- conj_treino$medv\n\nx_teste <- model.matrix(medv ~ . , data = conj_teste)[, -1]\ny_teste = conj_teste$medv"
  },
  {
    "objectID": "semanas/Aula07.4.html#regress√£o-ridge",
    "href": "semanas/Aula07.4.html#regress√£o-ridge",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Regress√£o Ridge",
    "text": "Regress√£o Ridge\nPrimeiro vamos ajustar um modelo de regress√£o Ridge. Isso √© conseguido chamando glmnet() com alpha=0, se alpha=1 ent√£o glmnet() ajusta um lasso.(veja o arquivo de ajuda).\n\n## Estabelecendo um grid de valores para lambda\ngrid <- 10^seq(-2, 10, length = 100)\najusreg.ridge <- glmnet(x_treino, y_treino, alpha=0, lambda = grid)\n\nPor padr√£o, a fun√ß√£o glmnet() executa a regress√£o ridge automaticamente selecionando a faixa de valores de \\(\\lambda\\). No entanto, aqui n√≥s escolhemos implementar usando uma grade de valores que variam de \\(\\lambda = 10^{-2}\\) a \\(\\lambda = 10^{10}\\), cobrindo toda a gama de cen√°rios do modelo nulo contendo apenas o coeficiente linear at√© o ajuste dos m√≠nimos quadrados.\nTamb√©m podemos calcular o modelo para um valor particular de \\(\\lambda\\) que n√£o √© um dos valores de grade. Observe que, por padr√£o, a fun√ß√£o glmnet() padroniza as vari√°veis para que elas estejam na mesma escala. Esta padroniza√ß√£o √© muito importante no caso da regress√£o Ridge, pois ela √© afetada pela mudan√ßa de escala das vari√°veis explicativas.\nAssociado a cada valor de \\(\\lambda\\) existe um vetor de coeficientes de regress√£o de ridge, que √© armazenado em uma matriz que pode ser acessada por ‚Äòcoef()‚Äô. Neste caso, √© uma matriz \\(14 \\times 100\\), com 14 linhas (uma para cada preditor, mais uma para o coeficiente linear) e 100 colunas (uma para cada valor de \\(\\lambda\\)).\n\ndim(coef(ajusreg.ridge))\n\n[1]  13 100\n\nplot(ajusreg.ridge, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n\n\n\n\nQuando \\(\\lambda\\) √© grande o esperado √© que os coeficentes sejam pequenos e quando \\(\\lambda\\) √© pequeno os coeficientes assumem valores maiores.\n\najusreg.ridge$lambda[1] # Mostra primeiro valor de lambda\n\n[1] 1e+10\n\ncoef(ajusreg.ridge)[,1] # Mostra os coeficientes associados com o primeiro valor\n\n  (Intercept)          crim            zn         indus          chas \n 2.247246e+01 -4.109894e-10  1.380771e-10 -6.245296e-10  6.798952e-09 \n          nox            rm           age           dis           tax \n-3.138930e-08  9.031398e-09 -1.154044e-10  1.094430e-09 -2.354379e-11 \n      ptratio         black         lstat \n-2.000167e-09  3.131126e-11 -8.446650e-10 \n\najusreg.ridge$lambda[100] # Mostra cent√©simo valor de lambda\n\n[1] 0.01\n\ncoef(ajusreg.ridge)[,100] # Mostra os coeficientes associados com o cent√©simo valor\n\n  (Intercept)          crim            zn         indus          chas \n 1.678767e+01 -1.657453e-02  2.307677e-02 -6.932521e-02  3.914065e+00 \n          nox            rm           age           dis           tax \n-1.315187e+01  5.586213e+00 -2.297883e-02 -1.312388e+00  6.917237e-04 \n      ptratio         black         lstat \n-8.347461e-01  1.262501e-02 -3.575121e-01 \n\n\n\nlibrary(plotmo)\nplot_glmnet(ajusreg.ridge)"
  },
  {
    "objectID": "semanas/Aula07.4.html#cross-validation-no-ridge",
    "href": "semanas/Aula07.4.html#cross-validation-no-ridge",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Cross-Validation no Ridge",
    "text": "Cross-Validation no Ridge\nN√≥s podemos usar o k-fold cross validation para identificar o melhor valor de \\(\\lambda\\)\nA biblioteca glmnet j√° tem internamente uma fun√ß√£o para uso do crosss validation. O default s√£o 10 envelopes de dados nfold=10.\n\nset.seed(21)\nridge_cv <- cv.glmnet(x_treino,y_treino, alpha=0) ## por padr√£o k=10\nplot(ridge_cv)\n\n\n\nm_lamb <- ridge_cv$lambda.min  # Seleciona o lambda que minimiza o MSE (EQM) de treino\nm_lamb\n\n[1] 0.6844251\n\nlog(m_lamb)\n\n[1] -0.3791761\n\ncoef(ridge_cv, s=m_lamb)\n\n13 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept) 14.7144706557\ncrim        -0.0214927174\nzn           0.0200504882\nindus       -0.0735317662\nchas         3.8343862492\nnox         -9.4460044931\nrm           5.3120091904\nage         -0.0185326152\ndis         -1.0110801641\ntax         -0.0003434427\nptratio     -0.7785448609\nblack        0.0116393260\nlstat       -0.3465721929"
  },
  {
    "objectID": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste",
    "href": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Avaliando com conjunto de teste",
    "text": "Avaliando com conjunto de teste\nEm seguida avaliamos seu MSE no conjunto de teste, usando \\(\\lambda\\) = m_lamb. Observe o uso da fun√ß√£o ‚Äòpredict()‚Äô: desta vez temos previs√µes para um conjunto de teste, com o argumento newx.\n\najusreg.ridge2 <- glmnet(x_treino, y_treino, alpha=0, lambda = m_lamb)\ny_prev <- predict(ajusreg.ridge2, s = m_lamb, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n\n[1] 5.980257"
  },
  {
    "objectID": "semanas/Aula07.4.html#lasso",
    "href": "semanas/Aula07.4.html#lasso",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "LASSO",
    "text": "LASSO\nPrimeiro ajustamos com todos os dados como no caso do Ridge\n\najusreg.lasso <- glmnet(x_treino,y_treino, alpha = 1)\nplot(ajusreg.lasso, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n\n\n\nplot_glmnet(ajusreg.lasso)"
  },
  {
    "objectID": "semanas/Aula07.4.html#valida√ß√£o-cruzada-no-lasso",
    "href": "semanas/Aula07.4.html#valida√ß√£o-cruzada-no-lasso",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Valida√ß√£o Cruzada no LASSO",
    "text": "Valida√ß√£o Cruzada no LASSO\n\nlasso_cv <- cv.glmnet(x_treino,y_treino, alpha = 1)\nplot(lasso_cv)\n\n\n\nm_lamb1 <- lasso_cv$lambda.min  # Seleciona o lambda que minimiza o MSE de treino\nm_lamb1\n\n[1] 0.0595278\n\nlog(m_lamb1)\n\n[1] -2.821312\n\ncoef(lasso_cv, s=m_lamb1)\n\n13 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  14.763435253\ncrim         -0.006217225\nzn            0.017479823\nindus        -0.050830256\nchas          3.644367387\nnox         -11.463040415\nrm            5.608066407\nage          -0.018352749\ndis          -1.107502465\ntax           .          \nptratio      -0.825247011\nblack         0.012263992\nlstat        -0.362939273"
  },
  {
    "objectID": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste-1",
    "href": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste-1",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Avaliando com conjunto de teste",
    "text": "Avaliando com conjunto de teste\n\najusreg.lasso2 <- glmnet(x_treino, y_treino, alpha=1, lambda = m_lamb1)\ny_prev <- predict(ajusreg.lasso2, s = m_lamb1, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n\n[1] 6.027343"
  },
  {
    "objectID": "semanas/Aula07.4.html#comparando-com-a-sele√ß√£o-de-modelos-usando-o-cp",
    "href": "semanas/Aula07.4.html#comparando-com-a-sele√ß√£o-de-modelos-usando-o-cp",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Comparando com a sele√ß√£o de modelos usando o Cp",
    "text": "Comparando com a sele√ß√£o de modelos usando o Cp\n\nlibrary(leaps)\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg <- summary(ajusreg.comp)\n## Os modelos v√£o ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"N√∫mero de Vari√°veis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 9\n\npoints(9,sumario.reg$cp[9],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.4.html#ajustando-no-lm-e-vendo-o-erro-no-conjunto-de-teste",
    "href": "semanas/Aula07.4.html#ajustando-no-lm-e-vendo-o-erro-no-conjunto-de-teste",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "Ajustando no lm() e vendo o erro no conjunto de teste",
    "text": "Ajustando no lm() e vendo o erro no conjunto de teste\nObservando so resultados de erro vemos que tanto a regress√£o Ridge como o LASSO apresentaram valores de erro maiores que o modelo definido atrav√©s da melhor sele√ß√£o de modelos (best subset regression). Aqui usamos o Cp de Mallows como crit√©rio de dele√ß√£o de vari√°veis.\n\ncoef(ajusreg.comp,9) \n\n (Intercept)           zn         chas          nox           rm          age \n 17.03537172   0.02326045   3.81378291 -14.60482205   5.66380782  -0.02328124 \n         dis      ptratio        black        lstat \n -1.26249225  -0.87101806   0.01301181  -0.36615078 \n\noutro_mod <- lm(medv ~ zn + chas + nox + rm + age + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + age + dis + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.9383  -2.6575  -0.5304   1.7899  27.0979 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.035372   5.393193   3.159 0.001707 ** \nzn            0.023260   0.014828   1.569 0.117534    \nchas          3.813783   1.008205   3.783 0.000179 ***\nnox         -14.604822   3.654556  -3.996 7.68e-05 ***\nrm            5.663808   0.473979  11.949  < 2e-16 ***\nage          -0.023281   0.014296  -1.629 0.104207    \ndis          -1.262492   0.209990  -6.012 4.19e-09 ***\nptratio      -0.871018   0.125529  -6.939 1.64e-11 ***\nblack         0.013012   0.002708   4.806 2.20e-06 ***\nlstat        -0.366151   0.057248  -6.396 4.54e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.608 on 393 degrees of freedom\nMultiple R-squared:  0.7549,    Adjusted R-squared:  0.7493 \nF-statistic: 134.5 on 9 and 393 DF,  p-value: < 2.2e-16\n\nsqrt(mean((conj_teste$medv - predict(outro_mod, conj_teste)) ^ 2)) \n\n[1] 6.032965"
  },
  {
    "objectID": "semanas/Aula07.4.html#e-o-bic",
    "href": "semanas/Aula07.4.html#e-o-bic",
    "title": "Regulariza√ß√£o de Modelos",
    "section": "E o BIC?",
    "text": "E o BIC?\nE se escolhessemos o BIC como crit√©rio de sele√ß√£o de vari√°veis explicativas? Neste caso os resultados foram iguais ao Cp. Entretanto, d√° para perceber que o BIC apresentou uma certa estabilidade entre 7 e 9 vari√°veis. Se quisermos ter um modelo mais enxuto poderiamos optar por 7 vari√°veis.\n\najusreg.comp1 <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg1 <- summary(ajusreg.comp1)\n## Os modelos v√£o ser escolhidos com base no menor BIC\nplot(sumario.reg1$bic,xlab=\"N√∫mero de Vari√°veis\",ylab=\"BIC\")\nwhich.min(sumario.reg1$bic)\n\n[1] 7\n\npoints(7,sumario.reg1$bic[7],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.comp1,7) \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735 \n\noutro_mod1 <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod1)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nsqrt(mean((conj_teste$medv - predict(outro_mod1, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula08.html",
    "href": "semanas/Aula08.html",
    "title": "KNN",
    "section": "",
    "text": "O KNN √© um algoritmo muito simples no qual cada observa√ß√£o √© prevista com base em sua ‚Äúsemelhan√ßa‚Äù com outras observa√ß√µes. Ao contr√°rio da maioria dos m√©todos, KNN √© um algoritmo baseado na mem√≥ria e n√£o pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento s√£o necess√°rias no tempo de execu√ß√£o e as previs√µes s√£o feitas diretamente das rela√ß√µes amostrais. Consequentemente, os KNNs tamb√©m s√£o conhecidos como aprendizes pregui√ßosos"
  },
  {
    "objectID": "semanas/Aula08.html#carregando-bibliotecas",
    "href": "semanas/Aula08.html#carregando-bibliotecas",
    "title": "KNN",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula08.html#manipulando-os-dados",
    "href": "semanas/Aula08.html#manipulando-os-dados",
    "title": "KNN",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula08.html#normaliza√ß√£o",
    "href": "semanas/Aula08.html#normaliza√ß√£o",
    "title": "KNN",
    "section": "Normaliza√ß√£o",
    "text": "Normaliza√ß√£o\nAntes de iniciarmos √© fundamental fazermos a normaliza√ß√£o (padroniza√ß√£o) dos dados para que o KNN tenha um melhor desempenho.\n\ncredito_n <- credito\ncredito_n[,3:4] <- scale(credito_n[,3:4])"
  },
  {
    "objectID": "semanas/Aula08.html#treino-e-teste",
    "href": "semanas/Aula08.html#treino-e-teste",
    "title": "KNN",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nset.seed(21)\ny <- credito_n$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito_n %>% slice(-indice_teste)\nconj_teste <- credito_n %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco             receita         \n Nao:7733     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.455267  \n Sim: 266     1st Qu.:0.0000   1st Qu.:-0.732026   1st Qu.:-0.913102  \n              Median :0.0000   Median :-0.033621   Median : 0.076805  \n              Mean   :0.2953   Mean   :-0.005588   Mean   : 0.001763  \n              3rd Qu.:1.0000   3rd Qu.: 0.685798   3rd Qu.: 0.774041  \n              Max.   :1.0000   Max.   : 3.760371   Max.   : 3.002050  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco             receita         \n Nao:1934     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.156595  \n Sim:  67     1st Qu.:0.0000   1st Qu.:-0.727536   1st Qu.:-0.910738  \n              Median :0.0000   Median : 0.002479   Median : 0.080508  \n              Mean   :0.2909   Mean   : 0.022340   Mean   :-0.007049  \n              3rd Qu.:1.0000   3rd Qu.: 0.677484   3rd Qu.: 0.759484  \n              Max.   :1.0000   Max.   : 3.361757   Max.   : 2.828416"
  },
  {
    "objectID": "semanas/Aula08.html#matriz-de-dispers√£o",
    "href": "semanas/Aula08.html#matriz-de-dispers√£o",
    "title": "KNN",
    "section": "Matriz de dispers√£o",
    "text": "Matriz de dispers√£o\nVamos agora explorar os dados originais para termos algum vis√£o do comportamento das vari√°veis explicativas e a vari√°vel dependente.\n\nlibrary(psych)\npairs.panels(credito, \n             method = \"pearson\", # metodo de correla√ß√£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correla√ß√£o\n             )"
  },
  {
    "objectID": "semanas/Aula08.html#avaliando-o-comportamento-das-vari√°veis-em-fun√ß√£o-do-status-inadimplente-estudante",
    "href": "semanas/Aula08.html#avaliando-o-comportamento-das-vari√°veis-em-fun√ß√£o-do-status-inadimplente-estudante",
    "title": "KNN",
    "section": "Avaliando o comportamento das vari√°veis em fun√ß√£o do status (inadimplente / estudante)",
    "text": "Avaliando o comportamento das vari√°veis em fun√ß√£o do status (inadimplente / estudante)\n\nggplot(credito, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula08.html#explorando-um-pouco-mais-balan√ßo-e-receita",
    "href": "semanas/Aula08.html#explorando-um-pouco-mais-balan√ßo-e-receita",
    "title": "KNN",
    "section": "Explorando um pouco mais Balan√ßo e Receita",
    "text": "Explorando um pouco mais Balan√ßo e Receita\n\nggplot(credito, aes(x=balanco)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))\n\n\n\nggplot(credito, aes(x=receita)) +\n    geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))"
  },
  {
    "objectID": "semanas/Aula08.html#balan√ßo-vs-receita",
    "href": "semanas/Aula08.html#balan√ßo-vs-receita",
    "title": "KNN",
    "section": "Balan√ßo vs Receita",
    "text": "Balan√ßo vs Receita\n\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula08.html#knn-1",
    "href": "semanas/Aula08.html#knn-1",
    "title": "KNN",
    "section": "KNN",
    "text": "KNN\nVamos usar a fun√ß√£o knn da biblioteca caret que tem √≥timas funcionalidades. Observem que a sa√≠da pode ser as classes ou as probabilidades de pertencer a uma classe\nComo o KNN usa as distancias entre os pontos ele √© afetado pela escala dos dados, portanto, √© necess√°rio que os dados sejam normalizados (padronizados) para eliminar este efeito.\nQuando temos diversas vari√°veis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padr√£o 1"
  },
  {
    "objectID": "semanas/Aula08.html#a-modelo",
    "href": "semanas/Aula08.html#a-modelo",
    "title": "KNN",
    "section": "1a Modelo",
    "text": "1a Modelo\n\n# Vamos usar a regra da raiz quadrada do tamnho da amostra\nsqrt(nrow(conj_treino)) ## ~90\n\n[1] 89.43713\n\nset.seed(21)\nt_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)\nt_knn1\n\n90-nearest neighbor model\nTraining set outcome distribution:\n\n Nao  Sim \n7733  266"
  },
  {
    "objectID": "semanas/Aula08.html#avaliando-o-modelo",
    "href": "semanas/Aula08.html#avaliando-o-modelo",
    "title": "KNN",
    "section": "Avaliando o modelo",
    "text": "Avaliando o modelo\nA acur√°cia deu um valor alto, mas isto n√£o √© suficiente para considerarmo que temos um bom modelo. Veja que a sensibilidade est√° muito baixa e que o ideal √© que tenhamos valores altos de sensibilidade e especificidade.\nObservar que a preval√™ncia √© muito baixa o que est√° afetando os resultados do modelo\n\n## \ny_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"class\")\n\n# Matriz de confus√£o para valiar os resultados\nconfusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1930   51\n       Sim    4   16\n                                          \n               Accuracy : 0.9725          \n                 95% CI : (0.9644, 0.9792)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.07329         \n                                          \n                  Kappa : 0.3579          \n                                          \n Mcnemar's Test P-Value : 5.552e-10       \n                                          \n            Sensitivity : 0.238806        \n            Specificity : 0.997932        \n         Pos Pred Value : 0.800000        \n         Neg Pred Value : 0.974255        \n             Prevalence : 0.033483        \n         Detection Rate : 0.007996        \n   Detection Prevalence : 0.009995        \n      Balanced Accuracy : 0.618369        \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula08.html#curva-roc",
    "href": "semanas/Aula08.html#curva-roc",
    "title": "KNN",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\n# Para a curva ROC preciso das probabilidades e n√£o das classes\np_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nhead(p_chapeu_knn1)\n\n           Nao        Sim\n[1,] 0.9777778 0.02222222\n[2,] 1.0000000 0.00000000\n[3,] 1.0000000 0.00000000\n[4,] 0.9888889 0.01111111\n[5,] 1.0000000 0.00000000\n[6,] 1.0000000 0.00000000\n\n# Aqui gera o curva e salvo numa vari√°vel\nroc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nlegend(\"bottomright\",legend=c(\"KNN1\"), \n       col=c(\"black\"),lwd=4)\n\n\n\n# Area abaixo da Curva (AUC)\nas.numeric(roc_knn1$auc)\n\n[1] 0.9276227"
  },
  {
    "objectID": "semanas/Aula08.html#variando-k",
    "href": "semanas/Aula08.html#variando-k",
    "title": "KNN",
    "section": "Variando K",
    "text": "Variando K\nAnteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a fun√ß√£o train da biblioteca caret \nObserve que a otimiza√ß√£o de k √© feita atrav√©s de acur√°cia\n\nset.seed(21)\n\n# Usando valida√ß√£o cruzada para obter o valor de k atrav√©s da fun√ß√£o train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.\nctrl <- trainControl(method = \"cv\")\nt_knn2 <- train(inadimplente ~ balanco + receita + estudante,\n                method = \"knn\", trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                data = conj_treino)\n## Resultados do treino\nt_knn2\n\nk-Nearest Neighbors \n\n7999 samples\n   3 predictor\n   2 classes: 'Nao', 'Sim' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \nResampling results across tuning parameters:\n\n  k    Accuracy   Kappa     \n   10  0.9699953  0.37022050\n   20  0.9717451  0.37122371\n   30  0.9714948  0.34761685\n   40  0.9713698  0.32858918\n   50  0.9712448  0.30506559\n   60  0.9711200  0.29038841\n   70  0.9711204  0.28281374\n   80  0.9698700  0.22792293\n   90  0.9696197  0.20538564\n  100  0.9689948  0.15840977\n  110  0.9677454  0.09462220\n  120  0.9669959  0.03351642\n  130  0.9669961  0.01339042\n  140  0.9669961  0.01339042\n  150  0.9667464  0.00000000\n  160  0.9667464  0.00000000\n  170  0.9667464  0.00000000\n  180  0.9667464  0.00000000\n  190  0.9667464  0.00000000\n  200  0.9667464  0.00000000\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 20.\n\nplot(t_knn2)\n\n\n\n## Previs√µes com o resultaddos do treino\nprev_knn2 <- predict(t_knn2, conj_teste)\nconfusionMatrix(prev_knn2, conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1926   40\n       Sim    8   27\n                                          \n               Accuracy : 0.976           \n                 95% CI : (0.9683, 0.9823)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.008318        \n                                          \n                  Kappa : 0.5183          \n                                          \n Mcnemar's Test P-Value : 7.66e-06        \n                                          \n            Sensitivity : 0.40299         \n            Specificity : 0.99586         \n         Pos Pred Value : 0.77143         \n         Neg Pred Value : 0.97965         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01349         \n   Detection Prevalence : 0.01749         \n      Balanced Accuracy : 0.69942         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula08.html#variando-k-de-outra-forma",
    "href": "semanas/Aula08.html#variando-k-de-outra-forma",
    "title": "KNN",
    "section": "Variando K de outra forma",
    "text": "Variando K de outra forma\nVamos adicionar mais op√ß√µes no trainControl\nAo colocar classProb = TRUE e summaryFunction ao inv√©s da acur√°cia a otimiza√ß√£o passa a ser atrav√©s o ROC\n\nset.seed(21)\n# ctrl <- trainControl(method = \"cv\", classProbs=TRUE, summaryFunction = twoClassSummary)\nctrl <- trainControl(method = \"repeatedcv\", \n                     number = 10,\n                     repeats = 5, \n                     classProbs = TRUE,\n                     summaryFunction = twoClassSummary)\n\nt_knn3 <- train(inadimplente ~ balanco + receita + estudante, \n                method = \"knn\", \n                trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                metric = \"ROC\",\n                data = conj_treino)\nt_knn3\n\nk-Nearest Neighbors \n\n7999 samples\n   3 predictor\n   2 classes: 'Nao', 'Sim' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 5 times) \nSummary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \nResampling results across tuning parameters:\n\n  k    ROC        Sens       Spec       \n   10  0.8532549  0.9936118  0.299230769\n   20  0.8962842  0.9957323  0.275897436\n   30  0.9129487  0.9965599  0.252507123\n   40  0.9223242  0.9972324  0.229401709\n   50  0.9260029  0.9976204  0.204558405\n   60  0.9275003  0.9978014  0.196239316\n   70  0.9283630  0.9979566  0.185014245\n   80  0.9324715  0.9981118  0.150284900\n   90  0.9335728  0.9986809  0.124643875\n  100  0.9390171  0.9991464  0.091566952\n  110  0.9401918  0.9994827  0.048062678\n  120  0.9405837  0.9998707  0.019515670\n  130  0.9416564  1.0000000  0.007492877\n  140  0.9429103  1.0000000  0.003703704\n  150  0.9434492  1.0000000  0.000000000\n  160  0.9432553  1.0000000  0.000000000\n  170  0.9444527  1.0000000  0.000000000\n  180  0.9452018  1.0000000  0.000000000\n  190  0.9450158  1.0000000  0.000000000\n  200  0.9447751  1.0000000  0.000000000\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was k = 180.\n\nplot(t_knn3)\n\n\n\nprev_knn3 <- predict(t_knn3, conj_teste)\nconfusionMatrix(prev_knn3, conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1934   66\n       Sim    0    1\n                                          \n               Accuracy : 0.967           \n                 95% CI : (0.9582, 0.9744)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.4829          \n                                          \n                  Kappa : 0.0285          \n                                          \n Mcnemar's Test P-Value : 1.235e-15       \n                                          \n            Sensitivity : 0.0149254       \n            Specificity : 1.0000000       \n         Pos Pred Value : 1.0000000       \n         Neg Pred Value : 0.9670000       \n             Prevalence : 0.0334833       \n         Detection Rate : 0.0004998       \n   Detection Prevalence : 0.0004998       \n      Balanced Accuracy : 0.5074627       \n                                          \n       'Positive' Class : Sim             \n                                          \n\n\nVeja que ao otimizar pela ROC o modelo escolhido tem sensibilidade zero! Isto obviamente n√£o √© um bom modelo! Neste caso a op√ß√£o de otimiza√ß√£o do parametro pela acur√°cia d√° melhores resultados."
  },
  {
    "objectID": "semanas/Aula08.html#curva-roc-dos-2-melhores-modelos-k90-e-k20",
    "href": "semanas/Aula08.html#curva-roc-dos-2-melhores-modelos-k90-e-k20",
    "title": "KNN",
    "section": "Curva ROC dos 2 melhores modelos k=90 e k=20",
    "text": "Curva ROC dos 2 melhores modelos k=90 e k=20\n\nprev_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nprev_knn2 <- predict(t_knn2, conj_teste, type = \"prob\")\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\nroc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\nlegend(\"bottomright\",legend=c(\"KNN1\", \"KNN2\"), \n       col=c(\"black\",\"green\"),lwd=4)\n\n\n\n## Area embaixo das curvas\nas.numeric(roc_knn1$auc)\n\n[1] 0.9276227\n\nas.numeric(roc_knn2$auc)\n\n[1] 0.9032436\n\n\nObserve que os resultados de √°rea abaixo da ROC n√£o s√£o suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!\nOs resultados encontrados apontam k=20 como a melhor op√ß√£o"
  },
  {
    "objectID": "semanas/Aula09.html",
    "href": "semanas/Aula09.html",
    "title": "Regress√£o Log√≠stica",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula09.html#manipulando-os-dados",
    "href": "semanas/Aula09.html#manipulando-os-dados",
    "title": "Regress√£o Log√≠stica",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09.html#treino-e-teste",
    "href": "semanas/Aula09.html#treino-e-teste",
    "title": "Regress√£o Log√≠stica",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula09.html#matriz-de-dispers√£o",
    "href": "semanas/Aula09.html#matriz-de-dispers√£o",
    "title": "Regress√£o Log√≠stica",
    "section": "Matriz de dispers√£o",
    "text": "Matriz de dispers√£o\n\nlibrary(psych)\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correla√ß√£o\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correla√ß√£o\n             )"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-comportamento-das-vari√°veis-em-fun√ß√£o-do-status-inadimplente-estudante",
    "href": "semanas/Aula09.html#avaliando-o-comportamento-das-vari√°veis-em-fun√ß√£o-do-status-inadimplente-estudante",
    "title": "Regress√£o Log√≠stica",
    "section": "Avaliando o comportamento das vari√°veis em fun√ß√£o do status (inadimplente / estudante)",
    "text": "Avaliando o comportamento das vari√°veis em fun√ß√£o do status (inadimplente / estudante)\n\nggplot(conj_treino, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula09.html#balan√ßo-vs-receita",
    "href": "semanas/Aula09.html#balan√ßo-vs-receita",
    "title": "Regress√£o Log√≠stica",
    "section": "Balan√ßo vs Receita",
    "text": "Balan√ßo vs Receita\n\nggplot(data = conj_treino, aes(x=balanco,  y = receita, col = inadimplente)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula09.html#regress√£o-linear",
    "href": "semanas/Aula09.html#regress√£o-linear",
    "title": "Regress√£o Log√≠stica",
    "section": "Regress√£o Linear?",
    "text": "Regress√£o Linear?\n\n## Primeiro precisa transformar qualitativa em num√©rica\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nmodelo_linear <- lm(inadimpl ~ balanco, data = conj_treino)\nplot(inadimpl ~ balanco, data = conj_treino, \n     col = \"darkorange\", pch = \"|\", ylim = c(-0.2, 1),\n     main = \"Regress√£o Linear - Classifica√ß√£o\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\nabline(modelo_linear, lwd = 3, col = \"dodgerblue\")"
  },
  {
    "objectID": "semanas/Aula09.html#outras-avalia√ß√µes",
    "href": "semanas/Aula09.html#outras-avalia√ß√µes",
    "title": "Regress√£o Log√≠stica",
    "section": "Outras avalia√ß√µes",
    "text": "Outras avalia√ß√µes\n\n# propor√ß√£o de inadimplentes\nconj_treino %>% select(inadimplente, balanco) %>% summarize(prop = mean(inadimplente == \"Sim\")) \n\n# A tibble: 1 √ó 1\n    prop\n   <dbl>\n1 0.0333\n\n# media do balan√ßo dos inadimplentes \nconj_treino %>% filter(inadimplente == \"Sim\") %>% summarize(valor= mean(balanco))   \n\n# A tibble: 1 √ó 1\n  valor\n  <dbl>\n1 1745.\n\nquantis <- quantile(conj_treino$balanco, probs = c(.1,.25, .50, .75, .9, .95, 0.97, 0.99))\nquantis\n\n      10%       25%       50%       75%       90%       95%       97%       99% \n 176.9895  481.2830  819.1118 1167.1059 1468.8300 1660.1834 1786.5132 1991.6971 \n\nconj_treino %>% \n            mutate(grupo_balanco = case_when(\n               balanco<=quantis[1] ~ quantis[1],\n               balanco>quantis[1] & balanco<=quantis[2] ~ quantis[2],\n               balanco>quantis[2] & balanco<=quantis[3]  ~ quantis[3],\n               balanco>quantis[3] & balanco<=quantis[4]  ~ quantis[4],\n               balanco>quantis[4] & balanco<=quantis[5]  ~ quantis[5],\n               balanco>quantis[5] & balanco<=quantis[6]  ~ quantis[6],\n               balanco>quantis[6] & balanco<=quantis[7]  ~ quantis[7],\n               balanco>quantis[7] ~ quantis[8])) %>%\n           group_by(grupo_balanco) %>%\n           summarize(prop = mean(inadimplente == \"Sim\")) %>%\n           ggplot(aes(grupo_balanco, prop)) +\n           geom_point() +\n           geom_line()"
  },
  {
    "objectID": "semanas/Aula09.html#a-regress√£o-log√≠stica-s√≥-balan√ßo",
    "href": "semanas/Aula09.html#a-regress√£o-log√≠stica-s√≥-balan√ßo",
    "title": "Regress√£o Log√≠stica",
    "section": "1a Regress√£o log√≠stica: s√≥ balan√ßo",
    "text": "1a Regress√£o log√≠stica: s√≥ balan√ßo\n\nmod1 <- glm(inadimplente ~ balanco,data=conj_treino,family=binomial)\nsummary(mod1)\n\n\nCall:\nglm(formula = inadimplente ~ balanco, family = binomial, data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3119  -0.1453  -0.0568  -0.0211   3.7748  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.077e+01  4.119e-01  -26.16   <2e-16 ***\nbalanco      5.593e-03  2.521e-04   22.18   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1268.0  on 7997  degrees of freedom\nAIC: 1272\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod1)\n\n  (Intercept)       balanco \n-10.772870680   0.005593346 \n\nsummary(mod1)$coef\n\n                 Estimate   Std. Error   z value      Pr(>|z|)\n(Intercept) -10.772870680 0.4118820840 -26.15523 8.593630e-151\nbalanco       0.005593346 0.0002521341  22.18401 4.901112e-109"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-modelo",
    "href": "semanas/Aula09.html#avaliando-o-modelo",
    "title": "Regress√£o Log√≠stica",
    "section": "Avaliando o modelo",
    "text": "Avaliando o modelo\n\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1922   41\n       Sim   12   26\n                                          \n               Accuracy : 0.9735          \n                 95% CI : (0.9655, 0.9801)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.04298         \n                                          \n                  Kappa : 0.4827          \n                                          \n Mcnemar's Test P-Value : 0.00012         \n                                          \n            Sensitivity : 0.38806         \n            Specificity : 0.99380         \n         Pos Pred Value : 0.68421         \n         Neg Pred Value : 0.97911         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01299         \n   Detection Prevalence : 0.01899         \n      Balanced Accuracy : 0.69093         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#veja-as-probabilidade-de-inadimplencia-para-balan√ßos-de-1000-2000-e-3000",
    "href": "semanas/Aula09.html#veja-as-probabilidade-de-inadimplencia-para-balan√ßos-de-1000-2000-e-3000",
    "title": "Regress√£o Log√≠stica",
    "section": "Veja as probabilidade de inadimplencia para balan√ßos de 1000, 2000 e 3000",
    "text": "Veja as probabilidade de inadimplencia para balan√ßos de 1000, 2000 e 3000\n\npredict(mod1, newdata = data.frame(balanco = c(1000,2000,3000)), type=\"response\")\n\n          1           2           3 \n0.005599153 0.602003608 0.997544989"
  },
  {
    "objectID": "semanas/Aula09.html#curva-s",
    "href": "semanas/Aula09.html#curva-s",
    "title": "Regress√£o Log√≠stica",
    "section": "Curva S",
    "text": "Curva S\n\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nplot(inadimpl ~ balanco, data = conj_treino, \n     col = \"darkorange\", pch = \"|\", ylim = c(0, 1),\n     main = \"Regress√£o Logistica - Classificac√£o\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\ncurve(predict(mod1, data.frame(balanco = x),\n        type = \"response\"), add = TRUE, lwd = 3, col = \"dodgerblue\")\nabline(v = -coef(mod1)[1] / coef(mod1)[2], lwd = 2)"
  },
  {
    "objectID": "semanas/Aula09.html#valor-de-balan√ßo-com-probabilidade-de-50",
    "href": "semanas/Aula09.html#valor-de-balan√ßo-com-probabilidade-de-50",
    "title": "Regress√£o Log√≠stica",
    "section": "Valor de balan√ßo com probabilidade de 50%",
    "text": "Valor de balan√ßo com probabilidade de 50%\n-\\(\\beta_0\\)/\\(\\beta_1\\)\n\n-coef(mod1)[1] / coef(mod1)[2]\n\n(Intercept) \n   1926.016"
  },
  {
    "objectID": "semanas/Aula09.html#a-regress√£o-log√≠stica-todas-as-vari√°veis",
    "href": "semanas/Aula09.html#a-regress√£o-log√≠stica-todas-as-vari√°veis",
    "title": "Regress√£o Log√≠stica",
    "section": "2a Regress√£o log√≠stica: todas as vari√°veis",
    "text": "2a Regress√£o log√≠stica: todas as vari√°veis\n\nmod2 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treino,family=binomial)\nsummary(mod2)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n    data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.5314  -0.1409  -0.0535  -0.0192   3.7500  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.123e+01  5.684e-01 -19.763   <2e-16 ***\nbalanco      5.842e-03  2.661e-04  21.955   <2e-16 ***\nreceita      8.476e-06  9.253e-06   0.916   0.3597    \nestudante   -5.106e-01  2.671e-01  -1.912   0.0559 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1248.2  on 7995  degrees of freedom\nAIC: 1256.2\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod2)\n\n  (Intercept)       balanco       receita     estudante \n-1.123321e+01  5.842417e-03  8.475971e-06 -5.106360e-01 \n\nsummary(mod2)$coef\n\n                 Estimate   Std. Error     z value      Pr(>|z|)\n(Intercept) -1.123321e+01 5.683883e-01 -19.7632675  6.167980e-87\nbalanco      5.842417e-03 2.661065e-04  21.9551820 7.727138e-107\nreceita      8.475971e-06 9.253027e-06   0.9160214  3.596557e-01\nestudante   -5.106360e-01 2.671246e-01  -1.9116025  5.592720e-02"
  },
  {
    "objectID": "semanas/Aula09.html#√©-poss√≠vel-se-ver-que-receita-n√£o-√©-significativa",
    "href": "semanas/Aula09.html#√©-poss√≠vel-se-ver-que-receita-n√£o-√©-significativa",
    "title": "Regress√£o Log√≠stica",
    "section": "√â poss√≠vel se ver que receita n√£o √© significativa",
    "text": "√â poss√≠vel se ver que receita n√£o √© significativa"
  },
  {
    "objectID": "semanas/Aula09.html#a-regress√£o-log√≠stica-sem-receita",
    "href": "semanas/Aula09.html#a-regress√£o-log√≠stica-sem-receita",
    "title": "Regress√£o Log√≠stica",
    "section": "3a Regress√£o Log√≠stica (sem receita)",
    "text": "3a Regress√£o Log√≠stica (sem receita)\n\nmod3 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\nsummary(mod3)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + estudante, family = binomial, \n    data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4991  -0.1410  -0.0535  -0.0192   3.7631  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.089e+01  4.220e-01  -25.81  < 2e-16 ***\nbalanco      5.842e-03  2.658e-04   21.98  < 2e-16 ***\nestudante   -7.016e-01  1.655e-01   -4.24 2.23e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1249.1  on 7996  degrees of freedom\nAIC: 1255.1\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod3)\n\n  (Intercept)       balanco     estudante \n-10.891361318   0.005842385  -0.701581567 \n\nsummary(mod3)$coef\n\n                 Estimate   Std. Error    z value      Pr(>|z|)\n(Intercept) -10.891361318 0.4220005414 -25.808880 7.048822e-147\nbalanco       0.005842385 0.0002658371  21.977315 4.747239e-107\nestudante    -0.701581567 0.1654530947  -4.240365  2.231563e-05"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-modelo-novamente",
    "href": "semanas/Aula09.html#avaliando-o-modelo-novamente",
    "title": "Regress√£o Log√≠stica",
    "section": "Avaliando o modelo novamente",
    "text": "Avaliando o modelo novamente\n\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1924   37\n       Sim   10   30\n                                          \n               Accuracy : 0.9765          \n                 95% CI : (0.9689, 0.9827)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.0056579       \n                                          \n                  Kappa : 0.5495          \n                                          \n Mcnemar's Test P-Value : 0.0001491       \n                                          \n            Sensitivity : 0.44776         \n            Specificity : 0.99483         \n         Pos Pred Value : 0.75000         \n         Neg Pred Value : 0.98113         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01499         \n   Detection Prevalence : 0.01999         \n      Balanced Accuracy : 0.72130         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#mudando-a-probabilidade-limite-para-aumentar-a-sensibilidade",
    "href": "semanas/Aula09.html#mudando-a-probabilidade-limite-para-aumentar-a-sensibilidade",
    "title": "Regress√£o Log√≠stica",
    "section": "Mudando a probabilidade (limite) para aumentar a sensibilidade",
    "text": "Mudando a probabilidade (limite) para aumentar a sensibilidade\n\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.1, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1809   18\n       Sim  125   49\n                                          \n               Accuracy : 0.9285          \n                 95% CI : (0.9164, 0.9394)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3765          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.73134         \n            Specificity : 0.93537         \n         Pos Pred Value : 0.28161         \n         Neg Pred Value : 0.99015         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02449         \n   Detection Prevalence : 0.08696         \n      Balanced Accuracy : 0.83336         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-modelo-s√≥-com-balan√ßo",
    "href": "semanas/Aula09.html#curva-roc-modelo-s√≥-com-balan√ßo",
    "title": "Regress√£o Log√≠stica",
    "section": "Curva ROC modelo s√≥ com balan√ßo",
    "text": "Curva ROC modelo s√≥ com balan√ßo\n\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.897038e-02 7.892012e-05 2.096006e-05 1.087093e-02 3.336139e-04 2.580431e-04 \n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n\n\n\n# Area debaixo da curva\nas.numeric(roc_log$auc)\n\n[1] 0.9389557"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-2-modelo-com-balan√ßo-estudante",
    "href": "semanas/Aula09.html#curva-roc-2-modelo-com-balan√ßo-estudante",
    "title": "Regress√£o Log√≠stica",
    "section": "Curva ROC 2: Modelo com balan√ßo + estudante",
    "text": "Curva ROC 2: Modelo com balan√ßo + estudante\n\np_chapeu_log <- predict(mod3, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.140962e-02 7.436487e-05 1.861803e-05 6.355948e-03 3.351978e-04 1.271000e-04 \n\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n\n\n\n# Area debaixo da curva\nas.numeric(roc_log2$auc)\n\n[1] 0.9415487"
  },
  {
    "objectID": "semanas/Aula09.html#duas-rocs-juntas",
    "href": "semanas/Aula09.html#duas-rocs-juntas",
    "title": "Regress√£o Log√≠stica",
    "section": "Duas ROCs juntas",
    "text": "Duas ROCs juntas\n\nplot(roc_log)\nplot(roc_log2, add=TRUE, col=\"blue\")\nlegend(\"bottomright\", legend=c(\"Mod 1\", \"Mod2\"),\n       col=c(par(\"fg\"), \"blue\"), lwd=2)"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-3-com-o-knn",
    "href": "semanas/Aula09.html#curva-roc-3-com-o-knn",
    "title": "Regress√£o Log√≠stica",
    "section": "Curva ROC 3 com o KNN",
    "text": "Curva ROC 3 com o KNN\n\n# Ajustando KNN \nset.seed(21)\nctrl <- trainControl(method = \"cv\")\ntreina_knn <- train(inadimplente ~ scale(balanco) + scale(estudante), method = \"knn\", trControl= ctrl, tuneGrid = data.frame(k = seq(5,140, by=4)), data = conj_treino)\n# treina_knn\nplot(treina_knn)\n\n\n\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n## ROC\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, col= \"black\", legacy.axes=TRUE) \nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg. Log\", \"KNN\"), \n       col=c(\"black\",\"green\"),lwd=4)\n\n\n\n# Area abaixo da curva\n# Regress√£o Log√≠stica\nas.numeric(roc_log2$auc)\n\n[1] 0.9415487\n\n## KNN\nas.numeric(roc_knn1$auc)\n\n[1] 0.9388361"
  },
  {
    "objectID": "semanas/Aula09A.html",
    "href": "semanas/Aula09A.html",
    "title": "Regress√£o Log√≠stica - SMOTE",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula09A.html#manipulando-os-dados",
    "href": "semanas/Aula09A.html#manipulando-os-dados",
    "title": "Regress√£o Log√≠stica - SMOTE",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          ))\n\nstr(credito)\n\ntibble [10,000 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09A.html#treino-e-teste",
    "href": "semanas/Aula09A.html#treino-e-teste",
    "title": "Regress√£o Log√≠stica - SMOTE",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula09A.html#smote",
    "href": "semanas/Aula09A.html#smote",
    "title": "Regress√£o Log√≠stica - SMOTE",
    "section": "SMOTE",
    "text": "SMOTE\n\nlibrary(smotefamily)\nset.seed(123)\nteste <- SMOTE(conj_treino[,-1], target = conj_treino$inadimplente, K=5)\nconj_treinoS <- teste$data\nconj_treinoS$class <- as.factor(conj_treinoS$class)\nconj_treinoS <- conj_treinoS %>% rename( inadimplente = class)\nprop.table(table(conj_treinoS$inadimplente))\n\n\n     Nao      Sim \n0.500615 0.499385 \n\nsummary(conj_treinoS)\n\n   estudante         balanco          receita      inadimplente\n Min.   :0.0000   Min.   :   0.0   Min.   :  772   Nao:7733    \n 1st Qu.:0.0000   1st Qu.: 795.5   1st Qu.:20166   Sim:7714    \n Median :0.0000   Median :1392.3   Median :33703               \n Mean   :0.3394   Mean   :1272.9   Mean   :32841               \n 3rd Qu.:1.0000   3rd Qu.:1769.2   3rd Qu.:43745               \n Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09A.html#a-regress√£o-log√≠stica",
    "href": "semanas/Aula09A.html#a-regress√£o-log√≠stica",
    "title": "Regress√£o Log√≠stica - SMOTE",
    "section": "1a Regress√£o log√≠stica",
    "text": "1a Regress√£o log√≠stica\n\nmod1 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treinoS,family=binomial)\nsummary(mod1)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n    data = conj_treinoS)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.9262  -0.1967  -0.0084   0.3402   3.0696  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -9.778e+00  2.279e-01 -42.898  < 2e-16 ***\nbalanco      7.115e-03  1.199e-04  59.356  < 2e-16 ***\nreceita      9.409e-06  3.645e-06   2.582  0.00984 ** \nestudante   -6.092e-01  1.071e-01  -5.688 1.28e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 21414.1  on 15446  degrees of freedom\nResidual deviance:  7490.3  on 15443  degrees of freedom\nAIC: 7498.3\n\nNumber of Fisher Scoring iterations: 7\n\ncoef(mod1)\n\n  (Intercept)       balanco       receita     estudante \n-9.778189e+00  7.114940e-03  9.409475e-06 -6.092070e-01 \n\nsummary(mod1)$coef\n\n                 Estimate   Std. Error    z value     Pr(>|z|)\n(Intercept) -9.778189e+00 2.279388e-01 -42.898311 0.000000e+00\nbalanco      7.114940e-03 1.198694e-04  59.355775 0.000000e+00\nreceita      9.409475e-06 3.644856e-06   2.581576 9.835023e-03\nestudante   -6.092070e-01 1.070945e-01  -5.688499 1.281605e-08"
  },
  {
    "objectID": "semanas/Aula09A.html#avaliando-o-modelo-novamente",
    "href": "semanas/Aula09A.html#avaliando-o-modelo-novamente",
    "title": "Regress√£o Log√≠stica - SMOTE",
    "section": "Avaliando o modelo novamente",
    "text": "Avaliando o modelo novamente\n\nprop.table(table(conj_teste$inadimplente))\n\n\n       Nao        Sim \n0.96651674 0.03348326 \n\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1696   11\n       Sim  238   56\n                                          \n               Accuracy : 0.8756          \n                 95% CI : (0.8603, 0.8897)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.2705          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.83582         \n            Specificity : 0.87694         \n         Pos Pred Value : 0.19048         \n         Neg Pred Value : 0.99356         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02799         \n   Detection Prevalence : 0.14693         \n      Balanced Accuracy : 0.85638         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09A.html#curva-roc",
    "href": "semanas/Aula09A.html#curva-roc",
    "title": "Regress√£o Log√≠stica - SMOTE",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.710555e-01 3.991424e-04 9.094011e-05 9.398313e-02 3.185776e-03 8.710220e-04 \n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=TRUE,\n                 legacy.axes=TRUE) \n\n\n\nas.numeric(roc_log$auc)\n\n[1] 0.941186"
  },
  {
    "objectID": "semanas/Aula10.html#carregando-bibliotecas",
    "href": "semanas/Aula10.html#carregando-bibliotecas",
    "title": "LDA e QDA",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula10.html#manipulando-os-dados",
    "href": "semanas/Aula10.html#manipulando-os-dados",
    "title": "LDA e QDA",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula10.html#treino-e-teste",
    "href": "semanas/Aula10.html#treino-e-teste",
    "title": "LDA e QDA",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula10.html#balan√ßo-e-receita",
    "href": "semanas/Aula10.html#balan√ßo-e-receita",
    "title": "LDA e QDA",
    "section": "Balan√ßo e receita",
    "text": "Balan√ßo e receita\n\nfeaturePlot(x = conj_treino[, c(\"balanco\", \"receita\")], \n            y = conj_treino$inadimplente,\n            plot = \"density\", \n            scales = list(x = list(relation = \"free\"), \n                          y = list(relation = \"free\")), \n            adjust = 1.5, \n            pch = \"|\", \n            layout = c(2, 1), \n            auto.key = list(columns = 2))"
  },
  {
    "objectID": "semanas/Aula10.html#bayes-ing√™nuo-naive-bayes",
    "href": "semanas/Aula10.html#bayes-ing√™nuo-naive-bayes",
    "title": "LDA e QDA",
    "section": "Bayes Ing√™nuo (Naive Bayes)",
    "text": "Bayes Ing√™nuo (Naive Bayes)\n\nparams <- conj_treino %>% \n     group_by(inadimplente) %>% \n     summarize(media = mean(balanco), desvpad = sd(balanco))\nparams\n\n# A tibble: 2 √ó 3\n  inadimplente media desvpad\n  <fct>        <dbl>   <dbl>\n1 Nao           801.    456.\n2 Sim          1745.    332.\n\npi <- conj_treino %>% summarize(pi=mean(inadimplente==\"Sim\")) %>% pull(pi)\npi\n\n[1] 0.03325416\n\nx <- conj_teste$balanco\n\nf0 <- dnorm(x, params$media[1], params$desvpad[1])\nf1 <- dnorm(x, params$media[2], params$desvpad[2])\n\np_chapeu_bayes <- f1*pi / (f1*pi + f0*(1 - pi))\ny_chapeu_bayes <- ifelse(p_chapeu_bayes > 0.5, \"Sim\", \"Nao\")\n\nconfusionMatrix(factor(y_chapeu_bayes), conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1927   44\n       Sim    7   23\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.4631         \n                                         \n Mcnemar's Test P-Value : 4.631e-07      \n                                         \n            Sensitivity : 0.34328        \n            Specificity : 0.99638        \n         Pos Pred Value : 0.76667        \n         Neg Pred Value : 0.97768        \n             Prevalence : 0.03348        \n         Detection Rate : 0.01149        \n   Detection Prevalence : 0.01499        \n      Balanced Accuracy : 0.66983        \n                                         \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#calcula-erro",
    "href": "semanas/Aula10.html#calcula-erro",
    "title": "LDA e QDA",
    "section": "Calcula Erro",
    "text": "Calcula Erro\n\ncalc_erro_class <- function(real, previsto) {\n  mean(real != previsto)\n}\n# Este valor √© igual a 1 - Accuracy da matriz de confus√£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu_bayes)\n\n[1] 0.02548726"
  },
  {
    "objectID": "semanas/Aula10.html#alterando-o-valor-da-probabilidade-priori",
    "href": "semanas/Aula10.html#alterando-o-valor-da-probabilidade-priori",
    "title": "LDA e QDA",
    "section": "Alterando o valor da probabilidade priori",
    "text": "Alterando o valor da probabilidade priori\n\np_chapeu_bayes <- f1*0.15 / (f1*0.15 + f0*(1 - 0.15))\ny_chapeu_bayes <- ifelse(p_chapeu_bayes > 0.5, \"Sim\", \"Nao\")\n\n\nconfusionMatrix(factor(y_chapeu_bayes), conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1839   22\n       Sim   95   45\n                                          \n               Accuracy : 0.9415          \n                 95% CI : (0.9303, 0.9514)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.408           \n                                          \n Mcnemar's Test P-Value : 2.806e-11       \n                                          \n            Sensitivity : 0.67164         \n            Specificity : 0.95088         \n         Pos Pred Value : 0.32143         \n         Neg Pred Value : 0.98818         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02249         \n   Detection Prevalence : 0.06997         \n      Balanced Accuracy : 0.81126         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor √© igual a 1 - Accuracy da matriz de confus√£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu_bayes)\n\n[1] 0.05847076"
  },
  {
    "objectID": "semanas/Aula10.html#lda",
    "href": "semanas/Aula10.html#lda",
    "title": "LDA e QDA",
    "section": "LDA",
    "text": "LDA\n\nlibrary(MASS)\n\ntreina_lda <- lda(inadimplente ~ balanco + estudante, data = conj_treino)\ntreina_lda\n\nCall:\nlda(inadimplente ~ balanco + estudante, data = conj_treino)\n\nPrior probabilities of groups:\n       Nao        Sim \n0.96674584 0.03325416 \n\nGroup means:\n      balanco estudante\nNao  801.3012 0.2919953\nSim 1744.6575 0.3909774\n\nCoefficients of linear discriminants:\n                   LD1\nbalanco    0.002242096\nestudante -0.216603545\n\nplot(treina_lda)\n\n\n\nnames(predict(treina_lda, conj_treino))\n\n[1] \"class\"     \"posterior\" \"x\"        \n\ny_chapeu <- predict(treina_lda, conj_teste)$class %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1928   45\n       Sim    6   22\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.4523         \n                                         \n Mcnemar's Test P-Value : 1.032e-07      \n                                         \n            Sensitivity : 0.32836        \n            Specificity : 0.99690        \n         Pos Pred Value : 0.78571        \n         Neg Pred Value : 0.97719        \n             Prevalence : 0.03348        \n         Detection Rate : 0.01099        \n   Detection Prevalence : 0.01399        \n      Balanced Accuracy : 0.66263        \n                                         \n       'Positive' Class : Sim            \n                                         \n\n# Este valor √© igual a 1 - Accuracy da matriz de confus√£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu)\n\n[1] 0.02548726"
  },
  {
    "objectID": "semanas/Aula10.html#lda---ajustando-probabilidade-limite",
    "href": "semanas/Aula10.html#lda---ajustando-probabilidade-limite",
    "title": "LDA e QDA",
    "section": "LDA - Ajustando probabilidade limite",
    "text": "LDA - Ajustando probabilidade limite\n\np_chapeu <- predict(treina_lda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9804367 0.0195633263\n2 0.9996897 0.0003102714\n3 0.9998980 0.0001019950\n4 0.9877333 0.0122667438\n5 0.9989602 0.0010397555\n6 0.9994672 0.0005327889\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1818   19\n       Sim  116   48\n                                          \n               Accuracy : 0.9325          \n                 95% CI : (0.9206, 0.9431)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3864          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.71642         \n            Specificity : 0.94002         \n         Pos Pred Value : 0.29268         \n         Neg Pred Value : 0.98966         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02399         \n   Detection Prevalence : 0.08196         \n      Balanced Accuracy : 0.82822         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor √© igual a 1 - Accuracy da matriz de confus√£o\ncalc_erro_class(conj_teste$inadimplente, y_chapeu)\n\n[1] 0.06746627"
  },
  {
    "objectID": "semanas/Aula10.html#qda",
    "href": "semanas/Aula10.html#qda",
    "title": "LDA e QDA",
    "section": "QDA",
    "text": "QDA\n\ntreina_qda <- qda(inadimplente ~ balanco + estudante, data = conj_treino)\ntreina_qda\n\nCall:\nqda(inadimplente ~ balanco + estudante, data = conj_treino)\n\nPrior probabilities of groups:\n       Nao        Sim \n0.96674584 0.03325416 \n\nGroup means:\n      balanco estudante\nNao  801.3012 0.2919953\nSim 1744.6575 0.3909774\n\ny_chapeu <- predict(treina_qda, conj_teste)$class %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1927   41\n       Sim    7   26\n                                          \n               Accuracy : 0.976           \n                 95% CI : (0.9683, 0.9823)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.008318        \n                                          \n                  Kappa : 0.5092          \n                                          \n Mcnemar's Test P-Value : 1.906e-06       \n                                          \n            Sensitivity : 0.38806         \n            Specificity : 0.99638         \n         Pos Pred Value : 0.78788         \n         Neg Pred Value : 0.97917         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01299         \n   Detection Prevalence : 0.01649         \n      Balanced Accuracy : 0.69222         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#qda---ajustando-probabilidade-limite",
    "href": "semanas/Aula10.html#qda---ajustando-probabilidade-limite",
    "title": "LDA e QDA",
    "section": "QDA - Ajustando probabilidade limite",
    "text": "QDA - Ajustando probabilidade limite\n\np_chapeu <- predict(treina_qda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9882876 1.171241e-02\n2 0.9999968 3.209822e-06\n3 0.9999998 1.848443e-07\n4 0.9946442 5.355842e-03\n5 0.9999472 5.284669e-05\n6 0.9999916 8.371285e-06\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1798   18\n       Sim  136   49\n                                          \n               Accuracy : 0.923           \n                 95% CI : (0.9105, 0.9343)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3573          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.73134         \n            Specificity : 0.92968         \n         Pos Pred Value : 0.26486         \n         Neg Pred Value : 0.99009         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02449         \n   Detection Prevalence : 0.09245         \n      Balanced Accuracy : 0.83051         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#curva-roc",
    "href": "semanas/Aula10.html#curva-roc",
    "title": "LDA e QDA",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\n# KNN\nset.seed(21)\nctrl <- trainControl(method = \"cv\")\ntreina_knn <- train(inadimplente ~ balanco + estudante, method = \"knn\", trControl= ctrl, preProcess=c(\"center\", \"scale\"), tuneGrid = data.frame(k = seq(21,140, by=4)), data = conj_treino)\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n# Reg Log\nmod2 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\np_chapeu_log <- predict(mod2, newdata = conj_teste, type = \"response\")\n\n# LDA e QDA\np_chapeu_lda <- predict(treina_lda, conj_teste)$posterior\np_chapeu_qda <- predict(treina_qda, conj_teste)$posterior\n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE,\n                 col=\"black\", legacy.axes=TRUE)\nroc_lda <- roc(conj_teste$inadimplente ~ p_chapeu_lda[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\nroc_qda <- roc(conj_teste$inadimplente ~ p_chapeu_qda[,2], plot = TRUE, print.auc=FALSE, col=\"blue\", legacy.axes=TRUE, add=TRUE)\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"red\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg Log\",\"LDA\",\"QDA\", \"KNN\"), \n       col=c(\"black\", \"green\",\"blue\", \"red\"),lwd=4)\n\n\n\nas.numeric(roc_log$auc)\n\n[1] 0.9415487\n\nas.numeric(roc_lda$auc)\n\n[1] 0.9412709\n\nas.numeric(roc_qda$auc)\n\n[1] 0.9414715\n\nas.numeric(roc_knn1$auc)\n\n[1] 0.9388361"
  },
  {
    "objectID": "semanas/Aula11.html",
    "href": "semanas/Aula11.html",
    "title": "Arvores de Regress√£o",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)\nlibrary(psych)"
  },
  {
    "objectID": "semanas/Aula11.html#avaliando-selecionando-dados",
    "href": "semanas/Aula11.html#avaliando-selecionando-dados",
    "title": "Arvores de Regress√£o",
    "section": "Avaliando, selecionando dados",
    "text": "Avaliando, selecionando dados\n\ndata(\"Boston\")\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\ndescribe(Boston)\n\n        vars   n   mean     sd median trimmed    mad    min    max  range  skew\ncrim       1 506   3.61   8.60   0.26    1.68   0.33   0.01  88.98  88.97  5.19\nzn         2 506  11.36  23.32   0.00    5.08   0.00   0.00 100.00 100.00  2.21\nindus      3 506  11.14   6.86   9.69   10.93   9.37   0.46  27.74  27.28  0.29\nchas       4 506   0.07   0.25   0.00    0.00   0.00   0.00   1.00   1.00  3.39\nnox        5 506   0.55   0.12   0.54    0.55   0.13   0.38   0.87   0.49  0.72\nrm         6 506   6.28   0.70   6.21    6.25   0.51   3.56   8.78   5.22  0.40\nage        7 506  68.57  28.15  77.50   71.20  28.98   2.90 100.00  97.10 -0.60\ndis        8 506   3.80   2.11   3.21    3.54   1.91   1.13  12.13  11.00  1.01\nrad        9 506   9.55   8.71   5.00    8.73   2.97   1.00  24.00  23.00  1.00\ntax       10 506 408.24 168.54 330.00  400.04 108.23 187.00 711.00 524.00  0.67\nptratio   11 506  18.46   2.16  19.05   18.66   1.70  12.60  22.00   9.40 -0.80\nblack     12 506 356.67  91.29 391.44  383.17   8.09   0.32 396.90 396.58 -2.87\nlstat     13 506  12.65   7.14  11.36   11.90   7.11   1.73  37.97  36.24  0.90\nmedv      14 506  22.53   9.20  21.20   21.56   5.93   5.00  50.00  45.00  1.10\n        kurtosis   se\ncrim       36.60 0.38\nzn          3.95 1.04\nindus      -1.24 0.30\nchas        9.48 0.01\nnox        -0.09 0.01\nrm          1.84 0.03\nage        -0.98 1.25\ndis         0.46 0.09\nrad        -0.88 0.39\ntax        -1.15 7.49\nptratio    -0.30 0.10\nblack       7.10 4.06\nlstat       0.46 0.32\nmedv        1.45 0.41\n\ndados <- Boston \nextrato <- dados %>% select(medv, nox, rm)  \nsummary(extrato)\n\n      medv            nox               rm       \n Min.   : 5.00   Min.   :0.3850   Min.   :3.561  \n 1st Qu.:17.02   1st Qu.:0.4490   1st Qu.:5.886  \n Median :21.20   Median :0.5380   Median :6.208  \n Mean   :22.53   Mean   :0.5547   Mean   :6.285  \n 3rd Qu.:25.00   3rd Qu.:0.6240   3rd Qu.:6.623  \n Max.   :50.00   Max.   :0.8710   Max.   :8.780  \n\nboxplot(extrato$medv)"
  },
  {
    "objectID": "semanas/Aula11.html#visualizando-os-dados",
    "href": "semanas/Aula11.html#visualizando-os-dados",
    "title": "Arvores de Regress√£o",
    "section": "Visualizando os dados",
    "text": "Visualizando os dados\n\n## Distribui√ß√£o de dados na maior parte sim√©trica com valores na cauda direta \n## maior do que o esperado para uam distribui√ß√£o sim√©trica\nggplot(extrato, aes(x=medv)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(extrato)),0))\n\n\n\n## Grafico de dispers√£o nox vs rm \nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point()"
  },
  {
    "objectID": "semanas/Aula11.html#arvore-de-regress√£o",
    "href": "semanas/Aula11.html#arvore-de-regress√£o",
    "title": "Arvores de Regress√£o",
    "section": "Arvore de Regress√£o",
    "text": "Arvore de Regress√£o\nNa biblioteca rpart as arvores de regress√£o s√£o obtidas usando o m√©todo anova. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo s√≥ definimos o menor conjunto de dados numa parti√ß√£o (minsplit) e o parametro de complexidade cp.¬†Qualquer parti√ß√£o/divis√£o que n√£o melhore o ajuste por um fator de cp n√£o √© tentada. Por exemplo, com a parti√ß√£o pela anova, isso significa que o R-quadrado geral deve aumentar pelo valor de cp a cada etapa. O principal papel deste par√¢metro √© economizar tempo de computa√ß√£o podando divis√µes que obviamente n√£o valem a pena. Essencialmente, o usu√°rio informa ao programa que qualquer divis√£o que n√£o melhore o ajuste pelo cp, provavelmente ser√° podada por valida√ß√£o cruzada, e que, portanto, n√£o √© necess√°rio persegui-lo.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvreg <- rpart(medv ~ ., \n                data=extrato,\n                method=\"anova\", #para arvore de regress√£o\n                control=rpart.control(minsplit=30,cp=0.06))\nplot(arvreg)\ntext(arvreg,pretty=0)"
  },
  {
    "objectID": "semanas/Aula11.html#segmentos",
    "href": "semanas/Aula11.html#segmentos",
    "title": "Arvores de Regress√£o",
    "section": "Segmentos",
    "text": "Segmentos\nA partir da √°rvore obtida no item anterior podemos fazer uma representa√ß√£o gr√°fica das parti√ß√µes obtidas.\n\nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point() +\n  geom_segment(aes(x = 0, y = 0.6695, xend = 6.941, yend = 0.6695), \n               linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 6.941, linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 7.437, linetype=\"dashed\", color=\"red\", size=1) \n\n\n\n  # scale_y_continuous(limits = c(0.3, 1)) +"
  },
  {
    "objectID": "semanas/Aula11.html#treino-e-teste-com-todas-as-vari√°veis",
    "href": "semanas/Aula11.html#treino-e-teste-com-todas-as-vari√°veis",
    "title": "Arvores de Regress√£o",
    "section": "Treino e Teste com todas as vari√°veis",
    "text": "Treino e Teste com todas as vari√°veis\nAgora vamos trabalhar com o conjunto completo criando um conjunto de treino e teste.\n\n## Vamos criar os conjuntos de treino teste e desenvolver a arvore \n## com todas as vari√°veis.\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\nindice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)\nconj_treino <- dados[indice,]\nconj_teste <- dados[-indice,]\nhead(conj_treino)\n\n     crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18.0  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n3 0.02729  0.0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0.0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0.0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0.0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n7 0.08829 12.5  7.87    0 0.524 6.012 66.6 5.5605   5 311    15.2 395.60 12.43\n  medv\n1 24.0\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n7 22.9\n\nhead(conj_teste)\n\n      crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n2  0.02731  0.0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n10 0.17004 12.5  7.87    0 0.524 6.004 85.9 6.5921   5 311    15.2 386.71 17.10\n12 0.11747 12.5  7.87    0 0.524 6.009 82.9 6.2267   5 311    15.2 396.90 13.27\n16 0.62739  0.0  8.14    0 0.538 5.834 56.5 4.4986   4 307    21.0 395.62  8.47\n19 0.80271  0.0  8.14    0 0.538 5.456 36.6 3.7965   4 307    21.0 288.99 11.69\n23 1.23247  0.0  8.14    0 0.538 6.142 91.7 3.9769   4 307    21.0 396.90 18.72\n   medv\n2  21.6\n10 18.9\n12 18.9\n16 19.9\n19 20.2\n23 15.2"
  },
  {
    "objectID": "semanas/Aula11.html#arvore-de-regress√£o-treino",
    "href": "semanas/Aula11.html#arvore-de-regress√£o-treino",
    "title": "Arvores de Regress√£o",
    "section": "Arvore de Regress√£o Treino",
    "text": "Arvore de Regress√£o Treino\n\n## A fun√ß√£o rpart tem diversos parametros aqui foi configurado um deles\n# cp o parametro de complexidade\n# Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande \n# resulta numa arvore muito pequena (underfitting).\n# Nos dois casos se diminui o desempenho do modelo.\narvreg1 <- rpart(medv ~ ., \n                data=conj_treino,\n                method=\"anova\", #para arvore de regress√£o\n                control=rpart.control(minsplit=30,cp=0.01))\nplot(arvreg1)\ntext(arvreg1,pretty=0)\n\n\n\narvreg1\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=9.65 10   467.4640 23.84000 *\n      13) lstat< 9.65 39   889.2800 32.90000 *\n     7) rm>=7.435 21   960.7895 45.23810 *"
  },
  {
    "objectID": "semanas/Aula11.html#erros-a-partir-do-conjunto-de-treino",
    "href": "semanas/Aula11.html#erros-a-partir-do-conjunto-de-treino",
    "title": "Arvores de Regress√£o",
    "section": "Erros a partir do conjunto de treino",
    "text": "Erros a partir do conjunto de treino\n\nO erro relativo (Rel error) √© obtido atrav√©s de 1 - R2\nO xerror √© obtido atrav√©s da valida√ß√£o cruzadada (10 fold)\nO xtsd √© o desvio padr√£o dos valores obtidos na valida√ß√£o cruzada.\n\n\n## Mostra 2 gr√°ficos:\n# 1) Varia√ß√£o do R2 aparente e relativo vs n√∫mero de parti√ß√µes\n# 2) Erro Relativo vs n√∫mero de parti√ß√µes\nrsq.rpart(arvreg1)\n\n\nRegression tree:\nrpart(formula = medv ~ ., data = conj_treino, method = \"anova\", \n    control = rpart.control(minsplit = 30, cp = 0.01))\n\nVariables actually used in tree construction:\n[1] crim  lstat rm   \n\nRoot node error: 31197/381 = 81.882\n\nn= 381 \n\n        CP nsplit rel error  xerror     xstd\n1 0.461731      0   1.00000 1.01028 0.096645\n2 0.161924      1   0.53827 0.65330 0.065046\n3 0.094840      2   0.37634 0.49315 0.059728\n4 0.034308      3   0.28151 0.37245 0.050769\n5 0.028069      4   0.24720 0.34074 0.051145\n6 0.020942      5   0.21913 0.29254 0.042692\n7 0.010000      6   0.19819 0.28562 0.042529\n\n\n\n\n\n\n\n## Mostra a varia√ß√£o do Erro relativo vs cp(parametro de complexidade)\nplotcp(arvreg1)"
  },
  {
    "objectID": "semanas/Aula11.html#gr√°fico-de-importancia-das-vari√°veis",
    "href": "semanas/Aula11.html#gr√°fico-de-importancia-das-vari√°veis",
    "title": "Arvores de Regress√£o",
    "section": "Gr√°fico de importancia das vari√°veis",
    "text": "Gr√°fico de importancia das vari√°veis\nA importancia das vari√°veis √© calculada com base nos resultados das melhores parti√ß√µes\n\n# Gr√°fico de Import√¢ncia de vari√°vel\nvar_imp <- arvreg1$variable.importance\nnomes_var <- names(var_imp)\nvar_impdf <- data.frame(Importancia=unname(var_imp), Variavel=nomes_var) %>%\n                        arrange(Importancia)\nvar_impdf$Variavel <- factor(var_impdf$Variavel, levels=var_impdf$Variavel)\nggplot(var_impdf, aes(x=Variavel, y=Importancia)) + \n         geom_col() + \n        coord_flip()"
  },
  {
    "objectID": "semanas/Aula11.html#mostrando-a-√°rvore-e-gerando-previs√µes",
    "href": "semanas/Aula11.html#mostrando-a-√°rvore-e-gerando-previs√µes",
    "title": "Arvores de Regress√£o",
    "section": "Mostrando a √°rvore e gerando previs√µes",
    "text": "Mostrando a √°rvore e gerando previs√µes\n\n# Mostrando a arvore\npar(xpd = NA)\nplot(arvreg1)\ntext(arvreg1,pretty=0)\n\n\n\n# Fazendo Previs√µes\nprevisao1 <- arvreg1 %>% predict(conj_teste)\nhead(previsao1)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previs√£o\nRMSE(previsao1, conj_teste$medv)\n\n[1] 5.303593"
  },
  {
    "objectID": "semanas/Aula11.html#arvore-de-regress√£o-com-caret",
    "href": "semanas/Aula11.html#arvore-de-regress√£o-com-caret",
    "title": "Arvores de Regress√£o",
    "section": "Arvore de Regress√£o com caret",
    "text": "Arvore de Regress√£o com caret\nAqui vamos usar a biblioteca caret que tem umas facilidades para otimiza√ß√£o do cp e apresenta√ß√£o dos resultados\n\nset.seed(21)\n## Otimizamos o valor de cp usando um 10-fold cv\n# O parametro tuneLength diz para o algoritmo escolher diferentes valores para cp\n# O parametro tuneGrid permite decidir que valores cp deve assumir enquanto que o\n# tuneLength somente limita o n√∫mero default de parametros que se usa.\narvreg2 <- train(medv ~ . , data = conj_treino, method = \"rpart\",\n                 trControl = trainControl(\"cv\", number = 10),\n                 tuneGrid = data.frame(cp = seq(0.01,0.10, length.out=100)) \n                 )\n# Mostra a acur√°cia vs cp (parametro de complexidade)\nplot(arvreg2)\n\n\n\n## Indica o melhor valor de cp\narvreg2$bestTune\n\n          cp\n4 0.01272727"
  },
  {
    "objectID": "semanas/Aula11.html#desenhando-a-√°rvore",
    "href": "semanas/Aula11.html#desenhando-a-√°rvore",
    "title": "Arvores de Regress√£o",
    "section": "Desenhando a √Årvore",
    "text": "Desenhando a √Årvore\n\n## Apresenta o modelo final de arvore ajustado\npar(xpd = NA)\nplot(arvreg2$finalModel)\ntext(arvreg2$finalModel,  digits = 3)\n\n\n\n## usando o rpart.plot\nlibrary(rpart.plot)\nrpart.plot(arvreg2$finalModel)"
  },
  {
    "objectID": "semanas/Aula11.html#previs√µes",
    "href": "semanas/Aula11.html#previs√µes",
    "title": "Arvores de Regress√£o",
    "section": "Previs√µes",
    "text": "Previs√µes\n\n# Regras de Decis√£o\narvreg2$finalModel\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=11.315 7   367.8886 21.88571 *\n      13) lstat< 11.315 42   956.1507 32.57857 *\n     7) rm>=7.435 21   960.7895 45.23810 *\n\n# Fazendo Previs√µes\nprevisao2 <- arvreg2 %>% predict(conj_teste)\nhead(previsao2)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previs√£o\nRMSE(previsao2, conj_teste$medv)\n\n[1] 5.304604"
  },
  {
    "objectID": "semanas/Aula11.html#vamos-comparar-com-regress√£o-multipla",
    "href": "semanas/Aula11.html#vamos-comparar-com-regress√£o-multipla",
    "title": "Arvores de Regress√£o",
    "section": "Vamos comparar com Regress√£o Multipla",
    "text": "Vamos comparar com Regress√£o Multipla\n\nlibrary(leaps)\n## Cria uma fun√ß√£o de predi√ß√£o para o leaps\npredict.regsubsets <- function(object,newdata,id,...){\n  form <- as.formula(object$call[[2]])\n  mat <- model.matrix(form,newdata)\n  coefi <- coef(object,id=id)\n  mat[,names(coefi)]%*%coefi\n}\nset.seed(21)\nenvelopes <- sample(rep(1:5,length=nrow(conj_treino)))\ntable(envelopes)\n\nenvelopes\n 1  2  3  4  5 \n77 76 76 76 76 \n\nerro_cv <- matrix(NA,5,13)\nfor(k in 1:5){\n  melh_ajus <- regsubsets(medv ~ ., data=conj_treino[envelopes!=k,], \n                          nvmax=13,method=\"forward\")\n  for(i in 1:13){\n    prev <- predict(melh_ajus, conj_treino[envelopes==k,],id=i)\n    erro_cv[k,i] <- mean( (conj_treino$medv[envelopes==k]-prev)^2)\n  }\n}\nrmse_cv <- sqrt(apply(erro_cv,2,mean))  # Erro medio quadratico de cada modelo\nplot(rmse_cv,pch=19,type=\"b\")"
  },
  {
    "objectID": "semanas/Aula11.html#obtem-a-f√≥rmula-do-modelo",
    "href": "semanas/Aula11.html#obtem-a-f√≥rmula-do-modelo",
    "title": "Arvores de Regress√£o",
    "section": "Obtem a f√≥rmula do modelo",
    "text": "Obtem a f√≥rmula do modelo\n\ncoef(melh_ajus, 11)\n\n  (Intercept)          crim            zn          chas           nox \n 37.051974686  -0.144753575   0.047778839   1.780110617 -14.931943579 \n           rm           dis           rad           tax       ptratio \n  3.815637016  -1.500993904   0.349882023  -0.015845438  -0.986230946 \n        black         lstat \n  0.009024705  -0.534163142"
  },
  {
    "objectID": "semanas/Aula11.html#teste-com-o-conjunto-de-teste",
    "href": "semanas/Aula11.html#teste-com-o-conjunto-de-teste",
    "title": "Arvores de Regress√£o",
    "section": "Teste com o conjunto de teste",
    "text": "Teste com o conjunto de teste\n\nprevisao3 <- predict(melh_ajus, conj_teste, 11) \nRMSE(previsao3, conj_teste$medv)\n\n[1] 5.936577"
  },
  {
    "objectID": "semanas/Aula11A.html",
    "href": "semanas/Aula11A.html",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)"
  },
  {
    "objectID": "semanas/Aula11A.html#avaliando-selecionando-dados",
    "href": "semanas/Aula11A.html#avaliando-selecionando-dados",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Avaliando, selecionando dados",
    "text": "Avaliando, selecionando dados\n\ndata(\"Boston\")\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\ndados <- Boston"
  },
  {
    "objectID": "semanas/Aula11A.html#treino-e-teste-com-todas-as-vari√°veis",
    "href": "semanas/Aula11A.html#treino-e-teste-com-todas-as-vari√°veis",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Treino e Teste com todas as vari√°veis",
    "text": "Treino e Teste com todas as vari√°veis\n\n## Vamos criar os conjuntos de treino teste e desenvolver a arvore \n## com todas as vari√°veis.\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\nindice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)\nconj_treino <- dados[indice,]\nconj_teste <- dados[-indice,]\nhead(conj_treino)\n\n     crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18.0  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n3 0.02729  0.0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0.0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0.0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0.0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n7 0.08829 12.5  7.87    0 0.524 6.012 66.6 5.5605   5 311    15.2 395.60 12.43\n  medv\n1 24.0\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n7 22.9\n\nhead(conj_teste)\n\n      crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n2  0.02731  0.0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n10 0.17004 12.5  7.87    0 0.524 6.004 85.9 6.5921   5 311    15.2 386.71 17.10\n12 0.11747 12.5  7.87    0 0.524 6.009 82.9 6.2267   5 311    15.2 396.90 13.27\n16 0.62739  0.0  8.14    0 0.538 5.834 56.5 4.4986   4 307    21.0 395.62  8.47\n19 0.80271  0.0  8.14    0 0.538 5.456 36.6 3.7965   4 307    21.0 288.99 11.69\n23 1.23247  0.0  8.14    0 0.538 6.142 91.7 3.9769   4 307    21.0 396.90 18.72\n   medv\n2  21.6\n10 18.9\n12 18.9\n16 19.9\n19 20.2\n23 15.2"
  },
  {
    "objectID": "semanas/Aula11A.html#a-tentativa-gbm",
    "href": "semanas/Aula11A.html#a-tentativa-gbm",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "1a tentativa GBM",
    "text": "1a tentativa GBM\n\nlibrary(gbm)\n\nLoaded gbm 2.1.8.1\n\nset.seed(21)\n# treinar o modelo GBM\ngbm.fit <- gbm(formula = medv ~ .,\n                distribution = \"gaussian\", #  minimizar erro quadr√°tico\n                data = conj_treino,\n                n.trees = 10000,  # n√∫mero de √°rvores\n                interaction.depth = 3,  # profundidade da arvore\n                shrinkage = 0.1,   # aprendizado r√°pido\n                cv.folds = 5, # 5 envelopes de valida√ß√µa cruzada\n                n.cores = NULL, # \n                verbose = FALSE)\n\n# Achar o √≠ndice do modelo com menor erro de valia√ß√£o cruzada\nmin_MSE <- which.min(gbm.fit$cv.error)\n\n# Obter o MSE e calcular o RMSE\nsqrt(gbm.fit$cv.error[min_MSE])\n\n[1] 3.385086\n\n# Mostrar a fun√ß√£o de perda (loss function) como resultado do n√∫mero de √°rvores combinadas\n# A linha preta s√£o os valores para as perdas de treino e a verde as de teste\n# A linha azul pontilhada indica o n√∫mero de √°rvores que minimiza os erros da valida√ß√£o cruzada\ngbm.perf(gbm.fit, method = \"cv\")\n\n\n\n\n[1] 497"
  },
  {
    "objectID": "semanas/Aula11A.html#criando-um-grid-para-avaliar-os-parametros-e-os-respectivos-rmses",
    "href": "semanas/Aula11A.html#criando-um-grid-para-avaliar-os-parametros-e-os-respectivos-rmses",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Criando um grid para avaliar os parametros e os respectivos RMSEs",
    "text": "Criando um grid para avaliar os parametros e os respectivos RMSEs\n\nhiper_grid <- expand.grid(\n  shrinkage = c(.01, .05, .1),\n  interaction.depth = c(1, 3, 5, 7),\n  n.minobsinnode = c(5, 10, 15),\n  bag.fraction = c(.65, .8, 1),\n  optimal_trees = 0, \n  min_RMSE = 0   \n  )\n\n# numero total de combina√ß√µes\nnrow(hiper_grid)\n\n[1] 108"
  },
  {
    "objectID": "semanas/Aula11A.html#avaliando-o-grid-de-parametros",
    "href": "semanas/Aula11A.html#avaliando-o-grid-de-parametros",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Avaliando o grid de parametros",
    "text": "Avaliando o grid de parametros\n\n# Busca no grid \nfor(i in 1:nrow(hiper_grid)) {\n  \n  # \n  set.seed(21)\n  \n  # treina o modelo\n  gbm.tune <- gbm(\n    formula = medv ~ .,\n    distribution = \"gaussian\",\n    data = conj_treino,\n    n.trees = 6000,\n    interaction.depth = hiper_grid$interaction.depth[i],\n    shrinkage = hiper_grid$shrinkage[i],\n    n.minobsinnode = hiper_grid$n.minobsinnode[i],\n    bag.fraction = hiper_grid$bag.fraction[i],\n    train.fraction = .75,\n    n.cores = NULL, \n    verbose = FALSE\n  )\n  \n # adiciona os erros de treino e arvores ao grid\n  hiper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)\n  hiper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))\n}\n\nhiper_grid %>% dplyr::arrange(min_RMSE) %>% head(10)\n\n   shrinkage interaction.depth n.minobsinnode bag.fraction optimal_trees\n1       0.10                 1             15         0.65          3074\n2       0.10                 1             10         0.65          5262\n3       0.05                 1             15         0.80          4392\n4       0.10                 1             15         0.80          3321\n5       0.05                 1             15         0.65          3074\n6       0.05                 1             10         1.00          4455\n7       0.10                 1             10         1.00          2073\n8       0.10                 1             15         1.00          4124\n9       0.05                 1             15         1.00          5996\n10      0.05                 5             15         0.65           178\n   min_RMSE\n1  4.420519\n2  4.655791\n3  4.667658\n4  4.686840\n5  4.699871\n6  4.775397\n7  4.780322\n8  4.788251\n9  4.818321\n10 4.818439"
  },
  {
    "objectID": "semanas/Aula11A.html#modelo-final",
    "href": "semanas/Aula11A.html#modelo-final",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Modelo final",
    "text": "Modelo final\n\n# \nset.seed(21)\n\n# treina o modelo GBM\ngbm.fit.final <- gbm(\n  formula = medv ~ .,\n  distribution = \"gaussian\",\n  data = conj_treino,\n  n.trees = 3074,\n  interaction.depth = 1,\n  shrinkage = 0.10,\n  n.minobsinnode = 15,\n  bag.fraction = 0.65, \n  train.fraction = 1,\n  n.cores = NULL, \n  verbose = FALSE\n  )"
  },
  {
    "objectID": "semanas/Aula11A.html#variable-importance",
    "href": "semanas/Aula11A.html#variable-importance",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Variable importance",
    "text": "Variable importance\n\nsummary(\n  gbm.fit.final, \n  cBars = 13,\n  method = relative.influence, # tamb√©m pode ser usado permutation.test.gbm\n  las = 2\n  )\n\n\n\n\n            var    rel.inf\nrm           rm 34.2998187\nlstat     lstat 29.4374141\ndis         dis  8.3574770\nnox         nox  5.9614131\ncrim       crim  5.5011677\nchas       chas  4.5023266\nptratio ptratio  3.5157834\nblack     black  3.4315023\nage         age  2.3514968\ntax         tax  1.4830798\nindus     indus  0.6084729\nrad         rad  0.4554056\nzn           zn  0.0946421"
  },
  {
    "objectID": "semanas/Aula11A.html#previs√£o",
    "href": "semanas/Aula11A.html#previs√£o",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Previs√£o",
    "text": "Previs√£o\n\n# Fazendo Previs√µes\nprevisao1 <- predict(gbm.fit.final, \n                     newdata = conj_teste,\n                     n.trees=gbm.fit.final$n.trees)\nhead(previsao1)\n\n[1] 19.73374 18.76262 19.89281 20.76348 18.34094 16.44815\n\n# Calcula os erros de previs√£o\ncaret::RMSE(previsao1, conj_teste$medv)\n\n[1] 4.189849"
  },
  {
    "objectID": "semanas/Aula11A.html#entendendo-melhor-os-resultados",
    "href": "semanas/Aula11A.html#entendendo-melhor-os-resultados",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Entendendo melhor os resultados",
    "text": "Entendendo melhor os resultados\n\nlibrary(lime)\n\n\nAttaching package: 'lime'\n\n\nThe following object is masked from 'package:dplyr':\n\n    explain\n\nmodel_type.gbm <- function(x, ...) {\n  return(\"regression\")\n}\n\npredict_model.gbm <- function(x, newdata, ...) {\n  pred <- predict(x, newdata, n.trees = x$n.trees)\n  return(as.data.frame(pred))\n}\n# Algumas observa√ß√µes para avaliar\nobs_pontuais <- conj_teste[1:2, ]\n\n# aplica o LIME\nexplicador <- lime(conj_treino, gbm.fit.final)\n\nWarning: chas does not contain enough variance to use quantile binning. Using\nstandard binning instead.\n\nexplicacao <- explain(obs_pontuais, explicador, n_features = 5)\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n =\nNULL, : skipping variable with zero or non-finite range\n\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n =\nNULL, : skipping variable with zero or non-finite range\n\nplot_features(explicacao)"
  },
  {
    "objectID": "semanas/Aula11A.html#gr√°fico-de-dependencia-parcial-partial-dependence-plot",
    "href": "semanas/Aula11A.html#gr√°fico-de-dependencia-parcial-partial-dependence-plot",
    "title": "Arvores de Regress√£o - Gradient Boosting",
    "section": "Gr√°fico de Dependencia Parcial (Partial Dependence Plot)",
    "text": "Gr√°fico de Dependencia Parcial (Partial Dependence Plot)\n\ngraf_rm <- plot(gbm.fit.final, i = \"rm\")\ngraf_lstat <- plot(gbm.fit.final, i = \"lstat\")\ngridExtra::grid.arrange(graf_lstat, graf_rm, ncol = 2)"
  },
  {
    "objectID": "semanas/Aula12.html",
    "href": "semanas/Aula12.html",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)"
  },
  {
    "objectID": "semanas/Aula12.html#dados",
    "href": "semanas/Aula12.html#dados",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Dados",
    "text": "Dados\nVamos come√ßar a aplicar a metodologia de √°rvores usando √°rvores de classifica√ß√£o para analisar os dados existentes em Carseats. Este conjunto de dados (simulado) √© sobre venda de assentos de crian√ßa para carros. Ele tem 400 observa√ß√µes das seguintes vari√°veis (11), cujos nomes ser√£o convertidos para o portugu√™s:\nSales: vendas em unidades (em mil) em cada local\nCompPrice: pre√ßo cobrado pelo competidor em cada local\nIncome: n√≠vel de renda da comunidade local (em mil US$)\nAdvertising: or√ßamento local de propaganda (em mil US$)\nPopulation: popula√ß√£o na regi√£o (em mil)\nPrice: pre√ßo cobrado pela empresa em cada local\nShelveLoc: um fator com n√≠veis Ruim, Bom e Medio indicando a qualidade da localiza√ß√£o das prateleiras para os assentos em cada lugar\nAge: idade media da popula√ß√£o local\nEducation: n√≠vel de educa√ß√£o em cada local\nUrban: um fator Sim e N√£o indicando se a loja esta em uma √°rea urbana ou rural\nUS: um fator indicando se a loja √© nos EUA ou n√£o\nNeste dados, Sales √© a vari√°vel resposta, s√≥ que ela √© uma vari√°vel cont√≠nua, por este motivo vamos us√°-la para criar uma vari√°vel bin√°ria. Vamos usar a fun√ß√£o ifelse() para criar a vari√°vel bin√°ria, que chamaremos de alta, ela assume os valores Sim se Sales for maior que 8 e assume o valor N√£o caso contr√°rio:\n\ndata(Carseats)\nsummary(Carseats)\n\n     Sales          CompPrice       Income        Advertising    \n Min.   : 0.000   Min.   : 77   Min.   : 21.00   Min.   : 0.000  \n 1st Qu.: 5.390   1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000  \n Median : 7.490   Median :125   Median : 69.00   Median : 5.000  \n Mean   : 7.496   Mean   :125   Mean   : 68.66   Mean   : 6.635  \n 3rd Qu.: 9.320   3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000  \n Max.   :16.270   Max.   :175   Max.   :120.00   Max.   :29.000  \n   Population        Price        ShelveLoc        Age          Education   \n Min.   : 10.0   Min.   : 24.0   Bad   : 96   Min.   :25.00   Min.   :10.0  \n 1st Qu.:139.0   1st Qu.:100.0   Good  : 85   1st Qu.:39.75   1st Qu.:12.0  \n Median :272.0   Median :117.0   Medium:219   Median :54.50   Median :14.0  \n Mean   :264.8   Mean   :115.8                Mean   :53.32   Mean   :13.9  \n 3rd Qu.:398.5   3rd Qu.:131.0                3rd Qu.:66.00   3rd Qu.:16.0  \n Max.   :509.0   Max.   :191.0                Max.   :80.00   Max.   :18.0  \n Urban       US     \n No :118   No :142  \n Yes:282   Yes:258  \n                    \n                    \n                    \n                    \n\nstr(Carseats)\n\n'data.frame':   400 obs. of  11 variables:\n $ Sales      : num  9.5 11.22 10.06 7.4 4.15 ...\n $ CompPrice  : num  138 111 113 117 141 124 115 136 132 132 ...\n $ Income     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ Advertising: num  11 16 10 4 3 13 0 15 0 0 ...\n $ Population : num  276 260 269 466 340 501 45 425 108 131 ...\n $ Price      : num  120 83 80 97 128 72 108 120 124 124 ...\n $ ShelveLoc  : Factor w/ 3 levels \"Bad\",\"Good\",\"Medium\": 1 2 3 3 1 1 3 2 3 3 ...\n $ Age        : num  42 65 59 55 38 78 71 67 76 76 ...\n $ Education  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ Urban      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 2 2 1 1 ...\n $ US         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 1 2 1 2 ..."
  },
  {
    "objectID": "semanas/Aula12.html#manipulando-os-dados",
    "href": "semanas/Aula12.html#manipulando-os-dados",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncad_crianca <- Carseats %>% rename(vendas = Sales, \n                                   preco_comp = CompPrice,\n                                   renda = Income,\n                                   propaganda = Advertising,\n                                   populacao = Population,\n                                   preco = Price,\n                                   local_prat = ShelveLoc,\n                                   idade = Age,\n                                   educacao = Education,\n                                   urbano = Urban,\n                                   eua = US)\n\ncad_crianca <- cad_crianca %>% mutate(alta = ifelse(vendas > 8, \"Sim\",\n                                                   \"N√£o\")) %>%\n                              mutate(alta = factor(alta))\n\ncad_crianca<- cad_crianca %>% mutate(local_prat =  case_when(\n                                      local_prat == \"Bad\"  ~ \"Ruim\",\n                                      local_prat == \"Good\" ~ \"Bom\",\n                                      local_prat == \"Medium\" ~ \"Medio\"))%>%                               mutate(local_prat = factor(local_prat))\n\ncad_crianca<- cad_crianca %>% mutate(urbano =  case_when(\n                                      urbano == \"Yes\"  ~ \"Sim\",\n                                      urbano == \"No\" ~ \"N√£o\")) %>%                                       mutate(urbano = factor(urbano))\n\ncad_crianca<- cad_crianca %>% mutate(eua =  case_when(\n                                      eua == \"Yes\"  ~ \"Sim\",\n                                      eua == \"No\" ~ \"N√£o\")) %>%                                          mutate(eua = factor(eua))\n\ncad_crianca<- cad_crianca %>% select(-vendas)\n\nstr(cad_crianca)\n\n'data.frame':   400 obs. of  11 variables:\n $ preco_comp: num  138 111 113 117 141 124 115 136 132 132 ...\n $ renda     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ propaganda: num  11 16 10 4 3 13 0 15 0 0 ...\n $ populacao : num  276 260 269 466 340 501 45 425 108 131 ...\n $ preco     : num  120 83 80 97 128 72 108 120 124 124 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 2 3 3 2 1 2 2 ...\n $ idade     : num  42 65 59 55 38 78 71 67 76 76 ...\n $ educacao  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 2 2 1 2 2 1 1 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 2 1 2 1 2 1 2 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 1 1 2 1 2 1 1 ...\n\nsummary(cad_crianca)\n\n   preco_comp      renda          propaganda       populacao    \n Min.   : 77   Min.   : 21.00   Min.   : 0.000   Min.   : 10.0  \n 1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000   1st Qu.:139.0  \n Median :125   Median : 69.00   Median : 5.000   Median :272.0  \n Mean   :125   Mean   : 68.66   Mean   : 6.635   Mean   :264.8  \n 3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000   3rd Qu.:398.5  \n Max.   :175   Max.   :120.00   Max.   :29.000   Max.   :509.0  \n     preco       local_prat      idade          educacao    urbano     eua     \n Min.   : 24.0   Bom  : 85   Min.   :25.00   Min.   :10.0   N√£o:118   N√£o:142  \n 1st Qu.:100.0   Medio:219   1st Qu.:39.75   1st Qu.:12.0   Sim:282   Sim:258  \n Median :117.0   Ruim : 96   Median :54.50   Median :14.0                      \n Mean   :115.8               Mean   :53.32   Mean   :13.9                      \n 3rd Qu.:131.0               3rd Qu.:66.00   3rd Qu.:16.0                      \n Max.   :191.0               Max.   :80.00   Max.   :18.0                      \n  alta    \n N√£o:236  \n Sim:164"
  },
  {
    "objectID": "semanas/Aula12.html#treino-e-teste",
    "href": "semanas/Aula12.html#treino-e-teste",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\ny <- cad_crianca$alta\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- cad_crianca %>% slice(-indice_teste)\nconj_teste <- cad_crianca %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   319 obs. of  11 variables:\n $ preco_comp: num  138 111 113 141 124 136 132 121 117 122 ...\n $ renda     : num  73 48 35 64 113 81 110 78 94 35 ...\n $ propaganda: num  11 16 10 3 13 15 0 9 4 2 ...\n $ populacao : num  276 260 269 340 501 425 108 150 503 393 ...\n $ preco     : num  120 83 80 128 72 120 124 100 94 136 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 3 3 1 2 3 1 2 ...\n $ idade     : num  42 65 59 38 78 67 76 26 50 62 ...\n $ educacao  : num  17 10 12 13 16 10 10 10 13 18 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 2 1 2 1 1 2 2 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n\nprop.table(table(conj_treino$alta))\n\n\n      N√£o       Sim \n0.5893417 0.4106583 \n\nstr(conj_teste)\n\n'data.frame':   81 obs. of  11 variables:\n $ preco_comp: num  117 115 132 115 147 145 114 121 123 103 ...\n $ renda     : num  100 105 113 28 74 119 38 41 42 93 ...\n $ propaganda: num  4 0 0 11 13 16 13 5 11 15 ...\n $ populacao : num  466 45 131 29 251 294 317 412 16 188 ...\n $ preco     : num  97 108 124 86 131 113 128 110 134 103 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 2 2 2 1 1 3 1 2 2 3 ...\n $ idade     : num  55 71 76 53 52 42 50 54 59 74 ...\n $ educacao  : num  14 15 17 18 10 12 16 10 13 16 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 1 2 2 2 2 2 2 2 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 1 2 2 2 2 2 2 2 2 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 1 1 1 2 2 2 2 1 1 1 ...\n\nprop.table(table(conj_teste$alta))\n\n\n      N√£o       Sim \n0.5925926 0.4074074"
  },
  {
    "objectID": "semanas/Aula12.html#arvore-de-classifica√ß√£o",
    "href": "semanas/Aula12.html#arvore-de-classifica√ß√£o",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Arvore de Classifica√ß√£o",
    "text": "Arvore de Classifica√ß√£o\nNa biblioteca rpart as arvores de classifica√ß√£o s√£o obtidas usando o m√©todo class. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo s√≥ definimos o menor conjunto de dados numa parti√ß√£o (minsplit) e o parametro de complexidade cp.¬†Posteriormente vamos ampliar este controle. Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande resulta numa arvore muito pequena (underfitting). Nos dois casos se diminui o desempenho do modelo.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(alta ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classifica√ß√£o\n                control=rpart.control(minsplit=30,cp=0.02))\nplot(arvcl)\ntext(arvcl,pretty=0)\n\n\n\n\n\n\n# Regras de Decis√£o\narvcl\n\nn= 319 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 319 131 N√£o (0.58934169 0.41065831)  \n   2) local_prat=Medio,Ruim 249  77 N√£o (0.69076305 0.30923695)  \n     4) preco>=92 213  51 N√£o (0.76056338 0.23943662)  \n       8) idade>=49.5 123  15 N√£o (0.87804878 0.12195122) *\n       9) idade< 49.5 90  36 N√£o (0.60000000 0.40000000)  \n        18) preco>=124.5 44   6 N√£o (0.86363636 0.13636364) *\n        19) preco< 124.5 46  16 Sim (0.34782609 0.65217391) *\n     5) preco< 92 36  10 Sim (0.27777778 0.72222222)  \n      10) local_prat=Ruim 13   5 N√£o (0.61538462 0.38461538) *\n      11) local_prat=Medio 23   2 Sim (0.08695652 0.91304348) *\n   3) local_prat=Bom 70  16 Sim (0.22857143 0.77142857)  \n     6) preco>=142.5 10   3 N√£o (0.70000000 0.30000000) *\n     7) preco< 142.5 60   9 Sim (0.15000000 0.85000000) *"
  },
  {
    "objectID": "semanas/Aula12.html#desenhando-a-√°rvore-de-uma-forma-mais-clara",
    "href": "semanas/Aula12.html#desenhando-a-√°rvore-de-uma-forma-mais-clara",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Desenhando a √Årvore de uma forma mais clara",
    "text": "Desenhando a √Årvore de uma forma mais clara\n\nlibrary(rattle)\n\nCarregando pacotes exigidos: bitops\n\n\nRattle: A free graphical interface for data science with R.\nVersion 5.5.1 Copyright (c) 2006-2021 Togaware Pty Ltd.\nType 'rattle()' to shake, rattle, and roll your data.\n\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)"
  },
  {
    "objectID": "semanas/Aula12.html#previs√µes",
    "href": "semanas/Aula12.html#previs√µes",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Previs√µes",
    "text": "Previs√µes\n\n# Fazendo Previs√µes\ny_chapeu <- predict(arvcl, newdata = conj_teste, type=\"class\")\n\nconfusionMatrix(y_chapeu, conj_teste$alta, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction N√£o Sim\n       N√£o  37  13\n       Sim  11  20\n                                          \n               Accuracy : 0.7037          \n                 95% CI : (0.5919, 0.8001)\n    No Information Rate : 0.5926          \n    P-Value [Acc > NIR] : 0.02573         \n                                          \n                  Kappa : 0.3805          \n                                          \n Mcnemar's Test P-Value : 0.83826         \n                                          \n            Sensitivity : 0.6061          \n            Specificity : 0.7708          \n         Pos Pred Value : 0.6452          \n         Neg Pred Value : 0.7400          \n             Prevalence : 0.4074          \n         Detection Rate : 0.2469          \n   Detection Prevalence : 0.3827          \n      Balanced Accuracy : 0.6884          \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula12.html#arvore-de-classifica√ß√£o-no-caret",
    "href": "semanas/Aula12.html#arvore-de-classifica√ß√£o-no-caret",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Arvore de Classifica√ß√£o no caret",
    "text": "Arvore de Classifica√ß√£o no caret\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\nset.seed(21)\n## Otimizamos o valor de cp usando um 10-fold cv\n# O parametro tuneLength diz para o algoritmo escolher diferentes valores para cp\n# O parametro tuneGrid permite decidir que valores cp deve assumir enquanto que o\n# tuneLength somente limita o n√∫mero default de parametros que se usa.\ntgrid <- expand.grid(cp = seq(0.01,0.10,0.001))\nctrl <- trainControl(method = \"cv\", classProbs=TRUE)\narvclass <- train(alta ~ . , data = conj_treino, method = \"rpart\",\n                 trControl = ctrl,\n                 tuneGrid = tgrid\n                 )\n# Mostra a acur√°cia vs cp (parametro de complexidade)\nplot(arvclass)\n\n\n\n## Indica o melhor valor de cp\narvclass$bestTune\n\n     cp\n7 0.016"
  },
  {
    "objectID": "semanas/Aula12.html#uma-forma-melhor-de-ver-a-√°rvore",
    "href": "semanas/Aula12.html#uma-forma-melhor-de-ver-a-√°rvore",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Uma forma melhor de ver a √Årvore",
    "text": "Uma forma melhor de ver a √Årvore\n\n## melhorando apresenta√ß√£o da √°rvore\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvclass$finalModel, caption = NULL)"
  },
  {
    "objectID": "semanas/Aula12.html#previs√µes-1",
    "href": "semanas/Aula12.html#previs√µes-1",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Previs√µes",
    "text": "Previs√µes\n\n# Fazendo Previs√µes\ny_chapeu <- arvclass %>% predict(conj_teste) %>% \n                   factor(levels = levels(conj_teste$alta))\nhead(y_chapeu)\n\n[1] N√£o N√£o N√£o Sim Sim N√£o\nLevels: N√£o Sim\n\nconfusionMatrix(y_chapeu, conj_teste$alta, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction N√£o Sim\n       N√£o  40  13\n       Sim   8  20\n                                          \n               Accuracy : 0.7407          \n                 95% CI : (0.6314, 0.8318)\n    No Information Rate : 0.5926          \n    P-Value [Acc > NIR] : 0.003896        \n                                          \n                  Kappa : 0.45            \n                                          \n Mcnemar's Test P-Value : 0.382733        \n                                          \n            Sensitivity : 0.6061          \n            Specificity : 0.8333          \n         Pos Pred Value : 0.7143          \n         Neg Pred Value : 0.7547          \n             Prevalence : 0.4074          \n         Detection Rate : 0.2469          \n   Detection Prevalence : 0.3457          \n      Balanced Accuracy : 0.7197          \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula12.html#gbm",
    "href": "semanas/Aula12.html#gbm",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "GBM",
    "text": "GBM"
  },
  {
    "objectID": "semanas/Aula12.html#criando-um-grid-para-avaliar-os-parametros",
    "href": "semanas/Aula12.html#criando-um-grid-para-avaliar-os-parametros",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Criando um grid para avaliar os parametros",
    "text": "Criando um grid para avaliar os parametros\n\nhiper_grid <- expand.grid(\n  shrinkage = c(.001, .01, .1),\n  interaction.depth = c(1, 3, 5),\n  n.minobsinnode = c(5, 10, 15),\n  bag.fraction = c(.65, 1),\n  optimal_trees = 0, # um lugar para guardar resultados\n  min_erro = 0   # um lugar para guardar resultados\n  )\n\n# n√∫mero total de combina√ß√µes\nnrow(hiper_grid)\n\n[1] 54"
  },
  {
    "objectID": "semanas/Aula12.html#avaliando-o-grid-de-parametros",
    "href": "semanas/Aula12.html#avaliando-o-grid-de-parametros",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Avaliando o grid de parametros",
    "text": "Avaliando o grid de parametros\n\nlibrary(gbm)\n\nLoaded gbm 2.1.8.1\n\nconj_treino$alta <- as.numeric(conj_treino$alta)\nconj_treino <- transform(conj_treino, alta=alta - 1)\nconj_treino$eua <- as.numeric(conj_treino$eua)\nconj_treino <- transform(conj_treino, eua=eua - 1)\nconj_treino$local_prat <- as.numeric(conj_treino$local_prat)\nconj_treino <- transform(conj_treino, local_prat=local_prat - 1)\n\n\n#Busca no grid\nfor(i in 1:nrow(hiper_grid)) {\n\n  #\n  set.seed(21)\n\n  # treina o modelo\n  gbm.tune <- gbm(\n    formula = alta ~ .,\n    distribution = \"bernoulli\",\n    data = conj_treino,\n    n.trees = 5000,\n    interaction.depth = hiper_grid$interaction.depth[i],\n    shrinkage = hiper_grid$shrinkage[i],\n    n.minobsinnode = hiper_grid$n.minobsinnode[i],\n    bag.fraction = hiper_grid$bag.fraction[i],\n    train.fraction = .75,\n    n.cores = NULL,\n    verbose = FALSE\n  )\n\n  # adiciona os erros de treino e arvores ao grid\n  hiper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)\n  hiper_grid$min_erro[i] <- min(gbm.tune$valid.error)\n}\n\nhiper_grid %>% dplyr::arrange(min_erro) %>% head(10)\n\n   shrinkage interaction.depth n.minobsinnode bag.fraction optimal_trees\n1       0.10                 1             15         0.65           372\n2       0.10                 1             10         0.65           293\n3       0.01                 1             15         0.65          2906\n4       0.10                 3              5         1.00           208\n5       0.01                 1             10         0.65          2904\n6       0.10                 1             15         1.00           645\n7       0.01                 3             10         1.00          1871\n8       0.10                 1              5         0.65           297\n9       0.10                 3             10         0.65            91\n10      0.01                 1              5         0.65          2721\n    min_erro\n1  0.5791345\n2  0.5845112\n3  0.5924547\n4  0.5972617\n5  0.5985068\n6  0.6025920\n7  0.6045516\n8  0.6046190\n9  0.6074368\n10 0.6101727"
  },
  {
    "objectID": "semanas/Aula12.html#modelo-final",
    "href": "semanas/Aula12.html#modelo-final",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Modelo final",
    "text": "Modelo final\n\n# \nset.seed(21)\n\n# treina o modelo GBM\ngbm.fit.final <- gbm(\n  formula = alta ~ .,\n  distribution = \"bernoulli\",\n  data = conj_treino,\n  n.trees = 372,\n  interaction.depth = 1,\n  shrinkage = 0.10,\n  n.minobsinnode = 15,\n  bag.fraction = 0.65, \n  train.fraction = 1,\n  n.cores = NULL, \n  verbose = FALSE\n  )"
  },
  {
    "objectID": "semanas/Aula12.html#import√¢ncia-das-vari√°veis",
    "href": "semanas/Aula12.html#import√¢ncia-das-vari√°veis",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Import√¢ncia das Vari√°veis",
    "text": "Import√¢ncia das Vari√°veis\n\npar(mai = c(1, 2, 1, 2))\nsummary(\n  gbm.fit.final, \n  cBars = 10,\n  method = relative.influence, # tamb√©m pode ser usado permutation.test.gbm\n  las = 2\n  )\n\n\n\n\n                  var   rel.inf\npreco           preco 29.933549\nlocal_prat local_prat 25.047847\npreco_comp preco_comp 11.862257\nidade           idade 11.216571\npropaganda propaganda  9.259809\nrenda           renda  8.997264\npopulacao   populacao  2.456444\neducacao     educacao  1.226259\nurbano         urbano  0.000000\neua               eua  0.000000"
  },
  {
    "objectID": "semanas/Aula12.html#previs√£o",
    "href": "semanas/Aula12.html#previs√£o",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Previs√£o",
    "text": "Previs√£o\n\nconj_teste$alta <- as.numeric(conj_teste$alta)\nconj_teste <- transform(conj_teste, alta=alta - 1)\nconj_teste$eua <- as.numeric(conj_teste$eua)\nconj_teste <- transform(conj_teste, eua=eua - 1)\nconj_teste$local_prat <- as.numeric(conj_teste$local_prat)\nconj_teste <- transform(conj_teste, local_prat=local_prat - 1)\n\n# Fazendo Previs√µes\nprevisao1 <- predict(gbm.fit.final, \n                     newdata = conj_teste,\n                     n.trees=gbm.fit.final$n.trees,\n                     type = \"response\")\nhead(previsao1)\n\n[1] 0.7636749 0.1247695 0.1744068 0.9893847 0.9904309 0.9449501\n\ngbm.ychapeu <- as.factor(ifelse(previsao1 < 0.5,0,1))\n \nconfusionMatrix(gbm.ychapeu,as.factor(conj_teste$alta), positive=\"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 43  5\n         1  5 28\n                                          \n               Accuracy : 0.8765          \n                 95% CI : (0.7847, 0.9392)\n    No Information Rate : 0.5926          \n    P-Value [Acc > NIR] : 2.162e-08       \n                                          \n                  Kappa : 0.7443          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.8485          \n            Specificity : 0.8958          \n         Pos Pred Value : 0.8485          \n         Neg Pred Value : 0.8958          \n             Prevalence : 0.4074          \n         Detection Rate : 0.3457          \n   Detection Prevalence : 0.4074          \n      Balanced Accuracy : 0.8722          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "semanas/Aula12.html#curva-roc",
    "href": "semanas/Aula12.html#curva-roc",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\np_chapeu_gbm <- previsao1\nroc_gbm <- roc(conj_teste$alta ~ p_chapeu_gbm, plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\n\n\nas.numeric(roc_gbm$auc)\n\n[1] 0.9248737"
  },
  {
    "objectID": "semanas/Aula12A.html",
    "href": "semanas/Aula12A.html",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)"
  },
  {
    "objectID": "semanas/Aula12A.html#dados",
    "href": "semanas/Aula12A.html#dados",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Dados",
    "text": "Dados\nVamos come√ßar a aplicar a metodologia de √°rvores usando √°rvores de classifica√ß√£o para analisar os dados existentes em Carseats. Este conjunto de dados (simulado) √© sobre venda de assentos de crian√ßa para carros. Ele tem 400 observa√ß√µes das seguintes vari√°veis (11), cujos nomes ser√£o convertidos para o portugu√™s:\nSales: vendas em unidades (em mil) em cada local\nCompPrice: pre√ßo cobrado pelo competidor em cada local\nIncome: n√≠vel de renda da comunidade local (em mil US$)\nAdvertising: or√ßamento local de propaganda (em mil US$)\nPopulation: popula√ß√£o na regi√£o (em mil)\nPrice: pre√ßo cobrado pela empresa em cada local\nShelveLoc: um fator com n√≠veis Ruim, Bom e Medio indicando a qualidade da localiza√ß√£o das prateleiras para os assentos em cada lugar\nAge: idade media da popula√ß√£o local\nEducation: n√≠vel de educa√ß√£o em cada local\nUrban: um fator Sim e N√£o indicando se a loja esta em uma √°rea urbana ou rural\nUS: um fator indicando se a loja √© nos EUA ou n√£o\nNeste dados, Sales √© a vari√°vel resposta, s√≥ que ela √© uma vari√°vel cont√≠nua, por este motivo vamos us√°-la para criar uma vari√°vel bin√°ria. Vamos usar a fun√ß√£o ifelse() para criar a vari√°vel bin√°ria, que chamaremos de alta, ela assume os valores Sim se Sales for maior que 8 e assume o valor N√£o caso contr√°rio:\n\ndata(Carseats)\nsummary(Carseats)\n\n     Sales          CompPrice       Income        Advertising    \n Min.   : 0.000   Min.   : 77   Min.   : 21.00   Min.   : 0.000  \n 1st Qu.: 5.390   1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000  \n Median : 7.490   Median :125   Median : 69.00   Median : 5.000  \n Mean   : 7.496   Mean   :125   Mean   : 68.66   Mean   : 6.635  \n 3rd Qu.: 9.320   3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000  \n Max.   :16.270   Max.   :175   Max.   :120.00   Max.   :29.000  \n   Population        Price        ShelveLoc        Age          Education   \n Min.   : 10.0   Min.   : 24.0   Bad   : 96   Min.   :25.00   Min.   :10.0  \n 1st Qu.:139.0   1st Qu.:100.0   Good  : 85   1st Qu.:39.75   1st Qu.:12.0  \n Median :272.0   Median :117.0   Medium:219   Median :54.50   Median :14.0  \n Mean   :264.8   Mean   :115.8                Mean   :53.32   Mean   :13.9  \n 3rd Qu.:398.5   3rd Qu.:131.0                3rd Qu.:66.00   3rd Qu.:16.0  \n Max.   :509.0   Max.   :191.0                Max.   :80.00   Max.   :18.0  \n Urban       US     \n No :118   No :142  \n Yes:282   Yes:258  \n                    \n                    \n                    \n                    \n\nstr(Carseats)\n\n'data.frame':   400 obs. of  11 variables:\n $ Sales      : num  9.5 11.22 10.06 7.4 4.15 ...\n $ CompPrice  : num  138 111 113 117 141 124 115 136 132 132 ...\n $ Income     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ Advertising: num  11 16 10 4 3 13 0 15 0 0 ...\n $ Population : num  276 260 269 466 340 501 45 425 108 131 ...\n $ Price      : num  120 83 80 97 128 72 108 120 124 124 ...\n $ ShelveLoc  : Factor w/ 3 levels \"Bad\",\"Good\",\"Medium\": 1 2 3 3 1 1 3 2 3 3 ...\n $ Age        : num  42 65 59 55 38 78 71 67 76 76 ...\n $ Education  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ Urban      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 2 2 1 1 ...\n $ US         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 1 2 1 2 ..."
  },
  {
    "objectID": "semanas/Aula12A.html#manipulando-os-dados",
    "href": "semanas/Aula12A.html#manipulando-os-dados",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncad_crianca <- Carseats %>% rename(vendas = Sales, \n                                   preco_comp = CompPrice,\n                                   renda = Income,\n                                   propaganda = Advertising,\n                                   populacao = Population,\n                                   preco = Price,\n                                   local_prat = ShelveLoc,\n                                   idade = Age,\n                                   educacao = Education,\n                                   urbano = Urban,\n                                   eua = US)\n\ncad_crianca <- cad_crianca %>% mutate(alta = ifelse(vendas > 8, \"Sim\",\n                                                   \"N√£o\")) %>%\n                              mutate(alta = factor(alta))\n\ncad_crianca<- cad_crianca %>% mutate(local_prat =  case_when(\n                                      local_prat == \"Bad\"  ~ \"Ruim\",\n                                      local_prat == \"Good\" ~ \"Bom\",\n                                      local_prat == \"Medium\" ~ \"Medio\"))%>%                               mutate(local_prat = factor(local_prat))\n\ncad_crianca<- cad_crianca %>% mutate(urbano =  case_when(\n                                      urbano == \"Yes\"  ~ \"Sim\",\n                                      urbano == \"No\" ~ \"N√£o\")) %>%                                       mutate(urbano = factor(urbano))\n\ncad_crianca<- cad_crianca %>% mutate(eua =  case_when(\n                                      eua == \"Yes\"  ~ \"Sim\",\n                                      eua == \"No\" ~ \"N√£o\")) %>%                                          mutate(eua = factor(eua))\n\ncad_crianca<- cad_crianca %>% select(-vendas)\n\nstr(cad_crianca)\n\n'data.frame':   400 obs. of  11 variables:\n $ preco_comp: num  138 111 113 117 141 124 115 136 132 132 ...\n $ renda     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ propaganda: num  11 16 10 4 3 13 0 15 0 0 ...\n $ populacao : num  276 260 269 466 340 501 45 425 108 131 ...\n $ preco     : num  120 83 80 97 128 72 108 120 124 124 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 2 3 3 2 1 2 2 ...\n $ idade     : num  42 65 59 55 38 78 71 67 76 76 ...\n $ educacao  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 2 2 1 2 2 1 1 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 2 1 2 1 2 1 2 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 1 1 2 1 2 1 1 ...\n\nsummary(cad_crianca)\n\n   preco_comp      renda          propaganda       populacao    \n Min.   : 77   Min.   : 21.00   Min.   : 0.000   Min.   : 10.0  \n 1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000   1st Qu.:139.0  \n Median :125   Median : 69.00   Median : 5.000   Median :272.0  \n Mean   :125   Mean   : 68.66   Mean   : 6.635   Mean   :264.8  \n 3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000   3rd Qu.:398.5  \n Max.   :175   Max.   :120.00   Max.   :29.000   Max.   :509.0  \n     preco       local_prat      idade          educacao    urbano     eua     \n Min.   : 24.0   Bom  : 85   Min.   :25.00   Min.   :10.0   N√£o:118   N√£o:142  \n 1st Qu.:100.0   Medio:219   1st Qu.:39.75   1st Qu.:12.0   Sim:282   Sim:258  \n Median :117.0   Ruim : 96   Median :54.50   Median :14.0                      \n Mean   :115.8               Mean   :53.32   Mean   :13.9                      \n 3rd Qu.:131.0               3rd Qu.:66.00   3rd Qu.:16.0                      \n Max.   :191.0               Max.   :80.00   Max.   :18.0                      \n  alta    \n N√£o:236  \n Sim:164"
  },
  {
    "objectID": "semanas/Aula12A.html#treino-e-teste",
    "href": "semanas/Aula12A.html#treino-e-teste",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\ny <- cad_crianca$alta\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- cad_crianca %>% slice(-indice_teste)\nconj_teste <- cad_crianca %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   319 obs. of  11 variables:\n $ preco_comp: num  138 111 113 141 124 136 132 121 117 122 ...\n $ renda     : num  73 48 35 64 113 81 110 78 94 35 ...\n $ propaganda: num  11 16 10 3 13 15 0 9 4 2 ...\n $ populacao : num  276 260 269 340 501 425 108 150 503 393 ...\n $ preco     : num  120 83 80 128 72 120 124 100 94 136 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 3 3 1 2 3 1 2 ...\n $ idade     : num  42 65 59 38 78 67 76 26 50 62 ...\n $ educacao  : num  17 10 12 13 16 10 10 10 13 18 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 2 1 2 1 1 2 2 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n\nprop.table(table(conj_treino$alta))\n\n\n      N√£o       Sim \n0.5893417 0.4106583 \n\nstr(conj_teste)\n\n'data.frame':   81 obs. of  11 variables:\n $ preco_comp: num  117 115 132 115 147 145 114 121 123 103 ...\n $ renda     : num  100 105 113 28 74 119 38 41 42 93 ...\n $ propaganda: num  4 0 0 11 13 16 13 5 11 15 ...\n $ populacao : num  466 45 131 29 251 294 317 412 16 188 ...\n $ preco     : num  97 108 124 86 131 113 128 110 134 103 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 2 2 2 1 1 3 1 2 2 3 ...\n $ idade     : num  55 71 76 53 52 42 50 54 59 74 ...\n $ educacao  : num  14 15 17 18 10 12 16 10 13 16 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 1 2 2 2 2 2 2 2 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 1 2 2 2 2 2 2 2 2 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 1 1 1 2 2 2 2 1 1 1 ...\n\nprop.table(table(conj_teste$alta))\n\n\n      N√£o       Sim \n0.5925926 0.4074074"
  },
  {
    "objectID": "semanas/Aula12A.html#arvore-de-classifica√ß√£o",
    "href": "semanas/Aula12A.html#arvore-de-classifica√ß√£o",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Arvore de Classifica√ß√£o",
    "text": "Arvore de Classifica√ß√£o\nNa biblioteca rpart as arvores de classifica√ß√£o s√£o obtidas usando o m√©todo class. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo s√≥ definimos o menor conjunto de dados numa parti√ß√£o (minsplit) e o parametro de complexidade cp.¬†Posteriormente vamos ampliar este controle. Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande resulta numa arvore muito pequena (underfitting). Nos dois casos se diminui o desempenho do modelo.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(alta ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classifica√ß√£o\n                control=rpart.control(minsplit=30,cp=0.02))"
  },
  {
    "objectID": "semanas/Aula12A.html#desenhando-a-√°rvore-de-uma-forma-mais-clara",
    "href": "semanas/Aula12A.html#desenhando-a-√°rvore-de-uma-forma-mais-clara",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Desenhando a √Årvore de uma forma mais clara",
    "text": "Desenhando a √Årvore de uma forma mais clara\n\nlibrary(rattle)\n\nCarregando pacotes exigidos: bitops\n\n\nRattle: A free graphical interface for data science with R.\nVersion 5.5.1 Copyright (c) 2006-2021 Togaware Pty Ltd.\nType 'rattle()' to shake, rattle, and roll your data.\n\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)\n\n\n\n\n\nset.seed(121)\ny <- cad_crianca$alta\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- cad_crianca %>% slice(-indice_teste)\nconj_teste <- cad_crianca %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   319 obs. of  11 variables:\n $ preco_comp: num  138 113 141 124 115 136 132 121 117 115 ...\n $ renda     : num  73 35 64 113 105 81 113 78 94 28 ...\n $ propaganda: num  11 10 3 13 0 15 0 9 4 11 ...\n $ populacao : num  276 269 340 501 45 425 131 150 503 29 ...\n $ preco     : num  120 80 128 72 108 120 124 100 94 86 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 2 3 3 2 1 2 3 1 1 ...\n $ idade     : num  42 59 38 78 71 67 76 26 50 53 ...\n $ educacao  : num  17 12 13 16 15 10 17 10 13 18 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 2 1 2 2 1 1 2 2 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 1 2 1 2 2 2 2 2 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 1 2 1 2 1 2 2 2 ...\n\nprop.table(table(conj_treino$alta))\n\n\n      N√£o       Sim \n0.5893417 0.4106583 \n\nstr(conj_teste)\n\n'data.frame':   81 obs. of  11 variables:\n $ preco_comp: num  111 117 132 122 125 139 103 125 122 121 ...\n $ renda     : num  48 100 110 35 90 32 74 94 76 90 ...\n $ propaganda: num  16 4 0 2 2 0 0 0 0 0 ...\n $ populacao : num  260 466 108 393 367 176 359 447 270 150 ...\n $ preco     : num  83 97 124 136 131 82 97 89 100 108 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 1 2 2 2 2 1 3 1 1 3 ...\n $ idade     : num  65 55 76 62 35 54 55 30 60 75 ...\n $ educacao  : num  10 14 10 18 18 11 11 12 18 16 ...\n $ urbano    : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 1 2 2 1 2 2 1 2 ...\n $ eua       : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 2 1 1 2 1 2 1 1 1 ...\n $ alta      : Factor w/ 2 levels \"N√£o\",\"Sim\": 2 1 1 1 1 2 1 2 2 1 ...\n\nprop.table(table(conj_teste$alta))\n\n\n      N√£o       Sim \n0.5925926 0.4074074 \n\n\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(alta ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classifica√ß√£o\n                control=rpart.control(minsplit=30,cp=0.02))"
  },
  {
    "objectID": "semanas/Aula12A.html#desenhando-a-√°rvore-de-uma-forma-mais-clara-1",
    "href": "semanas/Aula12A.html#desenhando-a-√°rvore-de-uma-forma-mais-clara-1",
    "title": "Arvores de Classifica√ß√£o - √önica e GBM",
    "section": "Desenhando a √Årvore de uma forma mais clara",
    "text": "Desenhando a √Årvore de uma forma mais clara\n\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)"
  },
  {
    "objectID": "semanas/Aula12B.html",
    "href": "semanas/Aula12B.html",
    "title": "Arvores de Regress√£o",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)\nlibrary(psych)"
  },
  {
    "objectID": "semanas/Aula12B.html#avaliando-selecionando-dados",
    "href": "semanas/Aula12B.html#avaliando-selecionando-dados",
    "title": "Arvores de Regress√£o",
    "section": "Avaliando, selecionando dados",
    "text": "Avaliando, selecionando dados\n\ndata(\"Boston\")\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\ndescribe(Boston)\n\n        vars   n   mean     sd median trimmed    mad    min    max  range  skew\ncrim       1 506   3.61   8.60   0.26    1.68   0.33   0.01  88.98  88.97  5.19\nzn         2 506  11.36  23.32   0.00    5.08   0.00   0.00 100.00 100.00  2.21\nindus      3 506  11.14   6.86   9.69   10.93   9.37   0.46  27.74  27.28  0.29\nchas       4 506   0.07   0.25   0.00    0.00   0.00   0.00   1.00   1.00  3.39\nnox        5 506   0.55   0.12   0.54    0.55   0.13   0.38   0.87   0.49  0.72\nrm         6 506   6.28   0.70   6.21    6.25   0.51   3.56   8.78   5.22  0.40\nage        7 506  68.57  28.15  77.50   71.20  28.98   2.90 100.00  97.10 -0.60\ndis        8 506   3.80   2.11   3.21    3.54   1.91   1.13  12.13  11.00  1.01\nrad        9 506   9.55   8.71   5.00    8.73   2.97   1.00  24.00  23.00  1.00\ntax       10 506 408.24 168.54 330.00  400.04 108.23 187.00 711.00 524.00  0.67\nptratio   11 506  18.46   2.16  19.05   18.66   1.70  12.60  22.00   9.40 -0.80\nblack     12 506 356.67  91.29 391.44  383.17   8.09   0.32 396.90 396.58 -2.87\nlstat     13 506  12.65   7.14  11.36   11.90   7.11   1.73  37.97  36.24  0.90\nmedv      14 506  22.53   9.20  21.20   21.56   5.93   5.00  50.00  45.00  1.10\n        kurtosis   se\ncrim       36.60 0.38\nzn          3.95 1.04\nindus      -1.24 0.30\nchas        9.48 0.01\nnox        -0.09 0.01\nrm          1.84 0.03\nage        -0.98 1.25\ndis         0.46 0.09\nrad        -0.88 0.39\ntax        -1.15 7.49\nptratio    -0.30 0.10\nblack       7.10 4.06\nlstat       0.46 0.32\nmedv        1.45 0.41\n\ndados <- Boston \nextrato <- dados %>% select(medv, nox, rm)  \nsummary(extrato)\n\n      medv            nox               rm       \n Min.   : 5.00   Min.   :0.3850   Min.   :3.561  \n 1st Qu.:17.02   1st Qu.:0.4490   1st Qu.:5.886  \n Median :21.20   Median :0.5380   Median :6.208  \n Mean   :22.53   Mean   :0.5547   Mean   :6.285  \n 3rd Qu.:25.00   3rd Qu.:0.6240   3rd Qu.:6.623  \n Max.   :50.00   Max.   :0.8710   Max.   :8.780  \n\nboxplot(extrato$medv)"
  },
  {
    "objectID": "semanas/Aula12B.html#visualizando-os-dados",
    "href": "semanas/Aula12B.html#visualizando-os-dados",
    "title": "Arvores de Regress√£o",
    "section": "Visualizando os dados",
    "text": "Visualizando os dados\n\n## Distribui√ß√£o de dados na maior parte sim√©trica com valores na cauda direta \n## maior do que o esperado para uam distribui√ß√£o sim√©trica\nggplot(extrato, aes(x=medv)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(extrato)),0))\n\n\n\n## Grafico de dispers√£o nox vs rm \nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point()"
  },
  {
    "objectID": "semanas/Aula12B.html#arvore-de-regress√£o",
    "href": "semanas/Aula12B.html#arvore-de-regress√£o",
    "title": "Arvores de Regress√£o",
    "section": "Arvore de Regress√£o",
    "text": "Arvore de Regress√£o\nNa biblioteca rpart as arvores de regress√£o s√£o obtidas usando o m√©todo anova. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo s√≥ definimos o menor conjunto de dados numa parti√ß√£o (minsplit) e o parametro de complexidade cp.¬†Posteriormente vamos ampliar este controle.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvreg <- rpart(medv ~ ., \n                data=extrato,\n                method=\"anova\", #para arvore de regress√£o\n                control=rpart.control(minsplit=30,cp=0.06))\nplot(arvreg)\ntext(arvreg,pretty=0)"
  },
  {
    "objectID": "semanas/Aula12B.html#segmentos",
    "href": "semanas/Aula12B.html#segmentos",
    "title": "Arvores de Regress√£o",
    "section": "Segmentos",
    "text": "Segmentos\nA partir da √°rvore obtida no item anterior podemos fazer uma representa√ß√£o gr√°fica das parti√ß√µes obtidas.\n\nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point() +\n  geom_segment(aes(x = 0, y = 0.6695, xend = 6.941, yend = 0.6695), \n               linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 6.941, linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 7.437, linetype=\"dashed\", color=\"red\", size=1) \n\n\n\n  # scale_y_continuous(limits = c(0.3, 1)) +"
  },
  {
    "objectID": "semanas/Aula12B.html#treino-e-teste-com-todas-as-vari√°veis",
    "href": "semanas/Aula12B.html#treino-e-teste-com-todas-as-vari√°veis",
    "title": "Arvores de Regress√£o",
    "section": "Treino e Teste com todas as vari√°veis",
    "text": "Treino e Teste com todas as vari√°veis\nAgora vamos trabalhar com o conjunto completo criando um conjunto de treino e teste.\n\n## Vamos criar os conjuntos de treino teste e desenvolver a arvore \n## com todas as vari√°veis.\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\nindice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)\nconj_treino <- dados[indice,]\nconj_teste <- dados[-indice,]\nhead(conj_treino)\n\n     crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18.0  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n3 0.02729  0.0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0.0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0.0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0.0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n7 0.08829 12.5  7.87    0 0.524 6.012 66.6 5.5605   5 311    15.2 395.60 12.43\n  medv\n1 24.0\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n7 22.9\n\nhead(conj_teste)\n\n      crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n2  0.02731  0.0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n10 0.17004 12.5  7.87    0 0.524 6.004 85.9 6.5921   5 311    15.2 386.71 17.10\n12 0.11747 12.5  7.87    0 0.524 6.009 82.9 6.2267   5 311    15.2 396.90 13.27\n16 0.62739  0.0  8.14    0 0.538 5.834 56.5 4.4986   4 307    21.0 395.62  8.47\n19 0.80271  0.0  8.14    0 0.538 5.456 36.6 3.7965   4 307    21.0 288.99 11.69\n23 1.23247  0.0  8.14    0 0.538 6.142 91.7 3.9769   4 307    21.0 396.90 18.72\n   medv\n2  21.6\n10 18.9\n12 18.9\n16 19.9\n19 20.2\n23 15.2"
  },
  {
    "objectID": "semanas/Aula12B.html#arvore-de-regress√£o-treino",
    "href": "semanas/Aula12B.html#arvore-de-regress√£o-treino",
    "title": "Arvores de Regress√£o",
    "section": "Arvore de Regress√£o Treino",
    "text": "Arvore de Regress√£o Treino\n\n## A fun√ß√£o rpart tem diversos parametros aqui foi configurado um deles\n# cp o parametro de complexidade\n# Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande \n# resulta numa arvore muito pequena (underfitting).\n# Nos dois casos se diminui o desempenho do modelo.\narvreg1 <- rpart(medv ~ ., \n                data=conj_treino,\n                method=\"anova\", #para arvore de regerss√£o\n                control=rpart.control(minsplit=30,cp=0.01))\n\narvreg1\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=9.65 10   467.4640 23.84000 *\n      13) lstat< 9.65 39   889.2800 32.90000 *\n     7) rm>=7.435 21   960.7895 45.23810 *"
  },
  {
    "objectID": "semanas/Aula12B.html#erros-a-partir-do-conjunto-de-treino",
    "href": "semanas/Aula12B.html#erros-a-partir-do-conjunto-de-treino",
    "title": "Arvores de Regress√£o",
    "section": "Erros a partir do conjunto de treino",
    "text": "Erros a partir do conjunto de treino\n\nO erro relativo (Rel error) √© obtido atrav√©s de 1 - R2\nO xerror √© obtido atrav√©s da valida√ß√£o cruzdada (10 fold)\nO xtsd √© o desvio padr√£o dos valores obtidos na valida√ß√£o cruzada.\n\n\n## Mostra 2 gr√°ficos:\n# 1) Varia√ß√£o do R2 aparente e relativo vs n√∫mero de parti√ß√µes\n# 2) Erro Relativo vs n√∫mero de parti√ß√µes\nrsq.rpart(arvreg1)\n\n\nRegression tree:\nrpart(formula = medv ~ ., data = conj_treino, method = \"anova\", \n    control = rpart.control(minsplit = 30, cp = 0.01))\n\nVariables actually used in tree construction:\n[1] crim  lstat rm   \n\nRoot node error: 31197/381 = 81.882\n\nn= 381 \n\n        CP nsplit rel error  xerror     xstd\n1 0.461731      0   1.00000 1.01028 0.096645\n2 0.161924      1   0.53827 0.65330 0.065046\n3 0.094840      2   0.37634 0.49315 0.059728\n4 0.034308      3   0.28151 0.37245 0.050769\n5 0.028069      4   0.24720 0.34074 0.051145\n6 0.020942      5   0.21913 0.29254 0.042692\n7 0.010000      6   0.19819 0.28562 0.042529\n\n\n\n\n\n\n\n## Mostra a varia√ß√£o do Erro relativo vs cp(parametro de complexidade)\nplotcp(arvreg1)"
  },
  {
    "objectID": "semanas/Aula12B.html#gr√°fico-de-importancia-das-vari√°veis",
    "href": "semanas/Aula12B.html#gr√°fico-de-importancia-das-vari√°veis",
    "title": "Arvores de Regress√£o",
    "section": "Gr√°fico de importancia das vari√°veis",
    "text": "Gr√°fico de importancia das vari√°veis\nA importancia das vari√°veis √© calculada com base nos resultados das melhores parti√ß√µes\n\n# Gr√°fico de Import√¢ncia de vari√°vel\nvar_imp <- arvreg1$variable.importance\nnomes_var <- names(var_imp)\nvar_impdf <- data.frame(Importancia=unname(var_imp), Variavel=nomes_var) %>%\n                        arrange(Importancia)\nvar_impdf$Variavel <- factor(var_impdf$Variavel, levels=var_impdf$Variavel)\nggplot(var_impdf, aes(x=Variavel, y=Importancia)) + \n         geom_col() + \n        coord_flip()"
  },
  {
    "objectID": "semanas/Aula12B.html#mostrando-a-√°rvore-e-gerando-previs√µes",
    "href": "semanas/Aula12B.html#mostrando-a-√°rvore-e-gerando-previs√µes",
    "title": "Arvores de Regress√£o",
    "section": "Mostrando a √°rvore e gerando previs√µes",
    "text": "Mostrando a √°rvore e gerando previs√µes\n\n# Mostrando a arvore\npar(xpd = NA)\nplot(arvreg1)\ntext(arvreg1,pretty=0)\n\n\n\n# Fazendo Previs√µes\nprevisao1 <- arvreg1 %>% predict(conj_teste)\nhead(previsao1)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previs√£o\nRMSE(previsao1, conj_teste$medv)\n\n[1] 5.303593"
  },
  {
    "objectID": "semanas/Aula12B.html#arvore-de-regress√£o-com-caret",
    "href": "semanas/Aula12B.html#arvore-de-regress√£o-com-caret",
    "title": "Arvores de Regress√£o",
    "section": "Arvore de Regress√£o com caret",
    "text": "Arvore de Regress√£o com caret\nAqui vamos usar a biblioteca caret que tem umas facilidades para otimiza√ß√£o do cp e apresenta√ß√£o dos resultados\n\nset.seed(21)\n## Otimizamos o valor de cp usando um 10-fold cv\n# O parametro tuneLength diz para o algoritmo escolher diferentes valores para cp\n# O parametro tuneGrid permite decidir que valores cp deve assumir enquanto que o\n# tuneLength somente limita o n√∫mero default de parametros que se usa.\narvreg2 <- train(medv ~ . , data = conj_treino, method = \"rpart\",\n                 trControl = trainControl(\"cv\", number = 10),\n                 tuneGrid = data.frame(cp = seq(0.01,0.10, length.out=100)) \n                 )\n# Mostra a acur√°cia vs cp (parametro de complexidade)\nplot(arvreg2)\n\n\n\n## Indica o melhor valor de cp\narvreg2$bestTune\n\n          cp\n4 0.01272727"
  },
  {
    "objectID": "semanas/Aula12B.html#desenhando-a-√°rvore",
    "href": "semanas/Aula12B.html#desenhando-a-√°rvore",
    "title": "Arvores de Regress√£o",
    "section": "Desenhando a √Årvore",
    "text": "Desenhando a √Årvore\n\n## Apresenta o modelo final de arvore ajustado\npar(xpd = NA)\nplot(arvreg2$finalModel)\ntext(arvreg2$finalModel,  digits = 3)\n\n\n\n## usando o rpart.plot\nlibrary(rpart.plot)\nrpart.plot(arvreg2$finalModel)"
  },
  {
    "objectID": "semanas/Aula12B.html#previs√µes",
    "href": "semanas/Aula12B.html#previs√µes",
    "title": "Arvores de Regress√£o",
    "section": "Previs√µes",
    "text": "Previs√µes\n\n# Regras de Decis√£o\narvreg2$finalModel\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=11.315 7   367.8886 21.88571 *\n      13) lstat< 11.315 42   956.1507 32.57857 *\n     7) rm>=7.435 21   960.7895 45.23810 *\n\n# Fazendo Previs√µes\nprevisao2 <- arvreg2 %>% predict(conj_teste)\nhead(previsao2)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previs√£o\nRMSE(previsao2, conj_teste$medv)\n\n[1] 5.304604"
  },
  {
    "objectID": "semanas/Aula12B.html#vamos-comparar-com-regress√£o-multipla",
    "href": "semanas/Aula12B.html#vamos-comparar-com-regress√£o-multipla",
    "title": "Arvores de Regress√£o",
    "section": "Vamos comparar com Regress√£o Multipla",
    "text": "Vamos comparar com Regress√£o Multipla\n\nlibrary(leaps)\n## Cria uma fun√ß√£o de predi√ß√£o para o leaps\npredict.regsubsets <- function(object,newdata,id,...){\n  form <- as.formula(object$call[[2]])\n  mat <- model.matrix(form,newdata)\n  coefi <- coef(object,id=id)\n  mat[,names(coefi)]%*%coefi\n}\nset.seed(21)\nenvelopes <- sample(rep(1:5,length=nrow(conj_treino)))\ntable(envelopes)\n\nenvelopes\n 1  2  3  4  5 \n77 76 76 76 76 \n\nerro_cv <- matrix(NA,5,13)\nfor(k in 1:5){\n  melh_ajus <- regsubsets(medv ~ ., data=conj_treino[envelopes!=k,], \n                          nvmax=13,method=\"forward\")\n  for(i in 1:13){\n    prev <- predict(melh_ajus, conj_treino[envelopes==k,],id=i)\n    erro_cv[k,i] <- mean( (conj_treino$medv[envelopes==k]-prev)^2)\n  }\n}\nrmse_cv <- sqrt(apply(erro_cv,2,mean))  # Erro medio quadratico de cada modelo\nplot(rmse_cv,pch=19,type=\"b\")"
  },
  {
    "objectID": "semanas/Aula12B.html#obtem-a-f√≥rmula-do-modelo",
    "href": "semanas/Aula12B.html#obtem-a-f√≥rmula-do-modelo",
    "title": "Arvores de Regress√£o",
    "section": "Obtem a f√≥rmula do modelo",
    "text": "Obtem a f√≥rmula do modelo\n\ncoef(melh_ajus, 11)\n\n  (Intercept)          crim            zn          chas           nox \n 37.051974686  -0.144753575   0.047778839   1.780110617 -14.931943579 \n           rm           dis           rad           tax       ptratio \n  3.815637016  -1.500993904   0.349882023  -0.015845438  -0.986230946 \n        black         lstat \n  0.009024705  -0.534163142"
  },
  {
    "objectID": "semanas/Aula12B.html#teste-com-o-conjunto-de-teste",
    "href": "semanas/Aula12B.html#teste-com-o-conjunto-de-teste",
    "title": "Arvores de Regress√£o",
    "section": "Teste com o conjunto de teste",
    "text": "Teste com o conjunto de teste\n\nprevisao3 <- predict(melh_ajus, conj_teste, 11) \nRMSE(previsao3, conj_teste$medv)\n\n[1] 5.936577"
  },
  {
    "objectID": "visao-do-curso.html",
    "href": "visao-do-curso.html",
    "title": "Minera√ß√£o de Dados",
    "section": "",
    "text": "Introdu√ß√£o a minera√ß√£o de dados\nVisualiza√ß√£o e prepara√ß√£o de Dados\nRegress√£o linear e sele√ß√£o de modelos\nM√©todos de Reamostragem\nM√©todos de encolhimento (Ridge e Lasso)\nClassifica√ß√£o (KNN, Regress√£o Log√≠stica, LDA e QDA)\nM√©todos baseados em √°rvores"
  }
]