[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre",
    "section": "",
    "text": "Esta é a página principal do site da disciplina Mineração de Dados IME05-12547.\nEste site foi construído usando Quarto e foi baseado em diversas fontes de informação obtidas na internet.\nSeguem algumas referências úteis para o Quarto:\nQuarto\nCurso da Duke University\nComo criar um blog com o Quarto\nWebnar do Quarto"
  },
  {
    "objectID": "acesso-rstudio.html",
    "href": "acesso-rstudio.html",
    "title": "RStudio Cloud",
    "section": "",
    "text": "RStudio"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IME05-12547 Mineração de Dados",
    "section": "",
    "text": "Aqui vocês vão encontrar alguns dos exemplos apresentados em aula, com uso do R. O objetivo é mostrar as possibilidades de aplicação do R nesta disciplina.\nOs códigos apresentados em aula serão colocado por aqui também.\n[📖] Aula 01\n[📖] Aula01A\n[📖] Aula02\n[📖] Aula03\n[📖] Aula04\n[📖] Aula05\n[📖] Aula06\n[📖] Aula7.1\n[📖] Aula7.2\n[📖] Aula7.3\n[📖] Aula7.4\n[📖] Aula08\n[📖] Aula09\n[📖] Aula09A\n[📖] Aula10\n[📖] Aula11\n[📖] Aula12"
  },
  {
    "objectID": "semanas/Aula01.html#lendo-dados-de-arquivos-csv",
    "href": "semanas/Aula01.html#lendo-dados-de-arquivos-csv",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de arquivos csv",
    "text": "Lendo dados de arquivos csv\n\nlibrary(readr)\nurl <- \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-acervo-de-dados-tecnicos/tabela-pocos.csv\"\n## O read_delim permite que seja definido o tipo de delimitador dos dados\npocos <- read_delim(url, delim = \";\", locale= locale(decimal_mark = \",\"), col_names = TRUE)\n\nRows: 30255 Columns: 60\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (51): POCO, CADASTRO, OPERADOR, POCO_OPERADOR, ESTADO, BACIA, BLOCO, SIG...\ndbl  (8): LATITUDE_BASE_DD, LONGITUDE_BASE_DD, PROFUNDIDADE_VERTICAL_M, PROF...\nlgl  (1): UNIDADE_ESTRATIGRAFICA\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(pocos)\n\n# A tibble: 6 × 60\n  POCO  CADAS…¹ OPERA…² POCO_…³ ESTADO BACIA BLOCO SIG_C…⁴ CAMPO TERRA…⁵ POCO_…⁶\n  <chr> <chr>   <chr>   <chr>   <chr>  <chr> <chr> <chr>   <chr> <chr>   <chr>  \n1 7-PC… 721000… 3R Mac… 7PC  0… RN     Poti… PC    \"PC   \" PORT… T       N      \n2 7-CO… 742810… Petrob… 7CO  0… RJ     Camp… CO    \"CO   \" CORV… M       N      \n3 7-BA… 202400… Petrob… 7BA  0… BA     Recô… BA    \"BA   \" BURA… T       N      \n4 7-ET… 721000… Petrob… 7ET  0… RN     Poti… ET    \"ET   \" ESTR… T       N      \n5 4-FS… 342700… Petrob… 4FSL 0… ES     Espí… FSL   \"FSL  \" FAZE… T       N      \n6 7-CA… 721000… Petrob… 7CAM 0… RN     Poti… CAM   \"CAM  \" CANT… T       N      \n# … with 49 more variables: TIPO <chr>, CATEGORIA <chr>, RECLASSIFICACAO <chr>,\n#   SITUACAO <chr>, INICIO <chr>, TERMINO <chr>, CONCLUSAO <chr>,\n#   TITULARIDADE <chr>, LATITUDE_BASE_4C <chr>, LONGITUDE_BASE_4C <chr>,\n#   LATITUDE_BASE_DD <dbl>, LONGITUDE_BASE_DD <dbl>, DATUM_HORIZONTAL <chr>,\n#   TIPO_DE_COORDENADA_DE_BASE <chr>, DIRECAO <chr>,\n#   PROFUNDIDADE_VERTICAL_M <dbl>, PROFUNDIDADE_SONDADOR_M <dbl>,\n#   PROFUNDIDADE_MEDIDA_M <dbl>, REFERENCIA_DE_PROFUNDIDADE <chr>, …\n# ℹ Use `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula01.html#bibliotecas",
    "href": "semanas/Aula01.html#bibliotecas",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Bibliotecas",
    "text": "Bibliotecas\nVamos carregar as bibliotecas que serão usadas na manipulação e visualização de dados.\nO pacote tidyverse carrega diversos pacotes muito uteis na manipulação e visualização de dados\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ dplyr   1.0.9\n✔ tibble  3.1.8     ✔ stringr 1.4.0\n✔ tidyr   1.2.0     ✔ forcats 0.5.1\n✔ purrr   0.3.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nVamos primeiro conhecer o que tem na base de dados pocos. A base de dados possui 30255 linhas\n\nclass(pocos)  # Tipo de base de dados\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nsummary(pocos) # Sumario da base de dados\n\n     POCO             CADASTRO           OPERADOR         POCO_OPERADOR     \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    ESTADO             BACIA              BLOCO            SIG_CAMPO        \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    CAMPO            TERRA_MAR         POCO_POS_ANP           TIPO          \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  CATEGORIA         RECLASSIFICACAO      SITUACAO            INICIO         \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   TERMINO           CONCLUSAO         TITULARIDADE       LATITUDE_BASE_4C  \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n LONGITUDE_BASE_4C  LATITUDE_BASE_DD  LONGITUDE_BASE_DD DATUM_HORIZONTAL  \n Length:30255       Min.   :-32.927   Min.   :-73.38    Length:30255      \n Class :character   1st Qu.:-12.691   1st Qu.:-39.61    Class :character  \n Mode  :character   Median :-10.710   Median :-37.83    Mode  :character  \n                    Mean   :-11.480   Mean   :-38.83                      \n                    3rd Qu.: -5.327   3rd Qu.:-36.98                      \n                    Max.   :  4.528   Max.   :-34.83                      \n                                                                          \n TIPO_DE_COORDENADA_DE_BASE   DIRECAO          PROFUNDIDADE_VERTICAL_M\n Length:30255               Length:30255       Min.   :-62550.0       \n Class :character           Class :character   1st Qu.:  -772.4       \n Mode  :character           Mode  :character   Median :     0.0       \n                                               Mean   :  -254.4       \n                                               3rd Qu.:   138.0       \n                                               Max.   :528084.0       \n                                               NA's   :19336          \n PROFUNDIDADE_SONDADOR_M PROFUNDIDADE_MEDIDA_M REFERENCIA_DE_PROFUNDIDADE\n Min.   :    0           Min.   :    0.0       Length:30255              \n 1st Qu.:  485           1st Qu.:  347.5       Class :character          \n Median :  999           Median :  870.2       Mode  :character          \n Mean   : 1507           Mean   : 1583.9                                 \n 3rd Qu.: 2230           3rd Qu.: 2644.0                                 \n Max.   :62750           Max.   :62800.0                                 \n NA's   :1043            NA's   :17787                                   \n MESA_ROTATIVA     COTA_ALTIMETRICA_M LAMINA_D_AGUA_M   DATUM_VERTICAL    \n Min.   :   0.00   Min.   :    0.00   Min.   :    0.0   Length:30255      \n 1st Qu.:  19.00   1st Qu.:    0.00   1st Qu.:    0.0   Class :character  \n Median :  32.40   Median :   12.30   Median :    0.0   Mode  :character  \n Mean   :  57.34   Mean   :   41.00   Mean   :  284.2                     \n 3rd Qu.:  75.68   3rd Qu.:   56.99   3rd Qu.:  116.0                     \n Max.   :2220.00   Max.   :30940.00   Max.   :30940.0                     \n                   NA's   :17225      NA's   :14761                       \n UNIDADE_ESTRATIGRAFICA GEOLOGIA_GRUPO_FINAL GEOLOGIA_FORMACAO_FINAL\n Mode:logical           Length:30255         Length:30255           \n NA's:30255             Class :character     Class :character       \n                        Mode  :character     Mode  :character       \n                                                                    \n                                                                    \n                                                                    \n                                                                    \n GEOLOGIA_MEMBRO_FINAL     CDPE               AGP                 PC           \n Length:30255          Length:30255       Length:30255       Length:30255      \n Class :character      Class :character   Class :character   Class :character  \n Mode  :character      Mode  :character   Mode  :character   Mode  :character  \n                                                                               \n                                                                               \n                                                                               \n                                                                               \n     PAG            PERFIS_CONVENCIONAIS DURANTE_PERFURACAO PERFIS_DIGITAIS   \n Length:30255       Length:30255         Length:30255       Length:30255      \n Class :character   Class :character     Class :character   Class :character  \n Mode  :character   Mode  :character     Mode  :character   Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n PERFIS_PROCESSADOS PERFIS_ESPECIAIS   AMOSTRA_LATERAL      SISMICA         \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n TABELA_TEMPO_PROFUNDIDADE DADOS_DIRECIONAIS  TESTE_A_CABO      \n Length:30255              Length:30255       Length:30255      \n Class :character          Class :character   Class :character  \n Mode  :character          Mode  :character   Mode  :character  \n                                                                \n                                                                \n                                                                \n                                                                \n TESTE_DE_FORMACAO   CANHONEIO          TESTEMUNHO         GEOQUIMICA       \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  SIG_SONDA          NOM_SONDA         DHA_ATUALIZACAO    ATINGIU_PRESAL    \n Length:30255       Length:30255       Length:30255       Length:30255      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "semanas/Aula01.html#dados-de-poços",
    "href": "semanas/Aula01.html#dados-de-poços",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Dados de poços",
    "text": "Dados de poços\nOs dados da tabela poços tem 60 colunas.\nVamos inicialmente selecionar algumas colunas para podermos trabalhar com os dados.\nAs colunas que vamos trabalhar são:\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\nPara selecionar colunas usamos a função select\n\n## Vamos selecionar as colunas listadas acima\npocos_01 <- pocos %>% select(POCO,OPERADOR,ESTADO,BACIA,BLOCO, CAMPO,TERRA_MAR,CATEGORIA,SITUACAO, INICIO, TERMINO, PROFUNDIDADE_MEDIDA_M)\nhead(pocos_01)\n\n# A tibble: 6 × 12\n  POCO   OPERA…¹ ESTADO BACIA BLOCO CAMPO TERRA…² CATEG…³ SITUA…⁴ INICIO TERMINO\n  <chr>  <chr>   <chr>  <chr> <chr> <chr> <chr>   <chr>   <chr>   <chr>  <chr>  \n1 7-PC-… 3R Mac… RN     Poti… PC    PORT… T       Desenv… ARRASA… 25/08… 27/08/…\n2 7-CO-… Petrob… RJ     Camp… CO    CORV… M       Desenv… ABANDO… 26/08… 11/10/…\n3 7-BA-… Petrob… BA     Recô… BA    BURA… T       Desenv… ABANDO… 28/08… 06/09/…\n4 7-ET-… Petrob… RN     Poti… ET    ESTR… T       Desenv… PRODUZ… 30/05… 31/05/…\n5 4-FSL… Petrob… ES     Espí… FSL   FAZE… T       Pionei… ABANDO… 31/05… 30/06/…\n6 7-CAM… Petrob… RN     Poti… CAM   CANT… T       Desenv… INJETA… 01/06… 04/06/…\n# … with 1 more variable: PROFUNDIDADE_MEDIDA_M <dbl>, and abbreviated variable\n#   names ¹​OPERADOR, ²​TERRA_MAR, ³​CATEGORIA, ⁴​SITUACAO\n# ℹ Use `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula01.html#manipulação-de-dados",
    "href": "semanas/Aula01.html#manipulação-de-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Manipulação de dados",
    "text": "Manipulação de dados\nVamos eliminar as linhas de dados que apresenta dados ausentes “NA” nas colunas TERMINO e PROFUNDIDADE_MEDIDA_M.\n\nsum(is.na(pocos_01))\n\n[1] 30235\n\nsum(is.na(pocos_01$INICIO))\n\n[1] 0\n\nsum(is.na(pocos_01$TERMINO))\n\n[1] 1861\n\nsum(is.na(pocos_01$PROFUNDIDADE_MEDIDA_M))\n\n[1] 17787\n\npocos_01 <- pocos_01 %>% drop_na(any_of(c(\"TERMINO\",\n                                          \"PROFUNDIDADE_MEDIDA_M\")))\n# melhorando a visualização dos dados\nknitr::kable(\n  head(pocos_01, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_01.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_01.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n1-MOR-1-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nPioneiro\nFECHADO\n12/06/1994 00:00\n28/06/1994 00:00\n0.0\n\n\n7-REP-28-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nDesenvolvimento\nINJETANDO\n12/04/1995 00:00\n18/04/1995 00:00\n0.0\n\n\n7-ET-647-RN\nPetrobras\nRN\nPotiguar\nET\nESTREITO\nT\nDesenvolvimento\nINJETANDO\n16/04/1995 00:00\n18/04/1995 00:00\n277.2\n\n\n7-MRL-54-RJS\nPetrobras\nRJ\nCampos\nMRL\nMARLIM\nM\nDesenvolvimento\nFECHADO\n30/05/1996 00:00\n13/06/1996 00:00\n0.0\n\n\n7-BVS-13-RN\nPetrobras\nRN\nPotiguar\nBEN\nBENFICA\nT\nDesenvolvimento\nFECHADO\n06/06/1996 00:00\n15/06/1996 00:00\n0.0\n\n\n9-LUC-31D-AM\nPetrobras\nAM\nSolimões\nLUC\nLESTE DO URUCU\nT\nEspecial\nABANDONADO PERMANENTEMENTE\n10/06/1996 00:00\n15/08/1996 00:00\n0.0\n\n\n1-RJS-500-RJS\nPetrobras\nRJ\nCampos\nESP\nESPADARTE\nM\nPioneiro\nABANDONADO PERMANENTEMENTE\n10/06/1996 00:00\n19/07/1996 00:00\n0.0\n\n\n8-MRL-36D-RJS\nPetrobras\nRJ\nCampos\nMRL\nMARLIM\nM\nInjeção\nFECHADO\n27/10/1993 00:00\n15/11/1993 00:00\n0.0\n\n\n3-ESP-2-RJS\nPetrobras\nRJ\nCampos\nESP\nESPADARTE\nM\nExtensão\nABANDONADO PERMANENTEMENTE\n09/05/1995 00:00\n19/06/1995 00:00\n0.0\n\n\n8-AB-49D-RJS\nPetrobras\nRJ\nCampos\nAB\nALBACORA\nM\nInjeção\nFECHADO\n15/04/1996 00:00\n30/07/1996 00:00\n0.0\n\n\n\n\nsum(is.na(pocos_01))\n\n[1] 4328\n\n\nVeja que existia um grande número de dados ausentes\nAntes: 30255 linhas Depois: 10715 linhas"
  },
  {
    "objectID": "semanas/Aula01.html#corrigindo-tipo-de-dados",
    "href": "semanas/Aula01.html#corrigindo-tipo-de-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Corrigindo tipo de dados",
    "text": "Corrigindo tipo de dados\nAs colunas INICIO e TERMINO são datas, mas foram lidas como caracter, vamos corrigir isto!\nPara trabalhar com datas vamos usar o pacote lubridate\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\npocos_01$INICIO <- as_date(pocos_01$INICIO, format=\"%d/%m/%Y\")\npocos_01$TERMINO <- as_date(pocos_01$TERMINO, format=\"%d/%m/%Y\")"
  },
  {
    "objectID": "semanas/Aula01.html#filtrando-dados",
    "href": "semanas/Aula01.html#filtrando-dados",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Filtrando dados",
    "text": "Filtrando dados\nVamos analisar os poços de uma detreminada região, para isto podemos fltrar os poços de um bloco. Vamos filtrar somente os poços do CAMPO PEREGRINO usando a função filter.\n\npocos_02 <- pocos_01 %>% filter(CAMPO==\"PEREGRINO\") ##  \nsummary(pocos_02)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:94          Length:94          Length:94          Length:94         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:94          Length:94          Length:94          Length:94         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:94          Min.   :1994-07-07   Min.   :1994-08-17  \n Class :character   1st Qu.:2011-12-16   1st Qu.:2012-01-27  \n Mode  :character   Median :2013-07-02   Median :2013-08-31  \n                    Mean   :2013-11-27   Mean   :2013-12-27  \n                    3rd Qu.:2015-10-06   3rd Qu.:2015-10-29  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M\n Min.   :   0         \n 1st Qu.:4457         \n Median :4925         \n Mean   :5136         \n 3rd Qu.:6213         \n Max.   :8613         \n\nknitr::kable(\n  head(pocos_02, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_02.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_02.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n1-RJS-498-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nPioneiro\nABANDONADO PERMANENTEMENTE\n1994-07-07\n1994-08-17\n0.00\n\n\n7-PRG-2HB-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2011-01-16\n2011-02-03\n4676.00\n\n\n7-PRG-64HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2018-11-11\n2018-12-05\n5790.00\n\n\n7-PRG-65HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2019-01-05\n2019-01-20\n4386.00\n\n\n7-PRG-73HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2022-02-25\n2022-03-09\n5694.00\n\n\n8-PRG-68H-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nInjeção\nEM AVALIAÇÃO\n2019-08-16\n2019-09-12\n4133.00\n\n\n7-PRG-66HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2019-02-11\n2019-03-07\n6529.00\n\n\n7-PRG-71HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2020-12-08\n2020-12-11\n3646.00\n\n\n7-PRG-71HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2020-12-18\n2020-01-06\n5404.00\n\n\n7-PRG-40HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2014-07-27\n2014-08-03\n4797.74\n\n\n\n\n\n\nAvaliando os dados\nOs poços possuem diversas categorias, vamos ver que categorias existem nestes poços do bloco BES-100.\n\nunique(pocos_02$CATEGORIA)\n\n[1] \"Pioneiro\"        \"Desenvolvimento\" \"Injeção\"         \"Especial\"       \n[5] \"Extensão\"       \n\n\n\n\nFiltrando poços de desenvolvimento\n\npocos_03 <- pocos_02 %>% filter(CATEGORIA==\"Desenvolvimento\") ##  \nsummary(pocos_03)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:73          Min.   :2010-11-10   Min.   :2010-11-11  \n Class :character   1st Qu.:2012-02-04   1st Qu.:2012-04-06  \n Mode  :character   Median :2013-10-20   Median :2013-11-15  \n                    Mean   :2014-07-23   Mean   :2014-08-21  \n                    3rd Qu.:2016-06-23   3rd Qu.:2016-08-27  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M\n Min.   : 742         \n 1st Qu.:4543         \n Median :5066         \n Mean   :5385         \n 3rd Qu.:6383         \n Max.   :8613         \n\nknitr::kable(\n  head(pocos_03, 10), booktabs = TRUE,\n  caption = 'Uma tabela mais elegante com as 10 primeras linhas de pocos_03.')\n\n\nUma tabela mais elegante com as 10 primeras linhas de pocos_03.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOCO\nOPERADOR\nESTADO\nBACIA\nBLOCO\nCAMPO\nTERRA_MAR\nCATEGORIA\nSITUACAO\nINICIO\nTERMINO\nPROFUNDIDADE_MEDIDA_M\n\n\n\n\n7-PRG-2HB-RJS\nEquinor Brasil\nRJ\nCampos\nBM-C-7\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2011-01-16\n2011-02-03\n4676.00\n\n\n7-PRG-64HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2018-11-11\n2018-12-05\n5790.00\n\n\n7-PRG-65HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2019-01-05\n2019-01-20\n4386.00\n\n\n7-PRG-73HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2022-02-25\n2022-03-09\n5694.00\n\n\n7-PRG-66HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2019-02-11\n2019-03-07\n6529.00\n\n\n7-PRG-71HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2020-12-08\n2020-12-11\n3646.00\n\n\n7-PRG-71HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2020-12-18\n2020-01-06\n5404.00\n\n\n7-PRG-40HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2014-07-27\n2014-08-03\n4797.74\n\n\n7-PRG-8HPA-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nABANDONADO PERMANENTEMENTE\n2011-11-07\n2011-12-02\n4959.87\n\n\n7-PRG-72HP-RJS\nEquinor Brasil\nRJ\nCampos\nNA\nPEREGRINO\nM\nDesenvolvimento\nFECHADO\n2021-11-17\n2021-12-08\n5302.00"
  },
  {
    "objectID": "semanas/Aula01.html#criando-uma-coluna-com-mutate",
    "href": "semanas/Aula01.html#criando-uma-coluna-com-mutate",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Criando uma coluna com mutate",
    "text": "Criando uma coluna com mutate\nVamos criar uma coluna que nos dará a duração da perfuração dos poços.\n\npocos_03$INICIO[1]\n\n[1] \"2011-01-16\"\n\npocos_03$TERMINO[1]\n\n[1] \"2011-02-03\"\n\npocos_03$TERMINO[1] - pocos_03$INICIO[1]\n\nTime difference of 18 days\n\ndifftime(pocos_03$TERMINO[1], pocos_03$INICIO[1], units = \"days\")\n\nTime difference of 18 days\n\ntempo <- difftime(pocos_03$TERMINO[1], pocos_03$INICIO[1], units = \"days\")\nstr(tempo)\n\n 'difftime' num 18\n - attr(*, \"units\")= chr \"days\"\n\n(pocos_03$INICIO[1] %--% pocos_03$TERMINO[1])/ddays(1)\n\n[1] 18\n\npocos_03 <- pocos_03 %>% mutate(TPERF = (INICIO %--% TERMINO)/ddays(1))\nsummary(pocos_03)\n\n     POCO             OPERADOR            ESTADO             BACIA          \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    BLOCO              CAMPO            TERRA_MAR          CATEGORIA        \n Length:73          Length:73          Length:73          Length:73         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   SITUACAO             INICIO              TERMINO          \n Length:73          Min.   :2010-11-10   Min.   :2010-11-11  \n Class :character   1st Qu.:2012-02-04   1st Qu.:2012-04-06  \n Mode  :character   Median :2013-10-20   Median :2013-11-15  \n                    Mean   :2014-07-23   Mean   :2014-08-21  \n                    3rd Qu.:2016-06-23   3rd Qu.:2016-08-27  \n                    Max.   :2022-02-25   Max.   :2022-03-09  \n PROFUNDIDADE_MEDIDA_M     TPERF       \n Min.   : 742          Min.   :-347.0  \n 1st Qu.:4543          1st Qu.:  16.0  \n Median :5066          Median :  24.0  \n Mean   :5385          Mean   :  28.9  \n 3rd Qu.:6383          3rd Qu.:  37.0  \n Max.   :8613          Max.   : 260.0  \n\n\n\nEliminando colunas com tempos negativos\n\npocos_03 <- pocos_03 %>% filter(TPERF > 0)"
  },
  {
    "objectID": "semanas/Aula01.html#visualizando-os-dados-de-peregrino",
    "href": "semanas/Aula01.html#visualizando-os-dados-de-peregrino",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Visualizando os dados de PEREGRINO",
    "text": "Visualizando os dados de PEREGRINO\n\nBox-Plot\n\nggplot(pocos_03, aes(x=CAMPO, y=TPERF)) +\n  geom_boxplot()\n\n\n\n\nVeja que existem alguns tempos bem elevados que estão representados por pontos no box-plot. Eles podem ser considerados pontos afastados (outliers), que neste caso vamos eliminar.\n\npocos_04 <- pocos_03 %>% filter(TPERF < 100)\nggplot(pocos_04, aes(x=CAMPO, y=TPERF)) +\n  geom_boxplot()\n\n\n\n\n\n\nHistograma\n\nggplot(pocos_04, aes(x=TPERF)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nVeja que desta forma o ggplot usa o seu padrão de 30 faixas de dados, que geralmente não é o mais adequado.\nVamos usar uma regra adequada para definição de número de faixas.\n\n\nCriando um histograma usando a regra de Sturges\nA regra de Sturges indica 7 faixas enquanto que o padrão do ggplot2 é 30.\n\nggplot(pocos_04, aes(x = TPERF)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(pocos_04)),0))\n\n\n\n\nVeja que agora temos um histograma mais suave.\n\n\nGráfico de Dispersão\n\nggplot(pocos_04, aes(x=PROFUNDIDADE_MEDIDA_M, y=TPERF)) + \n  geom_point()\n\n\n\n\nPodemos perceber que há uma relação entre o tempo de perfuração e a profundidade do poço.\nTambém é possível se perceber que ainda existem dados com comportamentos estranhos. Poços rasos com profundidade muito diferente dos demais, além disso um poço muito profundo com duração muito pequena.\nSe fossemos construir um modelo certamente terímos que investigar o porque destes comportamentos.\n\n\nAlterando nome das colunas\n\nnames(pocos_04)\n\n [1] \"POCO\"                  \"OPERADOR\"              \"ESTADO\"               \n [4] \"BACIA\"                 \"BLOCO\"                 \"CAMPO\"                \n [7] \"TERRA_MAR\"             \"CATEGORIA\"             \"SITUACAO\"             \n[10] \"INICIO\"                \"TERMINO\"               \"PROFUNDIDADE_MEDIDA_M\"\n[13] \"TPERF\"                \n\nnames(pocos_04) <- tolower(names(pocos_04))\nnames(pocos_04)\n\n [1] \"poco\"                  \"operador\"              \"estado\"               \n [4] \"bacia\"                 \"bloco\"                 \"campo\"                \n [7] \"terra_mar\"             \"categoria\"             \"situacao\"             \n[10] \"inicio\"                \"termino\"               \"profundidade_medida_m\"\n[13] \"tperf\""
  },
  {
    "objectID": "semanas/Aula01A.html#lendo-dados-de-arquivos-xlsx",
    "href": "semanas/Aula01A.html#lendo-dados-de-arquivos-xlsx",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de arquivos xlsx",
    "text": "Lendo dados de arquivos xlsx\n\nlibrary(readxl)\ndados_seg <- read_xlsx(\"C:/Users/ricar/OneDrive/Documents/GitHub/IME05-12547/indicadoressegurancapublicauf.xlsx\", col_names = TRUE, sheet = \"Ocorrências\")\nhead(dados_seg)\n\n# A tibble: 6 × 5\n  UF    `Tipo Crime`                      Ano Mês     Ocorrências\n  <chr> <chr>                           <dbl> <chr>         <dbl>\n1 Acre  Estupro                          2022 janeiro          31\n2 Acre  Furto de veículo                 2022 janeiro          50\n3 Acre  Homicídio doloso                 2022 janeiro          10\n4 Acre  Lesão corporal seguida de morte  2022 janeiro           0\n5 Acre  Roubo a instituição financeira   2022 janeiro           0\n6 Acre  Roubo de carga                   2022 janeiro           0\n\nstr(dados_seg)\n\ntibble [20,686 × 5] (S3: tbl_df/tbl/data.frame)\n $ UF         : chr [1:20686] \"Acre\" \"Acre\" \"Acre\" \"Acre\" ...\n $ Tipo Crime : chr [1:20686] \"Estupro\" \"Furto de veículo\" \"Homicídio doloso\" \"Lesão corporal seguida de morte\" ...\n $ Ano        : num [1:20686] 2022 2022 2022 2022 2022 ...\n $ Mês        : chr [1:20686] \"janeiro\" \"janeiro\" \"janeiro\" \"janeiro\" ...\n $ Ocorrências: num [1:20686] 31 50 10 0 0 0 72 0 22 34 ..."
  },
  {
    "objectID": "semanas/Aula01A.html#lendo-dados-de-através-de-uma-url",
    "href": "semanas/Aula01A.html#lendo-dados-de-através-de-uma-url",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Lendo dados de através de uma url",
    "text": "Lendo dados de através de uma url\n\nlibrary(readxl)\nlibrary(httr)\nurl <- \"http://dados.mj.gov.br/dataset/210b9ae2-21fc-4986-89c6-2006eb4db247/resource/feeae05e-faba-406c-8a4a-512aec91a9d1/download/indicadoressegurancapublicauf.xlsx\"\nGET(url, write_disk(tf <- tempfile(fileext = \".xlsx\")))\n\nResponse [https://dados.mj.gov.br/dataset/210b9ae2-21fc-4986-89c6-2006eb4db247/resource/feeae05e-faba-406c-8a4a-512aec91a9d1/download/indicadoressegurancapublicauf.xlsx]\n  Date: 2022-08-12 18:33\n  Status: 200\n  Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n  Size: 1.02 MB\n<ON DISK>  C:\\Users\\ricar\\AppData\\Local\\Temp\\Rtmp4wadjp\\file2d6462e33ec0.xlsx\n\nsegur <- read_xlsx(tf, sheet = \"Ocorrências\")\nstr(segur)\n\ntibble [20,957 × 5] (S3: tbl_df/tbl/data.frame)\n $ UF         : chr [1:20957] \"Acre\" \"Acre\" \"Acre\" \"Acre\" ...\n $ Tipo Crime : chr [1:20957] \"Estupro\" \"Furto de veículo\" \"Homicídio doloso\" \"Lesão corporal seguida de morte\" ...\n $ Ano        : num [1:20957] 2022 2022 2022 2022 2022 ...\n $ Mês        : chr [1:20957] \"janeiro\" \"janeiro\" \"janeiro\" \"janeiro\" ...\n $ Ocorrências: num [1:20957] 31 50 10 0 0 0 72 0 22 34 ...\n\nhead(segur)\n\n# A tibble: 6 × 5\n  UF    `Tipo Crime`                      Ano Mês     Ocorrências\n  <chr> <chr>                           <dbl> <chr>         <dbl>\n1 Acre  Estupro                          2022 janeiro          31\n2 Acre  Furto de veículo                 2022 janeiro          50\n3 Acre  Homicídio doloso                 2022 janeiro          10\n4 Acre  Lesão corporal seguida de morte  2022 janeiro           0\n5 Acre  Roubo a instituição financeira   2022 janeiro           0\n6 Acre  Roubo de carga                   2022 janeiro           0"
  },
  {
    "objectID": "semanas/Aula01A.html#bibliotecas",
    "href": "semanas/Aula01A.html#bibliotecas",
    "title": "Carregando dados, Manipulando e Visualizando",
    "section": "Bibliotecas",
    "text": "Bibliotecas\nVamos carregar as bibliotecas que serão usadas na manipulação e visualização de dados.\nO pacote tidyverse carrega diversos pacotes muito uteis na manipulação e visualização de dados\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\nglimpse(dados_seg)\n\nRows: 20,686\nColumns: 5\n$ UF           <chr> \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"Acre\", \"…\n$ `Tipo Crime` <chr> \"Estupro\", \"Furto de veículo\", \"Homicídio doloso\", \"Lesão…\n$ Ano          <dbl> 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 202…\n$ Mês          <chr> \"janeiro\", \"janeiro\", \"janeiro\", \"janeiro\", \"janeiro\", \"j…\n$ Ocorrências  <dbl> 31, 50, 10, 0, 0, 0, 72, 0, 22, 34, 55, 10, 0, 0, 0, 48, …\n\nunique(dados_seg$UF)\n\n [1] \"Acre\"                \"Alagoas\"             \"Amapá\"              \n [4] \"Amazonas\"            \"Bahia\"               \"Ceará\"              \n [7] \"Distrito Federal\"    \"Espírito Santo\"      \"Goiás\"              \n[10] \"Maranhão\"            \"Mato Grosso\"         \"Mato Grosso do Sul\" \n[13] \"Minas Gerais\"        \"Pará\"                \"Paraíba\"            \n[16] \"Paraná\"              \"Pernambuco\"          \"Piauí\"              \n[19] \"Rio Grande do Norte\" \"Rio Grande do Sul\"   \"Rondônia\"           \n[22] \"Roraima\"             \"Santa Catarina\"      \"São Paulo\"          \n[25] \"Sergipe\"             \"Tocantins\"           \"Rio de Janeiro\"     \n\ndados_segRJ <- dados_seg %>% filter(UF==\"Rio de Janeiro\")\nsummary(dados_segRJ)\n\n      UF             Tipo Crime             Ano           Mês           \n Length:756         Length:756         Min.   :2015   Length:756        \n Class :character   Class :character   1st Qu.:2016   Class :character  \n Mode  :character   Mode  :character   Median :2018   Mode  :character  \n                                       Mean   :2018                     \n                                       3rd Qu.:2020                     \n                                       Max.   :2021                     \n  Ocorrências    \n Min.   :   0.0  \n 1st Qu.:  10.0  \n Median : 335.0  \n Mean   : 683.3  \n 3rd Qu.: 744.5  \n Max.   :5358.0  \n\n\n\nunique(dados_segRJ$`Tipo Crime`)\n\n[1] \"Estupro\"                             \"Furto de veículo\"                   \n[3] \"Homicídio doloso\"                    \"Lesão corporal seguida de morte\"    \n[5] \"Roubo a instituição financeira\"      \"Roubo de carga\"                     \n[7] \"Roubo de veículo\"                    \"Roubo seguido de morte (latrocínio)\"\n[9] \"Tentativa de homicídio\"             \n\ndados_segRJ$`Tipo Crime` <- as.factor(dados_segRJ$`Tipo Crime`)\ndados_segRJ %>% filter(`Tipo Crime`==\"Homicídio doloso\" ) %>% ggplot(aes(x=as.factor(Ano), y=Ocorrências)) + geom_boxplot()\n\n\n\ndados_segRJ %>% filter(`Tipo Crime`==\"Roubo de veículo\" ) %>% ggplot(aes(x=as.factor(Ano), y=Ocorrências)) + geom_boxplot()\n\n\n\n\n\nsintese_RJ <- dados_segRJ %>% group_by(Ano,`Tipo Crime`) %>% summarise(total = sum(Ocorrências))\n\n`summarise()` has grouped output by 'Ano'. You can override using the `.groups`\nargument.\n\nsintese_RJ %>% ggplot(aes(x=Ano, y=total, color=`Tipo Crime`)) + geom_point() + geom_line()"
  },
  {
    "objectID": "semanas/Aula02.html",
    "href": "semanas/Aula02.html",
    "title": "Manipulação dos dados",
    "section": "",
    "text": "Vamos trabalhar de novo com os dados do gapminder para fazer algumas manipulações de dados que são muito úteis no dia a dia.\nEste material foi em parte adaptado do curso Data Visualization in R with ggplot2 de Kara Woo\n\nlibrary(\"gapminder\")\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")"
  },
  {
    "objectID": "semanas/Aula02.html#filtrando-2007",
    "href": "semanas/Aula02.html#filtrando-2007",
    "title": "Manipulação dos dados",
    "section": "Filtrando 2007",
    "text": "Filtrando 2007\n\n## Cria um extrato do ano de 2007\ndata(gapminder)\nsummary(gapminder)\n\n        country        continent        year         lifeExp     \n Afghanistan:  12   Africa  :624   Min.   :1952   Min.   :23.60  \n Albania    :  12   Americas:300   1st Qu.:1966   1st Qu.:48.20  \n Algeria    :  12   Asia    :396   Median :1980   Median :60.71  \n Angola     :  12   Europe  :360   Mean   :1980   Mean   :59.47  \n Argentina  :  12   Oceania : 24   3rd Qu.:1993   3rd Qu.:70.85  \n Australia  :  12                  Max.   :2007   Max.   :82.60  \n (Other)    :1632                                                \n      pop              gdpPercap       \n Min.   :6.001e+04   Min.   :   241.2  \n 1st Qu.:2.794e+06   1st Qu.:  1202.1  \n Median :7.024e+06   Median :  3531.8  \n Mean   :2.960e+07   Mean   :  7215.3  \n 3rd Qu.:1.959e+07   3rd Qu.:  9325.5  \n Max.   :1.319e+09   Max.   :113523.1  \n                                       \n\ngap_07 <- filter(gapminder, year == 2007)"
  },
  {
    "objectID": "semanas/Aula02.html#vendo-primeiras-e-últimas-10-linhas",
    "href": "semanas/Aula02.html#vendo-primeiras-e-últimas-10-linhas",
    "title": "Manipulação dos dados",
    "section": "Vendo primeiras e últimas 10 linhas",
    "text": "Vendo primeiras e últimas 10 linhas\n\nhead(gap_07, n=10) %>% knitr::kable(booktabs = TRUE) # primeiros dez paises da base de dados\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nAfghanistan\nAsia\n2007\n43.828\n31889923\n974.5803\n\n\nAlbania\nEurope\n2007\n76.423\n3600523\n5937.0295\n\n\nAlgeria\nAfrica\n2007\n72.301\n33333216\n6223.3675\n\n\nAngola\nAfrica\n2007\n42.731\n12420476\n4797.2313\n\n\nArgentina\nAmericas\n2007\n75.320\n40301927\n12779.3796\n\n\nAustralia\nOceania\n2007\n81.235\n20434176\n34435.3674\n\n\nAustria\nEurope\n2007\n79.829\n8199783\n36126.4927\n\n\nBahrain\nAsia\n2007\n75.635\n708573\n29796.0483\n\n\nBangladesh\nAsia\n2007\n64.062\n150448339\n1391.2538\n\n\nBelgium\nEurope\n2007\n79.441\n10392226\n33692.6051\n\n\n\n\ntail(gap_07, n=10) %>% knitr::kable(booktabs = TRUE) # últimos 10 países \n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nUganda\nAfrica\n2007\n51.542\n29170398\n1056.3801\n\n\nUnited Kingdom\nEurope\n2007\n79.425\n60776238\n33203.2613\n\n\nUnited States\nAmericas\n2007\n78.242\n301139947\n42951.6531\n\n\nUruguay\nAmericas\n2007\n76.384\n3447496\n10611.4630\n\n\nVenezuela\nAmericas\n2007\n73.747\n26084662\n11415.8057\n\n\nVietnam\nAsia\n2007\n74.249\n85262356\n2441.5764\n\n\nWest Bank and Gaza\nAsia\n2007\n73.422\n4018332\n3025.3498\n\n\nYemen, Rep.\nAsia\n2007\n62.698\n22211743\n2280.7699\n\n\nZambia\nAfrica\n2007\n42.384\n11746035\n1271.2116\n\n\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.7093"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-1",
    "href": "semanas/Aula02.html#manipulando-1",
    "title": "Manipulação dos dados",
    "section": "Manipulando 1",
    "text": "Manipulando 1\nSelecionando dados por país\n\nfilter(gap_07, country %in% c(\"Brazil\", \"Chile\"))\n\n# A tibble: 2 × 6\n  country continent  year lifeExp       pop gdpPercap\n  <fct>   <fct>     <int>   <dbl>     <int>     <dbl>\n1 Brazil  Americas   2007    72.4 190010647     9066.\n2 Chile   Americas   2007    78.6  16284741    13172."
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-2",
    "href": "semanas/Aula02.html#manipulando-2",
    "title": "Manipulação dos dados",
    "section": "Manipulando 2",
    "text": "Manipulando 2\nSelecionando dados para 2007 excluindo a Oceania\n\nfilter(gapminder, year == 2007 & continent != \"Oceania\")\n\n# A tibble: 140 × 6\n   country     continent  year lifeExp       pop gdpPercap\n   <fct>       <fct>     <int>   <dbl>     <int>     <dbl>\n 1 Afghanistan Asia       2007    43.8  31889923      975.\n 2 Albania     Europe     2007    76.4   3600523     5937.\n 3 Algeria     Africa     2007    72.3  33333216     6223.\n 4 Angola      Africa     2007    42.7  12420476     4797.\n 5 Argentina   Americas   2007    75.3  40301927    12779.\n 6 Austria     Europe     2007    79.8   8199783    36126.\n 7 Bahrain     Asia       2007    75.6    708573    29796.\n 8 Bangladesh  Asia       2007    64.1 150448339     1391.\n 9 Belgium     Europe     2007    79.4  10392226    33693.\n10 Benin       Africa     2007    56.7   8078314     1441.\n# … with 130 more rows\n# ℹ Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-3",
    "href": "semanas/Aula02.html#manipulando-3",
    "title": "Manipulação dos dados",
    "section": "Manipulando 3",
    "text": "Manipulando 3\nSelecionando dados de 2007, agrupando por continente e sumarizando para achar a média da população por continente\n\ngapminder %>%\n  filter(year == 2007) %>% \n  group_by(continent) %>% \n  summarize(mediapop = mean(pop))\n\n# A tibble: 5 × 2\n  continent   mediapop\n  <fct>          <dbl>\n1 Africa     17875763.\n2 Americas   35954847.\n3 Asia      115513752.\n4 Europe     19536618.\n5 Oceania    12274974."
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-1",
    "href": "semanas/Aula02.html#visualizando-1",
    "title": "Manipulação dos dados",
    "section": "Visualizando 1",
    "text": "Visualizando 1\nMostrar linhas e pontos do PIB ao longo do tempo para Brasil e Chile\n\ngap_brachi <- filter(gapminder, country %in% c(\"Brazil\", \"Chile\"))\np <- ggplot(gap_brachi, aes(x = year, y = gdpPercap, color=country))\np1 <- p + geom_point()\np1"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-2",
    "href": "semanas/Aula02.html#visualizando-2",
    "title": "Manipulação dos dados",
    "section": "Visualizando 2",
    "text": "Visualizando 2\n\np2 <- p + geom_line()\np2"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-3",
    "href": "semanas/Aula02.html#visualizando-3",
    "title": "Manipulação dos dados",
    "section": "Visualizando 3",
    "text": "Visualizando 3\n\np3 <- p + geom_point() + geom_line()\np3"
  },
  {
    "objectID": "semanas/Aula02.html#visualizando-4---usando-o-pacote-patchwork",
    "href": "semanas/Aula02.html#visualizando-4---usando-o-pacote-patchwork",
    "title": "Manipulação dos dados",
    "section": "Visualizando 4 - Usando o pacote patchwork",
    "text": "Visualizando 4 - Usando o pacote patchwork\n\n(p1 + p2) /\n  p3"
  },
  {
    "objectID": "semanas/Aula02.html#manipulando-4",
    "href": "semanas/Aula02.html#manipulando-4",
    "title": "Manipulação dos dados",
    "section": "Manipulando 4",
    "text": "Manipulando 4\nContando número de países e continentes com distinct\n\nnrow(gapminder) ## Esta não é a informação que eu quero\n\n[1] 1704\n\nhead(gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\nnrow(distinct(gapminder,country))\n\n[1] 142\n\nnrow(distinct(gapminder, continent))\n\n[1] 5"
  },
  {
    "objectID": "semanas/Aula02.html#fazendo-contagens-de-dados",
    "href": "semanas/Aula02.html#fazendo-contagens-de-dados",
    "title": "Manipulação dos dados",
    "section": "Fazendo contagens de dados",
    "text": "Fazendo contagens de dados\n\ngapminder %>% filter(year == 2007) %>% \n  group_by(continent) %>% summarise(n = n())\n\n# A tibble: 5 × 2\n  continent     n\n  <fct>     <int>\n1 Africa       52\n2 Americas     25\n3 Asia         33\n4 Europe       30\n5 Oceania       2"
  },
  {
    "objectID": "semanas/Aula02.html#mudando-orientação-dos-dados",
    "href": "semanas/Aula02.html#mudando-orientação-dos-dados",
    "title": "Manipulação dos dados",
    "section": "Mudando orientação dos dados",
    "text": "Mudando orientação dos dados\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nhead(propaganda)\n\n# A tibble: 6 × 4\n     TV Radio Newspaper Sales\n  <dbl> <dbl>     <dbl> <dbl>\n1 230.   37.8      69.2  22.1\n2  44.5  39.3      45.1  10.4\n3  17.2  45.9      69.3   9.3\n4 152.   41.3      58.5  18.5\n5 181.   10.8      58.4  12.9\n6   8.7  48.9      75     7.2\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)\npropaganda %>% tidyr::pivot_longer(!Vendas, names_to=\"Midia\", values_to=\"Orcamento\")\n\n# A tibble: 600 × 3\n   Vendas Midia  Orcamento\n    <dbl> <chr>      <dbl>\n 1   22.1 TV         230. \n 2   22.1 Radio       37.8\n 3   22.1 Jornal      69.2\n 4   10.4 TV          44.5\n 5   10.4 Radio       39.3\n 6   10.4 Jornal      45.1\n 7    9.3 TV          17.2\n 8    9.3 Radio       45.9\n 9    9.3 Jornal      69.3\n10   18.5 TV         152. \n# … with 590 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\nlibrary(readr)\npesquisa <- read.csv(\"data_joined.csv\", header = T)\nhead(pesquisa)\n\n  record_id month day year plot_id species_id sex hindfoot_length weight\n1         1     7  16 1977       2         NL   M              32     NA\n2        72     8  19 1977       2         NL   M              31     NA\n3       224     9  13 1977       2         NL                  NA     NA\n4       266    10  16 1977       2         NL                  NA     NA\n5       349    11  12 1977       2         NL                  NA     NA\n6       363    11  12 1977       2         NL                  NA     NA\n    genus  species   taxa plot_type\n1 Neotoma albigula Rodent   Control\n2 Neotoma albigula Rodent   Control\n3 Neotoma albigula Rodent   Control\n4 Neotoma albigula Rodent   Control\n5 Neotoma albigula Rodent   Control\n6 Neotoma albigula Rodent   Control\n\npesquisa_gw <- pesquisa %>% filter(!is.na(weight)) %>%\n  group_by(year, genus) %>%\n  summarize(peso_medio = mean(weight))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\nhead(pesquisa_gw)\n\n# A tibble: 6 × 3\n# Groups:   year [1]\n   year genus           peso_medio\n  <int> <chr>                <dbl>\n1  1977 Chaetodipus          15.3 \n2  1977 Dipodomys            52.5 \n3  1977 Onychomys            21.4 \n4  1977 Perognathus           7.17\n5  1977 Peromyscus           19.5 \n6  1977 Reithrodontomys      10   \n\npesquisa_gw %>% tidyr::pivot_wider(names_from=\"genus\", values_from=\"peso_medio\")\n\n# A tibble: 26 × 11\n# Groups:   year [26]\n    year Chaet…¹ Dipod…² Onych…³ Perog…⁴ Perom…⁵ Reith…⁶ Neotoma Sigmo…⁷ Sperm…⁸\n   <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  1977    15.3    52.5    21.4    7.17    19.5   10        NA       NA      NA\n 2  1978    14.9    73.9    26.5    7.09    20.5    7.5     185.      89     130\n 3  1979    15.1    74.9    27.4    7.53    21.3    8.33    138       NA      NA\n 4  1980    14.2    73.1    28.3    7.46    22.4   10.2     159.      NA      NA\n 5  1981    14.0    72.7    28.4    7.15    20.4   11.2     166.      NA      57\n 6  1982    16.1    66.3    29.9    6.92    21.3   10.5     161.      79      NA\n 7  1983    15.5    65.0    29.0    6.83    21.5    9.87    157.      NA      NA\n 8  1984    15.3    52.8    28.3   16.9     20.0   11.2     150.      NA      NA\n 9  1985    15.8    51.1    28.1   32.7     20.0    8.37    149.      NA      NA\n10  1986    16.8    56.4    27.5   18.3     22.1   10.8     160.      55      NA\n# … with 16 more rows, 1 more variable: Baiomys <dbl>, and abbreviated variable\n#   names ¹​Chaetodipus, ²​Dipodomys, ³​Onychomys, ⁴​Perognathus, ⁵​Peromyscus,\n#   ⁶​Reithrodontomys, ⁷​Sigmodon, ⁸​Spermophilus\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"
  },
  {
    "objectID": "semanas/Aula03.html",
    "href": "semanas/Aula03.html",
    "title": "Visualizando as distribuições",
    "section": "",
    "text": "Vamos trabalhar de novo com os dados do gapminder para fazer algumas visualizações de dados que são muito úteis no dia a dia.\nEste material foi adaptado do curso Data Visualization in R with ggplot2 de Kara Woo\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"gapminder\")"
  },
  {
    "objectID": "semanas/Aula03.html#selecionando-dados",
    "href": "semanas/Aula03.html#selecionando-dados",
    "title": "Visualizando as distribuições",
    "section": "Selecionando dados",
    "text": "Selecionando dados\n\ngap_07 <- filter(gapminder, year == 2007)"
  },
  {
    "objectID": "semanas/Aula03.html#vendo-a-distribuição",
    "href": "semanas/Aula03.html#vendo-a-distribuição",
    "title": "Visualizando as distribuições",
    "section": "Vendo a distribuição",
    "text": "Vendo a distribuição\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_histogram()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-histograma-usando-a-regra-de-sturges",
    "href": "semanas/Aula03.html#criando-um-histograma-usando-a-regra-de-sturges",
    "title": "Visualizando as distribuições",
    "section": "Criando um histograma usando a regra de Sturges",
    "text": "Criando um histograma usando a regra de Sturges\nA regra de Sturges indica 8 faixas enquanto que o padrão do ggplot2 é 30.\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(gap_07)),0))"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-gráfico-de-densidade",
    "href": "semanas/Aula03.html#criando-um-gráfico-de-densidade",
    "title": "Visualizando as distribuições",
    "section": "Criando um gráfico de densidade",
    "text": "Criando um gráfico de densidade\n\nggplot(gap_07, aes(x = gdpPercap)) +\n  geom_density()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-box-plot",
    "href": "semanas/Aula03.html#criando-um-box-plot",
    "title": "Visualizando as distribuições",
    "section": "Criando um box-plot",
    "text": "Criando um box-plot\n\nggplot(gap_07, aes(x = continent, y = lifeExp)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula03.html#criando-um-box-plot-com-visão-dos-dados",
    "href": "semanas/Aula03.html#criando-um-box-plot-com-visão-dos-dados",
    "title": "Visualizando as distribuições",
    "section": "Criando um box-plot com visão dos dados",
    "text": "Criando um box-plot com visão dos dados\n\nggplot(gap_07, aes(x = continent, y = lifeExp)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.5, alpha = 0.2)"
  },
  {
    "objectID": "semanas/Aula03.html#matriz-de-correlações",
    "href": "semanas/Aula03.html#matriz-de-correlações",
    "title": "Visualizando as distribuições",
    "section": "Matriz de Correlações",
    "text": "Matriz de Correlações\n\nlibrary(corrplot)\ngap_07_s <- gap_07 %>% select(lifeExp, pop, gdpPercap)\nmat_corr <- cor(gap_07_s)\ncorrplot(mat_corr, method = \"number\", col = \"black\", cl.pos = \"n\")\n\n\n\ncorrplot(mat_corr, method = \"number\")\n\n\n\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula03.html#splom",
    "href": "semanas/Aula03.html#splom",
    "title": "Visualizando as distribuições",
    "section": "SPLOM",
    "text": "SPLOM\n\nlibrary(psych)\npairs.panels(gap_07_s)\n\n\n\n\n\n\nlibrary(GGally)\nggpairs(gap_07_s)"
  },
  {
    "objectID": "semanas/Aula03.html#descrevendo-a-distribuição",
    "href": "semanas/Aula03.html#descrevendo-a-distribuição",
    "title": "Visualizando as distribuições",
    "section": "Descrevendo a distribuição",
    "text": "Descrevendo a distribuição\n\nlibrary(datawizard)\ndescribe_distribution(gap_07_s)\n\nVariable  |     Mean |       SD |      IQR |                Range | Skewness | Kurtosis |   n | n_Missing\n---------------------------------------------------------------------------------------------------------\nlifeExp   |    67.01 |    12.07 |    19.59 |       [39.61, 82.60] |    -0.69 |    -0.83 | 142 |         0\npop       | 4.40e+07 | 1.48e+08 | 2.78e+07 | [2.00e+05, 1.32e+09] |     7.40 |    58.33 | 142 |         0\ngdpPercap | 11680.07 | 12859.94 | 16579.19 |   [277.55, 49357.19] |     1.22 |     0.35 | 142 |         0"
  },
  {
    "objectID": "semanas/Aula04.html",
    "href": "semanas/Aula04.html",
    "title": "Melhorando a visualização",
    "section": "",
    "text": "library(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"gapminder\")"
  },
  {
    "objectID": "semanas/Aula04.html#cores-por-continente",
    "href": "semanas/Aula04.html#cores-por-continente",
    "title": "Melhorando a visualização",
    "section": "Cores por continente",
    "text": "Cores por continente\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#usando-formas-e-cores-diferentes",
    "href": "semanas/Aula04.html#usando-formas-e-cores-diferentes",
    "title": "Melhorando a visualização",
    "section": "Usando formas e cores diferentes",
    "text": "Usando formas e cores diferentes\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   shape = continent, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#cores-e-tamanho",
    "href": "semanas/Aula04.html#cores-e-tamanho",
    "title": "Melhorando a visualização",
    "section": "Cores e tamanho",
    "text": "Cores e tamanho\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp,\n                   size = pop, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#sumario-dos-dados-para-obter-pop-média-por-continente",
    "href": "semanas/Aula04.html#sumario-dos-dados-para-obter-pop-média-por-continente",
    "title": "Melhorando a visualização",
    "section": "Sumario dos dados para obter pop média por continente",
    "text": "Sumario dos dados para obter pop média por continente\n\ngap_pop <- gapminder %>% \n  group_by(continent, year) %>% \n  summarize(pop = mean(pop))\nhead(gap_pop)\n\n# A tibble: 6 × 3\n# Groups:   continent [1]\n  continent  year      pop\n  <fct>     <int>    <dbl>\n1 Africa     1952 4570010.\n2 Africa     1957 5093033.\n3 Africa     1962 5702247.\n4 Africa     1967 6447875.\n5 Africa     1972 7305376.\n6 Africa     1977 8328097."
  },
  {
    "objectID": "semanas/Aula04.html#grafico-de-linha-com-cores",
    "href": "semanas/Aula04.html#grafico-de-linha-com-cores",
    "title": "Melhorando a visualização",
    "section": "Grafico de linha com cores",
    "text": "Grafico de linha com cores\n\nggplot(gap_pop, aes(x = year, y = pop, color = continent)) +\n  geom_line() + geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#criando-grids-entre-os-anos-de-2002-e-2007",
    "href": "semanas/Aula04.html#criando-grids-entre-os-anos-de-2002-e-2007",
    "title": "Melhorando a visualização",
    "section": "Criando grids entre os anos de 2002 e 2007",
    "text": "Criando grids entre os anos de 2002 e 2007\n\ngap_0207 <- gapminder %>% filter(between(year, 2002, 2007))\nggplot(gap_0207, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_grid(continent ~ year)"
  },
  {
    "objectID": "semanas/Aula04.html#outro-tipo-de-apresentações-de-grid",
    "href": "semanas/Aula04.html#outro-tipo-de-apresentações-de-grid",
    "title": "Melhorando a visualização",
    "section": "Outro tipo de apresentações de grid",
    "text": "Outro tipo de apresentações de grid\n\ngap_life <- gapminder %>% \n  group_by(continent, year) %>% \n  summarize(lifeExp = mean(lifeExp))\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_grid(continent ~ .)"
  },
  {
    "objectID": "semanas/Aula04.html#grid-em-outra-direção",
    "href": "semanas/Aula04.html#grid-em-outra-direção",
    "title": "Melhorando a visualização",
    "section": "Grid em outra direção",
    "text": "Grid em outra direção\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_grid(. ~ continent)"
  },
  {
    "objectID": "semanas/Aula04.html#usando-o-wrap",
    "href": "semanas/Aula04.html#usando-o-wrap",
    "title": "Melhorando a visualização",
    "section": "Usando o wrap",
    "text": "Usando o wrap\n\nggplot(gap_life, aes(x = year, y = lifeExp)) +\n  geom_line() +\n  facet_wrap( ~ continent)"
  },
  {
    "objectID": "semanas/Aula04.html#filtrando-dados-e-fazendo-grafico-de-dispersão-padrão",
    "href": "semanas/Aula04.html#filtrando-dados-e-fazendo-grafico-de-dispersão-padrão",
    "title": "Melhorando a visualização",
    "section": "Filtrando dados e fazendo grafico de dispersão padrão",
    "text": "Filtrando dados e fazendo grafico de dispersão padrão\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula04.html#transformando-o-eixo-x-para-escala-logarítimica",
    "href": "semanas/Aula04.html#transformando-o-eixo-x-para-escala-logarítimica",
    "title": "Melhorando a visualização",
    "section": "Transformando o eixo x para escala logarítimica",
    "text": "Transformando o eixo x para escala logarítimica\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_continuous(trans = \"log10\")"
  },
  {
    "objectID": "semanas/Aula04.html#outra-forma-de-transformação-do-eixo-x",
    "href": "semanas/Aula04.html#outra-forma-de-transformação-do-eixo-x",
    "title": "Melhorando a visualização",
    "section": "Outra forma de transformação do eixo x",
    "text": "Outra forma de transformação do eixo x\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#definindo-limites-para-o-eixo-y",
    "href": "semanas/Aula04.html#definindo-limites-para-o-eixo-y",
    "title": "Melhorando a visualização",
    "section": "Definindo limites para o eixo y",
    "text": "Definindo limites para o eixo y\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 95))"
  },
  {
    "objectID": "semanas/Aula04.html#grafico-com-cores-normais",
    "href": "semanas/Aula04.html#grafico-com-cores-normais",
    "title": "Melhorando a visualização",
    "section": "Grafico com cores normais",
    "text": "Grafico com cores normais\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#grafico-usando-outra-paleta-de-cores",
    "href": "semanas/Aula04.html#grafico-usando-outra-paleta-de-cores",
    "title": "Melhorando a visualização",
    "section": "Grafico usando outra paleta de cores",
    "text": "Grafico usando outra paleta de cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "semanas/Aula04.html#usando-codigos-manuais-para-as-cores",
    "href": "semanas/Aula04.html#usando-codigos-manuais-para-as-cores",
    "title": "Melhorando a visualização",
    "section": "Usando codigos manuais para as cores",
    "text": "Usando codigos manuais para as cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_manual(values = c(\"#FF0000\", \"#00A08A\", \"#F2AD00\",\n                                \"#F98400\", \"#5BBCD6\"))"
  },
  {
    "objectID": "semanas/Aula04.html#definindo-as-cores-e-tamanho-dos-pontos",
    "href": "semanas/Aula04.html#definindo-as-cores-e-tamanho-dos-pontos",
    "title": "Melhorando a visualização",
    "section": "Definindo as cores e tamanho dos pontos",
    "text": "Definindo as cores e tamanho dos pontos\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(color = \"darkblue\", size = 3) +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula04.html#customizando-títulos-rótulos-de-eixo-e-legendas",
    "href": "semanas/Aula04.html#customizando-títulos-rótulos-de-eixo-e-legendas",
    "title": "Melhorando a visualização",
    "section": "Customizando títulos, rótulos de eixo e legendas",
    "text": "Customizando títulos, rótulos de eixo e legendas\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "semanas/Aula04.html#sem-legenda",
    "href": "semanas/Aula04.html#sem-legenda",
    "title": "Melhorando a visualização",
    "section": "Sem legenda",
    "text": "Sem legenda\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "semanas/Aula04.html#legenda-dentro-do-gráfico",
    "href": "semanas/Aula04.html#legenda-dentro-do-gráfico",
    "title": "Melhorando a visualização",
    "section": "Legenda dentro do gráfico",
    "text": "Legenda dentro do gráfico\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))"
  },
  {
    "objectID": "semanas/Aula04.html#salvando-o-gráfico",
    "href": "semanas/Aula04.html#salvando-o-gráfico",
    "title": "Melhorando a visualização",
    "section": "Salvando o gráfico",
    "text": "Salvando o gráfico\n\ngraf1 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))\n\ngraf1"
  },
  {
    "objectID": "semanas/Aula04.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "href": "semanas/Aula04.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "title": "Melhorando a visualização",
    "section": "Aumentando o tamanho do texto e mudando para portugues",
    "text": "Aumentando o tamanho do texto e mudando para portugues\n\ngraf2 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.80),\n        legend.key = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14)) +\n  labs(x = \"PIB Per capita (US$)\", \n       y = \"Expectativa de Vida (anos)\", \n       title = \"Expectativa de Vida vs PIB em 2007\",\n       color = \"Continente\")\n\ngraf2"
  },
  {
    "objectID": "semanas/Aula05.html",
    "href": "semanas/Aula05.html",
    "title": "Suavização",
    "section": "",
    "text": "library(\"ggplot2\")\nlibrary(\"gapminder\")\nlibrary(\"dplyr\")"
  },
  {
    "objectID": "semanas/Aula05.html#suavização",
    "href": "semanas/Aula05.html#suavização",
    "title": "Suavização",
    "section": "Suavização",
    "text": "Suavização\n(locally estimated scatterplot smoothing/Local Polynomial Regression Fitting)\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#fazendo-o-suavizador-mais-nervoso",
    "href": "semanas/Aula05.html#fazendo-o-suavizador-mais-nervoso",
    "title": "Suavização",
    "section": "Fazendo o suavizador mais nervoso",
    "text": "Fazendo o suavizador mais nervoso\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(span = 0.2)"
  },
  {
    "objectID": "semanas/Aula05.html#fazendo-o-suavizador-menos-nervoso",
    "href": "semanas/Aula05.html#fazendo-o-suavizador-menos-nervoso",
    "title": "Suavização",
    "section": "Fazendo o suavizador menos nervoso",
    "text": "Fazendo o suavizador menos nervoso\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(span = 0.9)"
  },
  {
    "objectID": "semanas/Aula05.html#removendo-intervalos-de-confiança",
    "href": "semanas/Aula05.html#removendo-intervalos-de-confiança",
    "title": "Suavização",
    "section": "Removendo intervalos de confiança",
    "text": "Removendo intervalos de confiança\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(se = FALSE)"
  },
  {
    "objectID": "semanas/Aula05.html#usando-ic-de-90",
    "href": "semanas/Aula05.html#usando-ic-de-90",
    "title": "Suavização",
    "section": "Usando IC de 90%",
    "text": "Usando IC de 90%\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(level = 0.90)"
  },
  {
    "objectID": "semanas/Aula05.html#usando-um-modelo-linear-ao-invés-do-loess",
    "href": "semanas/Aula05.html#usando-um-modelo-linear-ao-invés-do-loess",
    "title": "Suavização",
    "section": "Usando um modelo linear ao invés do loess",
    "text": "Usando um modelo linear ao invés do loess\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "semanas/Aula05.html#usando-basic-splines-para-melhorar-o-ajuste",
    "href": "semanas/Aula05.html#usando-basic-splines-para-melhorar-o-ajuste",
    "title": "Suavização",
    "section": "Usando basic splines para melhorar o ajuste",
    "text": "Usando basic splines para melhorar o ajuste\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ splines::bs(x, df = 3))"
  },
  {
    "objectID": "semanas/Aula05.html#usando-o-gam-general-addtive-models-com-regressão-spline",
    "href": "semanas/Aula05.html#usando-o-gam-general-addtive-models-com-regressão-spline",
    "title": "Suavização",
    "section": "Usando o gam (general addtive models) com regressão spline",
    "text": "Usando o gam (general addtive models) com regressão spline\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"gam\", formula = y ~ s(x))"
  },
  {
    "objectID": "semanas/Aula05.html#começando-a-construir-um-gráfico-do-tipo-facet-com-suavizações",
    "href": "semanas/Aula05.html#começando-a-construir-um-gráfico-do-tipo-facet-com-suavizações",
    "title": "Suavização",
    "section": "Começando a construir um gráfico do tipo facet com suavizações",
    "text": "Começando a construir um gráfico do tipo facet com suavizações\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula05.html#dividindo-por-continente",
    "href": "semanas/Aula05.html#dividindo-por-continente",
    "title": "Suavização",
    "section": "Dividindo por continente",
    "text": "Dividindo por continente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent)"
  },
  {
    "objectID": "semanas/Aula05.html#adicionando-suavizadores",
    "href": "semanas/Aula05.html#adicionando-suavizadores",
    "title": "Suavização",
    "section": "Adicionando suavizadores",
    "text": "Adicionando suavizadores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#colorindo-por-continente",
    "href": "semanas/Aula05.html#colorindo-por-continente",
    "title": "Suavização",
    "section": "Colorindo por continente",
    "text": "Colorindo por continente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth()"
  },
  {
    "objectID": "semanas/Aula05.html#colorindo-somente-a-curva",
    "href": "semanas/Aula05.html#colorindo-somente-a-curva",
    "title": "Suavização",
    "section": "Colorindo somente a curva",
    "text": "Colorindo somente a curva\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  facet_wrap(~ continent) +\n  geom_smooth(aes(color = continent))"
  },
  {
    "objectID": "semanas/Aula06.html",
    "href": "semanas/Aula06.html",
    "title": "Eixos - Escalas - Cores",
    "section": "",
    "text": "library(tidyverse)\nlibrary(gapminder)"
  },
  {
    "objectID": "semanas/Aula06.html#filtrando-dados-e-fazendo-grafico-de-dispersão-padrão",
    "href": "semanas/Aula06.html#filtrando-dados-e-fazendo-grafico-de-dispersão-padrão",
    "title": "Eixos - Escalas - Cores",
    "section": "Filtrando dados e fazendo grafico de dispersão padrão",
    "text": "Filtrando dados e fazendo grafico de dispersão padrão\n\ngap_07 <- filter(gapminder, year == 2007)\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula06.html#transformando-o-eixo-x-para-escala-logarítimica",
    "href": "semanas/Aula06.html#transformando-o-eixo-x-para-escala-logarítimica",
    "title": "Eixos - Escalas - Cores",
    "section": "Transformando o eixo x para escala logarítimica",
    "text": "Transformando o eixo x para escala logarítimica\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_continuous(trans = \"log10\")"
  },
  {
    "objectID": "semanas/Aula06.html#outra-forma-de-transformação-do-eixo-x",
    "href": "semanas/Aula06.html#outra-forma-de-transformação-do-eixo-x",
    "title": "Eixos - Escalas - Cores",
    "section": "Outra forma de transformação do eixo x",
    "text": "Outra forma de transformação do eixo x\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#definindo-limites-para-o-eixo-y",
    "href": "semanas/Aula06.html#definindo-limites-para-o-eixo-y",
    "title": "Eixos - Escalas - Cores",
    "section": "Definindo limites para o eixo y",
    "text": "Definindo limites para o eixo y\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 95))"
  },
  {
    "objectID": "semanas/Aula06.html#grafico-com-cores-normais",
    "href": "semanas/Aula06.html#grafico-com-cores-normais",
    "title": "Eixos - Escalas - Cores",
    "section": "Grafico com cores normais",
    "text": "Grafico com cores normais\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#grafico-usando-uma-paleta-de-cores-diferente",
    "href": "semanas/Aula06.html#grafico-usando-uma-paleta-de-cores-diferente",
    "title": "Eixos - Escalas - Cores",
    "section": "Grafico usando uma paleta de cores diferente",
    "text": "Grafico usando uma paleta de cores diferente\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "semanas/Aula06.html#usando-codigos-manuais-para-as-cores",
    "href": "semanas/Aula06.html#usando-codigos-manuais-para-as-cores",
    "title": "Eixos - Escalas - Cores",
    "section": "Usando codigos manuais para as cores",
    "text": "Usando codigos manuais para as cores\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_manual(values = c(\"#FF0000\", \"#00A08A\", \"#F2AD00\",\n                                \"#F98400\", \"#5BBCD6\"))"
  },
  {
    "objectID": "semanas/Aula06.html#definindo-as-cores-e-tamanho-dos-pontos",
    "href": "semanas/Aula06.html#definindo-as-cores-e-tamanho-dos-pontos",
    "title": "Eixos - Escalas - Cores",
    "section": "Definindo as cores e tamanho dos pontos",
    "text": "Definindo as cores e tamanho dos pontos\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(color = \"darkblue\", size = 3) +\n  scale_x_log10()"
  },
  {
    "objectID": "semanas/Aula06.html#customizando-títulos-rótulos-de-eixo-e-legendas",
    "href": "semanas/Aula06.html#customizando-títulos-rótulos-de-eixo-e-legendas",
    "title": "Eixos - Escalas - Cores",
    "section": "Customizando títulos, rótulos de eixo e legendas",
    "text": "Customizando títulos, rótulos de eixo e legendas\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "semanas/Aula06.html#sem-legenda",
    "href": "semanas/Aula06.html#sem-legenda",
    "title": "Eixos - Escalas - Cores",
    "section": "Sem legenda",
    "text": "Sem legenda\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "semanas/Aula06.html#legenda-dentro-do-gráfico",
    "href": "semanas/Aula06.html#legenda-dentro-do-gráfico",
    "title": "Eixos - Escalas - Cores",
    "section": "Legenda dentro do gráfico",
    "text": "Legenda dentro do gráfico\n\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))"
  },
  {
    "objectID": "semanas/Aula06.html#salvando-o-gráfico",
    "href": "semanas/Aula06.html#salvando-o-gráfico",
    "title": "Eixos - Escalas - Cores",
    "section": "Salvando o gráfico",
    "text": "Salvando o gráfico\n\ngraf1 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85))\n\ngraf1\n\n\n\nggsave(\"Exp_vida_pib_2007_1.png\", plot=graf1, width = 7, height = 7)"
  },
  {
    "objectID": "semanas/Aula06.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "href": "semanas/Aula06.html#aumentando-o-tamanho-do-texto-e-mudando-para-portugues",
    "title": "Eixos - Escalas - Cores",
    "section": "Aumentando o tamanho do texto e mudando para portugues",
    "text": "Aumentando o tamanho do texto e mudando para portugues\n\ngraf2 <- ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  theme_light() +\n  theme(legend.position = c(0.1, 0.85),\n        legend.key = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14)) +\n  labs(x = \"PIB Per capita (US$)\", \n       y = \"Expectativa de Vida (anos)\", \n       title = \"Expectativa de Vida vs PIB em 2007\",\n       color = \"Continente\")\n\ngraf2\n\n\n\nggsave(\"Exp_vida_pib_2007_2.png\", plot = graf2, width = 7, height = 7)"
  },
  {
    "objectID": "semanas/Aula06A.html",
    "href": "semanas/Aula06A.html",
    "title": "Explorando Dados",
    "section": "",
    "text": "library(tidyverse)\ndata(iris)"
  },
  {
    "objectID": "semanas/Aula06A.html#o-que-temos-aqui",
    "href": "semanas/Aula06A.html#o-que-temos-aqui",
    "title": "Explorando Dados",
    "section": "O que temos aqui?",
    "text": "O que temos aqui?\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\niris %>% count(Species)\n\n     Species  n\n1     setosa 50\n2 versicolor 50\n3  virginica 50"
  },
  {
    "objectID": "semanas/Aula06A.html#quais-são-as-médias",
    "href": "semanas/Aula06A.html#quais-são-as-médias",
    "title": "Explorando Dados",
    "section": "Quais são as médias?",
    "text": "Quais são as médias?\n\niris %>% \n  group_by(Species) %>% \n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 3 × 5\n  Species    Sepal.Length Sepal.Width Petal.Length Petal.Width\n  <fct>             <dbl>       <dbl>        <dbl>       <dbl>\n1 setosa             5.01        3.43         1.46       0.246\n2 versicolor         5.94        2.77         4.26       1.33 \n3 virginica          6.59        2.97         5.55       2.03"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relação entre as variáveis",
    "text": "Vamos ver se temos alguma relação entre as variáveis\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Sepal.Width, y=Sepal.Length, \n                                   color=Species)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis-2",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis-2",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relação entre as variáveis 2",
    "text": "Vamos ver se temos alguma relação entre as variáveis 2\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Sepal.Width, y=Sepal.Length, color=Species)) +\n  geom_point() + geom_smooth(method = \"lm\", se=FALSE)"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis-3",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis-3",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relação entre as variáveis 3",
    "text": "Vamos ver se temos alguma relação entre as variáveis 3\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Petal.Width, y=Petal.Length, \n                                   color=Species)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis-4",
    "href": "semanas/Aula06A.html#vamos-ver-se-temos-alguma-relação-entre-as-variáveis-4",
    "title": "Explorando Dados",
    "section": "Vamos ver se temos alguma relação entre as variáveis 4",
    "text": "Vamos ver se temos alguma relação entre as variáveis 4\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Petal.Width, y=Petal.Length, color=Species)) +\n  geom_point() + geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.width",
    "href": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.width",
    "title": "Explorando Dados",
    "section": "Vamos ver como se distribui o Petal.Width",
    "text": "Vamos ver como se distribui o Petal.Width\n\niris %>% \n  group_by(Species) %>% ggplot(aes(x=Petal.Width, \n                                   fill=Species)) + \n                                   geom_histogram()"
  },
  {
    "objectID": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.length",
    "href": "semanas/Aula06A.html#vamos-ver-como-se-distribui-o-petal.length",
    "title": "Explorando Dados",
    "section": "Vamos ver como se distribui o Petal.Length",
    "text": "Vamos ver como se distribui o Petal.Length\n\niris %>% \n  group_by(Species) %>% \n  ggplot(aes(x=Petal.Length, fill=Species)) + \n  geom_histogram()"
  },
  {
    "objectID": "semanas/Aula07.1.html",
    "href": "semanas/Aula07.1.html",
    "title": "Regressão Linear",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "semanas/Aula07.1.html#dados-de-propaganda",
    "href": "semanas/Aula07.1.html#dados-de-propaganda",
    "title": "Regressão Linear",
    "section": "Dados de propaganda",
    "text": "Dados de propaganda\nO conjunto de dados contém estatísticas sobre as vendas de um produto em 200 diferentes mercados, juntamente com orçamentos publicitários em cada um desses mercados, para diferentes canais de mídia: TV, rádio e jornal. As vendas estão em milhares de unidades e o orçamento está em milhares de dólares.\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nsummary(propaganda)\n\n       TV             Radio          Newspaper          Sales      \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00"
  },
  {
    "objectID": "semanas/Aula07.1.html#renomeando",
    "href": "semanas/Aula07.1.html#renomeando",
    "title": "Regressão Linear",
    "section": "Renomeando",
    "text": "Renomeando\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)"
  },
  {
    "objectID": "semanas/Aula07.1.html#sumario",
    "href": "semanas/Aula07.1.html#sumario",
    "title": "Regressão Linear",
    "section": "Sumario",
    "text": "Sumario\n\nsummary(propaganda)\n\n       TV             Radio            Jornal           Vendas     \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00  \n\nnrow(propaganda)\n\n[1] 200"
  },
  {
    "objectID": "semanas/Aula07.1.html#linhas-inicias",
    "href": "semanas/Aula07.1.html#linhas-inicias",
    "title": "Regressão Linear",
    "section": "Linhas inicias",
    "text": "Linhas inicias\n\nlibrary(gt)\ngt(head(propaganda, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    44.5\n39.3\n45.1\n10.4\n    17.2\n45.9\n69.3\n9.3\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    8.7\n48.9\n75.0\n7.2\n    57.5\n32.8\n23.5\n11.8\n    120.2\n19.6\n11.6\n13.2\n    8.6\n2.1\n1.0\n4.8\n    199.8\n2.6\n21.2\n10.6"
  },
  {
    "objectID": "semanas/Aula07.1.html#criando-amostra-de-treino-e-teste",
    "href": "semanas/Aula07.1.html#criando-amostra-de-treino-e-teste",
    "title": "Regressão Linear",
    "section": "Criando amostra de treino e teste",
    "text": "Criando amostra de treino e teste\n\nlibrary(caret)\nset.seed(21)\ny <- propaganda$Vendas\nindice_teste <- createDataPartition(y, times = 1, p = 0.40, list = FALSE)\n\nconj_treino <- propaganda %>% slice(-indice_teste)\nconj_teste <- propaganda %>% slice(indice_teste)\n\nstr(conj_treino)\n\ntibble [119 × 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:119] 230.1 151.5 180.8 199.8 66.1 ...\n $ Radio : num [1:119] 37.8 41.3 10.8 2.6 5.8 35.1 7.6 47.7 20.5 23.9 ...\n $ Jornal: num [1:119] 69.2 58.5 58.4 21.2 24.2 65.9 7.2 52.9 18.3 19.1 ...\n $ Vendas: num [1:119] 22.1 18.5 12.9 10.6 8.6 9.2 9.7 22.4 11.3 14.6 ...\n\nstr(conj_teste)\n\ntibble [81 × 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:81] 44.5 17.2 8.7 57.5 120.2 ...\n $ Radio : num [1:81] 39.3 45.9 48.9 32.8 19.6 2.1 24 32.9 36.6 39.6 ...\n $ Jornal: num [1:81] 45.1 69.3 75 23.5 11.6 1 4 46 114 55.8 ...\n $ Vendas: num [1:81] 10.4 9.3 7.2 11.8 13.2 4.8 17.4 19 12.5 24.4 ...\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6"
  },
  {
    "objectID": "semanas/Aula07.1.html#primeira-visualização-dos-dados",
    "href": "semanas/Aula07.1.html#primeira-visualização-dos-dados",
    "title": "Regressão Linear",
    "section": "Primeira visualização dos dados",
    "text": "Primeira visualização dos dados\nAqui estou usando uma função do pacote caret que de uma maneira simples apresenta a relação entre a variável resposta e suas possíveis variáveis explicativas\n\nfeaturePlot(x = conj_treino[ , c(\"TV\", \"Radio\", \"Jornal\")], y = conj_treino$Vendas)"
  },
  {
    "objectID": "semanas/Aula07.1.html#usando-o-ggplot",
    "href": "semanas/Aula07.1.html#usando-o-ggplot",
    "title": "Regressão Linear",
    "section": "Usando o ggplot",
    "text": "Usando o ggplot\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6\n  \n  \n  \n\n\n\nc_treino_pivot <- conj_treino %>% pivot_longer(!Vendas, names_to=\"Tipo\", values_to=\"Orçamento\" ) \ngt(head(c_treino_pivot, 10))\n\n\n\n\n\n  \n  \n    \n      Vendas\n      Tipo\n      Orçamento\n    \n  \n  \n    22.1\nTV\n230.1\n    22.1\nRadio\n37.8\n    22.1\nJornal\n69.2\n    18.5\nTV\n151.5\n    18.5\nRadio\n41.3\n    18.5\nJornal\n58.5\n    12.9\nTV\n180.8\n    12.9\nRadio\n10.8\n    12.9\nJornal\n58.4\n    10.6\nTV\n199.8\n  \n  \n  \n\n\n\nconj_treino %>% pivot_longer(!Vendas, names_to=\"Tipo\", values_to=\"Orçamento\" ) %>%\n            ggplot() + \n            geom_point(aes(x=Orçamento, y=Vendas)) +\n            facet_wrap( ~ Tipo, scales = \"free_x\") +\n            labs(x = \"Orçamento (1000 US$)\", \n                 y = \"Vendas (em 1000 unidades vendidas)\", \n                 title = \"Vendas vs Propaganda\"\n                 )"
  },
  {
    "objectID": "semanas/Aula07.1.html#matriz-de-dispersão",
    "href": "semanas/Aula07.1.html#matriz-de-dispersão",
    "title": "Regressão Linear",
    "section": "Matriz de dispersão",
    "text": "Matriz de dispersão\n\nlibrary(psych)\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-mod-regressão",
    "href": "semanas/Aula07.1.html#o-mod-regressão",
    "title": "Regressão Linear",
    "section": "1o Mod Regressão",
    "text": "1o Mod Regressão\n\nmod1 <- lm( Vendas ~ TV, data = conj_treino)\nnames(mod1)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoeflinear <- mod1$coefficients[1]\ncoefang <- mod1$coefficients[2]\nsummary(mod1)\n\n\nCall:\nlm(formula = Vendas ~ TV, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6383 -1.9426 -0.0565  1.7033  7.5277 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.929269   0.598642   11.57   <2e-16 ***\nTV          0.046471   0.003471   13.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.167 on 117 degrees of freedom\nMultiple R-squared:  0.605, Adjusted R-squared:  0.6017 \nF-statistic: 179.2 on 1 and 117 DF,  p-value: < 2.2e-16\n\nggplot(conj_treino, aes(x=TV, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representação-do-1o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representação-do-1o-modelo",
    "title": "Regressão Linear",
    "section": "Outra forma de representação do 1o Modelo",
    "text": "Outra forma de representação do 1o Modelo\n\nlibrary(car)\nscatterplot(Vendas ~ TV, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#extraindo-informações-do-1o-ajuste",
    "href": "semanas/Aula07.1.html#extraindo-informações-do-1o-ajuste",
    "title": "Regressão Linear",
    "section": "Extraindo informações do 1o ajuste",
    "text": "Extraindo informações do 1o ajuste\n\nsummary(mod1)$sigma\n\n[1] 3.167319\n\nsummary(mod1)$r.squared\n\n[1] 0.605027"
  },
  {
    "objectID": "semanas/Aula07.1.html#intervalo-de-confiança",
    "href": "semanas/Aula07.1.html#intervalo-de-confiança",
    "title": "Regressão Linear",
    "section": "Intervalo de Confiança",
    "text": "Intervalo de Confiança\n\nsummary(mod1)\n\n\nCall:\nlm(formula = Vendas ~ TV, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6383 -1.9426 -0.0565  1.7033  7.5277 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.929269   0.598642   11.57   <2e-16 ***\nTV          0.046471   0.003471   13.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.167 on 117 degrees of freedom\nMultiple R-squared:  0.605, Adjusted R-squared:  0.6017 \nF-statistic: 179.2 on 1 and 117 DF,  p-value: < 2.2e-16\n\nconfint(mod1)\n\n                 2.5 %     97.5 %\n(Intercept) 5.74368904 8.11484821\nTV          0.03959625 0.05334545"
  },
  {
    "objectID": "semanas/Aula07.1.html#anova",
    "href": "semanas/Aula07.1.html#anova",
    "title": "Regressão Linear",
    "section": "Anova",
    "text": "Anova\n\nanova(mod1)\n\nAnalysis of Variance Table\n\nResponse: Vendas\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nTV          1 1798.0 1797.95  179.22 < 2.2e-16 ***\nResiduals 117 1173.7   10.03                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.1.html#previsões",
    "href": "semanas/Aula07.1.html#previsões",
    "title": "Regressão Linear",
    "section": "Previsões",
    "text": "Previsões\n\n#?predict\npredict(mod1, data.frame(TV=c(50, 150, 250)), interval = \"prediction\")\n\n        fit       lwr      upr\n1  9.252811  2.915787 15.58983\n2 13.899896  7.600884 20.19891\n3 18.546982 12.211175 24.88279"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste",
    "title": "Regressão Linear",
    "section": "Calculando o erro padrão do resíduo com amostra de teste",
    "text": "Calculando o erro padrão do resíduo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod1, conj_teste)) ^ 2)) \n\n[1] 3.41382"
  },
  {
    "objectID": "semanas/Aula07.1.html#análise-do-modelo",
    "href": "semanas/Aula07.1.html#análise-do-modelo",
    "title": "Regressão Linear",
    "section": "Análise do modelo",
    "text": "Análise do modelo\n\nplot(mod1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#análise-do-modelo-2",
    "href": "semanas/Aula07.1.html#análise-do-modelo-2",
    "title": "Regressão Linear",
    "section": "Análise do modelo 2",
    "text": "Análise do modelo 2\n\nlibrary(performance)\ncheck_model(mod1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-modelo-de-regressão",
    "href": "semanas/Aula07.1.html#o-modelo-de-regressão",
    "title": "Regressão Linear",
    "section": "2o Modelo de Regressão",
    "text": "2o Modelo de Regressão\n\nmod2 <- lm( Vendas ~ Radio, data = conj_treino)\ncoeflinear <- mod2$coefficients[1]\ncoefang <- mod2$coefficients[2]\nsummary(mod2)\n\n\nCall:\nlm(formula = Vendas ~ Radio, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.396  -1.851   0.675   2.522   7.451 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  9.22746    0.64377  14.333  < 2e-16 ***\nRadio        0.22144    0.02515   8.806 1.38e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.908 on 117 degrees of freedom\nMultiple R-squared:  0.3986,    Adjusted R-squared:  0.3935 \nF-statistic: 77.55 on 1 and 117 DF,  p-value: 1.384e-14\n\nggplot(propaganda, aes(x=Radio, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representação-do-2o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representação-do-2o-modelo",
    "title": "Regressão Linear",
    "section": "Outra forma de representação do 2o Modelo",
    "text": "Outra forma de representação do 2o Modelo\n\nscatterplot(Vendas ~ Radio, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste-1",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste-1",
    "title": "Regressão Linear",
    "section": "Calculando o erro padrão do resíduo com amostra de teste",
    "text": "Calculando o erro padrão do resíduo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod2, conj_teste)) ^ 2)) \n\n[1] 4.808117"
  },
  {
    "objectID": "semanas/Aula07.1.html#análise-de-resíduos",
    "href": "semanas/Aula07.1.html#análise-de-resíduos",
    "title": "Regressão Linear",
    "section": "Análise de Resíduos",
    "text": "Análise de Resíduos\n\ncheck_model(mod2)"
  },
  {
    "objectID": "semanas/Aula07.1.html#o-modelo-de-regressão-1",
    "href": "semanas/Aula07.1.html#o-modelo-de-regressão-1",
    "title": "Regressão Linear",
    "section": "3o Modelo de Regressão",
    "text": "3o Modelo de Regressão\n\nmod3 <- lm( Vendas ~ Jornal, data = conj_treino)\ncoeflinear <- mod3$coefficients[1]\ncoefang <- mod3$coefficients[2]\nsummary(mod3)\n\n\nCall:\nlm(formula = Vendas ~ Jornal, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.0331  -3.2104  -0.8491   3.0389  13.0002 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 12.08457    0.80845  14.948  < 2e-16 ***\nJornal       0.06305    0.02290   2.753  0.00685 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.884 on 117 degrees of freedom\nMultiple R-squared:  0.06084,   Adjusted R-squared:  0.05281 \nF-statistic: 7.579 on 1 and 117 DF,  p-value: 0.006847\n\nggplot(propaganda, aes(x=Jornal, y=Vendas)) +\n    geom_point() +\n    geom_abline(slope = coefang,intercept = coeflinear, color=\"blue\" ) + \n    geom_hline(yintercept=coeflinear, linetype=\"dashed\", color = \"red\")"
  },
  {
    "objectID": "semanas/Aula07.1.html#outra-forma-de-representação-do-3o-modelo",
    "href": "semanas/Aula07.1.html#outra-forma-de-representação-do-3o-modelo",
    "title": "Regressão Linear",
    "section": "Outra forma de representação do 3o Modelo",
    "text": "Outra forma de representação do 3o Modelo\n\nscatterplot(Vendas ~ Jornal, data = conj_treino, smooth=F, id.n=1)"
  },
  {
    "objectID": "semanas/Aula07.1.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste-2",
    "href": "semanas/Aula07.1.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste-2",
    "title": "Regressão Linear",
    "section": "Calculando o erro padrão do resíduo com amostra de teste",
    "text": "Calculando o erro padrão do resíduo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod3, conj_teste)) ^ 2)) \n\n[1] 5.38693"
  },
  {
    "objectID": "semanas/Aula07.1.html#análise-de-resíduos-1",
    "href": "semanas/Aula07.1.html#análise-de-resíduos-1",
    "title": "Regressão Linear",
    "section": "Análise de Resíduos",
    "text": "Análise de Resíduos\n\ncheck_model(mod3)"
  },
  {
    "objectID": "semanas/Aula07.2.html",
    "href": "semanas/Aula07.2.html",
    "title": "Regressão Linear Múltipla",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "semanas/Aula07.2.html#dados-de-propaganda",
    "href": "semanas/Aula07.2.html#dados-de-propaganda",
    "title": "Regressão Linear Múltipla",
    "section": "Dados de propaganda",
    "text": "Dados de propaganda\nO conjunto de dados contém estatísticas sobre as vendas de um produto em 200 diferentes mercados, juntamente com orçamentos publicitários em cada um desses mercados, para diferentes canais de mídia: TV, rádio e jornal. As vendas estão em milhares de unidades e o orçamento está em milhares de dólares.\n\nlibrary(readxl)\npropaganda <- read_excel(\"Propaganda.xlsx\")\nsummary(propaganda)\n\n       TV             Radio          Newspaper          Sales      \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00"
  },
  {
    "objectID": "semanas/Aula07.2.html#renomeando",
    "href": "semanas/Aula07.2.html#renomeando",
    "title": "Regressão Linear Múltipla",
    "section": "Renomeando",
    "text": "Renomeando\n\npropaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)"
  },
  {
    "objectID": "semanas/Aula07.2.html#sumario",
    "href": "semanas/Aula07.2.html#sumario",
    "title": "Regressão Linear Múltipla",
    "section": "Sumario",
    "text": "Sumario\n\nsummary(propaganda)\n\n       TV             Radio            Jornal           Vendas     \n Min.   :  0.70   Min.   : 0.000   Min.   :  0.30   Min.   : 1.60  \n 1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75   1st Qu.:10.38  \n Median :149.75   Median :22.900   Median : 25.75   Median :12.90  \n Mean   :147.04   Mean   :23.264   Mean   : 30.55   Mean   :14.02  \n 3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10   3rd Qu.:17.40  \n Max.   :296.40   Max.   :49.600   Max.   :114.00   Max.   :27.00  \n\nnrow(propaganda)\n\n[1] 200"
  },
  {
    "objectID": "semanas/Aula07.2.html#linhas-inicias",
    "href": "semanas/Aula07.2.html#linhas-inicias",
    "title": "Regressão Linear Múltipla",
    "section": "Linhas inicias",
    "text": "Linhas inicias\n\nlibrary(gt)\ngt(head(propaganda, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    44.5\n39.3\n45.1\n10.4\n    17.2\n45.9\n69.3\n9.3\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    8.7\n48.9\n75.0\n7.2\n    57.5\n32.8\n23.5\n11.8\n    120.2\n19.6\n11.6\n13.2\n    8.6\n2.1\n1.0\n4.8\n    199.8\n2.6\n21.2\n10.6"
  },
  {
    "objectID": "semanas/Aula07.2.html#criando-amostra-de-treino-e-teste",
    "href": "semanas/Aula07.2.html#criando-amostra-de-treino-e-teste",
    "title": "Regressão Linear Múltipla",
    "section": "Criando amostra de treino e teste",
    "text": "Criando amostra de treino e teste\n\nlibrary(caret)\nset.seed(21)\ny <- propaganda$Vendas\nindice_teste <- createDataPartition(y, times = 1, p = 0.40, list = FALSE)\n\nconj_treino <- propaganda %>% slice(-indice_teste)\nconj_teste <- propaganda %>% slice(indice_teste)\n\nstr(conj_treino)\n\ntibble [119 × 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:119] 230.1 151.5 180.8 199.8 66.1 ...\n $ Radio : num [1:119] 37.8 41.3 10.8 2.6 5.8 35.1 7.6 47.7 20.5 23.9 ...\n $ Jornal: num [1:119] 69.2 58.5 58.4 21.2 24.2 65.9 7.2 52.9 18.3 19.1 ...\n $ Vendas: num [1:119] 22.1 18.5 12.9 10.6 8.6 9.2 9.7 22.4 11.3 14.6 ...\n\nstr(conj_teste)\n\ntibble [81 × 4] (S3: tbl_df/tbl/data.frame)\n $ TV    : num [1:81] 44.5 17.2 8.7 57.5 120.2 ...\n $ Radio : num [1:81] 39.3 45.9 48.9 32.8 19.6 2.1 24 32.9 36.6 39.6 ...\n $ Jornal: num [1:81] 45.1 69.3 75 23.5 11.6 1 4 46 114 55.8 ...\n $ Vendas: num [1:81] 10.4 9.3 7.2 11.8 13.2 4.8 17.4 19 12.5 24.4 ...\n\ngt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      TV\n      Radio\n      Jornal\n      Vendas\n    \n  \n  \n    230.1\n37.8\n69.2\n22.1\n    151.5\n41.3\n58.5\n18.5\n    180.8\n10.8\n58.4\n12.9\n    199.8\n2.6\n21.2\n10.6\n    66.1\n5.8\n24.2\n8.6\n    23.8\n35.1\n65.9\n9.2\n    97.5\n7.6\n7.2\n9.7\n    195.4\n47.7\n52.9\n22.4\n    69.2\n20.5\n18.3\n11.3\n    147.3\n23.9\n19.1\n14.6"
  },
  {
    "objectID": "semanas/Aula07.2.html#regressão-simples",
    "href": "semanas/Aula07.2.html#regressão-simples",
    "title": "Regressão Linear Múltipla",
    "section": "Regressão Simples",
    "text": "Regressão Simples\n\nmod1 <- lm( Vendas ~ TV, data = conj_treino)\nmod2 <- lm( Vendas ~ Radio, data = conj_treino)\nmod3 <- lm( Vendas ~ Jornal, data = conj_treino)"
  },
  {
    "objectID": "semanas/Aula07.2.html#a-regressão-multipla",
    "href": "semanas/Aula07.2.html#a-regressão-multipla",
    "title": "Regressão Linear Múltipla",
    "section": "1a Regressão Multipla",
    "text": "1a Regressão Multipla\n\nlibrary(car)\nscatterplotMatrix(conj_treino)\n\n\n\nmod4 <- lm( Vendas ~ TV + Radio + Jornal, data = conj_treino)\nsummary(mod4)\n\n\nCall:\nlm(formula = Vendas ~ TV + Radio + Jornal, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.1595 -0.6961  0.2676  1.0298  2.5871 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.268910   0.391828   8.343 1.81e-13 ***\nTV          0.042705   0.001776  24.039  < 2e-16 ***\nRadio       0.186439   0.011458  16.272  < 2e-16 ***\nJornal      0.008931   0.008292   1.077    0.284    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.606 on 115 degrees of freedom\nMultiple R-squared:  0.9002,    Adjusted R-squared:  0.8976 \nF-statistic: 345.9 on 3 and 115 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.2.html#a-regressao-multipla",
    "href": "semanas/Aula07.2.html#a-regressao-multipla",
    "title": "Regressão Linear Múltipla",
    "section": "2a Regressao Multipla",
    "text": "2a Regressao Multipla\n\nmod5 <- lm( Vendas ~ TV + Radio, data = conj_treino)\nsummary(mod5)\n\n\nCall:\nlm(formula = Vendas ~ TV + Radio, data = conj_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.4585 -0.6886  0.1687  1.0799  2.5529 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.441076   0.357985   9.612   <2e-16 ***\nTV          0.042575   0.001774  24.005   <2e-16 ***\nRadio       0.191607   0.010412  18.402   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.607 on 116 degrees of freedom\nMultiple R-squared:  0.8992,    Adjusted R-squared:  0.8975 \nF-statistic: 517.5 on 2 and 116 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.2.html#confirmando-o-teste-t-com-o-teste-f-anova",
    "href": "semanas/Aula07.2.html#confirmando-o-teste-t-com-o-teste-f-anova",
    "title": "Regressão Linear Múltipla",
    "section": "Confirmando o teste t com o teste F (ANOVA)",
    "text": "Confirmando o teste t com o teste F (ANOVA)\n\nanova(mod5, mod4)\n\nAnalysis of Variance Table\n\nModel 1: Vendas ~ TV + Radio\nModel 2: Vendas ~ TV + Radio + Jornal\n  Res.Df    RSS Df Sum of Sq    F Pr(>F)\n1    116 299.47                         \n2    115 296.48  1    2.9906 1.16 0.2837"
  },
  {
    "objectID": "semanas/Aula07.2.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste",
    "href": "semanas/Aula07.2.html#calculando-o-erro-padrão-do-resíduo-com-amostra-de-teste",
    "title": "Regressão Linear Múltipla",
    "section": "Calculando o erro padrão do resíduo com amostra de teste",
    "text": "Calculando o erro padrão do resíduo com amostra de teste\n\nsqrt(mean((conj_teste$Vendas - predict(mod5, conj_teste)) ^ 2)) \n\n[1] 1.846764"
  },
  {
    "objectID": "semanas/Aula07.2.html#comparando-com-a-melhor-regressão-simples",
    "href": "semanas/Aula07.2.html#comparando-com-a-melhor-regressão-simples",
    "title": "Regressão Linear Múltipla",
    "section": "Comparando com a melhor regressão simples",
    "text": "Comparando com a melhor regressão simples\n\n## Modelo com somente TV\nsummary(mod1)$sigma\n\n[1] 3.167319\n\nsummary(mod1)$r.squared\n\n[1] 0.605027\n\nsqrt(mean((conj_teste$Vendas - predict(mod1, conj_teste)) ^ 2))\n\n[1] 3.41382\n\n## Modelo com TV e Jornal\nsummary(mod5)$sigma\n\n[1] 1.606744\n\nsummary(mod5)$adj.r.squared\n\n[1] 0.8974883\n\nsqrt(mean((conj_teste$Vendas - predict(mod5, conj_teste)) ^ 2))\n\n[1] 1.846764"
  },
  {
    "objectID": "semanas/Aula07.2.html#análise-do-modelo-1",
    "href": "semanas/Aula07.2.html#análise-do-modelo-1",
    "title": "Regressão Linear Múltipla",
    "section": "Análise do Modelo 1",
    "text": "Análise do Modelo 1\n\nlibrary(performance)\ncheck_model(mod5)"
  },
  {
    "objectID": "semanas/Aula07.2.html#análise-do-modelo-2",
    "href": "semanas/Aula07.2.html#análise-do-modelo-2",
    "title": "Regressão Linear Múltipla",
    "section": "Análise do Modelo 2",
    "text": "Análise do Modelo 2\n\nplot(mod5)"
  },
  {
    "objectID": "semanas/Aula07.2.html#análise-do-modelo-3",
    "href": "semanas/Aula07.2.html#análise-do-modelo-3",
    "title": "Regressão Linear Múltipla",
    "section": "Análise do Modelo 3",
    "text": "Análise do Modelo 3\nPara o gráfico de resíduos versus valores ajustados, podemos usar um teste chamado teste de Tukey de não aditividade (Tukey, 1949), ele é obtido adicionando os quadrados dos valores ajustados ao modelo e reajustando. O valor p para o teste de Tukey é obtido comparando a estatística de teste para a distribuição padrão-normal. O teste confirma a visível impressão de curvatura no gráfico residual, reforçando ainda mais a conclusão que o modelo não é adequado.\n\nlibrary(car)\nresidualPlots(mod5)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nTV           -4.8383        4.102e-06 ***\nRadio         1.9290           0.0562 .  \nTukey test    6.4114        1.442e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.2.html#análise-do-modelo-com-car",
    "href": "semanas/Aula07.2.html#análise-do-modelo-com-car",
    "title": "Regressão Linear Múltipla",
    "section": "Análise do Modelo com car",
    "text": "Análise do Modelo com car\n\nlibrary(car)\nvif(mod5)\n\n      TV    Radio \n1.014454 1.014454"
  },
  {
    "objectID": "semanas/Aula07.2.html#tentando-corrigir-o-problema",
    "href": "semanas/Aula07.2.html#tentando-corrigir-o-problema",
    "title": "Regressão Linear Múltipla",
    "section": "Tentando corrigir o problema",
    "text": "Tentando corrigir o problema\n\nsummary(p1 <- powerTransform(Vendas ~ TV + Radio, data=conj_treino))\n\nbcPower Transformation to Normality \n   Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nY1    0.9937           1       0.8018       1.1856\n\nLikelihood ratio test that transformation parameter is equal to 0\n (log transformation)\n                          LRT df       pval\nLR test, lambda = (0) 111.042  1 < 2.22e-16\n\nLikelihood ratio test that no transformation is needed\n                              LRT df    pval\nLR test, lambda = (1) 0.004149754  1 0.94864\n\nsummary(p2 <- powerTransform(cbind(TV, Radio) ~1 , data=conj_treino))\n\nbcPower Transformations to Multinormality \n      Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nTV       0.7692         1.0       0.5311       1.0073\nRadio    0.5349         0.5       0.3429       0.7269\n\nLikelihood ratio test that transformation parameters are equal to 0\n (all log transformations)\n                            LRT df       pval\nLR test, lambda = (0 0) 102.457  2 < 2.22e-16\n\nLikelihood ratio test that no transformations are needed\n                           LRT df       pval\nLR test, lambda = (1 1) 22.189  2 1.5196e-05\n\nmod6 <- lm( log(Vendas) ~ TV + Radio, data = conj_treino)\nsummary(mod6)\n\n\nCall:\nlm(formula = log(Vendas) ~ TV + Radio, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.77994 -0.05255  0.04368  0.10055  0.17353 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.791156   0.043994  40.713  < 2e-16 ***\nTV          0.003492   0.000218  16.022  < 2e-16 ***\nRadio       0.011524   0.001280   9.006 5.04e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1975 on 116 degrees of freedom\nMultiple R-squared:  0.765, Adjusted R-squared:  0.761 \nF-statistic: 188.8 on 2 and 116 DF,  p-value: < 2.2e-16\n\nresidualPlots(mod6)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nTV           -6.8943        3.092e-10 ***\nRadio        -0.2563           0.7982    \nTukey test   -0.5761           0.5646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "semanas/Aula07.2.html#dado-que-parece-outlier-e-é-um-valor-influente",
    "href": "semanas/Aula07.2.html#dado-que-parece-outlier-e-é-um-valor-influente",
    "title": "Regressão Linear Múltipla",
    "section": "Dado que parece outlier e é um valor influente",
    "text": "Dado que parece outlier e é um valor influente\nA função OutlierTest () no pacote do car localiza o maior resíduo studentizado em valor absoluto e calcula o teste t com correção de Bonferroni. O testes de Outlier utiliza uma distribuição t para testar se o maior valor do residuo studentizado do modelo é estatisticamente diferente das outras observações. Um valor p significativo indica um outlier extremo que merece um exame mais aprofundado.\n\noutlierTest(mod6)\n\n    rstudent unadjusted p-value Bonferroni p\n83 -18.13798         1.5879e-35   1.8896e-33\n\nconj_treino[83,]\n\n# A tibble: 1 × 4\n     TV Radio Jornal Vendas\n  <dbl> <dbl>  <dbl>  <dbl>\n1   0.7  39.6    8.7    1.6"
  },
  {
    "objectID": "semanas/Aula07.3.html",
    "href": "semanas/Aula07.3.html",
    "title": "Seleção de Modelos",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)\nlibrary(leaps)"
  },
  {
    "objectID": "semanas/Aula07.3.html#carregando-os-dados",
    "href": "semanas/Aula07.3.html#carregando-os-dados",
    "title": "Seleção de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\ndata(Boston)\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nsummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\nnrow(Boston)\n\n[1] 506"
  },
  {
    "objectID": "semanas/Aula07.3.html#explicação-das-variáveis",
    "href": "semanas/Aula07.3.html#explicação-das-variáveis",
    "title": "Seleção de Modelos",
    "section": "Explicação das variáveis",
    "text": "Explicação das variáveis\n\n# Boston Database\n# \n# 1) crim - taxa de criminalidade per capita por cidade.\n# \n# 2) zn - proporção de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n# 3) indus - proporção de negócios não comerciais por acres e por cidade.\n# \n# 4) chas - variável dummy do Rio Charles (= 1 se próximo do rio; 0 de outra forma).\n# \n# 5) nox - concentração de óxido de nitrogênio (partes por 10 milhões).\n# \n# 6) rm - número médio de cômodos por habitação\n# \n# 7) age - proporção da unidade ocupadas pelos proprietários construídas antes 1940.\n# \n# 8) dis - média ponderada das distâncias dos 5 pontos de emprego em Boston.\n# \n# 9) rad - indice de acessibilidade das avenidas radiais.\n# \n# 10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n# 11) ptratio - razão aluno-professor por cidade.\n# \n# 12) black - 1000(Bk−0.63)21000(Bk−0.63)2 proporção de negros por cidade.\n# \n# 13) lstat - percentual de baixo status da população.\n# \n# 14) medv - valor mediano das casas ocupadas pelos proprietário em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.3.html#conjunto-de-teste-e-treino",
    "href": "semanas/Aula07.3.html#conjunto-de-teste-e-treino",
    "title": "Seleção de Modelos",
    "section": "Conjunto de teste e treino",
    "text": "Conjunto de teste e treino\n\nlibrary(caret)\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_teste <- Boston %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   403 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nstr(conj_teste)\n\n'data.frame':   103 obs. of  14 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ rad    : int  5 4 4 4 4 4 4 3 3 3 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ...\n\ngt::gt(head(conj_treino, 10))\n\n\n\n\n\n  \n  \n    \n      crim\n      zn\n      indus\n      chas\n      nox\n      rm\n      age\n      dis\n      rad\n      tax\n      ptratio\n      black\n      lstat\n      medv\n    \n  \n  \n    0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n    0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n    0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n    0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n    0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n    0.02985\n0.0\n2.18\n0\n0.458\n6.430\n58.7\n6.0622\n3\n222\n18.7\n394.12\n5.21\n28.7\n    0.08829\n12.5\n7.87\n0\n0.524\n6.012\n66.6\n5.5605\n5\n311\n15.2\n395.60\n12.43\n22.9\n    0.14455\n12.5\n7.87\n0\n0.524\n6.172\n96.1\n5.9505\n5\n311\n15.2\n396.90\n19.15\n27.1\n    0.17004\n12.5\n7.87\n0\n0.524\n6.004\n85.9\n6.5921\n5\n311\n15.2\n386.71\n17.10\n18.9\n    0.22489\n12.5\n7.87\n0\n0.524\n6.377\n94.3\n6.3467\n5\n311\n15.2\n392.52\n20.45\n15.0"
  },
  {
    "objectID": "semanas/Aula07.3.html#matriz-de-correlação",
    "href": "semanas/Aula07.3.html#matriz-de-correlação",
    "title": "Seleção de Modelos",
    "section": "Matriz de correlação",
    "text": "Matriz de correlação\n\nlibrary(corrplot)\nmat_corr <- cor(conj_treino)\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula07.3.html#matriz-de-dispersão",
    "href": "semanas/Aula07.3.html#matriz-de-dispersão",
    "title": "Seleção de Modelos",
    "section": "Matriz de dispersão",
    "text": "Matriz de dispersão\n\nlibrary(psych)\npairs.panels(conj_treino,\n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )"
  },
  {
    "objectID": "semanas/Aula07.3.html#métodos-de-seleção-de-modelo",
    "href": "semanas/Aula07.3.html#métodos-de-seleção-de-modelo",
    "title": "Seleção de Modelos",
    "section": "Métodos de seleção de modelo",
    "text": "Métodos de seleção de modelo\n\n## Best Subset sem definir o número máx de subsets a ser avaliado\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino)\nsummary(ajusreg.comp)\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 ) \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n\n## Não testou todas as combinações possíveis"
  },
  {
    "objectID": "semanas/Aula07.3.html#nvmax13",
    "href": "semanas/Aula07.3.html#nvmax13",
    "title": "Seleção de Modelos",
    "section": "nvmax=13",
    "text": "nvmax=13\n\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=13)\nsumario.reg <- summary(ajusreg.comp)\nsumario.reg\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: exhaustive\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nnames(sumario.reg)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\""
  },
  {
    "objectID": "semanas/Aula07.3.html#avaliando-os-modelos",
    "href": "semanas/Aula07.3.html#avaliando-os-modelos",
    "title": "Seleção de Modelos",
    "section": "Avaliando os modelos",
    "text": "Avaliando os modelos\n\n## Os modelos vão ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 11\n\npoints(11,sumario.reg$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste",
    "title": "Seleção de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.comp,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#forward-stepwise-passo-a-passo-à-frente",
    "href": "semanas/Aula07.3.html#forward-stepwise-passo-a-passo-à-frente",
    "title": "Seleção de Modelos",
    "section": "Forward Stepwise (passo a passo à frente)",
    "text": "Forward Stepwise (passo a passo à frente)\n\najusreg.fwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd <- summary(ajusreg.fwd)\nsumario.reg.fwd \n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"forward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: forward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nwhich.min(sumario.reg.fwd$cp)\n\n[1] 11\n\nplot(sumario.reg.fwd$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-1",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-1",
    "title": "Seleção de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.fwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#backward-stepwise-passo-a-passo-atrás",
    "href": "semanas/Aula07.3.html#backward-stepwise-passo-a-passo-atrás",
    "title": "Seleção de Modelos",
    "section": "Backward Stepwise (passo a passo atrás)",
    "text": "Backward Stepwise (passo a passo atrás)\n\najusreg.bwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"backward\")\nsumario.reg.bwd <- summary(ajusreg.bwd)\nsumario.reg.bwd\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"backward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: backward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nwhich.min(sumario.reg.bwd$cp)\n\n[1] 11\n\nplot(sumario.reg.bwd$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\npoints(11,sumario.reg.bwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-2",
    "href": "semanas/Aula07.3.html#como-extrair-detalhes-do-ajuste-2",
    "title": "Seleção de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\ncoef(ajusreg.bwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#comportamento-dos-erros-de-treino-e-teste",
    "href": "semanas/Aula07.3.html#comportamento-dos-erros-de-treino-e-teste",
    "title": "Seleção de Modelos",
    "section": "Comportamento dos erros de treino e teste",
    "text": "Comportamento dos erros de treino e teste\n\n## Codigo original de T. Hastie\nreg.fwd <- regsubsets(medv ~ . ,data=conj_treino,nvmax=13, method=\"forward\")\nval.erro <- rep(NA,13)\nx.teste <- model.matrix(medv~.,data=conj_teste)\nfor(i in 1:13){\n  coefi <- coef(reg.fwd,id=i)\n  pred <- x.teste[,names(coefi)]%*%coefi\n  val.erro[i] <- mean((conj_teste$medv - pred)^2)\n}\nplot(sqrt(val.erro),ylab=\"Raiz do EQM\",ylim=c(4,8),pch=19,type=\"b\")\npoints(sqrt(reg.fwd$rss[-1]/403),col=\"blue\",pch=19,type=\"b\")\nlegend(\"topright\",legend=c(\"Treino\",\"Teste\"),col=c(\"blue\",\"black\"),pch=19)"
  },
  {
    "objectID": "semanas/Aula07.3.html#testando-outra-estatística-de-seleção-de-modelos---bic",
    "href": "semanas/Aula07.3.html#testando-outra-estatística-de-seleção-de-modelos---bic",
    "title": "Seleção de Modelos",
    "section": "Testando outra estatística de seleção de modelos - BIC",
    "text": "Testando outra estatística de seleção de modelos - BIC\n\najusreg.fwd1 <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd1 <- summary(ajusreg.fwd1)\nnames(sumario.reg.fwd1)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   \n\nwhich.min(sumario.reg.fwd1$bic)\n\n[1] 7\n\nplot(sumario.reg.fwd1$bic,xlab=\"Número de Variáveis\",ylab=\"BIC\")\npoints(7,sumario.reg.fwd1$bic[7],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.fwd1,7)  \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735"
  },
  {
    "objectID": "semanas/Aula07.3.html#usando-o-cp-novamente",
    "href": "semanas/Aula07.3.html#usando-o-cp-novamente",
    "title": "Seleção de Modelos",
    "section": "Usando o Cp novamente",
    "text": "Usando o Cp novamente\n\nwhich.min(sumario.reg.fwd1$cp)\n\n[1] 11\n\nplot(sumario.reg.fwd1$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd1$cp[11],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.fwd1,11)\n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3.html#comparando-os-dois-modelos-com-o-lm",
    "href": "semanas/Aula07.3.html#comparando-os-dois-modelos-com-o-lm",
    "title": "Seleção de Modelos",
    "section": "Comparando os dois modelos com o lm()",
    "text": "Comparando os dois modelos com o lm()\n\n## Usando o lm para ajustar o modelo com as variáveis selecionadas pelo BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nmod_cp <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp)\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1857  -2.8830  -0.5641   1.8709  25.9074 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  24.119556   5.661887   4.260 2.56e-05 ***\ncrim         -0.059121   0.038751  -1.526 0.127902    \nzn            0.033951   0.015207   2.233 0.026139 *  \nchas          3.459703   0.995635   3.475 0.000568 ***\nnox         -17.228617   3.807289  -4.525 8.02e-06 ***\nrm            5.108916   0.466926  10.942  < 2e-16 ***\ndis          -1.272748   0.203301  -6.260 1.01e-09 ***\nrad           0.252036   0.067390   3.740 0.000212 ***\ntax          -0.010155   0.003556  -2.856 0.004525 ** \nptratio      -0.947329   0.141436  -6.698 7.38e-11 ***\nblack         0.012962   0.002822   4.593 5.90e-06 ***\nlstat        -0.396034   0.054069  -7.325 1.38e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.554 on 391 degrees of freedom\nMultiple R-squared:  0.7618,    Adjusted R-squared:  0.7551 \nF-statistic: 113.7 on 11 and 391 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3.html#eliminando-a-variável-não-significativa",
    "href": "semanas/Aula07.3.html#eliminando-a-variável-não-significativa",
    "title": "Seleção de Modelos",
    "section": "Eliminando a variável não significativa",
    "text": "Eliminando a variável não significativa\n\nmod_cp2 <- lm(medv ~ zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp2)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + tax + \n    ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1471  -2.7317  -0.5389   1.9772  25.9698 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  22.884672   5.613214   4.077 5.53e-05 ***\nzn            0.031594   0.015154   2.085 0.037726 *  \nchas          3.524816   0.996402   3.538 0.000452 ***\nnox         -16.721605   3.799175  -4.401 1.39e-05 ***\nrm            5.183515   0.465145  11.144  < 2e-16 ***\ndis          -1.231499   0.201836  -6.101 2.52e-09 ***\nrad           0.218320   0.063772   3.423 0.000683 ***\ntax          -0.009827   0.003556  -2.764 0.005984 ** \nptratio      -0.938621   0.141560  -6.631 1.11e-10 ***\nblack         0.013799   0.002773   4.976 9.72e-07 ***\nlstat        -0.406190   0.053749  -7.557 2.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.562 on 392 degrees of freedom\nMultiple R-squared:  0.7604,    Adjusted R-squared:  0.7543 \nF-statistic: 124.4 on 10 and 392 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3.html#avaliando-colinearidade",
    "href": "semanas/Aula07.3.html#avaliando-colinearidade",
    "title": "Seleção de Modelos",
    "section": "Avaliando Colinearidade",
    "text": "Avaliando Colinearidade\nUma investigação minuciosa da multicollinearidade envolverá a análise do valor do \\(R^2\\) que resulta da regressão de cada uma das variáveis explicativas contra todas as outras. A relação entre as variáveis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacionário da variância (FIV) ou Variance Inflation Factor (VIF). Seja \\(Rj~^{2}\\) o quadrado do coeficiente de correlação múltipla que resulta quando a variável explicativa \\(Xj~\\) é ajustada contra todas as outras variáveis explicativas. Então o vif para \\(Xj~\\) é \\(VIFj = 1 / (1-Rj~^{2})\\)\nA regra geral é que vifs superiores a 4 justificam novas investigações, enquanto VIFs superiores a 10 são sinais de multicollinearidade grave que requerem correção.\n\nlibrary(car)\nvif(mod_cp2)\n\n      zn     chas      nox       rm      dis      rad      tax  ptratio \n2.128862 1.076888 3.707463 2.032934 3.357506 6.005229 6.999822 1.796214 \n   black    lstat \n1.388299 3.010108 \n\n## Vamos eliminar tax e ver o que acontece\nmod_cp3 <- lm(medv ~ zn + chas + nox + rm + dis + rad + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp3)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.6480  -2.9158  -0.5013   1.9274  25.8537 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  21.606433   5.641174   3.830 0.000149 ***\nzn            0.021779   0.014856   1.466 0.143439    \nchas          3.623029   1.004143   3.608 0.000348 ***\nnox         -18.864099   3.750520  -5.030 7.48e-07 ***\nrm            5.337321   0.465687  11.461  < 2e-16 ***\ndis          -1.150869   0.201396  -5.714 2.18e-08 ***\nrad           0.079897   0.039806   2.007 0.045417 *  \nptratio      -1.016641   0.139883  -7.268 1.99e-12 ***\nblack         0.014071   0.002794   5.035 7.28e-07 ***\nlstat        -0.411503   0.054166  -7.597 2.24e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.6 on 393 degrees of freedom\nMultiple R-squared:  0.7557,    Adjusted R-squared:  0.7501 \nF-statistic: 135.1 on 9 and 393 DF,  p-value: < 2.2e-16\n\nvif(mod_cp3)\n\n      zn     chas      nox       rm      dis      rad  ptratio    black \n2.011936 1.075519 3.553096 2.003832 3.287355 2.300918 1.724780 1.386548 \n   lstat \n3.006257"
  },
  {
    "objectID": "semanas/Aula07.3.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "href": "semanas/Aula07.3.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "title": "Seleção de Modelos",
    "section": "Testando os dois modelos com o conjunto de teste",
    "text": "Testando os dois modelos com o conjunto de teste\n\n# Modelo com base no Cp\nsummary(mod_cp3)$sigma\n\n[1] 4.600016\n\nsummary(mod_cp3)$adj.r.squared\n\n[1] 0.7501409\n\nsqrt(mean((conj_teste$medv - predict(mod_cp3, conj_teste)) ^ 2))\n\n[1] 5.918251\n\n# Modelo com base no BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)$sigma\n\n[1] 4.630994\n\nsummary(mod_bic)$adj.r.squared\n\n[1] 0.7467643\n\nsqrt(mean((conj_teste$medv - predict(mod_bic, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula07.3A.html#carregando-bibliotecas",
    "href": "semanas/Aula07.3A.html#carregando-bibliotecas",
    "title": "Seleção de Modelos",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nCodelibrary(MASS)\nlibrary(tidyverse)\nlibrary(leaps)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#carregando-os-dados",
    "href": "semanas/Aula07.3A.html#carregando-os-dados",
    "title": "Seleção de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\nCodedata(Boston)\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nCodesummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\nCodenrow(Boston)\n\n[1] 506"
  },
  {
    "objectID": "semanas/Aula07.3A.html#explicação-das-variáveis",
    "href": "semanas/Aula07.3A.html#explicação-das-variáveis",
    "title": "Seleção de Modelos",
    "section": "Explicação das variáveis",
    "text": "Explicação das variáveis\n\nCode# Boston Database\n# \n# 1) crim - taxa de criminalidade per capita por cidade.\n# \n# 2) zn - proporção de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n# 3) indus - proporção de negócios não comerciais por acres e por cidade.\n# \n# 4) chas - variável dummy do Rio Charles (= 1 se próximo do rio; 0 de outra forma).\n# \n# 5) nox - concentração de óxido de nitrogênio (partes por 10 milhões).\n# \n# 6) rm - número médio de cômodos por habitação\n# \n# 7) age - proporção da unidade ocupadas pelos proprietários construídas antes 1940.\n# \n# 8) dis - média ponderada das distâncias dos 5 pontos de emprego em Boston.\n# \n# 9) rad - indice de acessibilidade das avenidas radiais.\n# \n# 10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n# 11) ptratio - razão aluno-professor por cidade.\n# \n# 12) black - 1000(Bk−0.63)21000(Bk−0.63)2 proporção de negros por cidade.\n# \n# 13) lstat - percentual de baixo status da população.\n# \n# 14) medv - valor mediano das casas ocupadas pelos proprietário em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#conjunto-de-teste-e-treino",
    "href": "semanas/Aula07.3A.html#conjunto-de-teste-e-treino",
    "title": "Seleção de Modelos",
    "section": "Conjunto de teste e treino",
    "text": "Conjunto de teste e treino\n\nCodelibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nCodeset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_teste <- Boston %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   403 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nCodestr(conj_teste)\n\n'data.frame':   103 obs. of  14 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ rad    : int  5 4 4 4 4 4 4 3 3 3 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ...\n\nCodegt::gt(head(conj_treino, 10))\n\n\n\n\n\n\ncrim\n      zn\n      indus\n      chas\n      nox\n      rm\n      age\n      dis\n      rad\n      tax\n      ptratio\n      black\n      lstat\n      medv\n    \n\n\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n0.02985\n0.0\n2.18\n0\n0.458\n6.430\n58.7\n6.0622\n3\n222\n18.7\n394.12\n5.21\n28.7\n\n\n0.08829\n12.5\n7.87\n0\n0.524\n6.012\n66.6\n5.5605\n5\n311\n15.2\n395.60\n12.43\n22.9\n\n\n0.14455\n12.5\n7.87\n0\n0.524\n6.172\n96.1\n5.9505\n5\n311\n15.2\n396.90\n19.15\n27.1\n\n\n0.17004\n12.5\n7.87\n0\n0.524\n6.004\n85.9\n6.5921\n5\n311\n15.2\n386.71\n17.10\n18.9\n\n\n0.22489\n12.5\n7.87\n0\n0.524\n6.377\n94.3\n6.3467\n5\n311\n15.2\n392.52\n20.45\n15.0"
  },
  {
    "objectID": "semanas/Aula07.3A.html#matriz-de-correlação",
    "href": "semanas/Aula07.3A.html#matriz-de-correlação",
    "title": "Seleção de Modelos",
    "section": "Matriz de correlação",
    "text": "Matriz de correlação\n\nCodelibrary(corrplot)\nmat_corr <- cor(conj_treino)\ncorrplot(mat_corr)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#matriz-de-dispersão",
    "href": "semanas/Aula07.3A.html#matriz-de-dispersão",
    "title": "Seleção de Modelos",
    "section": "Matriz de dispersão",
    "text": "Matriz de dispersão\n\nCodelibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nCodepairs.panels(conj_treino,\n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )"
  },
  {
    "objectID": "semanas/Aula07.3A.html#métodos-de-seleção-de-modelo",
    "href": "semanas/Aula07.3A.html#métodos-de-seleção-de-modelo",
    "title": "Seleção de Modelos",
    "section": "Métodos de seleção de modelo",
    "text": "Métodos de seleção de modelo\n\nCode## Best Subset sem definir o número máx de subsets a ser avaliado\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino)\nsummary(ajusreg.comp)\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 ) \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 ) \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 ) \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n\nCode## Não testou todas as combinações possíveis"
  },
  {
    "objectID": "semanas/Aula07.3A.html#nvmax13",
    "href": "semanas/Aula07.3A.html#nvmax13",
    "title": "Seleção de Modelos",
    "section": "nvmax=13",
    "text": "nvmax=13\n\nCodeajusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=13)\nsumario.reg <- summary(ajusreg.comp)\nsumario.reg\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13)\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: exhaustive\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodenames(sumario.reg)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\""
  },
  {
    "objectID": "semanas/Aula07.3A.html#avaliando-os-modelos",
    "href": "semanas/Aula07.3A.html#avaliando-os-modelos",
    "title": "Seleção de Modelos",
    "section": "Avaliando os modelos",
    "text": "Avaliando os modelos\n\nCode## Os modelos vão ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 11\n\nCodepoints(11,sumario.reg$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste",
    "title": "Seleção de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.comp,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#forward-stepwise-passo-a-passo-à-frente",
    "href": "semanas/Aula07.3A.html#forward-stepwise-passo-a-passo-à-frente",
    "title": "Seleção de Modelos",
    "section": "Forward Stepwise (passo a passo à frente)",
    "text": "Forward Stepwise (passo a passo à frente)\n\nCodeajusreg.fwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd <- summary(ajusreg.fwd)\nsumario.reg.fwd \n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"forward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: forward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodewhich.min(sumario.reg.fwd$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.fwd$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-1",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-1",
    "title": "Seleção de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.fwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#backward-stepwise-passo-a-passo-atrás",
    "href": "semanas/Aula07.3A.html#backward-stepwise-passo-a-passo-atrás",
    "title": "Seleção de Modelos",
    "section": "Backward Stepwise (passo a passo atrás)",
    "text": "Backward Stepwise (passo a passo atrás)\n\nCodeajusreg.bwd <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"backward\")\nsumario.reg.bwd <- summary(ajusreg.bwd)\nsumario.reg.bwd\n\nSubset selection object\nCall: regsubsets.formula(medv ~ ., data = conj_treino, nvmax = 13, \n    method = \"backward\")\n13 Variables  (and intercept)\n        Forced in Forced out\ncrim        FALSE      FALSE\nzn          FALSE      FALSE\nindus       FALSE      FALSE\nchas        FALSE      FALSE\nnox         FALSE      FALSE\nrm          FALSE      FALSE\nage         FALSE      FALSE\ndis         FALSE      FALSE\nrad         FALSE      FALSE\ntax         FALSE      FALSE\nptratio     FALSE      FALSE\nblack       FALSE      FALSE\nlstat       FALSE      FALSE\n1 subsets of each size up to 13\nSelection Algorithm: backward\n          crim zn  indus chas nox rm  age dis rad tax ptratio black lstat\n1  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \" \"  \n2  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \" \"     \" \"   \"*\"  \n3  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \" \"   \"*\"  \n4  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \" \" \" \" \" \" \"*\"     \"*\"   \"*\"  \n5  ( 1 )  \" \"  \" \" \" \"   \" \"  \" \" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n6  ( 1 )  \" \"  \" \" \" \"   \" \"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n7  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \" \" \" \" \"*\"     \"*\"   \"*\"  \n8  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \" \" \"*\"     \"*\"   \"*\"  \n9  ( 1 )  \" \"  \" \" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n10  ( 1 ) \" \"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n11  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \" \" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n12  ( 1 ) \"*\"  \"*\" \" \"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n13  ( 1 ) \"*\"  \"*\" \"*\"   \"*\"  \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"     \"*\"   \"*\"  \n\nCodewhich.min(sumario.reg.bwd$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.bwd$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\npoints(11,sumario.reg.bwd$cp[11],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-2",
    "href": "semanas/Aula07.3A.html#como-extrair-detalhes-do-ajuste-2",
    "title": "Seleção de Modelos",
    "section": "Como extrair detalhes do ajuste",
    "text": "Como extrair detalhes do ajuste\n\nCodecoef(ajusreg.bwd,11)  \n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#comportamento-dos-erros-de-treino-e-teste",
    "href": "semanas/Aula07.3A.html#comportamento-dos-erros-de-treino-e-teste",
    "title": "Seleção de Modelos",
    "section": "Comportamento dos erros de treino e teste",
    "text": "Comportamento dos erros de treino e teste\n\nCode## Codigo original de T. Hastie\nreg.fwd <- regsubsets(medv ~ . ,data=conj_treino,nvmax=13, method=\"forward\")\nval.erro <- rep(NA,13)\nx.teste <- model.matrix(medv~.,data=conj_teste)\nfor(i in 1:13){\n  coefi <- coef(reg.fwd,id=i)\n  pred <- x.teste[,names(coefi)]%*%coefi\n  val.erro[i] <- mean((conj_teste$medv - pred)^2)\n}\nplot(sqrt(val.erro),ylab=\"Raiz do EQM\",ylim=c(4,8),pch=19,type=\"b\")\npoints(sqrt(reg.fwd$rss[-1]/403),col=\"blue\",pch=19,type=\"b\")\nlegend(\"topright\",legend=c(\"Treino\",\"Teste\"),col=c(\"blue\",\"black\"),pch=19)"
  },
  {
    "objectID": "semanas/Aula07.3A.html#testando-outra-estatística-de-seleção-de-modelos---bic",
    "href": "semanas/Aula07.3A.html#testando-outra-estatística-de-seleção-de-modelos---bic",
    "title": "Seleção de Modelos",
    "section": "Testando outra estatística de seleção de modelos - BIC",
    "text": "Testando outra estatística de seleção de modelos - BIC\n\nCodeajusreg.fwd1 <- regsubsets(medv ~ . , data=conj_treino,nvmax=13, method=\"forward\")\nsumario.reg.fwd1 <- summary(ajusreg.fwd1)\nnames(sumario.reg.fwd1)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   \n\nCodewhich.min(sumario.reg.fwd1$bic)\n\n[1] 7\n\nCodeplot(sumario.reg.fwd1$bic,xlab=\"Número de Variáveis\",ylab=\"BIC\")\npoints(7,sumario.reg.fwd1$bic[7],pch=20,col=\"red\")\n\n\n\nCodecoef(ajusreg.fwd1,7)  \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735"
  },
  {
    "objectID": "semanas/Aula07.3A.html#usando-o-cp-novamente",
    "href": "semanas/Aula07.3A.html#usando-o-cp-novamente",
    "title": "Seleção de Modelos",
    "section": "Usando o Cp novamente",
    "text": "Usando o Cp novamente\n\nCodewhich.min(sumario.reg.fwd1$cp)\n\n[1] 11\n\nCodeplot(sumario.reg.fwd1$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\npoints(11,sumario.reg.fwd1$cp[11],pch=20,col=\"red\")\n\n\n\nCodecoef(ajusreg.fwd1,11)\n\n (Intercept)         crim           zn         chas          nox           rm \n 24.11955557  -0.05912124   0.03395127   3.45970324 -17.22861717   5.10891588 \n         dis          rad          tax      ptratio        black        lstat \n -1.27274817   0.25203587  -0.01015538  -0.94732891   0.01296186  -0.39603435"
  },
  {
    "objectID": "semanas/Aula07.3A.html#comparando-os-dois-modelos-com-o-lm",
    "href": "semanas/Aula07.3A.html#comparando-os-dois-modelos-com-o-lm",
    "title": "Seleção de Modelos",
    "section": "Comparando os dois modelos com o lm()",
    "text": "Comparando os dois modelos com o lm()\n\nCode## Usando o lm para ajustar o modelo com as variáveis selecionadas pelo BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nCodemod_cp <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp)\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1857  -2.8830  -0.5641   1.8709  25.9074 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  24.119556   5.661887   4.260 2.56e-05 ***\ncrim         -0.059121   0.038751  -1.526 0.127902    \nzn            0.033951   0.015207   2.233 0.026139 *  \nchas          3.459703   0.995635   3.475 0.000568 ***\nnox         -17.228617   3.807289  -4.525 8.02e-06 ***\nrm            5.108916   0.466926  10.942  < 2e-16 ***\ndis          -1.272748   0.203301  -6.260 1.01e-09 ***\nrad           0.252036   0.067390   3.740 0.000212 ***\ntax          -0.010155   0.003556  -2.856 0.004525 ** \nptratio      -0.947329   0.141436  -6.698 7.38e-11 ***\nblack         0.012962   0.002822   4.593 5.90e-06 ***\nlstat        -0.396034   0.054069  -7.325 1.38e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.554 on 391 degrees of freedom\nMultiple R-squared:  0.7618,    Adjusted R-squared:  0.7551 \nF-statistic: 113.7 on 11 and 391 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3A.html#eliminando-a-variável-não-significativa",
    "href": "semanas/Aula07.3A.html#eliminando-a-variável-não-significativa",
    "title": "Seleção de Modelos",
    "section": "Eliminando a variável não significativa",
    "text": "Eliminando a variável não significativa\n\nCodemod_cp2 <- lm(medv ~ zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp2)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + tax + \n    ptratio + black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1471  -2.7317  -0.5389   1.9772  25.9698 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  22.884672   5.613214   4.077 5.53e-05 ***\nzn            0.031594   0.015154   2.085 0.037726 *  \nchas          3.524816   0.996402   3.538 0.000452 ***\nnox         -16.721605   3.799175  -4.401 1.39e-05 ***\nrm            5.183515   0.465145  11.144  < 2e-16 ***\ndis          -1.231499   0.201836  -6.101 2.52e-09 ***\nrad           0.218320   0.063772   3.423 0.000683 ***\ntax          -0.009827   0.003556  -2.764 0.005984 ** \nptratio      -0.938621   0.141560  -6.631 1.11e-10 ***\nblack         0.013799   0.002773   4.976 9.72e-07 ***\nlstat        -0.406190   0.053749  -7.557 2.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.562 on 392 degrees of freedom\nMultiple R-squared:  0.7604,    Adjusted R-squared:  0.7543 \nF-statistic: 124.4 on 10 and 392 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "semanas/Aula07.3A.html#avaliando-colinearidade",
    "href": "semanas/Aula07.3A.html#avaliando-colinearidade",
    "title": "Seleção de Modelos",
    "section": "Avaliando Colinearidade",
    "text": "Avaliando Colinearidade\nUma investigação minuciosa da multicollinearidade envolverá a análise do valor do \\(R^2\\) que resulta da regressão de cada uma das variáveis explicativas contra todas as outras. A relação entre as variáveis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacionário da variância (FIV) ou Variance Inflation Factor (VIF). Seja \\(Rj~^{2}\\) o quadrado do coeficiente de correlação múltipla que resulta quando a variável explicativa \\(Xj~\\) é ajustada contra todas as outras variáveis explicativas. Então o vif para \\(Xj~\\) é \\(VIFj = 1 / (1-Rj~^{2})\\)\nA regra geral é que vifs superiores a 4 justificam novas investigações, enquanto VIFs superiores a 10 são sinais de multicollinearidade grave que requerem correção.\n\nCodelibrary(car)\nvif(mod_cp2)\n\n      zn     chas      nox       rm      dis      rad      tax  ptratio \n2.128862 1.076888 3.707463 2.032934 3.357506 6.005229 6.999822 1.796214 \n   black    lstat \n1.388299 3.010108 \n\nCode## Vamos eliminar tax e ver o que acontece\nmod_cp3 <- lm(medv ~ zn + chas + nox + rm + dis + rad + ptratio + black + lstat, data=conj_treino)\nsummary(mod_cp3)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + dis + rad + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.6480  -2.9158  -0.5013   1.9274  25.8537 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  21.606433   5.641174   3.830 0.000149 ***\nzn            0.021779   0.014856   1.466 0.143439    \nchas          3.623029   1.004143   3.608 0.000348 ***\nnox         -18.864099   3.750520  -5.030 7.48e-07 ***\nrm            5.337321   0.465687  11.461  < 2e-16 ***\ndis          -1.150869   0.201396  -5.714 2.18e-08 ***\nrad           0.079897   0.039806   2.007 0.045417 *  \nptratio      -1.016641   0.139883  -7.268 1.99e-12 ***\nblack         0.014071   0.002794   5.035 7.28e-07 ***\nlstat        -0.411503   0.054166  -7.597 2.24e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.6 on 393 degrees of freedom\nMultiple R-squared:  0.7557,    Adjusted R-squared:  0.7501 \nF-statistic: 135.1 on 9 and 393 DF,  p-value: < 2.2e-16\n\nCodevif(mod_cp3)\n\n      zn     chas      nox       rm      dis      rad  ptratio    black \n2.011936 1.075519 3.553096 2.003832 3.287355 2.300918 1.724780 1.386548 \n   lstat \n3.006257"
  },
  {
    "objectID": "semanas/Aula07.3A.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "href": "semanas/Aula07.3A.html#testando-os-dois-modelos-com-o-conjunto-de-teste",
    "title": "Seleção de Modelos",
    "section": "Testando os dois modelos com o conjunto de teste",
    "text": "Testando os dois modelos com o conjunto de teste\n\nCode# Modelo com base no Cp\nsummary(mod_cp3)$sigma\n\n[1] 4.600016\n\nCodesummary(mod_cp3)$adj.r.squared\n\n[1] 0.7501409\n\nCodesqrt(mean((conj_teste$medv - predict(mod_cp3, conj_teste)) ^ 2))\n\n[1] 5.918251\n\nCode# Modelo com base no BIC\nmod_bic <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino) \nsummary(mod_bic)$sigma\n\n[1] 4.630994\n\nCodesummary(mod_bic)$adj.r.squared\n\n[1] 0.7467643\n\nCodesqrt(mean((conj_teste$medv - predict(mod_bic, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula07.4.html#carregando-bibliotecas",
    "href": "semanas/Aula07.4.html#carregando-bibliotecas",
    "title": "Regularização de Modelos",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(glmnet)\ndata(Boston)"
  },
  {
    "objectID": "semanas/Aula07.4.html#carregando-os-dados",
    "href": "semanas/Aula07.4.html#carregando-os-dados",
    "title": "Regularização de Modelos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nVamos utilizar neste exemplo os dados contidos na biblioteca MASS. A base de dados Boston tem 506 de valores preços medianos de casas na região de Boston com 13 outras variáveis explicativas (potencialmente). Vamos explorar os dados e ajustar modelos com penalização o Ridge e o LASSO e depois vamos comparar com os mínimos quadrados.\n\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\nsummary(Boston)\n\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n\n\nObservamos acima que todas as variáveis são quantitativas e que não há necessidade de transformações."
  },
  {
    "objectID": "semanas/Aula07.4.html#significado-das-variáveis",
    "href": "semanas/Aula07.4.html#significado-das-variáveis",
    "title": "Regularização de Modelos",
    "section": "Significado das variáveis",
    "text": "Significado das variáveis\n\n# Boston Database\n# \n#1) crim - taxa de criminalidade per capita por cidade.\n# \n#2) zn - proporção de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n#3) indus - proporção de negócios não comerciais por acres e por cidade.\n# \n#4) chas - variável dummy do Rio Charles(= 1 se próximo do rio; 0 de outra forma).\n# \n#5) nox - concentração de óxido de nitrogênio (partes por 10 milhões).\n# \n#6) rm - número médio de quartos por habitação\n# \n#7) age - proporção da unidade ocupadas pelos proprietários construídas antes 1940.\n# \n#8) dis - média ponderada das distâncias dos 5 pontos de emprego em Boston.\n# \n#9) rad - indice de acessibilidade das avenidas radiais.\n# \n#10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n#11) ptratio - razão aluno-professor por cidade.\n# \n#12) black - 1000(Bk−0.63)21000(Bk−0.63)2 proporção de negros por cidade.\n# \n#13) lstat - percentual de baixo status da população.\n# \n#14) medv - valor mediano das cas ocupadas pelos proprietário em $1000s. (Var. Resposta)"
  },
  {
    "objectID": "semanas/Aula07.4.html#conjunto-de-treino-e-de-teste",
    "href": "semanas/Aula07.4.html#conjunto-de-treino-e-de-teste",
    "title": "Regularização de Modelos",
    "section": "Conjunto de treino e de teste",
    "text": "Conjunto de treino e de teste\n\nlibrary(caret)\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_treino <- conj_treino %>% select(-rad)\nconj_teste <- Boston %>% slice(indice_teste)\nconj_teste <- conj_teste %>% select(-rad)\nstr(conj_treino)\n\n'data.frame':   403 obs. of  13 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n\nstr(conj_teste)\n\n'data.frame':   103 obs. of  13 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ..."
  },
  {
    "objectID": "semanas/Aula07.4.html#métodos-de-regularização",
    "href": "semanas/Aula07.4.html#métodos-de-regularização",
    "title": "Regularização de Modelos",
    "section": "Métodos de Regularização",
    "text": "Métodos de Regularização\nO pacote glmnet não usa a linguagem de formula, em particular nós devemos passar \\(x\\) como uma matriz e \\(y\\) como um vetor, pois não se usa a sintaxe \\(y \\sim x\\). Com isso será necessário ajustar x e y. A função model.matrix() é particularmente útil para criar x; não só produz uma matriz correspondente as variáveis explicativas, mas também transforma automaticamente quaisquer variáveis qualitativas em variáveis dummy. Esta última propriedade é importante porque o glmnet() só pode tomar insumos numéricos e quantitativos.\n\nx_treino <- model.matrix(medv ~ . , data = conj_treino)[, -1]\ny_treino <- conj_treino$medv\n\nx_teste <- model.matrix(medv ~ . , data = conj_teste)[, -1]\ny_teste = conj_teste$medv"
  },
  {
    "objectID": "semanas/Aula07.4.html#regressão-ridge",
    "href": "semanas/Aula07.4.html#regressão-ridge",
    "title": "Regularização de Modelos",
    "section": "Regressão Ridge",
    "text": "Regressão Ridge\nPrimeiro vamos ajustar um modelo de regressão Ridge. Isso é conseguido chamando glmnet() com alpha=0, se alpha=1 então glmnet() ajusta um lasso.(veja o arquivo de ajuda).\n\n## Estabelecendo um grid de valores para lambda\ngrid <- 10^seq(-2, 10, length = 100)\najusreg.ridge <- glmnet(x_treino, y_treino, alpha=0, lambda = grid)\n\nPor padrão, a função glmnet() executa a regressão ridge automaticamente selecionando a faixa de valores de \\(\\lambda\\). No entanto, aqui nós escolhemos implementar usando uma grade de valores que variam de \\(\\lambda = 10^{-2}\\) a \\(\\lambda = 10^{10}\\), cobrindo toda a gama de cenários do modelo nulo contendo apenas o coeficiente linear até o ajuste dos mínimos quadrados.\nTambém podemos calcular o modelo para um valor particular de \\(\\lambda\\) que não é um dos valores de grade. Observe que, por padrão, a função glmnet() padroniza as variáveis para que elas estejam na mesma escala. Esta padronização é muito importante no caso da regressão Ridge, pois ela é afetada pela mudança de escala das variáveis explicativas.\nAssociado a cada valor de \\(\\lambda\\) existe um vetor de coeficientes de regressão de ridge, que é armazenado em uma matriz que pode ser acessada por ‘coef()’. Neste caso, é uma matriz \\(14 \\times 100\\), com 14 linhas (uma para cada preditor, mais uma para o coeficiente linear) e 100 colunas (uma para cada valor de \\(\\lambda\\)).\n\ndim(coef(ajusreg.ridge))\n\n[1]  13 100\n\nplot(ajusreg.ridge, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n\n\n\n\nQuando \\(\\lambda\\) é grande o esperado é que os coeficentes sejam pequenos e quando \\(\\lambda\\) é pequeno os coeficientes assumem valores maiores.\n\najusreg.ridge$lambda[1] # Mostra primeiro valor de lambda\n\n[1] 1e+10\n\ncoef(ajusreg.ridge)[,1] # Mostra os coeficientes associados com o primeiro valor\n\n  (Intercept)          crim            zn         indus          chas \n 2.247246e+01 -4.109894e-10  1.380771e-10 -6.245296e-10  6.798952e-09 \n          nox            rm           age           dis           tax \n-3.138930e-08  9.031398e-09 -1.154044e-10  1.094430e-09 -2.354379e-11 \n      ptratio         black         lstat \n-2.000167e-09  3.131126e-11 -8.446650e-10 \n\najusreg.ridge$lambda[100] # Mostra centésimo valor de lambda\n\n[1] 0.01\n\ncoef(ajusreg.ridge)[,100] # Mostra os coeficientes associados com o centésimo valor\n\n  (Intercept)          crim            zn         indus          chas \n 1.678767e+01 -1.657453e-02  2.307677e-02 -6.932521e-02  3.914065e+00 \n          nox            rm           age           dis           tax \n-1.315187e+01  5.586213e+00 -2.297883e-02 -1.312388e+00  6.917237e-04 \n      ptratio         black         lstat \n-8.347461e-01  1.262501e-02 -3.575121e-01 \n\n\n\nlibrary(plotmo)\nplot_glmnet(ajusreg.ridge)"
  },
  {
    "objectID": "semanas/Aula07.4.html#cross-validation-no-ridge",
    "href": "semanas/Aula07.4.html#cross-validation-no-ridge",
    "title": "Regularização de Modelos",
    "section": "Cross-Validation no Ridge",
    "text": "Cross-Validation no Ridge\nNós podemos usar o k-fold cross validation para identificar o melhor valor de \\(\\lambda\\)\nA biblioteca glmnet já tem internamente uma função para uso do crosss validation. O default são 10 envelopes de dados nfold=10.\n\nset.seed(21)\nridge_cv <- cv.glmnet(x_treino,y_treino, alpha=0) ## por padrão k=10\nplot(ridge_cv)\n\n\n\nm_lamb <- ridge_cv$lambda.min  # Seleciona o lambda que minimiza o MSE (EQM) de treino\nm_lamb\n\n[1] 0.6844251\n\nlog(m_lamb)\n\n[1] -0.3791761\n\ncoef(ridge_cv, s=m_lamb)\n\n13 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept) 14.7144706557\ncrim        -0.0214927174\nzn           0.0200504882\nindus       -0.0735317662\nchas         3.8343862492\nnox         -9.4460044931\nrm           5.3120091904\nage         -0.0185326152\ndis         -1.0110801641\ntax         -0.0003434427\nptratio     -0.7785448609\nblack        0.0116393260\nlstat       -0.3465721929"
  },
  {
    "objectID": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste",
    "href": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste",
    "title": "Regularização de Modelos",
    "section": "Avaliando com conjunto de teste",
    "text": "Avaliando com conjunto de teste\nEm seguida avaliamos seu MSE no conjunto de teste, usando \\(\\lambda\\) = m_lamb. Observe o uso da função ‘predict()’: desta vez temos previsões para um conjunto de teste, com o argumento newx.\n\najusreg.ridge2 <- glmnet(x_treino, y_treino, alpha=0, lambda = m_lamb)\ny_prev <- predict(ajusreg.ridge2, s = m_lamb, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n\n[1] 5.980257"
  },
  {
    "objectID": "semanas/Aula07.4.html#lasso",
    "href": "semanas/Aula07.4.html#lasso",
    "title": "Regularização de Modelos",
    "section": "LASSO",
    "text": "LASSO\nPrimeiro ajustamos com todos os dados como no caso do Ridge\n\najusreg.lasso <- glmnet(x_treino,y_treino, alpha = 1)\nplot(ajusreg.lasso, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n\n\n\nplot_glmnet(ajusreg.lasso)"
  },
  {
    "objectID": "semanas/Aula07.4.html#validação-cruzada-no-lasso",
    "href": "semanas/Aula07.4.html#validação-cruzada-no-lasso",
    "title": "Regularização de Modelos",
    "section": "Validação Cruzada no LASSO",
    "text": "Validação Cruzada no LASSO\n\nlasso_cv <- cv.glmnet(x_treino,y_treino, alpha = 1)\nplot(lasso_cv)\n\n\n\nm_lamb1 <- lasso_cv$lambda.min  # Seleciona o lambda que minimiza o MSE de treino\nm_lamb1\n\n[1] 0.0595278\n\nlog(m_lamb1)\n\n[1] -2.821312\n\ncoef(lasso_cv, s=m_lamb1)\n\n13 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  14.763435253\ncrim         -0.006217225\nzn            0.017479823\nindus        -0.050830256\nchas          3.644367387\nnox         -11.463040415\nrm            5.608066407\nage          -0.018352749\ndis          -1.107502465\ntax           .          \nptratio      -0.825247011\nblack         0.012263992\nlstat        -0.362939273"
  },
  {
    "objectID": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste-1",
    "href": "semanas/Aula07.4.html#avaliando-com-conjunto-de-teste-1",
    "title": "Regularização de Modelos",
    "section": "Avaliando com conjunto de teste",
    "text": "Avaliando com conjunto de teste\n\najusreg.lasso2 <- glmnet(x_treino, y_treino, alpha=1, lambda = m_lamb1)\ny_prev <- predict(ajusreg.lasso2, s = m_lamb1, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n\n[1] 6.027343"
  },
  {
    "objectID": "semanas/Aula07.4.html#comparando-com-a-seleção-de-modelos-usando-o-cp",
    "href": "semanas/Aula07.4.html#comparando-com-a-seleção-de-modelos-usando-o-cp",
    "title": "Regularização de Modelos",
    "section": "Comparando com a seleção de modelos usando o Cp",
    "text": "Comparando com a seleção de modelos usando o Cp\n\nlibrary(leaps)\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg <- summary(ajusreg.comp)\n## Os modelos vão ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n\n[1] 9\n\npoints(9,sumario.reg$cp[9],pch=20,col=\"red\")"
  },
  {
    "objectID": "semanas/Aula07.4.html#ajustando-no-lm-e-vendo-o-erro-no-conjunto-de-teste",
    "href": "semanas/Aula07.4.html#ajustando-no-lm-e-vendo-o-erro-no-conjunto-de-teste",
    "title": "Regularização de Modelos",
    "section": "Ajustando no lm() e vendo o erro no conjunto de teste",
    "text": "Ajustando no lm() e vendo o erro no conjunto de teste\nObservando so resultados de erro vemos que tanto a regressão Ridge como o LASSO apresentaram valores de erro maiores que o modelo definido através da melhor seleção de modelos (best subset regression). Aqui usamos o Cp de Mallows como critério de deleção de variáveis.\n\ncoef(ajusreg.comp,9) \n\n (Intercept)           zn         chas          nox           rm          age \n 17.03537172   0.02326045   3.81378291 -14.60482205   5.66380782  -0.02328124 \n         dis      ptratio        black        lstat \n -1.26249225  -0.87101806   0.01301181  -0.36615078 \n\noutro_mod <- lm(medv ~ zn + chas + nox + rm + age + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod)\n\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + age + dis + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.9383  -2.6575  -0.5304   1.7899  27.0979 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.035372   5.393193   3.159 0.001707 ** \nzn            0.023260   0.014828   1.569 0.117534    \nchas          3.813783   1.008205   3.783 0.000179 ***\nnox         -14.604822   3.654556  -3.996 7.68e-05 ***\nrm            5.663808   0.473979  11.949  < 2e-16 ***\nage          -0.023281   0.014296  -1.629 0.104207    \ndis          -1.262492   0.209990  -6.012 4.19e-09 ***\nptratio      -0.871018   0.125529  -6.939 1.64e-11 ***\nblack         0.013012   0.002708   4.806 2.20e-06 ***\nlstat        -0.366151   0.057248  -6.396 4.54e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.608 on 393 degrees of freedom\nMultiple R-squared:  0.7549,    Adjusted R-squared:  0.7493 \nF-statistic: 134.5 on 9 and 393 DF,  p-value: < 2.2e-16\n\nsqrt(mean((conj_teste$medv - predict(outro_mod, conj_teste)) ^ 2)) \n\n[1] 6.032965"
  },
  {
    "objectID": "semanas/Aula07.4.html#e-o-bic",
    "href": "semanas/Aula07.4.html#e-o-bic",
    "title": "Regularização de Modelos",
    "section": "E o BIC?",
    "text": "E o BIC?\nE se escolhessemos o BIC como critério de seleção de variáveis explicativas? Neste caso os resultados foram iguais ao Cp. Entretanto, dá para perceber que o BIC apresentou uma certa estabilidade entre 7 e 9 variáveis. Se quisermos ter um modelo mais enxuto poderiamos optar por 7 variáveis.\n\najusreg.comp1 <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg1 <- summary(ajusreg.comp1)\n## Os modelos vão ser escolhidos com base no menor BIC\nplot(sumario.reg1$bic,xlab=\"Número de Variáveis\",ylab=\"BIC\")\nwhich.min(sumario.reg1$bic)\n\n[1] 7\n\npoints(7,sumario.reg1$bic[7],pch=20,col=\"red\")\n\n\n\ncoef(ajusreg.comp1,7) \n\n (Intercept)         chas          nox           rm          dis      ptratio \n 18.15699005   3.62527238 -16.32477597   5.61737907  -1.00175093  -0.95906300 \n       black        lstat \n  0.01229926  -0.39019735 \n\noutro_mod1 <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod1)\n\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.4971  -2.7789  -0.5478   1.7933  26.9857 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.156990   5.385606   3.371 0.000822 ***\nchas          3.625272   1.009714   3.590 0.000372 ***\nnox         -16.324776   3.534591  -4.619 5.24e-06 ***\nrm            5.617379   0.457084  12.290  < 2e-16 ***\ndis          -1.001751   0.180856  -5.539 5.56e-08 ***\nptratio      -0.959063   0.119626  -8.017 1.24e-14 ***\nblack         0.012299   0.002702   4.552 7.07e-06 ***\nlstat        -0.390197   0.053934  -7.235 2.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.631 on 395 degrees of freedom\nMultiple R-squared:  0.7512,    Adjusted R-squared:  0.7468 \nF-statistic: 170.4 on 7 and 395 DF,  p-value: < 2.2e-16\n\nsqrt(mean((conj_teste$medv - predict(outro_mod1, conj_teste)) ^ 2))\n\n[1] 6.023672"
  },
  {
    "objectID": "semanas/Aula08.html",
    "href": "semanas/Aula08.html",
    "title": "KNN",
    "section": "",
    "text": "O KNN é um algoritmo muito simples no qual cada observação é prevista com base em sua “semelhança” com outras observações. Ao contrário da maioria dos métodos, KNN é um algoritmo baseado na memória e não pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento são necessárias no tempo de execução e as previsões são feitas diretamente das relações amostrais. Consequentemente, os KNNs também são conhecidos como aprendizes preguiçosos"
  },
  {
    "objectID": "semanas/Aula08.html#carregando-bibliotecas",
    "href": "semanas/Aula08.html#carregando-bibliotecas",
    "title": "KNN",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula08.html#manipulando-os-dados",
    "href": "semanas/Aula08.html#manipulando-os-dados",
    "title": "KNN",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula08.html#normalização",
    "href": "semanas/Aula08.html#normalização",
    "title": "KNN",
    "section": "Normalização",
    "text": "Normalização\nAntes de iniciarmos é fundamental fazermos a normalização (padronização) dos dados para que o KNN tenha um melhor desempenho.\n\ncredito_n <- credito\ncredito_n[,3:4] <- scale(credito_n[,3:4])"
  },
  {
    "objectID": "semanas/Aula08.html#treino-e-teste",
    "href": "semanas/Aula08.html#treino-e-teste",
    "title": "KNN",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nset.seed(21)\ny <- credito_n$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito_n %>% slice(-indice_teste)\nconj_teste <- credito_n %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco             receita         \n Nao:7733     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.455267  \n Sim: 266     1st Qu.:0.0000   1st Qu.:-0.732026   1st Qu.:-0.913102  \n              Median :0.0000   Median :-0.033621   Median : 0.076805  \n              Mean   :0.2953   Mean   :-0.005588   Mean   : 0.001763  \n              3rd Qu.:1.0000   3rd Qu.: 0.685798   3rd Qu.: 0.774041  \n              Max.   :1.0000   Max.   : 3.760371   Max.   : 3.002050  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco             receita         \n Nao:1934     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.156595  \n Sim:  67     1st Qu.:0.0000   1st Qu.:-0.727536   1st Qu.:-0.910738  \n              Median :0.0000   Median : 0.002479   Median : 0.080508  \n              Mean   :0.2909   Mean   : 0.022340   Mean   :-0.007049  \n              3rd Qu.:1.0000   3rd Qu.: 0.677484   3rd Qu.: 0.759484  \n              Max.   :1.0000   Max.   : 3.361757   Max.   : 2.828416"
  },
  {
    "objectID": "semanas/Aula08.html#matriz-de-dispersão",
    "href": "semanas/Aula08.html#matriz-de-dispersão",
    "title": "KNN",
    "section": "Matriz de dispersão",
    "text": "Matriz de dispersão\nVamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente.\n\nlibrary(psych)\npairs.panels(credito, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )"
  },
  {
    "objectID": "semanas/Aula08.html#avaliando-o-comportamento-das-variáveis-em-função-do-status-inadimplente-estudante",
    "href": "semanas/Aula08.html#avaliando-o-comportamento-das-variáveis-em-função-do-status-inadimplente-estudante",
    "title": "KNN",
    "section": "Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)",
    "text": "Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\nggplot(credito, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(credito, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula08.html#explorando-um-pouco-mais-balanço-e-receita",
    "href": "semanas/Aula08.html#explorando-um-pouco-mais-balanço-e-receita",
    "title": "KNN",
    "section": "Explorando um pouco mais Balanço e Receita",
    "text": "Explorando um pouco mais Balanço e Receita\n\nggplot(credito, aes(x=balanco)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))\n\n\n\nggplot(credito, aes(x=receita)) +\n    geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))"
  },
  {
    "objectID": "semanas/Aula08.html#balanço-vs-receita",
    "href": "semanas/Aula08.html#balanço-vs-receita",
    "title": "KNN",
    "section": "Balanço vs Receita",
    "text": "Balanço vs Receita\n\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point()"
  },
  {
    "objectID": "semanas/Aula08.html#knn-1",
    "href": "semanas/Aula08.html#knn-1",
    "title": "KNN",
    "section": "KNN",
    "text": "KNN\nVamos usar a função knn da biblioteca caret que tem ótimas funcionalidades. Observem que a saída pode ser as classes ou as probabilidades de pertencer a uma classe\nComo o KNN usa as distancias entre os pontos ele é afetado pela escala dos dados, portanto, é necessário que os dados sejam normalizados (padronizados) para eliminar este efeito.\nQuando temos diversas variáveis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrão 1"
  },
  {
    "objectID": "semanas/Aula08.html#a-modelo",
    "href": "semanas/Aula08.html#a-modelo",
    "title": "KNN",
    "section": "1a Modelo",
    "text": "1a Modelo\n\n# Vamos usar a regra da raiz quadrada do tamnho da amostra\nsqrt(nrow(conj_treino)) ## ~90\n\n[1] 89.43713\n\nset.seed(21)\nt_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)\nt_knn1\n\n90-nearest neighbor model\nTraining set outcome distribution:\n\n Nao  Sim \n7733  266"
  },
  {
    "objectID": "semanas/Aula08.html#avaliando-o-modelo",
    "href": "semanas/Aula08.html#avaliando-o-modelo",
    "title": "KNN",
    "section": "Avaliando o modelo",
    "text": "Avaliando o modelo\nA acurácia deu um valor alto, mas isto não é suficiente para considerarmo que temos um bom modelo. Veja que a sensibilidade está muito baixa e que o ideal é que tenhamos valores altos de sensibilidade e especificidade.\nObservar que a prevalência é muito baixa o que está afetando os resultados do modelo\n\n## \ny_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"class\")\n\n# Matriz de confusão para valiar os resultados\nconfusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1930   51\n       Sim    4   16\n                                          \n               Accuracy : 0.9725          \n                 95% CI : (0.9644, 0.9792)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.07329         \n                                          \n                  Kappa : 0.3579          \n                                          \n Mcnemar's Test P-Value : 5.552e-10       \n                                          \n            Sensitivity : 0.238806        \n            Specificity : 0.997932        \n         Pos Pred Value : 0.800000        \n         Neg Pred Value : 0.974255        \n             Prevalence : 0.033483        \n         Detection Rate : 0.007996        \n   Detection Prevalence : 0.009995        \n      Balanced Accuracy : 0.618369        \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula08.html#curva-roc",
    "href": "semanas/Aula08.html#curva-roc",
    "title": "KNN",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\n# Para a curva ROC preciso das probabilidades e não das classes\np_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nhead(p_chapeu_knn1)\n\n           Nao        Sim\n[1,] 0.9777778 0.02222222\n[2,] 1.0000000 0.00000000\n[3,] 1.0000000 0.00000000\n[4,] 0.9888889 0.01111111\n[5,] 1.0000000 0.00000000\n[6,] 1.0000000 0.00000000\n\n# Aqui gera o curva e salvo numa variável\nroc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nlegend(\"bottomright\",legend=c(\"KNN1\"), \n       col=c(\"black\"),lwd=4)\n\n\n\n# Area abaixo da Curva (AUC)\nas.numeric(roc_knn1$auc)\n\n[1] 0.9276227"
  },
  {
    "objectID": "semanas/Aula08.html#variando-k",
    "href": "semanas/Aula08.html#variando-k",
    "title": "KNN",
    "section": "Variando K",
    "text": "Variando K\nAnteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a função train da biblioteca caret \nObserve que a otimização de k é feita através de acurácia\n\nset.seed(21)\n\n# Usando validação cruzada para obter o valor de k através da função train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.\nctrl <- trainControl(method = \"cv\")\nt_knn2 <- train(inadimplente ~ balanco + receita + estudante,\n                method = \"knn\", trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                data = conj_treino)\n## Resultados do treino\nt_knn2\n\nk-Nearest Neighbors \n\n7999 samples\n   3 predictor\n   2 classes: 'Nao', 'Sim' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \nResampling results across tuning parameters:\n\n  k    Accuracy   Kappa     \n   10  0.9699953  0.37022050\n   20  0.9717451  0.37122371\n   30  0.9714948  0.34761685\n   40  0.9713698  0.32858918\n   50  0.9712448  0.30506559\n   60  0.9711200  0.29038841\n   70  0.9711204  0.28281374\n   80  0.9698700  0.22792293\n   90  0.9696197  0.20538564\n  100  0.9689948  0.15840977\n  110  0.9677454  0.09462220\n  120  0.9669959  0.03351642\n  130  0.9669961  0.01339042\n  140  0.9669961  0.01339042\n  150  0.9667464  0.00000000\n  160  0.9667464  0.00000000\n  170  0.9667464  0.00000000\n  180  0.9667464  0.00000000\n  190  0.9667464  0.00000000\n  200  0.9667464  0.00000000\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 20.\n\nplot(t_knn2)\n\n\n\n## Previsões com o resultaddos do treino\nprev_knn2 <- predict(t_knn2, conj_teste)\nconfusionMatrix(prev_knn2, conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1926   40\n       Sim    8   27\n                                          \n               Accuracy : 0.976           \n                 95% CI : (0.9683, 0.9823)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.008318        \n                                          \n                  Kappa : 0.5183          \n                                          \n Mcnemar's Test P-Value : 7.66e-06        \n                                          \n            Sensitivity : 0.40299         \n            Specificity : 0.99586         \n         Pos Pred Value : 0.77143         \n         Neg Pred Value : 0.97965         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01349         \n   Detection Prevalence : 0.01749         \n      Balanced Accuracy : 0.69942         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula08.html#variando-k-de-outra-forma",
    "href": "semanas/Aula08.html#variando-k-de-outra-forma",
    "title": "KNN",
    "section": "Variando K de outra forma",
    "text": "Variando K de outra forma\nVamos adicionar mais opções no trainControl\nAo colocar classProb = TRUE e summaryFunction ao invés da acurácia a otimização passa a ser através o ROC\n\nset.seed(21)\n# ctrl <- trainControl(method = \"cv\", classProbs=TRUE, summaryFunction = twoClassSummary)\nctrl <- trainControl(method = \"repeatedcv\", \n                     number = 10,\n                     repeats = 5, \n                     classProbs = TRUE,\n                     summaryFunction = twoClassSummary)\n\nt_knn3 <- train(inadimplente ~ balanco + receita + estudante, \n                method = \"knn\", \n                trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                metric = \"ROC\",\n                data = conj_treino)\nt_knn3\n\nk-Nearest Neighbors \n\n7999 samples\n   3 predictor\n   2 classes: 'Nao', 'Sim' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 5 times) \nSummary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \nResampling results across tuning parameters:\n\n  k    ROC        Sens       Spec       \n   10  0.8532549  0.9936118  0.299230769\n   20  0.8962842  0.9957323  0.275897436\n   30  0.9129487  0.9965599  0.252507123\n   40  0.9223242  0.9972324  0.229401709\n   50  0.9260029  0.9976204  0.204558405\n   60  0.9275003  0.9978014  0.196239316\n   70  0.9283630  0.9979566  0.185014245\n   80  0.9324715  0.9981118  0.150284900\n   90  0.9335728  0.9986809  0.124643875\n  100  0.9390171  0.9991464  0.091566952\n  110  0.9401918  0.9994827  0.048062678\n  120  0.9405837  0.9998707  0.019515670\n  130  0.9416564  1.0000000  0.007492877\n  140  0.9429103  1.0000000  0.003703704\n  150  0.9434492  1.0000000  0.000000000\n  160  0.9432553  1.0000000  0.000000000\n  170  0.9444527  1.0000000  0.000000000\n  180  0.9452018  1.0000000  0.000000000\n  190  0.9450158  1.0000000  0.000000000\n  200  0.9447751  1.0000000  0.000000000\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was k = 180.\n\nplot(t_knn3)\n\n\n\nprev_knn3 <- predict(t_knn3, conj_teste)\nconfusionMatrix(prev_knn3, conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1934   66\n       Sim    0    1\n                                          \n               Accuracy : 0.967           \n                 95% CI : (0.9582, 0.9744)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.4829          \n                                          \n                  Kappa : 0.0285          \n                                          \n Mcnemar's Test P-Value : 1.235e-15       \n                                          \n            Sensitivity : 0.0149254       \n            Specificity : 1.0000000       \n         Pos Pred Value : 1.0000000       \n         Neg Pred Value : 0.9670000       \n             Prevalence : 0.0334833       \n         Detection Rate : 0.0004998       \n   Detection Prevalence : 0.0004998       \n      Balanced Accuracy : 0.5074627       \n                                          \n       'Positive' Class : Sim             \n                                          \n\n\nVeja que ao otimizar pela ROC o modelo escolhido tem sensibilidade zero! Isto obviamente não é um bom modelo! Neste caso a opção de otimização do parametro pela acurácia dá melhores resultados."
  },
  {
    "objectID": "semanas/Aula08.html#curva-roc-dos-2-melhores-modelos-k90-e-k20",
    "href": "semanas/Aula08.html#curva-roc-dos-2-melhores-modelos-k90-e-k20",
    "title": "KNN",
    "section": "Curva ROC dos 2 melhores modelos k=90 e k=20",
    "text": "Curva ROC dos 2 melhores modelos k=90 e k=20\n\nprev_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nprev_knn2 <- predict(t_knn2, conj_teste, type = \"prob\")\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\nroc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\nlegend(\"bottomright\",legend=c(\"KNN1\", \"KNN2\"), \n       col=c(\"black\",\"green\"),lwd=4)\n\n\n\n## Area embaixo das curvas\nas.numeric(roc_knn1$auc)\n\n[1] 0.9276227\n\nas.numeric(roc_knn2$auc)\n\n[1] 0.9032436\n\n\nObserve que os resultados de área abaixo da ROC não são suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!\nOs resultados encontrados apontam k=20 como a melhor opção"
  },
  {
    "objectID": "semanas/Aula09.html",
    "href": "semanas/Aula09.html",
    "title": "Regressão Logística",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula09.html#manipulando-os-dados",
    "href": "semanas/Aula09.html#manipulando-os-dados",
    "title": "Regressão Logística",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09.html#treino-e-teste",
    "href": "semanas/Aula09.html#treino-e-teste",
    "title": "Regressão Logística",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula09.html#matriz-de-dispersão",
    "href": "semanas/Aula09.html#matriz-de-dispersão",
    "title": "Regressão Logística",
    "section": "Matriz de dispersão",
    "text": "Matriz de dispersão\n\nlibrary(psych)\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-comportamento-das-variáveis-em-função-do-status-inadimplente-estudante",
    "href": "semanas/Aula09.html#avaliando-o-comportamento-das-variáveis-em-função-do-status-inadimplente-estudante",
    "title": "Regressão Logística",
    "section": "Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)",
    "text": "Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\nggplot(conj_treino, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\n\n\n\nggplot(conj_treino, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()"
  },
  {
    "objectID": "semanas/Aula09.html#balanço-vs-receita",
    "href": "semanas/Aula09.html#balanço-vs-receita",
    "title": "Regressão Logística",
    "section": "Balanço vs Receita",
    "text": "Balanço vs Receita\n\nggplot(data = conj_treino, aes(x=balanco,  y = receita, col = inadimplente)) +\n  geom_point()"
  },
  {
    "objectID": "semanas/Aula09.html#regressão-linear",
    "href": "semanas/Aula09.html#regressão-linear",
    "title": "Regressão Logística",
    "section": "Regressão Linear?",
    "text": "Regressão Linear?\n\n## Primeiro precisa transformar qualitativa em numérica\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nmodelo_linear <- lm(inadimpl ~ balanco, data = conj_treino)\nplot(inadimpl ~ balanco, data = conj_treino, \n     col = \"darkorange\", pch = \"|\", ylim = c(-0.2, 1),\n     main = \"Regressão Linear - Classificação\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\nabline(modelo_linear, lwd = 3, col = \"dodgerblue\")"
  },
  {
    "objectID": "semanas/Aula09.html#outras-avaliações",
    "href": "semanas/Aula09.html#outras-avaliações",
    "title": "Regressão Logística",
    "section": "Outras avaliações",
    "text": "Outras avaliações\n\n# proporção de inadimplentes\nconj_treino %>% select(inadimplente, balanco) %>% summarize(prop = mean(inadimplente == \"Sim\")) \n\n# A tibble: 1 × 1\n    prop\n   <dbl>\n1 0.0333\n\n# media do balanço dos inadimplentes \nconj_treino %>% filter(inadimplente == \"Sim\") %>% summarize(valor= mean(balanco))   \n\n# A tibble: 1 × 1\n  valor\n  <dbl>\n1 1745.\n\nquantis <- quantile(conj_treino$balanco, probs = c(.1,.25, .50, .75, .9, .95, 0.97, 0.99))\nquantis\n\n      10%       25%       50%       75%       90%       95%       97%       99% \n 176.9895  481.2830  819.1118 1167.1059 1468.8300 1660.1834 1786.5132 1991.6971 \n\nconj_treino %>% \n            mutate(grupo_balanco = case_when(\n               balanco<=quantis[1] ~ quantis[1],\n               balanco>quantis[1] & balanco<=quantis[2] ~ quantis[2],\n               balanco>quantis[2] & balanco<=quantis[3]  ~ quantis[3],\n               balanco>quantis[3] & balanco<=quantis[4]  ~ quantis[4],\n               balanco>quantis[4] & balanco<=quantis[5]  ~ quantis[5],\n               balanco>quantis[5] & balanco<=quantis[6]  ~ quantis[6],\n               balanco>quantis[6] & balanco<=quantis[7]  ~ quantis[7],\n               balanco>quantis[7] ~ quantis[8])) %>%\n           group_by(grupo_balanco) %>%\n           summarize(prop = mean(inadimplente == \"Sim\")) %>%\n           ggplot(aes(grupo_balanco, prop)) +\n           geom_point() +\n           geom_line()"
  },
  {
    "objectID": "semanas/Aula09.html#a-regressão-logística-só-balanço",
    "href": "semanas/Aula09.html#a-regressão-logística-só-balanço",
    "title": "Regressão Logística",
    "section": "1a Regressão logística: só balanço",
    "text": "1a Regressão logística: só balanço\n\nmod1 <- glm(inadimplente ~ balanco,data=conj_treino,family=binomial)\nsummary(mod1)\n\n\nCall:\nglm(formula = inadimplente ~ balanco, family = binomial, data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3119  -0.1453  -0.0568  -0.0211   3.7748  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.077e+01  4.119e-01  -26.16   <2e-16 ***\nbalanco      5.593e-03  2.521e-04   22.18   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1268.0  on 7997  degrees of freedom\nAIC: 1272\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod1)\n\n  (Intercept)       balanco \n-10.772870680   0.005593346 \n\nsummary(mod1)$coef\n\n                 Estimate   Std. Error   z value      Pr(>|z|)\n(Intercept) -10.772870680 0.4118820840 -26.15523 8.593630e-151\nbalanco       0.005593346 0.0002521341  22.18401 4.901112e-109"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-modelo",
    "href": "semanas/Aula09.html#avaliando-o-modelo",
    "title": "Regressão Logística",
    "section": "Avaliando o modelo",
    "text": "Avaliando o modelo\n\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1922   41\n       Sim   12   26\n                                          \n               Accuracy : 0.9735          \n                 95% CI : (0.9655, 0.9801)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.04298         \n                                          \n                  Kappa : 0.4827          \n                                          \n Mcnemar's Test P-Value : 0.00012         \n                                          \n            Sensitivity : 0.38806         \n            Specificity : 0.99380         \n         Pos Pred Value : 0.68421         \n         Neg Pred Value : 0.97911         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01299         \n   Detection Prevalence : 0.01899         \n      Balanced Accuracy : 0.69093         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#veja-as-probabilidade-de-inadimplencia-para-balanços-de-1000-2000-e-3000",
    "href": "semanas/Aula09.html#veja-as-probabilidade-de-inadimplencia-para-balanços-de-1000-2000-e-3000",
    "title": "Regressão Logística",
    "section": "Veja as probabilidade de inadimplencia para balanços de 1000, 2000 e 3000",
    "text": "Veja as probabilidade de inadimplencia para balanços de 1000, 2000 e 3000\n\npredict(mod1, newdata = data.frame(balanco = c(1000,2000,3000)), type=\"response\")\n\n          1           2           3 \n0.005599153 0.602003608 0.997544989"
  },
  {
    "objectID": "semanas/Aula09.html#curva-s",
    "href": "semanas/Aula09.html#curva-s",
    "title": "Regressão Logística",
    "section": "Curva S",
    "text": "Curva S\n\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nplot(inadimpl ~ balanco, data = conj_treino, \n     col = \"darkorange\", pch = \"|\", ylim = c(0, 1),\n     main = \"Regressão Logistica - Classificacão\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\ncurve(predict(mod1, data.frame(balanco = x),\n        type = \"response\"), add = TRUE, lwd = 3, col = \"dodgerblue\")\nabline(v = -coef(mod1)[1] / coef(mod1)[2], lwd = 2)"
  },
  {
    "objectID": "semanas/Aula09.html#valor-de-balanço-com-probabilidade-de-50",
    "href": "semanas/Aula09.html#valor-de-balanço-com-probabilidade-de-50",
    "title": "Regressão Logística",
    "section": "Valor de balanço com probabilidade de 50%",
    "text": "Valor de balanço com probabilidade de 50%\n-\\(\\beta_0\\)/\\(\\beta_1\\)\n\n-coef(mod1)[1] / coef(mod1)[2]\n\n(Intercept) \n   1926.016"
  },
  {
    "objectID": "semanas/Aula09.html#a-regressão-logística-todas-as-variáveis",
    "href": "semanas/Aula09.html#a-regressão-logística-todas-as-variáveis",
    "title": "Regressão Logística",
    "section": "2a Regressão logística: todas as variáveis",
    "text": "2a Regressão logística: todas as variáveis\n\nmod2 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treino,family=binomial)\nsummary(mod2)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n    data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.5314  -0.1409  -0.0535  -0.0192   3.7500  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.123e+01  5.684e-01 -19.763   <2e-16 ***\nbalanco      5.842e-03  2.661e-04  21.955   <2e-16 ***\nreceita      8.476e-06  9.253e-06   0.916   0.3597    \nestudante   -5.106e-01  2.671e-01  -1.912   0.0559 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1248.2  on 7995  degrees of freedom\nAIC: 1256.2\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod2)\n\n  (Intercept)       balanco       receita     estudante \n-1.123321e+01  5.842417e-03  8.475971e-06 -5.106360e-01 \n\nsummary(mod2)$coef\n\n                 Estimate   Std. Error     z value      Pr(>|z|)\n(Intercept) -1.123321e+01 5.683883e-01 -19.7632675  6.167980e-87\nbalanco      5.842417e-03 2.661065e-04  21.9551820 7.727138e-107\nreceita      8.475971e-06 9.253027e-06   0.9160214  3.596557e-01\nestudante   -5.106360e-01 2.671246e-01  -1.9116025  5.592720e-02"
  },
  {
    "objectID": "semanas/Aula09.html#é-possível-se-ver-que-receita-não-é-significativa",
    "href": "semanas/Aula09.html#é-possível-se-ver-que-receita-não-é-significativa",
    "title": "Regressão Logística",
    "section": "É possível se ver que receita não é significativa",
    "text": "É possível se ver que receita não é significativa"
  },
  {
    "objectID": "semanas/Aula09.html#a-regressão-logística-sem-receita",
    "href": "semanas/Aula09.html#a-regressão-logística-sem-receita",
    "title": "Regressão Logística",
    "section": "3a Regressão Logística (sem receita)",
    "text": "3a Regressão Logística (sem receita)\n\nmod3 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\nsummary(mod3)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + estudante, family = binomial, \n    data = conj_treino)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4991  -0.1410  -0.0535  -0.0192   3.7631  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.089e+01  4.220e-01  -25.81  < 2e-16 ***\nbalanco      5.842e-03  2.658e-04   21.98  < 2e-16 ***\nestudante   -7.016e-01  1.655e-01   -4.24 2.23e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2333.8  on 7998  degrees of freedom\nResidual deviance: 1249.1  on 7996  degrees of freedom\nAIC: 1255.1\n\nNumber of Fisher Scoring iterations: 8\n\ncoef(mod3)\n\n  (Intercept)       balanco     estudante \n-10.891361318   0.005842385  -0.701581567 \n\nsummary(mod3)$coef\n\n                 Estimate   Std. Error    z value      Pr(>|z|)\n(Intercept) -10.891361318 0.4220005414 -25.808880 7.048822e-147\nbalanco       0.005842385 0.0002658371  21.977315 4.747239e-107\nestudante    -0.701581567 0.1654530947  -4.240365  2.231563e-05"
  },
  {
    "objectID": "semanas/Aula09.html#avaliando-o-modelo-novamente",
    "href": "semanas/Aula09.html#avaliando-o-modelo-novamente",
    "title": "Regressão Logística",
    "section": "Avaliando o modelo novamente",
    "text": "Avaliando o modelo novamente\n\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1924   37\n       Sim   10   30\n                                          \n               Accuracy : 0.9765          \n                 95% CI : (0.9689, 0.9827)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.0056579       \n                                          \n                  Kappa : 0.5495          \n                                          \n Mcnemar's Test P-Value : 0.0001491       \n                                          \n            Sensitivity : 0.44776         \n            Specificity : 0.99483         \n         Pos Pred Value : 0.75000         \n         Neg Pred Value : 0.98113         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01499         \n   Detection Prevalence : 0.01999         \n      Balanced Accuracy : 0.72130         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#mudando-a-probabilidade-limite-para-aumentar-a-sensibilidade",
    "href": "semanas/Aula09.html#mudando-a-probabilidade-limite-para-aumentar-a-sensibilidade",
    "title": "Regressão Logística",
    "section": "Mudando a probabilidade (limite) para aumentar a sensibilidade",
    "text": "Mudando a probabilidade (limite) para aumentar a sensibilidade\n\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.1, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1809   18\n       Sim  125   49\n                                          \n               Accuracy : 0.9285          \n                 95% CI : (0.9164, 0.9394)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3765          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.73134         \n            Specificity : 0.93537         \n         Pos Pred Value : 0.28161         \n         Neg Pred Value : 0.99015         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02449         \n   Detection Prevalence : 0.08696         \n      Balanced Accuracy : 0.83336         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-modelo-só-com-balanço",
    "href": "semanas/Aula09.html#curva-roc-modelo-só-com-balanço",
    "title": "Regressão Logística",
    "section": "Curva ROC modelo só com balanço",
    "text": "Curva ROC modelo só com balanço\n\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.897038e-02 7.892012e-05 2.096006e-05 1.087093e-02 3.336139e-04 2.580431e-04 \n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n\n\n\n# Area debaixo da curva\nas.numeric(roc_log$auc)\n\n[1] 0.9389557"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-2-modelo-com-balanço-estudante",
    "href": "semanas/Aula09.html#curva-roc-2-modelo-com-balanço-estudante",
    "title": "Regressão Logística",
    "section": "Curva ROC 2: Modelo com balanço + estudante",
    "text": "Curva ROC 2: Modelo com balanço + estudante\n\np_chapeu_log <- predict(mod3, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.140962e-02 7.436487e-05 1.861803e-05 6.355948e-03 3.351978e-04 1.271000e-04 \n\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n\n\n\n# Area debaixo da curva\nas.numeric(roc_log2$auc)\n\n[1] 0.9415487"
  },
  {
    "objectID": "semanas/Aula09.html#duas-rocs-juntas",
    "href": "semanas/Aula09.html#duas-rocs-juntas",
    "title": "Regressão Logística",
    "section": "Duas ROCs juntas",
    "text": "Duas ROCs juntas\n\nplot(roc_log)\nplot(roc_log2, add=TRUE, col=\"blue\")\nlegend(\"bottomright\", legend=c(\"Mod 1\", \"Mod2\"),\n       col=c(par(\"fg\"), \"blue\"), lwd=2)"
  },
  {
    "objectID": "semanas/Aula09.html#curva-roc-3-com-o-knn",
    "href": "semanas/Aula09.html#curva-roc-3-com-o-knn",
    "title": "Regressão Logística",
    "section": "Curva ROC 3 com o KNN",
    "text": "Curva ROC 3 com o KNN\n\n# Ajustando KNN \nset.seed(21)\nctrl <- trainControl(method = \"cv\")\ntreina_knn <- train(inadimplente ~ scale(balanco) + scale(estudante), method = \"knn\", trControl= ctrl, tuneGrid = data.frame(k = seq(5,140, by=4)), data = conj_treino)\n# treina_knn\nplot(treina_knn)\n\n\n\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n## ROC\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, col= \"black\", legacy.axes=TRUE) \nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg. Log\", \"KNN\"), \n       col=c(\"black\",\"green\"),lwd=4)\n\n\n\n# Area abaixo da curva\n# Regressão Logística\nas.numeric(roc_log2$auc)\n\n[1] 0.9415487\n\n## KNN\nas.numeric(roc_knn1$auc)\n\n[1] 0.9388361"
  },
  {
    "objectID": "semanas/Aula09A.html",
    "href": "semanas/Aula09A.html",
    "title": "Regressão Logística - SMOTE",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula09A.html#manipulando-os-dados",
    "href": "semanas/Aula09A.html#manipulando-os-dados",
    "title": "Regressão Logística - SMOTE",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          ))\n\nstr(credito)\n\ntibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09A.html#treino-e-teste",
    "href": "semanas/Aula09A.html#treino-e-teste",
    "title": "Regressão Logística - SMOTE",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula09A.html#smote",
    "href": "semanas/Aula09A.html#smote",
    "title": "Regressão Logística - SMOTE",
    "section": "SMOTE",
    "text": "SMOTE\n\nlibrary(smotefamily)\nset.seed(123)\nteste <- SMOTE(conj_treino[,-1], target = conj_treino$inadimplente, K=5)\nconj_treinoS <- teste$data\nconj_treinoS$class <- as.factor(conj_treinoS$class)\nconj_treinoS <- conj_treinoS %>% rename( inadimplente = class)\nprop.table(table(conj_treinoS$inadimplente))\n\n\n     Nao      Sim \n0.500615 0.499385 \n\nsummary(conj_treinoS)\n\n   estudante         balanco          receita      inadimplente\n Min.   :0.0000   Min.   :   0.0   Min.   :  772   Nao:7733    \n 1st Qu.:0.0000   1st Qu.: 795.5   1st Qu.:20166   Sim:7714    \n Median :0.0000   Median :1392.3   Median :33703               \n Mean   :0.3394   Mean   :1272.9   Mean   :32841               \n 3rd Qu.:1.0000   3rd Qu.:1769.2   3rd Qu.:43745               \n Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula09A.html#a-regressão-logística",
    "href": "semanas/Aula09A.html#a-regressão-logística",
    "title": "Regressão Logística - SMOTE",
    "section": "1a Regressão logística",
    "text": "1a Regressão logística\n\nmod1 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treinoS,family=binomial)\nsummary(mod1)\n\n\nCall:\nglm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n    data = conj_treinoS)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.9262  -0.1967  -0.0084   0.3402   3.0696  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -9.778e+00  2.279e-01 -42.898  < 2e-16 ***\nbalanco      7.115e-03  1.199e-04  59.356  < 2e-16 ***\nreceita      9.409e-06  3.645e-06   2.582  0.00984 ** \nestudante   -6.092e-01  1.071e-01  -5.688 1.28e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 21414.1  on 15446  degrees of freedom\nResidual deviance:  7490.3  on 15443  degrees of freedom\nAIC: 7498.3\n\nNumber of Fisher Scoring iterations: 7\n\ncoef(mod1)\n\n  (Intercept)       balanco       receita     estudante \n-9.778189e+00  7.114940e-03  9.409475e-06 -6.092070e-01 \n\nsummary(mod1)$coef\n\n                 Estimate   Std. Error    z value     Pr(>|z|)\n(Intercept) -9.778189e+00 2.279388e-01 -42.898311 0.000000e+00\nbalanco      7.114940e-03 1.198694e-04  59.355775 0.000000e+00\nreceita      9.409475e-06 3.644856e-06   2.581576 9.835023e-03\nestudante   -6.092070e-01 1.070945e-01  -5.688499 1.281605e-08"
  },
  {
    "objectID": "semanas/Aula09A.html#avaliando-o-modelo-novamente",
    "href": "semanas/Aula09A.html#avaliando-o-modelo-novamente",
    "title": "Regressão Logística - SMOTE",
    "section": "Avaliando o modelo novamente",
    "text": "Avaliando o modelo novamente\n\nprop.table(table(conj_teste$inadimplente))\n\n\n       Nao        Sim \n0.96651674 0.03348326 \n\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1696   11\n       Sim  238   56\n                                          \n               Accuracy : 0.8756          \n                 95% CI : (0.8603, 0.8897)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.2705          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.83582         \n            Specificity : 0.87694         \n         Pos Pred Value : 0.19048         \n         Neg Pred Value : 0.99356         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02799         \n   Detection Prevalence : 0.14693         \n      Balanced Accuracy : 0.85638         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula09A.html#curva-roc",
    "href": "semanas/Aula09A.html#curva-roc",
    "title": "Regressão Logística - SMOTE",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n\n           1            2            3            4            5            6 \n1.710555e-01 3.991424e-04 9.094011e-05 9.398313e-02 3.185776e-03 8.710220e-04 \n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=TRUE,\n                 legacy.axes=TRUE) \n\n\n\nas.numeric(roc_log$auc)\n\n[1] 0.941186"
  },
  {
    "objectID": "semanas/Aula10.html#carregando-bibliotecas",
    "href": "semanas/Aula10.html#carregando-bibliotecas",
    "title": "LDA e QDA",
    "section": "Carregando Bibliotecas",
    "text": "Carregando Bibliotecas\n\nlibrary(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\nstr(Default)\n\n'data.frame':   10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n\nhead(Default)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "semanas/Aula10.html#manipulando-os-dados",
    "href": "semanas/Aula10.html#manipulando-os-dados",
    "title": "LDA e QDA",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncredito <- tibble(Default)\nsummary(credito)\n\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n\ntibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n\nsummary(credito)\n\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554"
  },
  {
    "objectID": "semanas/Aula10.html#treino-e-teste",
    "href": "semanas/Aula10.html#treino-e-teste",
    "title": "LDA e QDA",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n\nsummary(conj_teste)\n\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239"
  },
  {
    "objectID": "semanas/Aula10.html#balanço-e-receita",
    "href": "semanas/Aula10.html#balanço-e-receita",
    "title": "LDA e QDA",
    "section": "Balanço e receita",
    "text": "Balanço e receita\n\nfeaturePlot(x = conj_treino[, c(\"balanco\", \"receita\")], \n            y = conj_treino$inadimplente,\n            plot = \"density\", \n            scales = list(x = list(relation = \"free\"), \n                          y = list(relation = \"free\")), \n            adjust = 1.5, \n            pch = \"|\", \n            layout = c(2, 1), \n            auto.key = list(columns = 2))"
  },
  {
    "objectID": "semanas/Aula10.html#bayes-ingênuo-naive-bayes",
    "href": "semanas/Aula10.html#bayes-ingênuo-naive-bayes",
    "title": "LDA e QDA",
    "section": "Bayes Ingênuo (Naive Bayes)",
    "text": "Bayes Ingênuo (Naive Bayes)\n\nparams <- conj_treino %>% \n     group_by(inadimplente) %>% \n     summarize(media = mean(balanco), desvpad = sd(balanco))\nparams\n\n# A tibble: 2 × 3\n  inadimplente media desvpad\n  <fct>        <dbl>   <dbl>\n1 Nao           801.    456.\n2 Sim          1745.    332.\n\npi <- conj_treino %>% summarize(pi=mean(inadimplente==\"Sim\")) %>% pull(pi)\npi\n\n[1] 0.03325416\n\nx <- conj_teste$balanco\n\nf0 <- dnorm(x, params$media[1], params$desvpad[1])\nf1 <- dnorm(x, params$media[2], params$desvpad[2])\n\np_chapeu_bayes <- f1*pi / (f1*pi + f0*(1 - pi))\ny_chapeu_bayes <- ifelse(p_chapeu_bayes > 0.5, \"Sim\", \"Nao\")\n\nconfusionMatrix(factor(y_chapeu_bayes), conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1927   44\n       Sim    7   23\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.4631         \n                                         \n Mcnemar's Test P-Value : 4.631e-07      \n                                         \n            Sensitivity : 0.34328        \n            Specificity : 0.99638        \n         Pos Pred Value : 0.76667        \n         Neg Pred Value : 0.97768        \n             Prevalence : 0.03348        \n         Detection Rate : 0.01149        \n   Detection Prevalence : 0.01499        \n      Balanced Accuracy : 0.66983        \n                                         \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#calcula-erro",
    "href": "semanas/Aula10.html#calcula-erro",
    "title": "LDA e QDA",
    "section": "Calcula Erro",
    "text": "Calcula Erro\n\ncalc_erro_class <- function(real, previsto) {\n  mean(real != previsto)\n}\n# Este valor é igual a 1 - Accuracy da matriz de confusão\ncalc_erro_class(conj_teste$inadimplente, y_chapeu_bayes)\n\n[1] 0.02548726"
  },
  {
    "objectID": "semanas/Aula10.html#alterando-o-valor-da-probabilidade-priori",
    "href": "semanas/Aula10.html#alterando-o-valor-da-probabilidade-priori",
    "title": "LDA e QDA",
    "section": "Alterando o valor da probabilidade priori",
    "text": "Alterando o valor da probabilidade priori\n\np_chapeu_bayes <- f1*0.15 / (f1*0.15 + f0*(1 - 0.15))\ny_chapeu_bayes <- ifelse(p_chapeu_bayes > 0.5, \"Sim\", \"Nao\")\n\n\nconfusionMatrix(factor(y_chapeu_bayes), conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1839   22\n       Sim   95   45\n                                          \n               Accuracy : 0.9415          \n                 95% CI : (0.9303, 0.9514)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.408           \n                                          \n Mcnemar's Test P-Value : 2.806e-11       \n                                          \n            Sensitivity : 0.67164         \n            Specificity : 0.95088         \n         Pos Pred Value : 0.32143         \n         Neg Pred Value : 0.98818         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02249         \n   Detection Prevalence : 0.06997         \n      Balanced Accuracy : 0.81126         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor é igual a 1 - Accuracy da matriz de confusão\ncalc_erro_class(conj_teste$inadimplente, y_chapeu_bayes)\n\n[1] 0.05847076"
  },
  {
    "objectID": "semanas/Aula10.html#lda",
    "href": "semanas/Aula10.html#lda",
    "title": "LDA e QDA",
    "section": "LDA",
    "text": "LDA\n\nlibrary(MASS)\n\ntreina_lda <- lda(inadimplente ~ balanco + estudante, data = conj_treino)\ntreina_lda\n\nCall:\nlda(inadimplente ~ balanco + estudante, data = conj_treino)\n\nPrior probabilities of groups:\n       Nao        Sim \n0.96674584 0.03325416 \n\nGroup means:\n      balanco estudante\nNao  801.3012 0.2919953\nSim 1744.6575 0.3909774\n\nCoefficients of linear discriminants:\n                   LD1\nbalanco    0.002242096\nestudante -0.216603545\n\nplot(treina_lda)\n\n\n\nnames(predict(treina_lda, conj_treino))\n\n[1] \"class\"     \"posterior\" \"x\"        \n\ny_chapeu <- predict(treina_lda, conj_teste)$class %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1928   45\n       Sim    6   22\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.4523         \n                                         \n Mcnemar's Test P-Value : 1.032e-07      \n                                         \n            Sensitivity : 0.32836        \n            Specificity : 0.99690        \n         Pos Pred Value : 0.78571        \n         Neg Pred Value : 0.97719        \n             Prevalence : 0.03348        \n         Detection Rate : 0.01099        \n   Detection Prevalence : 0.01399        \n      Balanced Accuracy : 0.66263        \n                                         \n       'Positive' Class : Sim            \n                                         \n\n# Este valor é igual a 1 - Accuracy da matriz de confusão\ncalc_erro_class(conj_teste$inadimplente, y_chapeu)\n\n[1] 0.02548726"
  },
  {
    "objectID": "semanas/Aula10.html#lda---ajustando-probabilidade-limite",
    "href": "semanas/Aula10.html#lda---ajustando-probabilidade-limite",
    "title": "LDA e QDA",
    "section": "LDA - Ajustando probabilidade limite",
    "text": "LDA - Ajustando probabilidade limite\n\np_chapeu <- predict(treina_lda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9804367 0.0195633263\n2 0.9996897 0.0003102714\n3 0.9998980 0.0001019950\n4 0.9877333 0.0122667438\n5 0.9989602 0.0010397555\n6 0.9994672 0.0005327889\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1818   19\n       Sim  116   48\n                                          \n               Accuracy : 0.9325          \n                 95% CI : (0.9206, 0.9431)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3864          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.71642         \n            Specificity : 0.94002         \n         Pos Pred Value : 0.29268         \n         Neg Pred Value : 0.98966         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02399         \n   Detection Prevalence : 0.08196         \n      Balanced Accuracy : 0.82822         \n                                          \n       'Positive' Class : Sim             \n                                          \n\n# Este valor é igual a 1 - Accuracy da matriz de confusão\ncalc_erro_class(conj_teste$inadimplente, y_chapeu)\n\n[1] 0.06746627"
  },
  {
    "objectID": "semanas/Aula10.html#qda",
    "href": "semanas/Aula10.html#qda",
    "title": "LDA e QDA",
    "section": "QDA",
    "text": "QDA\n\ntreina_qda <- qda(inadimplente ~ balanco + estudante, data = conj_treino)\ntreina_qda\n\nCall:\nqda(inadimplente ~ balanco + estudante, data = conj_treino)\n\nPrior probabilities of groups:\n       Nao        Sim \n0.96674584 0.03325416 \n\nGroup means:\n      balanco estudante\nNao  801.3012 0.2919953\nSim 1744.6575 0.3909774\n\ny_chapeu <- predict(treina_qda, conj_teste)$class %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1927   41\n       Sim    7   26\n                                          \n               Accuracy : 0.976           \n                 95% CI : (0.9683, 0.9823)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.008318        \n                                          \n                  Kappa : 0.5092          \n                                          \n Mcnemar's Test P-Value : 1.906e-06       \n                                          \n            Sensitivity : 0.38806         \n            Specificity : 0.99638         \n         Pos Pred Value : 0.78788         \n         Neg Pred Value : 0.97917         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01299         \n   Detection Prevalence : 0.01649         \n      Balanced Accuracy : 0.69222         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#qda---ajustando-probabilidade-limite",
    "href": "semanas/Aula10.html#qda---ajustando-probabilidade-limite",
    "title": "LDA e QDA",
    "section": "QDA - Ajustando probabilidade limite",
    "text": "QDA - Ajustando probabilidade limite\n\np_chapeu <- predict(treina_qda, conj_teste)$posterior\nhead(p_chapeu)\n\n        Nao          Sim\n1 0.9882876 1.171241e-02\n2 0.9999968 3.209822e-06\n3 0.9999998 1.848443e-07\n4 0.9946442 5.355842e-03\n5 0.9999472 5.284669e-05\n6 0.9999916 8.371285e-06\n\ny_chapeu <- ifelse(p_chapeu[, 2] > 0.11, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1798   18\n       Sim  136   49\n                                          \n               Accuracy : 0.923           \n                 95% CI : (0.9105, 0.9343)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3573          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.73134         \n            Specificity : 0.92968         \n         Pos Pred Value : 0.26486         \n         Neg Pred Value : 0.99009         \n             Prevalence : 0.03348         \n         Detection Rate : 0.02449         \n   Detection Prevalence : 0.09245         \n      Balanced Accuracy : 0.83051         \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula10.html#curva-roc",
    "href": "semanas/Aula10.html#curva-roc",
    "title": "LDA e QDA",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\n# KNN\nset.seed(21)\nctrl <- trainControl(method = \"cv\")\ntreina_knn <- train(inadimplente ~ balanco + estudante, method = \"knn\", trControl= ctrl, preProcess=c(\"center\", \"scale\"), tuneGrid = data.frame(k = seq(21,140, by=4)), data = conj_treino)\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n# Reg Log\nmod2 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\np_chapeu_log <- predict(mod2, newdata = conj_teste, type = \"response\")\n\n# LDA e QDA\np_chapeu_lda <- predict(treina_lda, conj_teste)$posterior\np_chapeu_qda <- predict(treina_qda, conj_teste)$posterior\n\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE,\n                 col=\"black\", legacy.axes=TRUE)\nroc_lda <- roc(conj_teste$inadimplente ~ p_chapeu_lda[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\nroc_qda <- roc(conj_teste$inadimplente ~ p_chapeu_qda[,2], plot = TRUE, print.auc=FALSE, col=\"blue\", legacy.axes=TRUE, add=TRUE)\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"red\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg Log\",\"LDA\",\"QDA\", \"KNN\"), \n       col=c(\"black\", \"green\",\"blue\", \"red\"),lwd=4)\n\n\n\nas.numeric(roc_log$auc)\n\n[1] 0.9415487\n\nas.numeric(roc_lda$auc)\n\n[1] 0.9412709\n\nas.numeric(roc_qda$auc)\n\n[1] 0.9414715\n\nas.numeric(roc_knn1$auc)\n\n[1] 0.9388361"
  },
  {
    "objectID": "semanas/Aula11.html",
    "href": "semanas/Aula11.html",
    "title": "Arvores de Regressão",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)\nlibrary(psych)"
  },
  {
    "objectID": "semanas/Aula11.html#avaliando-selecionando-dados",
    "href": "semanas/Aula11.html#avaliando-selecionando-dados",
    "title": "Arvores de Regressão",
    "section": "Avaliando, selecionando dados",
    "text": "Avaliando, selecionando dados\n\ndata(\"Boston\")\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\ndescribe(Boston)\n\n        vars   n   mean     sd median trimmed    mad    min    max  range  skew\ncrim       1 506   3.61   8.60   0.26    1.68   0.33   0.01  88.98  88.97  5.19\nzn         2 506  11.36  23.32   0.00    5.08   0.00   0.00 100.00 100.00  2.21\nindus      3 506  11.14   6.86   9.69   10.93   9.37   0.46  27.74  27.28  0.29\nchas       4 506   0.07   0.25   0.00    0.00   0.00   0.00   1.00   1.00  3.39\nnox        5 506   0.55   0.12   0.54    0.55   0.13   0.38   0.87   0.49  0.72\nrm         6 506   6.28   0.70   6.21    6.25   0.51   3.56   8.78   5.22  0.40\nage        7 506  68.57  28.15  77.50   71.20  28.98   2.90 100.00  97.10 -0.60\ndis        8 506   3.80   2.11   3.21    3.54   1.91   1.13  12.13  11.00  1.01\nrad        9 506   9.55   8.71   5.00    8.73   2.97   1.00  24.00  23.00  1.00\ntax       10 506 408.24 168.54 330.00  400.04 108.23 187.00 711.00 524.00  0.67\nptratio   11 506  18.46   2.16  19.05   18.66   1.70  12.60  22.00   9.40 -0.80\nblack     12 506 356.67  91.29 391.44  383.17   8.09   0.32 396.90 396.58 -2.87\nlstat     13 506  12.65   7.14  11.36   11.90   7.11   1.73  37.97  36.24  0.90\nmedv      14 506  22.53   9.20  21.20   21.56   5.93   5.00  50.00  45.00  1.10\n        kurtosis   se\ncrim       36.60 0.38\nzn          3.95 1.04\nindus      -1.24 0.30\nchas        9.48 0.01\nnox        -0.09 0.01\nrm          1.84 0.03\nage        -0.98 1.25\ndis         0.46 0.09\nrad        -0.88 0.39\ntax        -1.15 7.49\nptratio    -0.30 0.10\nblack       7.10 4.06\nlstat       0.46 0.32\nmedv        1.45 0.41\n\ndados <- Boston \nextrato <- dados %>% select(medv, nox, rm)  \nsummary(extrato)\n\n      medv            nox               rm       \n Min.   : 5.00   Min.   :0.3850   Min.   :3.561  \n 1st Qu.:17.02   1st Qu.:0.4490   1st Qu.:5.886  \n Median :21.20   Median :0.5380   Median :6.208  \n Mean   :22.53   Mean   :0.5547   Mean   :6.285  \n 3rd Qu.:25.00   3rd Qu.:0.6240   3rd Qu.:6.623  \n Max.   :50.00   Max.   :0.8710   Max.   :8.780  \n\nboxplot(extrato$medv)"
  },
  {
    "objectID": "semanas/Aula11.html#visualizando-os-dados",
    "href": "semanas/Aula11.html#visualizando-os-dados",
    "title": "Arvores de Regressão",
    "section": "Visualizando os dados",
    "text": "Visualizando os dados\n\n## Distribuição de dados na maior parte simétrica com valores na cauda direta \n## maior do que o esperado para uam distribuição simétrica\nggplot(extrato, aes(x=medv)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(extrato)),0))\n\n\n\n## Grafico de dispersão nox vs rm \nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point()"
  },
  {
    "objectID": "semanas/Aula11.html#arvore-de-regressão",
    "href": "semanas/Aula11.html#arvore-de-regressão",
    "title": "Arvores de Regressão",
    "section": "Arvore de Regressão",
    "text": "Arvore de Regressão\nNa biblioteca rpart as arvores de regressão são obtidas usando o método anova. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo só definimos o menor conjunto de dados numa partição (minsplit) e o parametro de complexidade cp. Qualquer partição/divisão que não melhore o ajuste por um fator de cp não é tentada. Por exemplo, com a partição pela anova, isso significa que o R-quadrado geral deve aumentar pelo valor de cp a cada etapa. O principal papel deste parâmetro é economizar tempo de computação podando divisões que obviamente não valem a pena. Essencialmente, o usuário informa ao programa que qualquer divisão que não melhore o ajuste pelo cp, provavelmente será podada por validação cruzada, e que, portanto, não é necessário persegui-lo.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvreg <- rpart(medv ~ ., \n                data=extrato,\n                method=\"anova\", #para arvore de regressão\n                control=rpart.control(minsplit=30,cp=0.06))\nplot(arvreg)\ntext(arvreg,pretty=0)"
  },
  {
    "objectID": "semanas/Aula11.html#segmentos",
    "href": "semanas/Aula11.html#segmentos",
    "title": "Arvores de Regressão",
    "section": "Segmentos",
    "text": "Segmentos\nA partir da árvore obtida no item anterior podemos fazer uma representação gráfica das partições obtidas.\n\nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point() +\n  geom_segment(aes(x = 0, y = 0.6695, xend = 6.941, yend = 0.6695), \n               linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 6.941, linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 7.437, linetype=\"dashed\", color=\"red\", size=1) \n\n\n\n  # scale_y_continuous(limits = c(0.3, 1)) +"
  },
  {
    "objectID": "semanas/Aula11.html#treino-e-teste-com-todas-as-variáveis",
    "href": "semanas/Aula11.html#treino-e-teste-com-todas-as-variáveis",
    "title": "Arvores de Regressão",
    "section": "Treino e Teste com todas as variáveis",
    "text": "Treino e Teste com todas as variáveis\nAgora vamos trabalhar com o conjunto completo criando um conjunto de treino e teste.\n\n## Vamos criar os conjuntos de treino teste e desenvolver a arvore \n## com todas as variáveis.\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\nindice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)\nconj_treino <- dados[indice,]\nconj_teste <- dados[-indice,]\nhead(conj_treino)\n\n     crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18.0  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n3 0.02729  0.0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0.0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0.0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0.0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n7 0.08829 12.5  7.87    0 0.524 6.012 66.6 5.5605   5 311    15.2 395.60 12.43\n  medv\n1 24.0\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n7 22.9\n\nhead(conj_teste)\n\n      crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n2  0.02731  0.0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n10 0.17004 12.5  7.87    0 0.524 6.004 85.9 6.5921   5 311    15.2 386.71 17.10\n12 0.11747 12.5  7.87    0 0.524 6.009 82.9 6.2267   5 311    15.2 396.90 13.27\n16 0.62739  0.0  8.14    0 0.538 5.834 56.5 4.4986   4 307    21.0 395.62  8.47\n19 0.80271  0.0  8.14    0 0.538 5.456 36.6 3.7965   4 307    21.0 288.99 11.69\n23 1.23247  0.0  8.14    0 0.538 6.142 91.7 3.9769   4 307    21.0 396.90 18.72\n   medv\n2  21.6\n10 18.9\n12 18.9\n16 19.9\n19 20.2\n23 15.2"
  },
  {
    "objectID": "semanas/Aula11.html#arvore-de-regressão-treino",
    "href": "semanas/Aula11.html#arvore-de-regressão-treino",
    "title": "Arvores de Regressão",
    "section": "Arvore de Regressão Treino",
    "text": "Arvore de Regressão Treino\n\n## A função rpart tem diversos parametros aqui foi configurado um deles\n# cp o parametro de complexidade\n# Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande \n# resulta numa arvore muito pequena (underfitting).\n# Nos dois casos se diminui o desempenho do modelo.\narvreg1 <- rpart(medv ~ ., \n                data=conj_treino,\n                method=\"anova\", #para arvore de regressão\n                control=rpart.control(minsplit=30,cp=0.01))\nplot(arvreg1)\ntext(arvreg1,pretty=0)\n\n\n\narvreg1\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=9.65 10   467.4640 23.84000 *\n      13) lstat< 9.65 39   889.2800 32.90000 *\n     7) rm>=7.435 21   960.7895 45.23810 *"
  },
  {
    "objectID": "semanas/Aula11.html#erros-a-partir-do-conjunto-de-treino",
    "href": "semanas/Aula11.html#erros-a-partir-do-conjunto-de-treino",
    "title": "Arvores de Regressão",
    "section": "Erros a partir do conjunto de treino",
    "text": "Erros a partir do conjunto de treino\n\nO erro relativo (Rel error) é obtido através de 1 - R2\nO xerror é obtido através da validação cruzadada (10 fold)\nO xtsd é o desvio padrão dos valores obtidos na validação cruzada.\n\n\n## Mostra 2 gráficos:\n# 1) Variação do R2 aparente e relativo vs número de partições\n# 2) Erro Relativo vs número de partições\nrsq.rpart(arvreg1)\n\n\nRegression tree:\nrpart(formula = medv ~ ., data = conj_treino, method = \"anova\", \n    control = rpart.control(minsplit = 30, cp = 0.01))\n\nVariables actually used in tree construction:\n[1] crim  lstat rm   \n\nRoot node error: 31197/381 = 81.882\n\nn= 381 \n\n        CP nsplit rel error  xerror     xstd\n1 0.461731      0   1.00000 1.01028 0.096645\n2 0.161924      1   0.53827 0.65330 0.065046\n3 0.094840      2   0.37634 0.49315 0.059728\n4 0.034308      3   0.28151 0.37245 0.050769\n5 0.028069      4   0.24720 0.34074 0.051145\n6 0.020942      5   0.21913 0.29254 0.042692\n7 0.010000      6   0.19819 0.28562 0.042529\n\n\n\n\n\n\n\n## Mostra a variação do Erro relativo vs cp(parametro de complexidade)\nplotcp(arvreg1)"
  },
  {
    "objectID": "semanas/Aula11.html#gráfico-de-importancia-das-variáveis",
    "href": "semanas/Aula11.html#gráfico-de-importancia-das-variáveis",
    "title": "Arvores de Regressão",
    "section": "Gráfico de importancia das variáveis",
    "text": "Gráfico de importancia das variáveis\nA importancia das variáveis é calculada com base nos resultados das melhores partições\n\n# Gráfico de Importância de variável\nvar_imp <- arvreg1$variable.importance\nnomes_var <- names(var_imp)\nvar_impdf <- data.frame(Importancia=unname(var_imp), Variavel=nomes_var) %>%\n                        arrange(Importancia)\nvar_impdf$Variavel <- factor(var_impdf$Variavel, levels=var_impdf$Variavel)\nggplot(var_impdf, aes(x=Variavel, y=Importancia)) + \n         geom_col() + \n        coord_flip()"
  },
  {
    "objectID": "semanas/Aula11.html#mostrando-a-árvore-e-gerando-previsões",
    "href": "semanas/Aula11.html#mostrando-a-árvore-e-gerando-previsões",
    "title": "Arvores de Regressão",
    "section": "Mostrando a árvore e gerando previsões",
    "text": "Mostrando a árvore e gerando previsões\n\n# Mostrando a arvore\npar(xpd = NA)\nplot(arvreg1)\ntext(arvreg1,pretty=0)\n\n\n\n# Fazendo Previsões\nprevisao1 <- arvreg1 %>% predict(conj_teste)\nhead(previsao1)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previsão\nRMSE(previsao1, conj_teste$medv)\n\n[1] 5.303593"
  },
  {
    "objectID": "semanas/Aula11.html#arvore-de-regressão-com-caret",
    "href": "semanas/Aula11.html#arvore-de-regressão-com-caret",
    "title": "Arvores de Regressão",
    "section": "Arvore de Regressão com caret",
    "text": "Arvore de Regressão com caret\nAqui vamos usar a biblioteca caret que tem umas facilidades para otimização do cp e apresentação dos resultados\n\nset.seed(21)\n## Otimizamos o valor de cp usando um 10-fold cv\n# O parametro tuneLength diz para o algoritmo escolher diferentes valores para cp\n# O parametro tuneGrid permite decidir que valores cp deve assumir enquanto que o\n# tuneLength somente limita o número default de parametros que se usa.\narvreg2 <- train(medv ~ . , data = conj_treino, method = \"rpart\",\n                 trControl = trainControl(\"cv\", number = 10),\n                 tuneGrid = data.frame(cp = seq(0.01,0.10, length.out=100)) \n                 )\n# Mostra a acurácia vs cp (parametro de complexidade)\nplot(arvreg2)\n\n\n\n## Indica o melhor valor de cp\narvreg2$bestTune\n\n          cp\n4 0.01272727"
  },
  {
    "objectID": "semanas/Aula11.html#desenhando-a-árvore",
    "href": "semanas/Aula11.html#desenhando-a-árvore",
    "title": "Arvores de Regressão",
    "section": "Desenhando a Árvore",
    "text": "Desenhando a Árvore\n\n## Apresenta o modelo final de arvore ajustado\npar(xpd = NA)\nplot(arvreg2$finalModel)\ntext(arvreg2$finalModel,  digits = 3)\n\n\n\n## usando o rpart.plot\nlibrary(rpart.plot)\nrpart.plot(arvreg2$finalModel)"
  },
  {
    "objectID": "semanas/Aula11.html#previsões",
    "href": "semanas/Aula11.html#previsões",
    "title": "Arvores de Regressão",
    "section": "Previsões",
    "text": "Previsões\n\n# Regras de Decisão\narvreg2$finalModel\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=11.315 7   367.8886 21.88571 *\n      13) lstat< 11.315 42   956.1507 32.57857 *\n     7) rm>=7.435 21   960.7895 45.23810 *\n\n# Fazendo Previsões\nprevisao2 <- arvreg2 %>% predict(conj_teste)\nhead(previsao2)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previsão\nRMSE(previsao2, conj_teste$medv)\n\n[1] 5.304604"
  },
  {
    "objectID": "semanas/Aula11.html#vamos-comparar-com-regressão-multipla",
    "href": "semanas/Aula11.html#vamos-comparar-com-regressão-multipla",
    "title": "Arvores de Regressão",
    "section": "Vamos comparar com Regressão Multipla",
    "text": "Vamos comparar com Regressão Multipla\n\nlibrary(leaps)\n## Cria uma função de predição para o leaps\npredict.regsubsets <- function(object,newdata,id,...){\n  form <- as.formula(object$call[[2]])\n  mat <- model.matrix(form,newdata)\n  coefi <- coef(object,id=id)\n  mat[,names(coefi)]%*%coefi\n}\nset.seed(21)\nenvelopes <- sample(rep(1:5,length=nrow(conj_treino)))\ntable(envelopes)\n\nenvelopes\n 1  2  3  4  5 \n77 76 76 76 76 \n\nerro_cv <- matrix(NA,5,13)\nfor(k in 1:5){\n  melh_ajus <- regsubsets(medv ~ ., data=conj_treino[envelopes!=k,], \n                          nvmax=13,method=\"forward\")\n  for(i in 1:13){\n    prev <- predict(melh_ajus, conj_treino[envelopes==k,],id=i)\n    erro_cv[k,i] <- mean( (conj_treino$medv[envelopes==k]-prev)^2)\n  }\n}\nrmse_cv <- sqrt(apply(erro_cv,2,mean))  # Erro medio quadratico de cada modelo\nplot(rmse_cv,pch=19,type=\"b\")"
  },
  {
    "objectID": "semanas/Aula11.html#obtem-a-fórmula-do-modelo",
    "href": "semanas/Aula11.html#obtem-a-fórmula-do-modelo",
    "title": "Arvores de Regressão",
    "section": "Obtem a fórmula do modelo",
    "text": "Obtem a fórmula do modelo\n\ncoef(melh_ajus, 11)\n\n  (Intercept)          crim            zn          chas           nox \n 37.051974686  -0.144753575   0.047778839   1.780110617 -14.931943579 \n           rm           dis           rad           tax       ptratio \n  3.815637016  -1.500993904   0.349882023  -0.015845438  -0.986230946 \n        black         lstat \n  0.009024705  -0.534163142"
  },
  {
    "objectID": "semanas/Aula11.html#teste-com-o-conjunto-de-teste",
    "href": "semanas/Aula11.html#teste-com-o-conjunto-de-teste",
    "title": "Arvores de Regressão",
    "section": "Teste com o conjunto de teste",
    "text": "Teste com o conjunto de teste\n\nprevisao3 <- predict(melh_ajus, conj_teste, 11) \nRMSE(previsao3, conj_teste$medv)\n\n[1] 5.936577"
  },
  {
    "objectID": "semanas/Aula11A.html",
    "href": "semanas/Aula11A.html",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)"
  },
  {
    "objectID": "semanas/Aula11A.html#avaliando-selecionando-dados",
    "href": "semanas/Aula11A.html#avaliando-selecionando-dados",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Avaliando, selecionando dados",
    "text": "Avaliando, selecionando dados\n\ndata(\"Boston\")\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\ndados <- Boston"
  },
  {
    "objectID": "semanas/Aula11A.html#treino-e-teste-com-todas-as-variáveis",
    "href": "semanas/Aula11A.html#treino-e-teste-com-todas-as-variáveis",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Treino e Teste com todas as variáveis",
    "text": "Treino e Teste com todas as variáveis\n\n## Vamos criar os conjuntos de treino teste e desenvolver a arvore \n## com todas as variáveis.\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\nindice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)\nconj_treino <- dados[indice,]\nconj_teste <- dados[-indice,]\nhead(conj_treino)\n\n     crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18.0  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n3 0.02729  0.0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0.0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0.0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0.0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n7 0.08829 12.5  7.87    0 0.524 6.012 66.6 5.5605   5 311    15.2 395.60 12.43\n  medv\n1 24.0\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n7 22.9\n\nhead(conj_teste)\n\n      crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n2  0.02731  0.0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n10 0.17004 12.5  7.87    0 0.524 6.004 85.9 6.5921   5 311    15.2 386.71 17.10\n12 0.11747 12.5  7.87    0 0.524 6.009 82.9 6.2267   5 311    15.2 396.90 13.27\n16 0.62739  0.0  8.14    0 0.538 5.834 56.5 4.4986   4 307    21.0 395.62  8.47\n19 0.80271  0.0  8.14    0 0.538 5.456 36.6 3.7965   4 307    21.0 288.99 11.69\n23 1.23247  0.0  8.14    0 0.538 6.142 91.7 3.9769   4 307    21.0 396.90 18.72\n   medv\n2  21.6\n10 18.9\n12 18.9\n16 19.9\n19 20.2\n23 15.2"
  },
  {
    "objectID": "semanas/Aula11A.html#a-tentativa-gbm",
    "href": "semanas/Aula11A.html#a-tentativa-gbm",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "1a tentativa GBM",
    "text": "1a tentativa GBM\n\nlibrary(gbm)\n\nLoaded gbm 2.1.8.1\n\nset.seed(21)\n# treinar o modelo GBM\ngbm.fit <- gbm(formula = medv ~ .,\n                distribution = \"gaussian\", #  minimizar erro quadrático\n                data = conj_treino,\n                n.trees = 10000,  # número de árvores\n                interaction.depth = 3,  # profundidade da arvore\n                shrinkage = 0.1,   # aprendizado rápido\n                cv.folds = 5, # 5 envelopes de validaçõa cruzada\n                n.cores = NULL, # \n                verbose = FALSE)\n\n# Achar o índice do modelo com menor erro de valiação cruzada\nmin_MSE <- which.min(gbm.fit$cv.error)\n\n# Obter o MSE e calcular o RMSE\nsqrt(gbm.fit$cv.error[min_MSE])\n\n[1] 3.385086\n\n# Mostrar a função de perda (loss function) como resultado do número de árvores combinadas\n# A linha preta são os valores para as perdas de treino e a verde as de teste\n# A linha azul pontilhada indica o número de árvores que minimiza os erros da validação cruzada\ngbm.perf(gbm.fit, method = \"cv\")\n\n\n\n\n[1] 497"
  },
  {
    "objectID": "semanas/Aula11A.html#criando-um-grid-para-avaliar-os-parametros-e-os-respectivos-rmses",
    "href": "semanas/Aula11A.html#criando-um-grid-para-avaliar-os-parametros-e-os-respectivos-rmses",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Criando um grid para avaliar os parametros e os respectivos RMSEs",
    "text": "Criando um grid para avaliar os parametros e os respectivos RMSEs\n\nhiper_grid <- expand.grid(\n  shrinkage = c(.01, .05, .1),\n  interaction.depth = c(1, 3, 5, 7),\n  n.minobsinnode = c(5, 10, 15),\n  bag.fraction = c(.65, .8, 1),\n  optimal_trees = 0, \n  min_RMSE = 0   \n  )\n\n# numero total de combinações\nnrow(hiper_grid)\n\n[1] 108"
  },
  {
    "objectID": "semanas/Aula11A.html#avaliando-o-grid-de-parametros",
    "href": "semanas/Aula11A.html#avaliando-o-grid-de-parametros",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Avaliando o grid de parametros",
    "text": "Avaliando o grid de parametros\n\n# Busca no grid \nfor(i in 1:nrow(hiper_grid)) {\n  \n  # \n  set.seed(21)\n  \n  # treina o modelo\n  gbm.tune <- gbm(\n    formula = medv ~ .,\n    distribution = \"gaussian\",\n    data = conj_treino,\n    n.trees = 6000,\n    interaction.depth = hiper_grid$interaction.depth[i],\n    shrinkage = hiper_grid$shrinkage[i],\n    n.minobsinnode = hiper_grid$n.minobsinnode[i],\n    bag.fraction = hiper_grid$bag.fraction[i],\n    train.fraction = .75,\n    n.cores = NULL, \n    verbose = FALSE\n  )\n  \n # adiciona os erros de treino e arvores ao grid\n  hiper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)\n  hiper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))\n}\n\nhiper_grid %>% dplyr::arrange(min_RMSE) %>% head(10)\n\n   shrinkage interaction.depth n.minobsinnode bag.fraction optimal_trees\n1       0.10                 1             15         0.65          3074\n2       0.10                 1             10         0.65          5262\n3       0.05                 1             15         0.80          4392\n4       0.10                 1             15         0.80          3321\n5       0.05                 1             15         0.65          3074\n6       0.05                 1             10         1.00          4455\n7       0.10                 1             10         1.00          2073\n8       0.10                 1             15         1.00          4124\n9       0.05                 1             15         1.00          5996\n10      0.05                 5             15         0.65           178\n   min_RMSE\n1  4.420519\n2  4.655791\n3  4.667658\n4  4.686840\n5  4.699871\n6  4.775397\n7  4.780322\n8  4.788251\n9  4.818321\n10 4.818439"
  },
  {
    "objectID": "semanas/Aula11A.html#modelo-final",
    "href": "semanas/Aula11A.html#modelo-final",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Modelo final",
    "text": "Modelo final\n\n# \nset.seed(21)\n\n# treina o modelo GBM\ngbm.fit.final <- gbm(\n  formula = medv ~ .,\n  distribution = \"gaussian\",\n  data = conj_treino,\n  n.trees = 3074,\n  interaction.depth = 1,\n  shrinkage = 0.10,\n  n.minobsinnode = 15,\n  bag.fraction = 0.65, \n  train.fraction = 1,\n  n.cores = NULL, \n  verbose = FALSE\n  )"
  },
  {
    "objectID": "semanas/Aula11A.html#variable-importance",
    "href": "semanas/Aula11A.html#variable-importance",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Variable importance",
    "text": "Variable importance\n\nsummary(\n  gbm.fit.final, \n  cBars = 13,\n  method = relative.influence, # também pode ser usado permutation.test.gbm\n  las = 2\n  )\n\n\n\n\n            var    rel.inf\nrm           rm 34.2998187\nlstat     lstat 29.4374141\ndis         dis  8.3574770\nnox         nox  5.9614131\ncrim       crim  5.5011677\nchas       chas  4.5023266\nptratio ptratio  3.5157834\nblack     black  3.4315023\nage         age  2.3514968\ntax         tax  1.4830798\nindus     indus  0.6084729\nrad         rad  0.4554056\nzn           zn  0.0946421"
  },
  {
    "objectID": "semanas/Aula11A.html#previsão",
    "href": "semanas/Aula11A.html#previsão",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Previsão",
    "text": "Previsão\n\n# Fazendo Previsões\nprevisao1 <- predict(gbm.fit.final, \n                     newdata = conj_teste,\n                     n.trees=gbm.fit.final$n.trees)\nhead(previsao1)\n\n[1] 19.73374 18.76262 19.89281 20.76348 18.34094 16.44815\n\n# Calcula os erros de previsão\ncaret::RMSE(previsao1, conj_teste$medv)\n\n[1] 4.189849"
  },
  {
    "objectID": "semanas/Aula11A.html#entendendo-melhor-os-resultados",
    "href": "semanas/Aula11A.html#entendendo-melhor-os-resultados",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Entendendo melhor os resultados",
    "text": "Entendendo melhor os resultados\n\nlibrary(lime)\n\n\nAttaching package: 'lime'\n\n\nThe following object is masked from 'package:dplyr':\n\n    explain\n\nmodel_type.gbm <- function(x, ...) {\n  return(\"regression\")\n}\n\npredict_model.gbm <- function(x, newdata, ...) {\n  pred <- predict(x, newdata, n.trees = x$n.trees)\n  return(as.data.frame(pred))\n}\n# Algumas observações para avaliar\nobs_pontuais <- conj_teste[1:2, ]\n\n# aplica o LIME\nexplicador <- lime(conj_treino, gbm.fit.final)\n\nWarning: chas does not contain enough variance to use quantile binning. Using\nstandard binning instead.\n\nexplicacao <- explain(obs_pontuais, explicador, n_features = 5)\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n =\nNULL, : skipping variable with zero or non-finite range\n\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n =\nNULL, : skipping variable with zero or non-finite range\n\nplot_features(explicacao)"
  },
  {
    "objectID": "semanas/Aula11A.html#gráfico-de-dependencia-parcial-partial-dependence-plot",
    "href": "semanas/Aula11A.html#gráfico-de-dependencia-parcial-partial-dependence-plot",
    "title": "Arvores de Regressão - Gradient Boosting",
    "section": "Gráfico de Dependencia Parcial (Partial Dependence Plot)",
    "text": "Gráfico de Dependencia Parcial (Partial Dependence Plot)\n\ngraf_rm <- plot(gbm.fit.final, i = \"rm\")\ngraf_lstat <- plot(gbm.fit.final, i = \"lstat\")\ngridExtra::grid.arrange(graf_lstat, graf_rm, ncol = 2)"
  },
  {
    "objectID": "semanas/Aula12.html",
    "href": "semanas/Aula12.html",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)"
  },
  {
    "objectID": "semanas/Aula12.html#dados",
    "href": "semanas/Aula12.html#dados",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Dados",
    "text": "Dados\nVamos começar a aplicar a metodologia de árvores usando árvores de classificação para analisar os dados existentes em Carseats. Este conjunto de dados (simulado) é sobre venda de assentos de criança para carros. Ele tem 400 observações das seguintes variáveis (11), cujos nomes serão convertidos para o português:\nSales: vendas em unidades (em mil) em cada local\nCompPrice: preço cobrado pelo competidor em cada local\nIncome: nível de renda da comunidade local (em mil US$)\nAdvertising: orçamento local de propaganda (em mil US$)\nPopulation: população na região (em mil)\nPrice: preço cobrado pela empresa em cada local\nShelveLoc: um fator com níveis Ruim, Bom e Medio indicando a qualidade da localização das prateleiras para os assentos em cada lugar\nAge: idade media da população local\nEducation: nível de educação em cada local\nUrban: um fator Sim e Não indicando se a loja esta em uma área urbana ou rural\nUS: um fator indicando se a loja é nos EUA ou não\nNeste dados, Sales é a variável resposta, só que ela é uma variável contínua, por este motivo vamos usá-la para criar uma variável binária. Vamos usar a função ifelse() para criar a variável binária, que chamaremos de alta, ela assume os valores Sim se Sales for maior que 8 e assume o valor Não caso contrário:\n\ndata(Carseats)\nsummary(Carseats)\n\n     Sales          CompPrice       Income        Advertising    \n Min.   : 0.000   Min.   : 77   Min.   : 21.00   Min.   : 0.000  \n 1st Qu.: 5.390   1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000  \n Median : 7.490   Median :125   Median : 69.00   Median : 5.000  \n Mean   : 7.496   Mean   :125   Mean   : 68.66   Mean   : 6.635  \n 3rd Qu.: 9.320   3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000  \n Max.   :16.270   Max.   :175   Max.   :120.00   Max.   :29.000  \n   Population        Price        ShelveLoc        Age          Education   \n Min.   : 10.0   Min.   : 24.0   Bad   : 96   Min.   :25.00   Min.   :10.0  \n 1st Qu.:139.0   1st Qu.:100.0   Good  : 85   1st Qu.:39.75   1st Qu.:12.0  \n Median :272.0   Median :117.0   Medium:219   Median :54.50   Median :14.0  \n Mean   :264.8   Mean   :115.8                Mean   :53.32   Mean   :13.9  \n 3rd Qu.:398.5   3rd Qu.:131.0                3rd Qu.:66.00   3rd Qu.:16.0  \n Max.   :509.0   Max.   :191.0                Max.   :80.00   Max.   :18.0  \n Urban       US     \n No :118   No :142  \n Yes:282   Yes:258  \n                    \n                    \n                    \n                    \n\nstr(Carseats)\n\n'data.frame':   400 obs. of  11 variables:\n $ Sales      : num  9.5 11.22 10.06 7.4 4.15 ...\n $ CompPrice  : num  138 111 113 117 141 124 115 136 132 132 ...\n $ Income     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ Advertising: num  11 16 10 4 3 13 0 15 0 0 ...\n $ Population : num  276 260 269 466 340 501 45 425 108 131 ...\n $ Price      : num  120 83 80 97 128 72 108 120 124 124 ...\n $ ShelveLoc  : Factor w/ 3 levels \"Bad\",\"Good\",\"Medium\": 1 2 3 3 1 1 3 2 3 3 ...\n $ Age        : num  42 65 59 55 38 78 71 67 76 76 ...\n $ Education  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ Urban      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 2 2 1 1 ...\n $ US         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 1 2 1 2 ..."
  },
  {
    "objectID": "semanas/Aula12.html#manipulando-os-dados",
    "href": "semanas/Aula12.html#manipulando-os-dados",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncad_crianca <- Carseats %>% rename(vendas = Sales, \n                                   preco_comp = CompPrice,\n                                   renda = Income,\n                                   propaganda = Advertising,\n                                   populacao = Population,\n                                   preco = Price,\n                                   local_prat = ShelveLoc,\n                                   idade = Age,\n                                   educacao = Education,\n                                   urbano = Urban,\n                                   eua = US)\n\ncad_crianca <- cad_crianca %>% mutate(alta = ifelse(vendas > 8, \"Sim\",\n                                                   \"Não\")) %>%\n                              mutate(alta = factor(alta))\n\ncad_crianca<- cad_crianca %>% mutate(local_prat =  case_when(\n                                      local_prat == \"Bad\"  ~ \"Ruim\",\n                                      local_prat == \"Good\" ~ \"Bom\",\n                                      local_prat == \"Medium\" ~ \"Medio\"))%>%                               mutate(local_prat = factor(local_prat))\n\ncad_crianca<- cad_crianca %>% mutate(urbano =  case_when(\n                                      urbano == \"Yes\"  ~ \"Sim\",\n                                      urbano == \"No\" ~ \"Não\")) %>%                                       mutate(urbano = factor(urbano))\n\ncad_crianca<- cad_crianca %>% mutate(eua =  case_when(\n                                      eua == \"Yes\"  ~ \"Sim\",\n                                      eua == \"No\" ~ \"Não\")) %>%                                          mutate(eua = factor(eua))\n\ncad_crianca<- cad_crianca %>% select(-vendas)\n\nstr(cad_crianca)\n\n'data.frame':   400 obs. of  11 variables:\n $ preco_comp: num  138 111 113 117 141 124 115 136 132 132 ...\n $ renda     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ propaganda: num  11 16 10 4 3 13 0 15 0 0 ...\n $ populacao : num  276 260 269 466 340 501 45 425 108 131 ...\n $ preco     : num  120 83 80 97 128 72 108 120 124 124 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 2 3 3 2 1 2 2 ...\n $ idade     : num  42 65 59 55 38 78 71 67 76 76 ...\n $ educacao  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 2 2 1 2 2 1 1 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 2 1 2 1 2 1 2 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 1 1 2 1 2 1 1 ...\n\nsummary(cad_crianca)\n\n   preco_comp      renda          propaganda       populacao    \n Min.   : 77   Min.   : 21.00   Min.   : 0.000   Min.   : 10.0  \n 1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000   1st Qu.:139.0  \n Median :125   Median : 69.00   Median : 5.000   Median :272.0  \n Mean   :125   Mean   : 68.66   Mean   : 6.635   Mean   :264.8  \n 3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000   3rd Qu.:398.5  \n Max.   :175   Max.   :120.00   Max.   :29.000   Max.   :509.0  \n     preco       local_prat      idade          educacao    urbano     eua     \n Min.   : 24.0   Bom  : 85   Min.   :25.00   Min.   :10.0   Não:118   Não:142  \n 1st Qu.:100.0   Medio:219   1st Qu.:39.75   1st Qu.:12.0   Sim:282   Sim:258  \n Median :117.0   Ruim : 96   Median :54.50   Median :14.0                      \n Mean   :115.8               Mean   :53.32   Mean   :13.9                      \n 3rd Qu.:131.0               3rd Qu.:66.00   3rd Qu.:16.0                      \n Max.   :191.0               Max.   :80.00   Max.   :18.0                      \n  alta    \n Não:236  \n Sim:164"
  },
  {
    "objectID": "semanas/Aula12.html#treino-e-teste",
    "href": "semanas/Aula12.html#treino-e-teste",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\ny <- cad_crianca$alta\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- cad_crianca %>% slice(-indice_teste)\nconj_teste <- cad_crianca %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   319 obs. of  11 variables:\n $ preco_comp: num  138 111 113 141 124 136 132 121 117 122 ...\n $ renda     : num  73 48 35 64 113 81 110 78 94 35 ...\n $ propaganda: num  11 16 10 3 13 15 0 9 4 2 ...\n $ populacao : num  276 260 269 340 501 425 108 150 503 393 ...\n $ preco     : num  120 83 80 128 72 120 124 100 94 136 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 3 3 1 2 3 1 2 ...\n $ idade     : num  42 65 59 38 78 67 76 26 50 62 ...\n $ educacao  : num  17 10 12 13 16 10 10 10 13 18 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 2 1 2 1 1 2 2 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n\nprop.table(table(conj_treino$alta))\n\n\n      Não       Sim \n0.5893417 0.4106583 \n\nstr(conj_teste)\n\n'data.frame':   81 obs. of  11 variables:\n $ preco_comp: num  117 115 132 115 147 145 114 121 123 103 ...\n $ renda     : num  100 105 113 28 74 119 38 41 42 93 ...\n $ propaganda: num  4 0 0 11 13 16 13 5 11 15 ...\n $ populacao : num  466 45 131 29 251 294 317 412 16 188 ...\n $ preco     : num  97 108 124 86 131 113 128 110 134 103 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 2 2 2 1 1 3 1 2 2 3 ...\n $ idade     : num  55 71 76 53 52 42 50 54 59 74 ...\n $ educacao  : num  14 15 17 18 10 12 16 10 13 16 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 1 2 2 2 2 2 2 2 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 1 2 2 2 2 2 2 2 2 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 1 1 1 2 2 2 2 1 1 1 ...\n\nprop.table(table(conj_teste$alta))\n\n\n      Não       Sim \n0.5925926 0.4074074"
  },
  {
    "objectID": "semanas/Aula12.html#arvore-de-classificação",
    "href": "semanas/Aula12.html#arvore-de-classificação",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Arvore de Classificação",
    "text": "Arvore de Classificação\nNa biblioteca rpart as arvores de classificação são obtidas usando o método class. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo só definimos o menor conjunto de dados numa partição (minsplit) e o parametro de complexidade cp. Posteriormente vamos ampliar este controle. Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande resulta numa arvore muito pequena (underfitting). Nos dois casos se diminui o desempenho do modelo.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(alta ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classificação\n                control=rpart.control(minsplit=30,cp=0.02))\nplot(arvcl)\ntext(arvcl,pretty=0)\n\n\n\n\n\n\n# Regras de Decisão\narvcl\n\nn= 319 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 319 131 Não (0.58934169 0.41065831)  \n   2) local_prat=Medio,Ruim 249  77 Não (0.69076305 0.30923695)  \n     4) preco>=92 213  51 Não (0.76056338 0.23943662)  \n       8) idade>=49.5 123  15 Não (0.87804878 0.12195122) *\n       9) idade< 49.5 90  36 Não (0.60000000 0.40000000)  \n        18) preco>=124.5 44   6 Não (0.86363636 0.13636364) *\n        19) preco< 124.5 46  16 Sim (0.34782609 0.65217391) *\n     5) preco< 92 36  10 Sim (0.27777778 0.72222222)  \n      10) local_prat=Ruim 13   5 Não (0.61538462 0.38461538) *\n      11) local_prat=Medio 23   2 Sim (0.08695652 0.91304348) *\n   3) local_prat=Bom 70  16 Sim (0.22857143 0.77142857)  \n     6) preco>=142.5 10   3 Não (0.70000000 0.30000000) *\n     7) preco< 142.5 60   9 Sim (0.15000000 0.85000000) *"
  },
  {
    "objectID": "semanas/Aula12.html#desenhando-a-árvore-de-uma-forma-mais-clara",
    "href": "semanas/Aula12.html#desenhando-a-árvore-de-uma-forma-mais-clara",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Desenhando a Árvore de uma forma mais clara",
    "text": "Desenhando a Árvore de uma forma mais clara\n\nlibrary(rattle)\n\nCarregando pacotes exigidos: bitops\n\n\nRattle: A free graphical interface for data science with R.\nVersion 5.5.1 Copyright (c) 2006-2021 Togaware Pty Ltd.\nType 'rattle()' to shake, rattle, and roll your data.\n\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)"
  },
  {
    "objectID": "semanas/Aula12.html#previsões",
    "href": "semanas/Aula12.html#previsões",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Previsões",
    "text": "Previsões\n\n# Fazendo Previsões\ny_chapeu <- predict(arvcl, newdata = conj_teste, type=\"class\")\n\nconfusionMatrix(y_chapeu, conj_teste$alta, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Não Sim\n       Não  37  13\n       Sim  11  20\n                                          \n               Accuracy : 0.7037          \n                 95% CI : (0.5919, 0.8001)\n    No Information Rate : 0.5926          \n    P-Value [Acc > NIR] : 0.02573         \n                                          \n                  Kappa : 0.3805          \n                                          \n Mcnemar's Test P-Value : 0.83826         \n                                          \n            Sensitivity : 0.6061          \n            Specificity : 0.7708          \n         Pos Pred Value : 0.6452          \n         Neg Pred Value : 0.7400          \n             Prevalence : 0.4074          \n         Detection Rate : 0.2469          \n   Detection Prevalence : 0.3827          \n      Balanced Accuracy : 0.6884          \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula12.html#arvore-de-classificação-no-caret",
    "href": "semanas/Aula12.html#arvore-de-classificação-no-caret",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Arvore de Classificação no caret",
    "text": "Arvore de Classificação no caret\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\nset.seed(21)\n## Otimizamos o valor de cp usando um 10-fold cv\n# O parametro tuneLength diz para o algoritmo escolher diferentes valores para cp\n# O parametro tuneGrid permite decidir que valores cp deve assumir enquanto que o\n# tuneLength somente limita o número default de parametros que se usa.\ntgrid <- expand.grid(cp = seq(0.01,0.10,0.001))\nctrl <- trainControl(method = \"cv\", classProbs=TRUE)\narvclass <- train(alta ~ . , data = conj_treino, method = \"rpart\",\n                 trControl = ctrl,\n                 tuneGrid = tgrid\n                 )\n# Mostra a acurácia vs cp (parametro de complexidade)\nplot(arvclass)\n\n\n\n## Indica o melhor valor de cp\narvclass$bestTune\n\n     cp\n7 0.016"
  },
  {
    "objectID": "semanas/Aula12.html#uma-forma-melhor-de-ver-a-árvore",
    "href": "semanas/Aula12.html#uma-forma-melhor-de-ver-a-árvore",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Uma forma melhor de ver a Árvore",
    "text": "Uma forma melhor de ver a Árvore\n\n## melhorando apresentação da árvore\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvclass$finalModel, caption = NULL)"
  },
  {
    "objectID": "semanas/Aula12.html#previsões-1",
    "href": "semanas/Aula12.html#previsões-1",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Previsões",
    "text": "Previsões\n\n# Fazendo Previsões\ny_chapeu <- arvclass %>% predict(conj_teste) %>% \n                   factor(levels = levels(conj_teste$alta))\nhead(y_chapeu)\n\n[1] Não Não Não Sim Sim Não\nLevels: Não Sim\n\nconfusionMatrix(y_chapeu, conj_teste$alta, positive=\"Sim\") \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Não Sim\n       Não  40  13\n       Sim   8  20\n                                          \n               Accuracy : 0.7407          \n                 95% CI : (0.6314, 0.8318)\n    No Information Rate : 0.5926          \n    P-Value [Acc > NIR] : 0.003896        \n                                          \n                  Kappa : 0.45            \n                                          \n Mcnemar's Test P-Value : 0.382733        \n                                          \n            Sensitivity : 0.6061          \n            Specificity : 0.8333          \n         Pos Pred Value : 0.7143          \n         Neg Pred Value : 0.7547          \n             Prevalence : 0.4074          \n         Detection Rate : 0.2469          \n   Detection Prevalence : 0.3457          \n      Balanced Accuracy : 0.7197          \n                                          \n       'Positive' Class : Sim"
  },
  {
    "objectID": "semanas/Aula12.html#gbm",
    "href": "semanas/Aula12.html#gbm",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "GBM",
    "text": "GBM"
  },
  {
    "objectID": "semanas/Aula12.html#criando-um-grid-para-avaliar-os-parametros",
    "href": "semanas/Aula12.html#criando-um-grid-para-avaliar-os-parametros",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Criando um grid para avaliar os parametros",
    "text": "Criando um grid para avaliar os parametros\n\nhiper_grid <- expand.grid(\n  shrinkage = c(.001, .01, .1),\n  interaction.depth = c(1, 3, 5),\n  n.minobsinnode = c(5, 10, 15),\n  bag.fraction = c(.65, 1),\n  optimal_trees = 0, # um lugar para guardar resultados\n  min_erro = 0   # um lugar para guardar resultados\n  )\n\n# número total de combinações\nnrow(hiper_grid)\n\n[1] 54"
  },
  {
    "objectID": "semanas/Aula12.html#avaliando-o-grid-de-parametros",
    "href": "semanas/Aula12.html#avaliando-o-grid-de-parametros",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Avaliando o grid de parametros",
    "text": "Avaliando o grid de parametros\n\nlibrary(gbm)\n\nLoaded gbm 2.1.8.1\n\nconj_treino$alta <- as.numeric(conj_treino$alta)\nconj_treino <- transform(conj_treino, alta=alta - 1)\nconj_treino$eua <- as.numeric(conj_treino$eua)\nconj_treino <- transform(conj_treino, eua=eua - 1)\nconj_treino$local_prat <- as.numeric(conj_treino$local_prat)\nconj_treino <- transform(conj_treino, local_prat=local_prat - 1)\n\n\n#Busca no grid\nfor(i in 1:nrow(hiper_grid)) {\n\n  #\n  set.seed(21)\n\n  # treina o modelo\n  gbm.tune <- gbm(\n    formula = alta ~ .,\n    distribution = \"bernoulli\",\n    data = conj_treino,\n    n.trees = 5000,\n    interaction.depth = hiper_grid$interaction.depth[i],\n    shrinkage = hiper_grid$shrinkage[i],\n    n.minobsinnode = hiper_grid$n.minobsinnode[i],\n    bag.fraction = hiper_grid$bag.fraction[i],\n    train.fraction = .75,\n    n.cores = NULL,\n    verbose = FALSE\n  )\n\n  # adiciona os erros de treino e arvores ao grid\n  hiper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)\n  hiper_grid$min_erro[i] <- min(gbm.tune$valid.error)\n}\n\nhiper_grid %>% dplyr::arrange(min_erro) %>% head(10)\n\n   shrinkage interaction.depth n.minobsinnode bag.fraction optimal_trees\n1       0.10                 1             15         0.65           372\n2       0.10                 1             10         0.65           293\n3       0.01                 1             15         0.65          2906\n4       0.10                 3              5         1.00           208\n5       0.01                 1             10         0.65          2904\n6       0.10                 1             15         1.00           645\n7       0.01                 3             10         1.00          1871\n8       0.10                 1              5         0.65           297\n9       0.10                 3             10         0.65            91\n10      0.01                 1              5         0.65          2721\n    min_erro\n1  0.5791345\n2  0.5845112\n3  0.5924547\n4  0.5972617\n5  0.5985068\n6  0.6025920\n7  0.6045516\n8  0.6046190\n9  0.6074368\n10 0.6101727"
  },
  {
    "objectID": "semanas/Aula12.html#modelo-final",
    "href": "semanas/Aula12.html#modelo-final",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Modelo final",
    "text": "Modelo final\n\n# \nset.seed(21)\n\n# treina o modelo GBM\ngbm.fit.final <- gbm(\n  formula = alta ~ .,\n  distribution = \"bernoulli\",\n  data = conj_treino,\n  n.trees = 372,\n  interaction.depth = 1,\n  shrinkage = 0.10,\n  n.minobsinnode = 15,\n  bag.fraction = 0.65, \n  train.fraction = 1,\n  n.cores = NULL, \n  verbose = FALSE\n  )"
  },
  {
    "objectID": "semanas/Aula12.html#importância-das-variáveis",
    "href": "semanas/Aula12.html#importância-das-variáveis",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Importância das Variáveis",
    "text": "Importância das Variáveis\n\npar(mai = c(1, 2, 1, 2))\nsummary(\n  gbm.fit.final, \n  cBars = 10,\n  method = relative.influence, # também pode ser usado permutation.test.gbm\n  las = 2\n  )\n\n\n\n\n                  var   rel.inf\npreco           preco 29.933549\nlocal_prat local_prat 25.047847\npreco_comp preco_comp 11.862257\nidade           idade 11.216571\npropaganda propaganda  9.259809\nrenda           renda  8.997264\npopulacao   populacao  2.456444\neducacao     educacao  1.226259\nurbano         urbano  0.000000\neua               eua  0.000000"
  },
  {
    "objectID": "semanas/Aula12.html#previsão",
    "href": "semanas/Aula12.html#previsão",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Previsão",
    "text": "Previsão\n\nconj_teste$alta <- as.numeric(conj_teste$alta)\nconj_teste <- transform(conj_teste, alta=alta - 1)\nconj_teste$eua <- as.numeric(conj_teste$eua)\nconj_teste <- transform(conj_teste, eua=eua - 1)\nconj_teste$local_prat <- as.numeric(conj_teste$local_prat)\nconj_teste <- transform(conj_teste, local_prat=local_prat - 1)\n\n# Fazendo Previsões\nprevisao1 <- predict(gbm.fit.final, \n                     newdata = conj_teste,\n                     n.trees=gbm.fit.final$n.trees,\n                     type = \"response\")\nhead(previsao1)\n\n[1] 0.7636749 0.1247695 0.1744068 0.9893847 0.9904309 0.9449501\n\ngbm.ychapeu <- as.factor(ifelse(previsao1 < 0.5,0,1))\n \nconfusionMatrix(gbm.ychapeu,as.factor(conj_teste$alta), positive=\"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 43  5\n         1  5 28\n                                          \n               Accuracy : 0.8765          \n                 95% CI : (0.7847, 0.9392)\n    No Information Rate : 0.5926          \n    P-Value [Acc > NIR] : 2.162e-08       \n                                          \n                  Kappa : 0.7443          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.8485          \n            Specificity : 0.8958          \n         Pos Pred Value : 0.8485          \n         Neg Pred Value : 0.8958          \n             Prevalence : 0.4074          \n         Detection Rate : 0.3457          \n   Detection Prevalence : 0.4074          \n      Balanced Accuracy : 0.8722          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "semanas/Aula12.html#curva-roc",
    "href": "semanas/Aula12.html#curva-roc",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Curva ROC",
    "text": "Curva ROC\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\np_chapeu_gbm <- previsao1\nroc_gbm <- roc(conj_teste$alta ~ p_chapeu_gbm, plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\n\n\nas.numeric(roc_gbm$auc)\n\n[1] 0.9248737"
  },
  {
    "objectID": "semanas/Aula12A.html",
    "href": "semanas/Aula12A.html",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ISLR)"
  },
  {
    "objectID": "semanas/Aula12A.html#dados",
    "href": "semanas/Aula12A.html#dados",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Dados",
    "text": "Dados\nVamos começar a aplicar a metodologia de árvores usando árvores de classificação para analisar os dados existentes em Carseats. Este conjunto de dados (simulado) é sobre venda de assentos de criança para carros. Ele tem 400 observações das seguintes variáveis (11), cujos nomes serão convertidos para o português:\nSales: vendas em unidades (em mil) em cada local\nCompPrice: preço cobrado pelo competidor em cada local\nIncome: nível de renda da comunidade local (em mil US$)\nAdvertising: orçamento local de propaganda (em mil US$)\nPopulation: população na região (em mil)\nPrice: preço cobrado pela empresa em cada local\nShelveLoc: um fator com níveis Ruim, Bom e Medio indicando a qualidade da localização das prateleiras para os assentos em cada lugar\nAge: idade media da população local\nEducation: nível de educação em cada local\nUrban: um fator Sim e Não indicando se a loja esta em uma área urbana ou rural\nUS: um fator indicando se a loja é nos EUA ou não\nNeste dados, Sales é a variável resposta, só que ela é uma variável contínua, por este motivo vamos usá-la para criar uma variável binária. Vamos usar a função ifelse() para criar a variável binária, que chamaremos de alta, ela assume os valores Sim se Sales for maior que 8 e assume o valor Não caso contrário:\n\ndata(Carseats)\nsummary(Carseats)\n\n     Sales          CompPrice       Income        Advertising    \n Min.   : 0.000   Min.   : 77   Min.   : 21.00   Min.   : 0.000  \n 1st Qu.: 5.390   1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000  \n Median : 7.490   Median :125   Median : 69.00   Median : 5.000  \n Mean   : 7.496   Mean   :125   Mean   : 68.66   Mean   : 6.635  \n 3rd Qu.: 9.320   3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000  \n Max.   :16.270   Max.   :175   Max.   :120.00   Max.   :29.000  \n   Population        Price        ShelveLoc        Age          Education   \n Min.   : 10.0   Min.   : 24.0   Bad   : 96   Min.   :25.00   Min.   :10.0  \n 1st Qu.:139.0   1st Qu.:100.0   Good  : 85   1st Qu.:39.75   1st Qu.:12.0  \n Median :272.0   Median :117.0   Medium:219   Median :54.50   Median :14.0  \n Mean   :264.8   Mean   :115.8                Mean   :53.32   Mean   :13.9  \n 3rd Qu.:398.5   3rd Qu.:131.0                3rd Qu.:66.00   3rd Qu.:16.0  \n Max.   :509.0   Max.   :191.0                Max.   :80.00   Max.   :18.0  \n Urban       US     \n No :118   No :142  \n Yes:282   Yes:258  \n                    \n                    \n                    \n                    \n\nstr(Carseats)\n\n'data.frame':   400 obs. of  11 variables:\n $ Sales      : num  9.5 11.22 10.06 7.4 4.15 ...\n $ CompPrice  : num  138 111 113 117 141 124 115 136 132 132 ...\n $ Income     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ Advertising: num  11 16 10 4 3 13 0 15 0 0 ...\n $ Population : num  276 260 269 466 340 501 45 425 108 131 ...\n $ Price      : num  120 83 80 97 128 72 108 120 124 124 ...\n $ ShelveLoc  : Factor w/ 3 levels \"Bad\",\"Good\",\"Medium\": 1 2 3 3 1 1 3 2 3 3 ...\n $ Age        : num  42 65 59 55 38 78 71 67 76 76 ...\n $ Education  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ Urban      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 2 2 1 1 ...\n $ US         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 1 2 1 2 ..."
  },
  {
    "objectID": "semanas/Aula12A.html#manipulando-os-dados",
    "href": "semanas/Aula12A.html#manipulando-os-dados",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Manipulando os dados",
    "text": "Manipulando os dados\n\ncad_crianca <- Carseats %>% rename(vendas = Sales, \n                                   preco_comp = CompPrice,\n                                   renda = Income,\n                                   propaganda = Advertising,\n                                   populacao = Population,\n                                   preco = Price,\n                                   local_prat = ShelveLoc,\n                                   idade = Age,\n                                   educacao = Education,\n                                   urbano = Urban,\n                                   eua = US)\n\ncad_crianca <- cad_crianca %>% mutate(alta = ifelse(vendas > 8, \"Sim\",\n                                                   \"Não\")) %>%\n                              mutate(alta = factor(alta))\n\ncad_crianca<- cad_crianca %>% mutate(local_prat =  case_when(\n                                      local_prat == \"Bad\"  ~ \"Ruim\",\n                                      local_prat == \"Good\" ~ \"Bom\",\n                                      local_prat == \"Medium\" ~ \"Medio\"))%>%                               mutate(local_prat = factor(local_prat))\n\ncad_crianca<- cad_crianca %>% mutate(urbano =  case_when(\n                                      urbano == \"Yes\"  ~ \"Sim\",\n                                      urbano == \"No\" ~ \"Não\")) %>%                                       mutate(urbano = factor(urbano))\n\ncad_crianca<- cad_crianca %>% mutate(eua =  case_when(\n                                      eua == \"Yes\"  ~ \"Sim\",\n                                      eua == \"No\" ~ \"Não\")) %>%                                          mutate(eua = factor(eua))\n\ncad_crianca<- cad_crianca %>% select(-vendas)\n\nstr(cad_crianca)\n\n'data.frame':   400 obs. of  11 variables:\n $ preco_comp: num  138 111 113 117 141 124 115 136 132 132 ...\n $ renda     : num  73 48 35 100 64 113 105 81 110 113 ...\n $ propaganda: num  11 16 10 4 3 13 0 15 0 0 ...\n $ populacao : num  276 260 269 466 340 501 45 425 108 131 ...\n $ preco     : num  120 83 80 97 128 72 108 120 124 124 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 2 3 3 2 1 2 2 ...\n $ idade     : num  42 65 59 55 38 78 71 67 76 76 ...\n $ educacao  : num  17 10 12 14 13 16 15 10 10 17 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 2 2 1 2 2 1 1 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 2 1 2 1 2 1 2 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 1 1 2 1 2 1 1 ...\n\nsummary(cad_crianca)\n\n   preco_comp      renda          propaganda       populacao    \n Min.   : 77   Min.   : 21.00   Min.   : 0.000   Min.   : 10.0  \n 1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000   1st Qu.:139.0  \n Median :125   Median : 69.00   Median : 5.000   Median :272.0  \n Mean   :125   Mean   : 68.66   Mean   : 6.635   Mean   :264.8  \n 3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000   3rd Qu.:398.5  \n Max.   :175   Max.   :120.00   Max.   :29.000   Max.   :509.0  \n     preco       local_prat      idade          educacao    urbano     eua     \n Min.   : 24.0   Bom  : 85   Min.   :25.00   Min.   :10.0   Não:118   Não:142  \n 1st Qu.:100.0   Medio:219   1st Qu.:39.75   1st Qu.:12.0   Sim:282   Sim:258  \n Median :117.0   Ruim : 96   Median :54.50   Median :14.0                      \n Mean   :115.8               Mean   :53.32   Mean   :13.9                      \n 3rd Qu.:131.0               3rd Qu.:66.00   3rd Qu.:16.0                      \n Max.   :191.0               Max.   :80.00   Max.   :18.0                      \n  alta    \n Não:236  \n Sim:164"
  },
  {
    "objectID": "semanas/Aula12A.html#treino-e-teste",
    "href": "semanas/Aula12A.html#treino-e-teste",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Treino e Teste",
    "text": "Treino e Teste\n\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\ny <- cad_crianca$alta\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- cad_crianca %>% slice(-indice_teste)\nconj_teste <- cad_crianca %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   319 obs. of  11 variables:\n $ preco_comp: num  138 111 113 141 124 136 132 121 117 122 ...\n $ renda     : num  73 48 35 64 113 81 110 78 94 35 ...\n $ propaganda: num  11 16 10 3 13 15 0 9 4 2 ...\n $ populacao : num  276 260 269 340 501 425 108 150 503 393 ...\n $ preco     : num  120 83 80 128 72 120 124 100 94 136 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 1 2 3 3 1 2 3 1 2 ...\n $ idade     : num  42 65 59 38 78 67 76 26 50 62 ...\n $ educacao  : num  17 10 12 13 16 10 10 10 13 18 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 2 1 2 1 1 2 2 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 1 2 2 1 2 2 1 ...\n\nprop.table(table(conj_treino$alta))\n\n\n      Não       Sim \n0.5893417 0.4106583 \n\nstr(conj_teste)\n\n'data.frame':   81 obs. of  11 variables:\n $ preco_comp: num  117 115 132 115 147 145 114 121 123 103 ...\n $ renda     : num  100 105 113 28 74 119 38 41 42 93 ...\n $ propaganda: num  4 0 0 11 13 16 13 5 11 15 ...\n $ populacao : num  466 45 131 29 251 294 317 412 16 188 ...\n $ preco     : num  97 108 124 86 131 113 128 110 134 103 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 2 2 2 1 1 3 1 2 2 3 ...\n $ idade     : num  55 71 76 53 52 42 50 54 59 74 ...\n $ educacao  : num  14 15 17 18 10 12 16 10 13 16 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 1 2 2 2 2 2 2 2 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 1 2 2 2 2 2 2 2 2 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 1 1 1 2 2 2 2 1 1 1 ...\n\nprop.table(table(conj_teste$alta))\n\n\n      Não       Sim \n0.5925926 0.4074074"
  },
  {
    "objectID": "semanas/Aula12A.html#arvore-de-classificação",
    "href": "semanas/Aula12A.html#arvore-de-classificação",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Arvore de Classificação",
    "text": "Arvore de Classificação\nNa biblioteca rpart as arvores de classificação são obtidas usando o método class. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo só definimos o menor conjunto de dados numa partição (minsplit) e o parametro de complexidade cp. Posteriormente vamos ampliar este controle. Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande resulta numa arvore muito pequena (underfitting). Nos dois casos se diminui o desempenho do modelo.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(alta ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classificação\n                control=rpart.control(minsplit=30,cp=0.02))"
  },
  {
    "objectID": "semanas/Aula12A.html#desenhando-a-árvore-de-uma-forma-mais-clara",
    "href": "semanas/Aula12A.html#desenhando-a-árvore-de-uma-forma-mais-clara",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Desenhando a Árvore de uma forma mais clara",
    "text": "Desenhando a Árvore de uma forma mais clara\n\nlibrary(rattle)\n\nCarregando pacotes exigidos: bitops\n\n\nRattle: A free graphical interface for data science with R.\nVersion 5.5.1 Copyright (c) 2006-2021 Togaware Pty Ltd.\nType 'rattle()' to shake, rattle, and roll your data.\n\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)\n\n\n\n\n\nset.seed(121)\ny <- cad_crianca$alta\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- cad_crianca %>% slice(-indice_teste)\nconj_teste <- cad_crianca %>% slice(indice_teste)\n\nstr(conj_treino)\n\n'data.frame':   319 obs. of  11 variables:\n $ preco_comp: num  138 113 141 124 115 136 132 121 117 115 ...\n $ renda     : num  73 35 64 113 105 81 113 78 94 28 ...\n $ propaganda: num  11 10 3 13 0 15 0 9 4 11 ...\n $ populacao : num  276 269 340 501 45 425 131 150 503 29 ...\n $ preco     : num  120 80 128 72 108 120 124 100 94 86 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 3 2 3 3 2 1 2 3 1 1 ...\n $ idade     : num  42 59 38 78 71 67 76 26 50 53 ...\n $ educacao  : num  17 12 13 16 15 10 17 10 13 18 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 2 1 2 2 1 1 2 2 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 1 2 1 2 2 2 2 2 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 1 2 1 2 1 2 2 2 ...\n\nprop.table(table(conj_treino$alta))\n\n\n      Não       Sim \n0.5893417 0.4106583 \n\nstr(conj_teste)\n\n'data.frame':   81 obs. of  11 variables:\n $ preco_comp: num  111 117 132 122 125 139 103 125 122 121 ...\n $ renda     : num  48 100 110 35 90 32 74 94 76 90 ...\n $ propaganda: num  16 4 0 2 2 0 0 0 0 0 ...\n $ populacao : num  260 466 108 393 367 176 359 447 270 150 ...\n $ preco     : num  83 97 124 136 131 82 97 89 100 108 ...\n $ local_prat: Factor w/ 3 levels \"Bom\",\"Medio\",..: 1 2 2 2 2 1 3 1 1 3 ...\n $ idade     : num  65 55 76 62 35 54 55 30 60 75 ...\n $ educacao  : num  10 14 10 18 18 11 11 12 18 16 ...\n $ urbano    : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 1 2 2 1 2 2 1 2 ...\n $ eua       : Factor w/ 2 levels \"Não\",\"Sim\": 2 2 1 1 2 1 2 1 1 1 ...\n $ alta      : Factor w/ 2 levels \"Não\",\"Sim\": 2 1 1 1 1 2 1 2 2 1 ...\n\nprop.table(table(conj_teste$alta))\n\n\n      Não       Sim \n0.5925926 0.4074074 \n\n\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(alta ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classificação\n                control=rpart.control(minsplit=30,cp=0.02))"
  },
  {
    "objectID": "semanas/Aula12A.html#desenhando-a-árvore-de-uma-forma-mais-clara-1",
    "href": "semanas/Aula12A.html#desenhando-a-árvore-de-uma-forma-mais-clara-1",
    "title": "Arvores de Classificação - Única e GBM",
    "section": "Desenhando a Árvore de uma forma mais clara",
    "text": "Desenhando a Árvore de uma forma mais clara\n\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)"
  },
  {
    "objectID": "semanas/Aula12B.html",
    "href": "semanas/Aula12B.html",
    "title": "Arvores de Regressão",
    "section": "",
    "text": "library(MASS)\nlibrary(tidyverse)\nlibrary(psych)"
  },
  {
    "objectID": "semanas/Aula12B.html#avaliando-selecionando-dados",
    "href": "semanas/Aula12B.html#avaliando-selecionando-dados",
    "title": "Arvores de Regressão",
    "section": "Avaliando, selecionando dados",
    "text": "Avaliando, selecionando dados\n\ndata(\"Boston\")\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\ndescribe(Boston)\n\n        vars   n   mean     sd median trimmed    mad    min    max  range  skew\ncrim       1 506   3.61   8.60   0.26    1.68   0.33   0.01  88.98  88.97  5.19\nzn         2 506  11.36  23.32   0.00    5.08   0.00   0.00 100.00 100.00  2.21\nindus      3 506  11.14   6.86   9.69   10.93   9.37   0.46  27.74  27.28  0.29\nchas       4 506   0.07   0.25   0.00    0.00   0.00   0.00   1.00   1.00  3.39\nnox        5 506   0.55   0.12   0.54    0.55   0.13   0.38   0.87   0.49  0.72\nrm         6 506   6.28   0.70   6.21    6.25   0.51   3.56   8.78   5.22  0.40\nage        7 506  68.57  28.15  77.50   71.20  28.98   2.90 100.00  97.10 -0.60\ndis        8 506   3.80   2.11   3.21    3.54   1.91   1.13  12.13  11.00  1.01\nrad        9 506   9.55   8.71   5.00    8.73   2.97   1.00  24.00  23.00  1.00\ntax       10 506 408.24 168.54 330.00  400.04 108.23 187.00 711.00 524.00  0.67\nptratio   11 506  18.46   2.16  19.05   18.66   1.70  12.60  22.00   9.40 -0.80\nblack     12 506 356.67  91.29 391.44  383.17   8.09   0.32 396.90 396.58 -2.87\nlstat     13 506  12.65   7.14  11.36   11.90   7.11   1.73  37.97  36.24  0.90\nmedv      14 506  22.53   9.20  21.20   21.56   5.93   5.00  50.00  45.00  1.10\n        kurtosis   se\ncrim       36.60 0.38\nzn          3.95 1.04\nindus      -1.24 0.30\nchas        9.48 0.01\nnox        -0.09 0.01\nrm          1.84 0.03\nage        -0.98 1.25\ndis         0.46 0.09\nrad        -0.88 0.39\ntax        -1.15 7.49\nptratio    -0.30 0.10\nblack       7.10 4.06\nlstat       0.46 0.32\nmedv        1.45 0.41\n\ndados <- Boston \nextrato <- dados %>% select(medv, nox, rm)  \nsummary(extrato)\n\n      medv            nox               rm       \n Min.   : 5.00   Min.   :0.3850   Min.   :3.561  \n 1st Qu.:17.02   1st Qu.:0.4490   1st Qu.:5.886  \n Median :21.20   Median :0.5380   Median :6.208  \n Mean   :22.53   Mean   :0.5547   Mean   :6.285  \n 3rd Qu.:25.00   3rd Qu.:0.6240   3rd Qu.:6.623  \n Max.   :50.00   Max.   :0.8710   Max.   :8.780  \n\nboxplot(extrato$medv)"
  },
  {
    "objectID": "semanas/Aula12B.html#visualizando-os-dados",
    "href": "semanas/Aula12B.html#visualizando-os-dados",
    "title": "Arvores de Regressão",
    "section": "Visualizando os dados",
    "text": "Visualizando os dados\n\n## Distribuição de dados na maior parte simétrica com valores na cauda direta \n## maior do que o esperado para uam distribuição simétrica\nggplot(extrato, aes(x=medv)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(extrato)),0))\n\n\n\n## Grafico de dispersão nox vs rm \nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point()"
  },
  {
    "objectID": "semanas/Aula12B.html#arvore-de-regressão",
    "href": "semanas/Aula12B.html#arvore-de-regressão",
    "title": "Arvores de Regressão",
    "section": "Arvore de Regressão",
    "text": "Arvore de Regressão\nNa biblioteca rpart as arvores de regressão são obtidas usando o método anova. Existem alguns controles que podem ser feitos nos parametros da arvore.\nNeste exemplo só definimos o menor conjunto de dados numa partição (minsplit) e o parametro de complexidade cp. Posteriormente vamos ampliar este controle.\n\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvreg <- rpart(medv ~ ., \n                data=extrato,\n                method=\"anova\", #para arvore de regressão\n                control=rpart.control(minsplit=30,cp=0.06))\nplot(arvreg)\ntext(arvreg,pretty=0)"
  },
  {
    "objectID": "semanas/Aula12B.html#segmentos",
    "href": "semanas/Aula12B.html#segmentos",
    "title": "Arvores de Regressão",
    "section": "Segmentos",
    "text": "Segmentos\nA partir da árvore obtida no item anterior podemos fazer uma representação gráfica das partições obtidas.\n\nggplot(extrato, aes(x=rm, y=nox)) + \n  geom_point() +\n  geom_segment(aes(x = 0, y = 0.6695, xend = 6.941, yend = 0.6695), \n               linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 6.941, linetype=\"dashed\", color=\"red\", size=1) +\n  geom_vline(xintercept = 7.437, linetype=\"dashed\", color=\"red\", size=1) \n\n\n\n  # scale_y_continuous(limits = c(0.3, 1)) +"
  },
  {
    "objectID": "semanas/Aula12B.html#treino-e-teste-com-todas-as-variáveis",
    "href": "semanas/Aula12B.html#treino-e-teste-com-todas-as-variáveis",
    "title": "Arvores de Regressão",
    "section": "Treino e Teste com todas as variáveis",
    "text": "Treino e Teste com todas as variáveis\nAgora vamos trabalhar com o conjunto completo criando um conjunto de treino e teste.\n\n## Vamos criar os conjuntos de treino teste e desenvolver a arvore \n## com todas as variáveis.\nlibrary(caret)\n\nCarregando pacotes exigidos: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(21)\nindice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)\nconj_treino <- dados[indice,]\nconj_teste <- dados[-indice,]\nhead(conj_treino)\n\n     crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18.0  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n3 0.02729  0.0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0.0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0.0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0.0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n7 0.08829 12.5  7.87    0 0.524 6.012 66.6 5.5605   5 311    15.2 395.60 12.43\n  medv\n1 24.0\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n7 22.9\n\nhead(conj_teste)\n\n      crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n2  0.02731  0.0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n10 0.17004 12.5  7.87    0 0.524 6.004 85.9 6.5921   5 311    15.2 386.71 17.10\n12 0.11747 12.5  7.87    0 0.524 6.009 82.9 6.2267   5 311    15.2 396.90 13.27\n16 0.62739  0.0  8.14    0 0.538 5.834 56.5 4.4986   4 307    21.0 395.62  8.47\n19 0.80271  0.0  8.14    0 0.538 5.456 36.6 3.7965   4 307    21.0 288.99 11.69\n23 1.23247  0.0  8.14    0 0.538 6.142 91.7 3.9769   4 307    21.0 396.90 18.72\n   medv\n2  21.6\n10 18.9\n12 18.9\n16 19.9\n19 20.2\n23 15.2"
  },
  {
    "objectID": "semanas/Aula12B.html#arvore-de-regressão-treino",
    "href": "semanas/Aula12B.html#arvore-de-regressão-treino",
    "title": "Arvores de Regressão",
    "section": "Arvore de Regressão Treino",
    "text": "Arvore de Regressão Treino\n\n## A função rpart tem diversos parametros aqui foi configurado um deles\n# cp o parametro de complexidade\n# Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande \n# resulta numa arvore muito pequena (underfitting).\n# Nos dois casos se diminui o desempenho do modelo.\narvreg1 <- rpart(medv ~ ., \n                data=conj_treino,\n                method=\"anova\", #para arvore de regerssão\n                control=rpart.control(minsplit=30,cp=0.01))\n\narvreg1\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=9.65 10   467.4640 23.84000 *\n      13) lstat< 9.65 39   889.2800 32.90000 *\n     7) rm>=7.435 21   960.7895 45.23810 *"
  },
  {
    "objectID": "semanas/Aula12B.html#erros-a-partir-do-conjunto-de-treino",
    "href": "semanas/Aula12B.html#erros-a-partir-do-conjunto-de-treino",
    "title": "Arvores de Regressão",
    "section": "Erros a partir do conjunto de treino",
    "text": "Erros a partir do conjunto de treino\n\nO erro relativo (Rel error) é obtido através de 1 - R2\nO xerror é obtido através da validação cruzdada (10 fold)\nO xtsd é o desvio padrão dos valores obtidos na validação cruzada.\n\n\n## Mostra 2 gráficos:\n# 1) Variação do R2 aparente e relativo vs número de partições\n# 2) Erro Relativo vs número de partições\nrsq.rpart(arvreg1)\n\n\nRegression tree:\nrpart(formula = medv ~ ., data = conj_treino, method = \"anova\", \n    control = rpart.control(minsplit = 30, cp = 0.01))\n\nVariables actually used in tree construction:\n[1] crim  lstat rm   \n\nRoot node error: 31197/381 = 81.882\n\nn= 381 \n\n        CP nsplit rel error  xerror     xstd\n1 0.461731      0   1.00000 1.01028 0.096645\n2 0.161924      1   0.53827 0.65330 0.065046\n3 0.094840      2   0.37634 0.49315 0.059728\n4 0.034308      3   0.28151 0.37245 0.050769\n5 0.028069      4   0.24720 0.34074 0.051145\n6 0.020942      5   0.21913 0.29254 0.042692\n7 0.010000      6   0.19819 0.28562 0.042529\n\n\n\n\n\n\n\n## Mostra a variação do Erro relativo vs cp(parametro de complexidade)\nplotcp(arvreg1)"
  },
  {
    "objectID": "semanas/Aula12B.html#gráfico-de-importancia-das-variáveis",
    "href": "semanas/Aula12B.html#gráfico-de-importancia-das-variáveis",
    "title": "Arvores de Regressão",
    "section": "Gráfico de importancia das variáveis",
    "text": "Gráfico de importancia das variáveis\nA importancia das variáveis é calculada com base nos resultados das melhores partições\n\n# Gráfico de Importância de variável\nvar_imp <- arvreg1$variable.importance\nnomes_var <- names(var_imp)\nvar_impdf <- data.frame(Importancia=unname(var_imp), Variavel=nomes_var) %>%\n                        arrange(Importancia)\nvar_impdf$Variavel <- factor(var_impdf$Variavel, levels=var_impdf$Variavel)\nggplot(var_impdf, aes(x=Variavel, y=Importancia)) + \n         geom_col() + \n        coord_flip()"
  },
  {
    "objectID": "semanas/Aula12B.html#mostrando-a-árvore-e-gerando-previsões",
    "href": "semanas/Aula12B.html#mostrando-a-árvore-e-gerando-previsões",
    "title": "Arvores de Regressão",
    "section": "Mostrando a árvore e gerando previsões",
    "text": "Mostrando a árvore e gerando previsões\n\n# Mostrando a arvore\npar(xpd = NA)\nplot(arvreg1)\ntext(arvreg1,pretty=0)\n\n\n\n# Fazendo Previsões\nprevisao1 <- arvreg1 %>% predict(conj_teste)\nhead(previsao1)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previsão\nRMSE(previsao1, conj_teste$medv)\n\n[1] 5.303593"
  },
  {
    "objectID": "semanas/Aula12B.html#arvore-de-regressão-com-caret",
    "href": "semanas/Aula12B.html#arvore-de-regressão-com-caret",
    "title": "Arvores de Regressão",
    "section": "Arvore de Regressão com caret",
    "text": "Arvore de Regressão com caret\nAqui vamos usar a biblioteca caret que tem umas facilidades para otimização do cp e apresentação dos resultados\n\nset.seed(21)\n## Otimizamos o valor de cp usando um 10-fold cv\n# O parametro tuneLength diz para o algoritmo escolher diferentes valores para cp\n# O parametro tuneGrid permite decidir que valores cp deve assumir enquanto que o\n# tuneLength somente limita o número default de parametros que se usa.\narvreg2 <- train(medv ~ . , data = conj_treino, method = \"rpart\",\n                 trControl = trainControl(\"cv\", number = 10),\n                 tuneGrid = data.frame(cp = seq(0.01,0.10, length.out=100)) \n                 )\n# Mostra a acurácia vs cp (parametro de complexidade)\nplot(arvreg2)\n\n\n\n## Indica o melhor valor de cp\narvreg2$bestTune\n\n          cp\n4 0.01272727"
  },
  {
    "objectID": "semanas/Aula12B.html#desenhando-a-árvore",
    "href": "semanas/Aula12B.html#desenhando-a-árvore",
    "title": "Arvores de Regressão",
    "section": "Desenhando a Árvore",
    "text": "Desenhando a Árvore\n\n## Apresenta o modelo final de arvore ajustado\npar(xpd = NA)\nplot(arvreg2$finalModel)\ntext(arvreg2$finalModel,  digits = 3)\n\n\n\n## usando o rpart.plot\nlibrary(rpart.plot)\nrpart.plot(arvreg2$finalModel)"
  },
  {
    "objectID": "semanas/Aula12B.html#previsões",
    "href": "semanas/Aula12B.html#previsões",
    "title": "Arvores de Regressão",
    "section": "Previsões",
    "text": "Previsões\n\n# Regras de Decisão\narvreg2$finalModel\n\nn= 381 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 381 31196.9300 22.34672  \n   2) rm< 6.8375 311 10862.7700 19.42958  \n     4) lstat>=14.405 131  2579.9460 14.70534  \n       8) crim>=7.006285 53   523.4645 11.23774 *\n       9) crim< 7.006285 78   986.1646 17.06154 *\n     5) lstat< 14.405 180  3231.2930 22.86778  \n      10) rm< 6.5445 145  1867.9540 21.78414 *\n      11) rm>=6.5445 35   487.6657 27.35714 *\n   3) rm>=6.8375 70  5929.5660 35.30714  \n     6) rm< 7.435 49  2010.0620 31.05102  \n      12) lstat>=11.315 7   367.8886 21.88571 *\n      13) lstat< 11.315 42   956.1507 32.57857 *\n     7) rm>=7.435 21   960.7895 45.23810 *\n\n# Fazendo Previsões\nprevisao2 <- arvreg2 %>% predict(conj_teste)\nhead(previsao2)\n\n       2       10       12       16       19       23 \n21.78414 17.06154 21.78414 21.78414 21.78414 17.06154 \n\n# Calcula os erros de previsão\nRMSE(previsao2, conj_teste$medv)\n\n[1] 5.304604"
  },
  {
    "objectID": "semanas/Aula12B.html#vamos-comparar-com-regressão-multipla",
    "href": "semanas/Aula12B.html#vamos-comparar-com-regressão-multipla",
    "title": "Arvores de Regressão",
    "section": "Vamos comparar com Regressão Multipla",
    "text": "Vamos comparar com Regressão Multipla\n\nlibrary(leaps)\n## Cria uma função de predição para o leaps\npredict.regsubsets <- function(object,newdata,id,...){\n  form <- as.formula(object$call[[2]])\n  mat <- model.matrix(form,newdata)\n  coefi <- coef(object,id=id)\n  mat[,names(coefi)]%*%coefi\n}\nset.seed(21)\nenvelopes <- sample(rep(1:5,length=nrow(conj_treino)))\ntable(envelopes)\n\nenvelopes\n 1  2  3  4  5 \n77 76 76 76 76 \n\nerro_cv <- matrix(NA,5,13)\nfor(k in 1:5){\n  melh_ajus <- regsubsets(medv ~ ., data=conj_treino[envelopes!=k,], \n                          nvmax=13,method=\"forward\")\n  for(i in 1:13){\n    prev <- predict(melh_ajus, conj_treino[envelopes==k,],id=i)\n    erro_cv[k,i] <- mean( (conj_treino$medv[envelopes==k]-prev)^2)\n  }\n}\nrmse_cv <- sqrt(apply(erro_cv,2,mean))  # Erro medio quadratico de cada modelo\nplot(rmse_cv,pch=19,type=\"b\")"
  },
  {
    "objectID": "semanas/Aula12B.html#obtem-a-fórmula-do-modelo",
    "href": "semanas/Aula12B.html#obtem-a-fórmula-do-modelo",
    "title": "Arvores de Regressão",
    "section": "Obtem a fórmula do modelo",
    "text": "Obtem a fórmula do modelo\n\ncoef(melh_ajus, 11)\n\n  (Intercept)          crim            zn          chas           nox \n 37.051974686  -0.144753575   0.047778839   1.780110617 -14.931943579 \n           rm           dis           rad           tax       ptratio \n  3.815637016  -1.500993904   0.349882023  -0.015845438  -0.986230946 \n        black         lstat \n  0.009024705  -0.534163142"
  },
  {
    "objectID": "semanas/Aula12B.html#teste-com-o-conjunto-de-teste",
    "href": "semanas/Aula12B.html#teste-com-o-conjunto-de-teste",
    "title": "Arvores de Regressão",
    "section": "Teste com o conjunto de teste",
    "text": "Teste com o conjunto de teste\n\nprevisao3 <- predict(melh_ajus, conj_teste, 11) \nRMSE(previsao3, conj_teste$medv)\n\n[1] 5.936577"
  },
  {
    "objectID": "visao-do-curso.html",
    "href": "visao-do-curso.html",
    "title": "Mineração de Dados",
    "section": "",
    "text": "Introdução a mineração de dados\nVisualização e preparação de Dados\nRegressão linear e seleção de modelos\nMétodos de Reamostragem\nMétodos de encolhimento (Ridge e Lasso)\nClassificação (KNN, Regressão Logística, LDA e QDA)\nMétodos baseados em árvores"
  }
]