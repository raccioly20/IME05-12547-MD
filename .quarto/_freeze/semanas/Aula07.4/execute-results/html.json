{
  "hash": "6fc8f933d03d423fd131e21327aac01f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regularização de Modelos\"\nauthor: \"Ricardo Accioly\"\ndate: \"2024-03-05\"\nformat:\n html:\n    code-link: true\n---\n\n\n## Regularização de modelos\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(glmnet)\ndata(Boston)\n```\n:::\n\n\n## Carregando os dados\n\nVamos utilizar neste exemplo os dados contidos na biblioteca MASS. A base de dados Boston tem 506 de valores preços medianos de casas na região de Boston com 13 outras variáveis explicativas (potencialmente). Vamos explorar os dados e ajustar modelos com penalização o Ridge e o LASSO e depois vamos comparar com os mínimos quadrados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(Boston)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(Boston)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n```\n\n\n:::\n:::\n\n\nObservamos acima que todas as variáveis são quantitativas e que não há necessidade de transformações.\n\n## Significado das variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boston Database\n# \n#1) crim - taxa de criminalidade per capita por cidade.\n# \n#2) zn - proporção de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n#3) indus - proporção de negócios não comerciais por acres e por cidade.\n# \n#4) chas - variável dummy do Rio Charles(= 1 se próximo do rio; 0 de outra forma).\n# \n#5) nox - concentração de óxido de nitrogênio (partes por 10 milhões).\n# \n#6) rm - número médio de quartos por habitação\n# \n#7) age - proporção da unidade ocupadas pelos proprietários construídas antes 1940.\n# \n#8) dis - média ponderada das distâncias dos 5 pontos de emprego em Boston.\n# \n#9) rad - indice de acessibilidade das avenidas radiais.\n# \n#10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n#11) ptratio - razão aluno-professor por cidade.\n# \n#12) black - 1000(Bk−0.63)21000(Bk−0.63)2 proporção de negros por cidade.\n# \n#13) lstat - percentual de baixo status da população.\n# \n#14) medv - valor mediano das cas ocupadas pelos proprietário em $1000s. (Var. Resposta)\n```\n:::\n\n\n## Conjunto de treino e de teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: lattice\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'caret'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Slicing with a 1-column matrix was deprecated in dplyr 1.1.0.\n```\n\n\n:::\n\n```{.r .cell-code}\nconj_teste <- Boston %>% slice(indice_teste)\n\nstr(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t403 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 85.9 94.3 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 18.9 15 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t103 obs. of  14 variables:\n $ crim   : num  0.211 0.63 0.627 1.252 0.852 ...\n $ zn     : num  12.5 0 0 0 0 0 0 75 0 0 ...\n $ indus  : num  7.87 8.14 8.14 8.14 8.14 8.14 8.14 2.95 6.91 6.91 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.538 0.538 0.538 0.538 0.538 0.538 0.428 0.448 0.448 ...\n $ rm     : num  5.63 5.95 5.83 5.57 5.96 ...\n $ age    : num  100 61.8 56.5 98.1 89.2 94.1 96.9 21.8 6.5 95.3 ...\n $ dis    : num  6.08 4.71 4.5 3.8 4.01 ...\n $ rad    : int  5 4 4 4 4 4 4 3 3 3 ...\n $ tax    : num  311 307 307 307 307 307 307 252 233 233 ...\n $ ptratio: num  15.2 21 21 21 21 21 21 18.3 17.9 17.9 ...\n $ black  : num  387 397 396 377 393 ...\n $ lstat  : num  29.93 8.26 8.47 21.02 13.83 ...\n $ medv   : num  16.5 20.4 19.9 13.6 19.6 12.7 13.5 30.8 24.7 14.4 ...\n```\n\n\n:::\n:::\n\n\n## Métodos de Regularização\n\nO pacote glmnet não usa a linguagem de formula, em particular nós devemos passar $x$ como uma matriz e $y$ como um vetor, pois não se usa a sintaxe $y \\sim x$. Com isso será necessário ajustar x e y. A função model.matrix() é particularmente útil para criar x; não só produz uma matriz correspondente as variáveis explicativas, **mas também transforma automaticamente quaisquer variáveis qualitativas em variáveis dummy. Esta última propriedade é importante porque o glmnet() só pode tomar insumos numéricos e quantitativos.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_treino <- model.matrix(medv ~ . , data = conj_treino)[, -1]\ny_treino <- conj_treino$medv\n\nx_teste <- model.matrix(medv ~ . , data = conj_teste)[, -1]\ny_teste = conj_teste$medv\n```\n:::\n\n\n## Regressão Ridge\n\nPrimeiro vamos ajustar um modelo de regressão Ridge. Isso é conseguido chamando `glmnet()` com `alpha=0`, se `alpha=1` então `glmnet()` ajusta um lasso.(veja o arquivo de ajuda).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Estabelecendo um grid de valores para lambda\ngrid <- 10^seq(-2, 10, length = 100)\najusreg.ridge <- glmnet(x_treino, y_treino, alpha=0, lambda = grid)\n```\n:::\n\n\nPor padrão, a função `glmnet()` executa a regressão ridge automaticamente selecionando a faixa de valores de $\\lambda$. No entanto, aqui nós escolhemos implementar usando uma grade de valores que variam de $\\lambda = 10^{-2}$ a $\\lambda = 10^{10}$, cobrindo toda a gama de cenários do modelo nulo contendo apenas o coeficiente linear até o ajuste dos mínimos quadrados.\n\nTambém podemos calcular o modelo para um valor particular de $\\lambda$ que não é um dos valores de grade. Observe que, por padrão, a função `glmnet()` padroniza as variáveis para que elas estejam na mesma escala. **Esta padronização é muito importante no caso da regressão Ridge, pois ela é afetada pela mudança de escala das variáveis explicativas.**\n\nAssociado a cada valor de $\\lambda$ existe um vetor de coeficientes de regressão de ridge, que é armazenado em uma matriz que pode ser acessada por 'coef()'. Neste caso, é uma matriz $13 \\times 100$, com 13 linhas (uma para cada preditor, mais uma para o coeficiente linear) e 100 colunas (uma para cada valor de $\\lambda$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(coef(ajusreg.ridge))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  14 100\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(ajusreg.ridge, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n```\n\n::: {.cell-output-display}\n![](Aula07.4_files/figure-html/r1-1.png){width=672}\n:::\n:::\n\n\nQuando $\\lambda$ é grande o esperado é que os coeficentes sejam pequenos e quando $\\lambda$ é pequeno os coeficientes assumem valores maiores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.ridge$lambda[1] # Mostra primeiro valor de lambda\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1e+10\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(ajusreg.ridge)[,1] # Mostra os coeficientes associados com o primeiro valor\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept)          crim            zn         indus          chas \n 2.247246e+01 -4.109894e-10  1.380771e-10 -6.245296e-10  6.798952e-09 \n          nox            rm           age           dis           rad \n-3.138930e-08  9.031398e-09 -1.154044e-10  1.094430e-09 -3.674422e-10 \n          tax       ptratio         black         lstat \n-2.354379e-11 -2.000167e-09  3.131126e-11 -8.446650e-10 \n```\n\n\n:::\n\n```{.r .cell-code}\najusreg.ridge$lambda[100] # Mostra centésimo valor de lambda\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(ajusreg.ridge)[,100] # Mostra os coeficientes associados com o centésimo valor\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept)          crim            zn         indus          chas \n 22.759904862  -0.056219660   0.030787704  -0.008666631   3.586521053 \n          nox            rm           age           dis           rad \n-15.478419836   5.269777225  -0.018838697  -1.344328941   0.236682494 \n          tax       ptratio         black         lstat \n -0.009629017  -0.919062486   0.013256877  -0.368967475 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plotmo)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: Formula\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: plotrix\n```\n\n\n:::\n\n```{.r .cell-code}\nplot_glmnet(ajusreg.ridge)\n```\n\n::: {.cell-output-display}\n![](Aula07.4_files/figure-html/r3-1.png){width=672}\n:::\n:::\n\n\n## Cross-Validation no Ridge\n\nNós podemos usar o k-fold cross validation para identificar o melhor valor de $\\lambda$\n\nA biblioteca glmnet já tem internamente uma função para uso do crosss validation. O default são 10 envelopes de dados `nfold=10`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(21)\nridge_cv <- cv.glmnet(x_treino,y_treino, alpha=0) ## por padrão k=10\nplot(ridge_cv)\n```\n\n::: {.cell-output-display}\n![](Aula07.4_files/figure-html/r4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm_lamb <- ridge_cv$lambda.min  # Seleciona o lambda que minimiza o MSE (EQM) de treino\nm_lamb\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6844251\n```\n\n\n:::\n\n```{.r .cell-code}\nlog(m_lamb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.3791761\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(ridge_cv, s=m_lamb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n14 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  17.657157531\ncrim         -0.045123105\nzn            0.022084973\nindus        -0.057135170\nchas          3.693730171\nnox         -10.615446064\nrm            5.158120571\nage          -0.016983710\ndis          -1.018076903\nrad           0.124455264\ntax          -0.004785845\nptratio      -0.833820900\nblack         0.012199513\nlstat        -0.351368264\n```\n\n\n:::\n:::\n\n\n## Avaliando com conjunto de teste\n\nEm seguida avaliamos seu MSE no conjunto de teste, usando $\\lambda$ = m_lamb. Observe o uso da função 'predict()': desta vez temos previsões para um conjunto de teste, com o argumento `newx`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.ridge2 <- glmnet(x_treino, y_treino, alpha=0, lambda = m_lamb)\ny_prev <- predict(ajusreg.ridge2, s = m_lamb, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.866046\n```\n\n\n:::\n:::\n\n\n## LASSO\n\nPrimeiro ajustamos com todos os dados como no caso do Ridge\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.lasso <- glmnet(x_treino,y_treino, alpha = 1)\nplot(ajusreg.lasso, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n```\n\n::: {.cell-output-display}\n![](Aula07.4_files/figure-html/LASSO-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_glmnet(ajusreg.lasso)\n```\n\n::: {.cell-output-display}\n![](Aula07.4_files/figure-html/LASSO-2.png){width=672}\n:::\n:::\n\n\n## Validação Cruzada no LASSO\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_cv <- cv.glmnet(x_treino,y_treino, alpha = 1)\nplot(lasso_cv)\n```\n\n::: {.cell-output-display}\n![](Aula07.4_files/figure-html/Lasso2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm_lamb1 <- lasso_cv$lambda.min  # Seleciona o lambda que minimiza o MSE de treino\nm_lamb1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007688312\n```\n\n\n:::\n\n```{.r .cell-code}\nlog(m_lamb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -4.868054\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(lasso_cv, s=m_lamb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n14 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  22.344480900\ncrim         -0.053770703\nzn            0.029746910\nindus        -0.009368146\nchas          3.567282914\nnox         -15.274329592\nrm            5.286463806\nage          -0.018472588\ndis          -1.322216902\nrad           0.226880624\ntax          -0.009200337\nptratio      -0.916730239\nblack         0.013199949\nlstat        -0.369341087\n```\n\n\n:::\n:::\n\n\n## Avaliando com conjunto de teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.lasso2 <- glmnet(x_treino, y_treino, alpha=1, lambda = m_lamb1)\ny_prev <- predict(ajusreg.lasso2, s = m_lamb1, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.796153\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Aula07.4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}