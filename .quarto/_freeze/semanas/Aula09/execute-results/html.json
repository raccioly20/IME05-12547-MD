{
  "hash": "c6701fe088759a99fe1eedcdf31a5bfb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regressão Logística\"\nauthor: \"Ricardo Accioly\"\ndate: \"2025-09-23\"\nexecute: \n  echo: true\n  warning: false\n  message: false\n  freeze: auto\nformat:\n html:\n    code-link: true\n    fig-height: 8\n    fig-width: 12\n    fig-align: center\nknitr: \n  opts_chunk: \n    out.width: 90%\n    fig.showtext: true\n---\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n```\n\n\n:::\n\n```{.r .cell-code}\nstr(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559\n```\n\n\n:::\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncredito <- tibble(Default)\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n```\n\n\n:::\n\n```{.r .cell-code}\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n```\n\n\n:::\n:::\n\n\n## Treino e Teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nset.seed(2025)\ny <- credito$inadimplente\ncredito_split <- createDataPartition(y, times = 1, p = 0.10, list = FALSE)\n\nconj_treino <- credito[-credito_split,]\nconj_teste <- credito[credito_split,]\n                           \nsummary(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n inadimplente   estudante         balanco          receita     \n Nao:8700     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 299     1st Qu.:0.0000   1st Qu.: 483.6   1st Qu.:21343  \n              Median :0.0000   Median : 821.3   Median :34576  \n              Mean   :0.2946   Mean   : 836.3   Mean   :33556  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43854  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n inadimplente   estudante         balanco          receita     \n Nao:967      Min.   :0.0000   Min.   :   0.0   Min.   : 5386  \n Sim: 34      1st Qu.:0.0000   1st Qu.: 453.6   1st Qu.:21319  \n              Median :0.0000   Median : 839.9   Median :34086  \n              Mean   :0.2927   Mean   : 827.4   Mean   :33170  \n              3rd Qu.:1.0000   3rd Qu.:1156.3   3rd Qu.:42856  \n              Max.   :1.0000   Max.   :2221.0   Max.   :70701  \n```\n\n\n:::\n:::\n\n\n## Matriz de dispersão\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/splom-1.png){width=90%}\n:::\n:::\n\n\n## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\np1 <- ggplot(credito, aes(x=inadimplente, y=balanco, color=inadimplente)) +\n  geom_boxplot()\np2 <- ggplot(credito, aes(x=inadimplente, y=receita, color=inadimplente)) +\n  geom_boxplot()\np3 <- ggplot(credito, aes(x=as.factor(estudante), y=balanco, color=as.factor(estudante))) +\n  geom_boxplot()\np4 <- ggplot(credito, aes(x=as.factor(estudante), y=receita, color=as.factor(estudante))) +\n  geom_boxplot()\n(p1 + p2) / (p3 + p4)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/box-plot-1.png){width=90%}\n:::\n:::\n\n\n## Balanço vs Receita\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) +\n  geom_point() \n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/dispersao-1.png){width=90%}\n:::\n:::\n\n\n## Avaliando comportamento\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# proporção de inadimplentes\ncredito %>% select(inadimplente, balanco) %>% summarize(prop = mean(inadimplente == \"Sim\")) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n    prop\n   <dbl>\n1 0.0333\n```\n\n\n:::\n\n```{.r .cell-code}\n# media do balanço dos inadimplentes \ncredito %>% filter(inadimplente == \"Sim\") %>% summarize(valor= mean(balanco))   \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  valor\n  <dbl>\n1 1748.\n```\n\n\n:::\n\n```{.r .cell-code}\nquantis <- quantile(credito$balanco, probs = c(.1,.25, .50, .75, .9, .95, 0.97, 0.99))\nquantis\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      10%       25%       50%       75%       90%       95%       97%       99% \n 180.5753  481.7311  823.6370 1166.3084 1471.6253 1665.9626 1793.2910 2008.4709 \n```\n\n\n:::\n\n```{.r .cell-code}\ncredito %>% \n            mutate(grupo_balanco = case_when(\n               balanco<=quantis[1] ~ quantis[1],\n               balanco>quantis[1] & balanco<=quantis[2] ~ quantis[2],\n               balanco>quantis[2] & balanco<=quantis[3]  ~ quantis[3],\n               balanco>quantis[3] & balanco<=quantis[4]  ~ quantis[4],\n               balanco>quantis[4] & balanco<=quantis[5]  ~ quantis[5],\n               balanco>quantis[5] & balanco<=quantis[6]  ~ quantis[6],\n               balanco>quantis[6] & balanco<=quantis[7]  ~ quantis[7],\n               balanco>quantis[7] ~ quantis[8])) %>%\n           group_by(grupo_balanco) %>%\n           summarize(prop = mean(inadimplente == \"Sim\")) %>%\n           ggplot(aes(grupo_balanco, prop)) +\n           geom_point() +\n           geom_line()\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/1avaliacao-1.png){width=90%}\n:::\n:::\n\n\n## 1a Regressão logística: só balanço\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- glm(inadimplente ~ balanco,data=conj_treino,family=binomial)\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = inadimplente ~ balanco, family = binomial, data = conj_treino)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.081e+01  3.900e-01  -27.72   <2e-16 ***\nbalanco      5.594e-03  2.375e-04   23.55   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2623.8  on 8998  degrees of freedom\nResidual deviance: 1415.7  on 8997  degrees of freedom\nAIC: 1419.7\n\nNumber of Fisher Scoring iterations: 8\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept)       balanco \n-10.810958936   0.005594178 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mod1)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Estimate   Std. Error   z value      Pr(>|z|)\n(Intercept) -10.810958936 0.3900304107 -27.71825 4.208540e-169\nbalanco       0.005594178 0.0002374991  23.55452 1.128292e-122\n```\n\n\n:::\n:::\n\n\n## Avaliando o modelo\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Nao Sim\n       Nao 958  25\n       Sim   9   9\n                                          \n               Accuracy : 0.966           \n                 95% CI : (0.9529, 0.9764)\n    No Information Rate : 0.966           \n    P-Value [Acc > NIR] : 0.5454          \n                                          \n                  Kappa : 0.3304          \n                                          \n Mcnemar's Test P-Value : 0.0101          \n                                          \n            Sensitivity : 0.264706        \n            Specificity : 0.990693        \n         Pos Pred Value : 0.500000        \n         Neg Pred Value : 0.974568        \n             Prevalence : 0.033966        \n         Detection Rate : 0.008991        \n   Detection Prevalence : 0.017982        \n      Balanced Accuracy : 0.627699        \n                                          \n       'Positive' Class : Sim             \n                                          \n```\n\n\n:::\n:::\n\n\n## Veja as probabilidade de inadimplencia para balanços de 1000, 2000 e 3000\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(mod1, newdata = data.frame(balanco = c(1000,2000,3000)), type=\"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          1           2           3 \n0.005395494 0.593245119 0.997456265 \n```\n\n\n:::\n:::\n\n\n## Curva S\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Mostrar a curva S com o resultado da regressão logística\n# Salvar o gráfico em um arquivo .png\npng(\"regressao_logistica.png\", width = 800, height = 600)\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nplot(inadimpl ~ balanco, data = conj_treino, col = \"darkorange\", pch = \"|\", ylim = c(0, 1), main = \"Regressão Logistica - Classificacão\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\ncurve(predict(mod1, data.frame(balanco = x), type = \"response\"), add = TRUE, lwd = 3, col = \"dodgerblue\")\nabline(v = -coef(mod1)[1] / coef(mod1)[2], lwd = 2)\ndev.off()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\npng \n  2 \n```\n\n\n:::\n\n```{.r .cell-code}\nknitr::include_graphics(\"regressao_logistica.png\")\n```\n\n::: {.cell-output-display}\n![](regressao_logistica.png){width=90%}\n:::\n:::\n\n\n## Valor de balanço com probabilidade de 50%\n\n\\-$\\beta_0$/$\\beta_1$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-coef(mod1)[1] / coef(mod1)[2]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) \n   1932.538 \n```\n\n\n:::\n:::\n\n\n## 2a Regressão logística: todas as variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treino,family=binomial)\nsummary(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n    data = conj_treino)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.100e+01  5.277e-01 -20.850   <2e-16 ***\nbalanco      5.810e-03  2.488e-04  23.356   <2e-16 ***\nreceita      2.751e-06  8.799e-06   0.313   0.7546    \nestudante   -5.942e-01  2.516e-01  -2.362   0.0182 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2623.8  on 8998  degrees of freedom\nResidual deviance: 1396.8  on 8995  degrees of freedom\nAIC: 1404.8\n\nNumber of Fisher Scoring iterations: 8\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept)       balanco       receita     estudante \n-1.100205e+01  5.810150e-03  2.750839e-06 -5.942048e-01 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mod2)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Estimate   Std. Error     z value      Pr(>|z|)\n(Intercept) -1.100205e+01 5.276811e-01 -20.8498149  1.530134e-96\nbalanco      5.810150e-03 2.487659e-04  23.3558946 1.200621e-120\nreceita      2.750839e-06 8.798705e-06   0.3126414  7.545531e-01\nestudante   -5.942048e-01 2.515801e-01  -2.3618911  1.818198e-02\n```\n\n\n:::\n:::\n\n\n**É possível se ver que receita não é significativa**\n\n## 3a Regressão Logística (sem receita)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod3 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\nsummary(mod3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = inadimplente ~ balanco + estudante, family = binomial, \n    data = conj_treino)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.089e+01  3.974e-01 -27.416  < 2e-16 ***\nbalanco      5.812e-03  2.487e-04  23.368  < 2e-16 ***\nestudante   -6.561e-01  1.550e-01  -4.234  2.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2623.8  on 8998  degrees of freedom\nResidual deviance: 1396.9  on 8996  degrees of freedom\nAIC: 1402.9\n\nNumber of Fisher Scoring iterations: 8\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(mod3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept)       balanco     estudante \n-10.894208021   0.005811976  -0.656054023 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mod3)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Estimate   Std. Error   z value      Pr(>|z|)\n(Intercept) -10.894208021 0.3973729389 -27.41558 1.788553e-165\nbalanco       0.005811976 0.0002487146  23.36806 9.031818e-121\nestudante    -0.656054023 0.1549533866  -4.23388  2.296937e-05\n```\n\n\n:::\n:::\n\n\n## Comparando os modelos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod2,mod3,test='LR')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: inadimplente ~ balanco + receita + estudante\nModel 2: inadimplente ~ balanco + estudante\n  Resid. Df Resid. Dev Df  Deviance Pr(>Chi)\n1      8995     1396.8                      \n2      8996     1396.9 -1 -0.097739   0.7546\n```\n\n\n:::\n:::\n\n\n## StepAIC\n\nAo invé de usarmos a estatística de Wald para selecionar as variáveis significativas, podemos usar o AIC (**equivalente ao Cp**) como usamos na regressão múltipla para selecionar as variáveis explicativas.\n\nA função **stepAIC** tem um parametro k que define se vamos usar o AIC ou o BIC para fazer a seleção. Quando k=2 temos o AIC e quando k=log(n) temos o BIC.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nmod3a <- stepAIC(mod2, k=2, trace=FALSE)\nsummary(mod3a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = inadimplente ~ balanco + estudante, family = binomial, \n    data = conj_treino)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.089e+01  3.974e-01 -27.416  < 2e-16 ***\nbalanco      5.812e-03  2.487e-04  23.368  < 2e-16 ***\nestudante   -6.561e-01  1.550e-01  -4.234  2.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2623.8  on 8998  degrees of freedom\nResidual deviance: 1396.9  on 8996  degrees of freedom\nAIC: 1402.9\n\nNumber of Fisher Scoring iterations: 8\n```\n\n\n:::\n\n```{.r .cell-code}\n(k <- log(nrow(conj_treino)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.104869\n```\n\n\n:::\n\n```{.r .cell-code}\nmod3b <- stepAIC(mod2, k=k, trace=FALSE)\nsummary(mod3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = inadimplente ~ balanco + estudante, family = binomial, \n    data = conj_treino)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.089e+01  3.974e-01 -27.416  < 2e-16 ***\nbalanco      5.812e-03  2.487e-04  23.368  < 2e-16 ***\nestudante   -6.561e-01  1.550e-01  -4.234  2.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2623.8  on 8998  degrees of freedom\nResidual deviance: 1396.9  on 8996  degrees of freedom\nAIC: 1402.9\n\nNumber of Fisher Scoring iterations: 8\n```\n\n\n:::\n:::\n\n\n## Avaliando o modelo novamente\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Nao Sim\n       Nao 960  24\n       Sim   7  10\n                                          \n               Accuracy : 0.969           \n                 95% CI : (0.9563, 0.9789)\n    No Information Rate : 0.966           \n    P-Value [Acc > NIR] : 0.339451        \n                                          \n                  Kappa : 0.3781          \n                                          \n Mcnemar's Test P-Value : 0.004057        \n                                          \n            Sensitivity : 0.29412         \n            Specificity : 0.99276         \n         Pos Pred Value : 0.58824         \n         Neg Pred Value : 0.97561         \n             Prevalence : 0.03397         \n         Detection Rate : 0.00999         \n   Detection Prevalence : 0.01698         \n      Balanced Accuracy : 0.64344         \n                                          \n       'Positive' Class : Sim             \n                                          \n```\n\n\n:::\n:::\n\n\n## Mudando a probabilidade (limite) para aumentar a sensibilidade\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.1, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Nao Sim\n       Nao 912  11\n       Sim  55  23\n                                          \n               Accuracy : 0.9341          \n                 95% CI : (0.9169, 0.9486)\n    No Information Rate : 0.966           \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.3815          \n                                          \n Mcnemar's Test P-Value : 1.204e-07       \n                                          \n            Sensitivity : 0.67647         \n            Specificity : 0.94312         \n         Pos Pred Value : 0.29487         \n         Neg Pred Value : 0.98808         \n             Prevalence : 0.03397         \n         Detection Rate : 0.02298         \n   Detection Prevalence : 0.07792         \n      Balanced Accuracy : 0.80980         \n                                          \n       'Positive' Class : Sim             \n                                          \n```\n\n\n:::\n:::\n\n\n## Curva ROC modelo só com balanço\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           1            2            3            4            5            6 \n0.0104785745 0.0002668725 0.0029780343 0.0042745671 0.0073908814 0.0005687871 \n```\n\n\n:::\n\n```{.r .cell-code}\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROC-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n# Area debaixo da curva\nas.numeric(roc_log$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9291015\n```\n\n\n:::\n:::\n\n\n## Curva ROC 2: Modelo com balanço + estudante\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu_log <- predict(mod3, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           1            2            3            4            5            6 \n0.0064107246 0.0002715269 0.0017294056 0.0048430770 0.0085502222 0.0005960041 \n```\n\n\n:::\n\n```{.r .cell-code}\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROC2-1.png){width=90%}\n:::\n:::\n\n\n## AUC\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Area debaixo da curva\nas.numeric(roc_log2$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9325385\n```\n\n\n:::\n:::\n\n\n## Melhor limite\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_limite <- coords(roc_log2, \"best\", ret = \"threshold\")$threshold\nm_limite\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03721192\n```\n\n\n:::\n\n```{.r .cell-code}\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > m_limite, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Nao Sim\n       Nao 857   5\n       Sim 110  29\n                                          \n               Accuracy : 0.8851          \n                 95% CI : (0.8637, 0.9042)\n    No Information Rate : 0.966           \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.2969          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.85294         \n            Specificity : 0.88625         \n         Pos Pred Value : 0.20863         \n         Neg Pred Value : 0.99420         \n             Prevalence : 0.03397         \n         Detection Rate : 0.02897         \n   Detection Prevalence : 0.13886         \n      Balanced Accuracy : 0.86959         \n                                          \n       'Positive' Class : Sim             \n                                          \n```\n\n\n:::\n:::\n\n\n## Duas ROCs juntas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(roc_log)\nplot(roc_log2, add=TRUE, col=\"blue\")\nlegend(\"bottomright\", legend=c(\"Mod 1\", \"Mod2\"),\n       col=c(par(\"fg\"), \"blue\"), lwd=2)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROCs-1.png){width=90%}\n:::\n:::\n\n\n## Curva ROC 3 com o KNN\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustando KNN \nconj_treino[,3:4] <- scale(conj_treino[,3:4]) # scale normaliza\nconj_teste[,3:4] <- scale(conj_teste[, 3:4])\nset.seed(2025)\ntreina_knn <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 20)\n# treina_knn\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n## ROC\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, col= \"black\", legacy.axes=TRUE) \nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg. Log\", \"KNN\"), \n       col=c(\"black\",\"green\"),lwd=4)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROC3-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n# Area abaixo da curva\n# Regressão Logística\nas.numeric(roc_log2$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9325385\n```\n\n\n:::\n\n```{.r .cell-code}\n## KNN\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9041304\n```\n\n\n:::\n:::\n\n",
    "supporting": [
      "Aula09_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}