{
  "hash": "1815cc5dba8e156220d0a58258028b42",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regressão Logística\"\nauthor: \"Ricardo Accioly\"\ndate: \"2024-05-24\"\nformat:\n html:\n    code-link: true\n    fig-width: 9\n    fig-height: 7\n    fig-dpi: 300\nknitr:\n  opts_chunk: \n    out.width: 90%\n    comment: \"#>\"\n---\n\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#> ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n#> ✔ purrr     1.0.2     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 'data.frame':\t10000 obs. of  4 variables:\n#>  $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n#>  $ balance: num  730 817 1074 529 786 ...\n#>  $ income : num  44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   default student   balance    income\n#> 1      No      No  729.5265 44361.625\n#> 2      No     Yes  817.1804 12106.135\n#> 3      No      No 1073.5492 31767.139\n#> 4      No      No  529.2506 35704.494\n#> 5      No      No  785.6559 38463.496\n#> 6      No     Yes  919.5885  7491.559\n```\n\n\n:::\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncredito <- tibble(Default)\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n\n```{.r .cell-code}\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#>  $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n#>  $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n#>  $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco          receita     \n#>  Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n#>  Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n#>               Median :0.0000   Median : 823.6   Median :34553  \n#>               Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n#>               3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n#>               Max.   :1.0000   Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n:::\n\n\n## Treino e Teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Carregando pacotes exigidos: lattice\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> \n#> Anexando pacote: 'caret'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> O seguinte objeto é mascarado por 'package:purrr':\n#> \n#>     lift\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(2024)\ny <- credito$inadimplente\ncredito_split <- createDataPartition(y, times = 1, p = 0.80, list = FALSE)\n\nconj_treino <- credito[credito_split,]\nconj_teste <- credito[-credito_split,]\n                           \nsummary(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco          receita     \n#>  Nao:7734     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n#>  Sim: 267     1st Qu.:0.0000   1st Qu.: 479.5   1st Qu.:21309  \n#>               Median :0.0000   Median : 825.9   Median :34468  \n#>               Mean   :0.2945   Mean   : 835.9   Mean   :33437  \n#>               3rd Qu.:1.0000   3rd Qu.:1170.0   3rd Qu.:43706  \n#>               Max.   :1.0000   Max.   :2654.3   Max.   :72461\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco          receita     \n#>  Nao:1933     Min.   :0.0000   Min.   :   0.0   Min.   : 5083  \n#>  Sim:  66     1st Qu.:0.0000   1st Qu.: 489.5   1st Qu.:21422  \n#>               Median :0.0000   Median : 813.9   Median :35177  \n#>               Mean   :0.2941   Mean   : 833.3   Mean   :33837  \n#>               3rd Qu.:1.0000   3rd Qu.:1143.4   3rd Qu.:44208  \n#>               Max.   :1.0000   Max.   :2502.7   Max.   :73554\n```\n\n\n:::\n:::\n\n\n## Matriz de dispersão\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> \n#> Anexando pacote: 'psych'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Os seguintes objetos são mascarados por 'package:ggplot2':\n#> \n#>     %+%, alpha\n```\n\n\n:::\n\n```{.r .cell-code}\npairs.panels(conj_treino, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/splom-1.png){width=90%}\n:::\n:::\n\n\n## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\np1 <- ggplot(credito, aes(x=inadimplente, y=balanco, color=inadimplente)) +\n  geom_boxplot()\np2 <- ggplot(credito, aes(x=inadimplente, y=receita, color=inadimplente)) +\n  geom_boxplot()\np3 <- ggplot(credito, aes(x=as.factor(estudante), y=balanco, color=as.factor(estudante))) +\n  geom_boxplot()\np4 <- ggplot(credito, aes(x=as.factor(estudante), y=receita, color=as.factor(estudante))) +\n  geom_boxplot()\n(p1 + p2) / (p3 + p4)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/box-plot-1.png){width=90%}\n:::\n:::\n\n\n## Balanço vs Receita\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) +\n  geom_point() \n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/dispersao-1.png){width=90%}\n:::\n:::\n\n\n## Regressão Linear?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Primeiro precisa transformar qualitativa em numérica\ninadimpl <- as.numeric(credito$inadimplente) - 1\nmodelo_linear <- lm(inadimpl ~ balanco, data = credito)\nplot(inadimpl ~ balanco, data = credito, \n     col = \"darkorange\", pch = \"|\", ylim = c(-0.2, 1),\n     main = \"Regressão Linear - Classificação\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\nabline(modelo_linear, lwd = 3, col = \"dodgerblue\")\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/reg-linear-1.png){width=90%}\n:::\n:::\n\n\n## Outras avaliações\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# proporção de inadimplentes\ncredito %>% select(inadimplente, balanco) %>% summarize(prop = mean(inadimplente == \"Sim\")) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>     prop\n#>    <dbl>\n#> 1 0.0333\n```\n\n\n:::\n\n```{.r .cell-code}\n# media do balanço dos inadimplentes \ncredito %>% filter(inadimplente == \"Sim\") %>% summarize(valor= mean(balanco))   \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>   valor\n#>   <dbl>\n#> 1 1748.\n```\n\n\n:::\n\n```{.r .cell-code}\nquantis <- quantile(credito$balanco, probs = c(.1,.25, .50, .75, .9, .95, 0.97, 0.99))\nquantis\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       10%       25%       50%       75%       90%       95%       97%       99% \n#>  180.5753  481.7311  823.6370 1166.3084 1471.6253 1665.9626 1793.2910 2008.4709\n```\n\n\n:::\n\n```{.r .cell-code}\ncredito %>% \n            mutate(grupo_balanco = case_when(\n               balanco<=quantis[1] ~ quantis[1],\n               balanco>quantis[1] & balanco<=quantis[2] ~ quantis[2],\n               balanco>quantis[2] & balanco<=quantis[3]  ~ quantis[3],\n               balanco>quantis[3] & balanco<=quantis[4]  ~ quantis[4],\n               balanco>quantis[4] & balanco<=quantis[5]  ~ quantis[5],\n               balanco>quantis[5] & balanco<=quantis[6]  ~ quantis[6],\n               balanco>quantis[6] & balanco<=quantis[7]  ~ quantis[7],\n               balanco>quantis[7] ~ quantis[8])) %>%\n           group_by(grupo_balanco) %>%\n           summarize(prop = mean(inadimplente == \"Sim\")) %>%\n           ggplot(aes(grupo_balanco, prop)) +\n           geom_point() +\n           geom_line()\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/1avaliacao-1.png){width=90%}\n:::\n:::\n\n\n## 1a Regressão logística: só balanço\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- glm(inadimplente ~ balanco,data=conj_treino,family=binomial)\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = inadimplente ~ balanco, family = binomial, data = conj_treino)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept) -1.047e+01  3.931e-01  -26.64   <2e-16 ***\n#> balanco      5.386e-03  2.405e-04   22.40   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 2340.6  on 8000  degrees of freedom\n#> Residual deviance: 1302.1  on 7999  degrees of freedom\n#> AIC: 1306.1\n#> \n#> Number of Fisher Scoring iterations: 8\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   (Intercept)       balanco \n#> -10.471543192   0.005385567\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mod1)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                  Estimate   Std. Error   z value      Pr(>|z|)\n#> (Intercept) -10.471543192 0.3931122212 -26.63754 2.495385e-156\n#> balanco       0.005385567 0.0002404507  22.39780 4.134795e-111\n```\n\n\n:::\n:::\n\n\n## Avaliando o modelo\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu <- predict(mod1, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1929   45\n#>        Sim    4   21\n#>                                           \n#>                Accuracy : 0.9755          \n#>                  95% CI : (0.9677, 0.9818)\n#>     No Information Rate : 0.967           \n#>     P-Value [Acc > NIR] : 0.01625         \n#>                                           \n#>                   Kappa : 0.4516          \n#>                                           \n#>  Mcnemar's Test P-Value : 1.102e-08       \n#>                                           \n#>             Sensitivity : 0.31818         \n#>             Specificity : 0.99793         \n#>          Pos Pred Value : 0.84000         \n#>          Neg Pred Value : 0.97720         \n#>              Prevalence : 0.03302         \n#>          Detection Rate : 0.01051         \n#>    Detection Prevalence : 0.01251         \n#>       Balanced Accuracy : 0.65806         \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Veja as probabilidade de inadimplencia para balanços de 1000, 2000 e 3000\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(mod1, newdata = data.frame(balanco = c(1000,2000,3000)), type=\"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           1           2           3 \n#> 0.006144857 0.574342575 0.996615498\n```\n\n\n:::\n:::\n\n\n## Curva S\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninadimpl <- as.numeric(conj_treino$inadimplente) - 1\nplot(inadimpl ~ balanco, data = conj_treino, \n     col = \"darkorange\", pch = \"|\", ylim = c(0, 1),\n     main = \"Regressão Logistica - Classificacão\")\nabline(h = 0, lty = 3)\nabline(h = 1, lty = 3)\nabline(h = 0.5, lty = 2)\ncurve(predict(mod1, data.frame(balanco = x),\n        type = \"response\"), add = TRUE, lwd = 3, col = \"dodgerblue\")\nabline(v = -coef(mod1)[1] / coef(mod1)[2], lwd = 2)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/Curva_S-1.png){width=90%}\n:::\n:::\n\n\n## Valor de balanço com probabilidade de 50%\n\n\\-$\\beta_0$/$\\beta_1$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-coef(mod1)[1] / coef(mod1)[2]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> (Intercept) \n#>    1944.371\n```\n\n\n:::\n:::\n\n\n## 2a Regressão logística: todas as variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2 <- glm(inadimplente ~ balanco + receita + estudante,data=conj_treino,family=binomial)\nsummary(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = inadimplente ~ balanco + receita + estudante, family = binomial, \n#>     data = conj_treino)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept) -1.075e+01  5.417e-01 -19.847   <2e-16 ***\n#> balanco      5.628e-03  2.538e-04  22.180   <2e-16 ***\n#> receita      4.416e-06  9.088e-06   0.486   0.6270    \n#> estudante   -6.264e-01  2.612e-01  -2.398   0.0165 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 2340.6  on 8000  degrees of freedom\n#> Residual deviance: 1281.3  on 7997  degrees of freedom\n#> AIC: 1289.3\n#> \n#> Number of Fisher Scoring iterations: 8\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   (Intercept)       balanco       receita     estudante \n#> -1.075144e+01  5.628328e-03  4.415834e-06 -6.263630e-01\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mod2)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                  Estimate   Std. Error     z value      Pr(>|z|)\n#> (Intercept) -1.075144e+01 5.417102e-01 -19.8472260  1.164551e-87\n#> balanco      5.628328e-03 2.537535e-04  22.1802958 5.322786e-109\n#> receita      4.415834e-06 9.088132e-06   0.4858902  6.270450e-01\n#> estudante   -6.263630e-01 2.611624e-01  -2.3983656  1.646842e-02\n```\n\n\n:::\n:::\n\n\n**É possível se ver que receita não é significativa**\n\n## 3a Regressão Logística (sem receita)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod3 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)\nsummary(mod3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = inadimplente ~ balanco + estudante, family = binomial, \n#>     data = conj_treino)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept) -1.058e+01  4.027e-01 -26.264  < 2e-16 ***\n#> balanco      5.629e-03  2.537e-04  22.190  < 2e-16 ***\n#> estudante   -7.246e-01  1.646e-01  -4.401 1.08e-05 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 2340.6  on 8000  degrees of freedom\n#> Residual deviance: 1281.6  on 7998  degrees of freedom\n#> AIC: 1287.6\n#> \n#> Number of Fisher Scoring iterations: 8\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(mod3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   (Intercept)       balanco     estudante \n#> -10.577195871   0.005629461  -0.724574801\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mod3)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                  Estimate   Std. Error   z value      Pr(>|z|)\n#> (Intercept) -10.577195871 0.4027279496 -26.26387 4.962858e-152\n#> balanco       0.005629461 0.0002536895  22.19035 4.256243e-109\n#> estudante    -0.724574801 0.1646214717  -4.40146  1.075250e-05\n```\n\n\n:::\n:::\n\n\n## Comparando os modelos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod2,mod3,test='LR')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Analysis of Deviance Table\n#> \n#> Model 1: inadimplente ~ balanco + receita + estudante\n#> Model 2: inadimplente ~ balanco + estudante\n#>   Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n#> 1      7997     1281.3                     \n#> 2      7998     1281.6 -1 -0.23621    0.627\n```\n\n\n:::\n:::\n\n\n## StepAIC\n\nAo invé de usarmos a estatística de Wald para selecionar as variáveis significativas, podemos usar o AIC (**equivalente ao Cp**) como usamos na regressão múltipla para selecionar as variáveis explicativas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> \n#> Anexando pacote: 'MASS'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> O seguinte objeto é mascarado por 'package:patchwork':\n#> \n#>     area\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> O seguinte objeto é mascarado por 'package:dplyr':\n#> \n#>     select\n```\n\n\n:::\n\n```{.r .cell-code}\n(k <- log(nrow(conj_treino)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 8.987322\n```\n\n\n:::\n\n```{.r .cell-code}\nmod3a <- stepAIC(mod2, trace=FALSE)\nsummary(mod3a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = inadimplente ~ balanco + estudante, family = binomial, \n#>     data = conj_treino)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept) -1.058e+01  4.027e-01 -26.264  < 2e-16 ***\n#> balanco      5.629e-03  2.537e-04  22.190  < 2e-16 ***\n#> estudante   -7.246e-01  1.646e-01  -4.401 1.08e-05 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 2340.6  on 8000  degrees of freedom\n#> Residual deviance: 1281.6  on 7998  degrees of freedom\n#> AIC: 1287.6\n#> \n#> Number of Fisher Scoring iterations: 8\n```\n\n\n:::\n:::\n\n\n## Avaliando o modelo novamente\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.5, \"Sim\", \"Nao\") %>% factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1927   43\n#>        Sim    6   23\n#>                                           \n#>                Accuracy : 0.9755          \n#>                  95% CI : (0.9677, 0.9818)\n#>     No Information Rate : 0.967           \n#>     P-Value [Acc > NIR] : 0.01625         \n#>                                           \n#>                   Kappa : 0.4736          \n#>                                           \n#>  Mcnemar's Test P-Value : 2.706e-07       \n#>                                           \n#>             Sensitivity : 0.34848         \n#>             Specificity : 0.99690         \n#>          Pos Pred Value : 0.79310         \n#>          Neg Pred Value : 0.97817         \n#>              Prevalence : 0.03302         \n#>          Detection Rate : 0.01151         \n#>    Detection Prevalence : 0.01451         \n#>       Balanced Accuracy : 0.67269         \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Mudando a probabilidade (limite) para aumentar a sensibilidade\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > 0.1, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1823   15\n#>        Sim  110   51\n#>                                           \n#>                Accuracy : 0.9375          \n#>                  95% CI : (0.9259, 0.9477)\n#>     No Information Rate : 0.967           \n#>     P-Value [Acc > NIR] : 1               \n#>                                           \n#>                   Kappa : 0.4223          \n#>                                           \n#>  Mcnemar's Test P-Value : <2e-16          \n#>                                           \n#>             Sensitivity : 0.77273         \n#>             Specificity : 0.94309         \n#>          Pos Pred Value : 0.31677         \n#>          Neg Pred Value : 0.99184         \n#>              Prevalence : 0.03302         \n#>          Detection Rate : 0.02551         \n#>    Detection Prevalence : 0.08054         \n#>       Balanced Accuracy : 0.85791         \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Curva ROC modelo só com balanço\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\np_chapeu_log <- predict(mod1, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            1            2            3            4            5            6 \n#> 0.0023045487 0.0145058938 0.0000283305 0.0048096860 0.0028238187 0.0116350810\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROC-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n# Area debaixo da curva\nas.numeric(roc_log$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9579708\n```\n\n\n:::\n:::\n\n\n## Curva ROC 2: Modelo com balanço + estudante\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_chapeu_log <- predict(mod3, newdata = conj_teste, type = \"response\")\nhead(p_chapeu_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            1            2            3            4            5            6 \n#> 1.227576e-03 1.727504e-02 2.549008e-05 5.457908e-03 3.128840e-03 6.698177e-03\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, legacy.axes=TRUE)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROC2-1.png){width=90%}\n:::\n:::\n\n\n## AUC\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Area debaixo da curva\nas.numeric(roc_log2$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9586919\n```\n\n\n:::\n:::\n\n\n## Melhor limite\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_limite <- coords(roc_log2, \"best\", ret = \"threshold\")$threshold\nm_limite\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.03752365\n```\n\n\n:::\n\n```{.r .cell-code}\np_chapeu <- predict(mod3, newdata = conj_teste, type = \"response\")\ny_chapeu <- ifelse(p_chapeu > m_limite, \"Sim\", \"Nao\") %>% \n             factor(levels = levels(conj_teste$inadimplente))\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1701    6\n#>        Sim  232   60\n#>                                           \n#>                Accuracy : 0.8809          \n#>                  95% CI : (0.8659, 0.8948)\n#>     No Information Rate : 0.967           \n#>     P-Value [Acc > NIR] : 1               \n#>                                           \n#>                   Kappa : 0.2974          \n#>                                           \n#>  Mcnemar's Test P-Value : <2e-16          \n#>                                           \n#>             Sensitivity : 0.90909         \n#>             Specificity : 0.87998         \n#>          Pos Pred Value : 0.20548         \n#>          Neg Pred Value : 0.99649         \n#>              Prevalence : 0.03302         \n#>          Detection Rate : 0.03002         \n#>    Detection Prevalence : 0.14607         \n#>       Balanced Accuracy : 0.89454         \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Duas ROCs juntas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(roc_log)\nplot(roc_log2, add=TRUE, col=\"blue\")\nlegend(\"bottomright\", legend=c(\"Mod 1\", \"Mod2\"),\n       col=c(par(\"fg\"), \"blue\"), lwd=2)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROCs-1.png){width=90%}\n:::\n:::\n\n\n## Curva ROC 3 com o KNN\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustando KNN \nset.seed(23)\nconj_treino[,3:4] <- scale(conj_treino[,3:4]) # scale normaliza\nconj_teste[,3:4] <- scale(conj_teste[, 3:4])\nctrl <- trainControl(method = \"cv\")\ntreina_knn <- train(inadimplente ~ balanco + estudante, method = \"knn\", trControl= ctrl, tuneGrid = data.frame(k = seq(5,140, by=5)), data = conj_treino)\n# treina_knn\nplot(treina_knn)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROC3-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nprev_knn <- predict(treina_knn, conj_teste,type = \"prob\")\n\n## ROC\nroc_log2 <- roc(conj_teste$inadimplente ~ p_chapeu_log, plot = TRUE, print.auc=FALSE, col= \"black\", legacy.axes=TRUE) \nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\n\nlegend(\"bottomright\",legend=c(\"Reg. Log\", \"KNN\"), \n       col=c(\"black\",\"green\"),lwd=4)\n```\n\n::: {.cell-output-display}\n![](Aula09_files/figure-html/ROC3-2.png){width=90%}\n:::\n\n```{.r .cell-code}\n# Area abaixo da curva\n# Regressão Logística\nas.numeric(roc_log2$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9586919\n```\n\n\n:::\n\n```{.r .cell-code}\n## KNN\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.943462\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Aula09_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}