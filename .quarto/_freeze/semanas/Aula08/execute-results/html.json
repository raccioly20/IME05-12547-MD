{
  "hash": "b6285ca308207a3b66980dc5374fe12f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"KNN\"\nauthor: \"Ricardo Accioly\"\ndate: \"2024-04-11\"\nformat:\n html:\n    code-link: true\n    fig-width: 9\n    fig-height: 7\n    fig-dpi: 300\nknitr:\n  opts_chunk: \n    out.width: 90%\n    comment: \"#>\"\n---\n\n\n## KNN\n\n**O KNN é um algoritmo muito simples no qual cada observação é prevista com base em sua \"semelhança\" com outras observações. Ao contrário da maioria dos métodos, KNN é um algoritmo baseado na memória e não pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento são necessárias no tempo de execução e as previsões são feitas diretamente das relações amostrais. Consequentemente, os KNNs também são conhecidos como aprendizes preguiçosos**\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 'data.frame':\t10000 obs. of  4 variables:\n#>  $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n#>  $ balance: num  730 817 1074 529 786 ...\n#>  $ income : num  44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   default student   balance    income\n#> 1      No      No  729.5265 44361.625\n#> 2      No     Yes  817.1804 12106.135\n#> 3      No      No 1073.5492 31767.139\n#> 4      No      No  529.2506 35704.494\n#> 5      No      No  785.6559 38463.496\n#> 6      No     Yes  919.5885  7491.559\n```\n\n\n:::\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncredito <- tibble(Default)\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n\n```{.r .cell-code}\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#>  $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n#>  $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n#>  $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco          receita     \n#>  Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n#>  Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n#>               Median :0.0000   Median : 823.6   Median :34553  \n#>               Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n#>               3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n#>               Max.   :1.0000   Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n:::\n\n\n## Matriz de dispersão\n\nVamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\npairs.panels(credito, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/splom-1.png){width=90%}\n:::\n:::\n\n\n## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\np1 <- ggplot(credito, aes(x=inadimplente, y=balanco, color=inadimplente)) +\n  geom_boxplot()\np2 <- ggplot(credito, aes(x=inadimplente, y=receita, color=inadimplente)) +\n  geom_boxplot()\np3 <- ggplot(credito, aes(x=as.factor(estudante), y=balanco, color=as.factor(estudante))) +\n  geom_boxplot()\np4 <- ggplot(credito, aes(x=as.factor(estudante), y=receita, color=as.factor(estudante))) +\n  geom_boxplot()\n(p1 + p2) / (p3 + p4)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/box-plot-1.png){width=90%}\n:::\n:::\n\n\n## Explorando um pouco mais Balanço e Receita\n\n\n::: {.cell}\n\n```{.r .cell-code}\np5 <- ggplot(credito, aes(x=balanco)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(credito)),0))\np6 <- ggplot(credito, aes(x=receita)) +\n    geom_histogram(bins = round(1+3.322*log10(nrow(credito)),0))\np5 + p6\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/histogramas-1.png){width=90%}\n:::\n:::\n\n\n## Balanço vs Receita\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point() \n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/dispersao-1.png){width=90%}\n:::\n:::\n\n\n## KNN\n\nVamos usar a função knn da biblioteca caret que tem ótimas funcionalidades. Observem que a saída pode ser as classes ou as probabilidades de pertencer a uma classe\n\n**Como o KNN usa as distancias entre os pontos ele é afetado pela escala dos dados, portanto, é necessário que os dados sejam normalizados (padronizados) para eliminar este efeito.**\n\nQuando temos diversas variáveis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrão 1\n\n## Criando conjuntos de treino e teste e normalizando variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nset.seed(2024)\ny <- credito$inadimplente\ncredito_split <- createDataPartition(y, times = 1, p = 0.80, list = FALSE)\n\nconj_treino <- credito[credito_split,]\nconj_treino[,3:4] <- scale(conj_treino[,3:4]) # scale normaliza\nconj_teste <- credito[-credito_split,]\nconj_teste[,3:4] <- scale(conj_teste[, 3:4])\n                           \nsummary(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco            receita        \n#>  Nao:7734     Min.   :0.0000   Min.   :-1.72131   Min.   :-2.45922  \n#>  Sim: 267     1st Qu.:0.0000   1st Qu.:-0.73380   1st Qu.:-0.91305  \n#>               Median :0.0000   Median :-0.02068   Median : 0.07759  \n#>               Mean   :0.2945   Mean   : 0.00000   Mean   : 0.00000  \n#>               3rd Qu.:1.0000   3rd Qu.: 0.68805   3rd Qu.: 0.77310  \n#>               Max.   :1.0000   Max.   : 3.74460   Max.   : 2.93799\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco            receita        \n#>  Nao:1933     Min.   :0.0000   Min.   :-1.75009   Min.   :-2.12222  \n#>  Sim:  66     1st Qu.:0.0000   1st Qu.:-0.72205   1st Qu.:-0.91629  \n#>               Median :0.0000   Median :-0.04085   Median : 0.09891  \n#>               Mean   :0.2941   Mean   : 0.00000   Mean   : 0.00000  \n#>               3rd Qu.:1.0000   3rd Qu.: 0.65118   3rd Qu.: 0.76539  \n#>               Max.   :1.0000   Max.   : 3.50597   Max.   : 2.93133\n```\n\n\n:::\n:::\n\n\n## 1a Modelo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Vamos usar a regra da raiz quadrada do tamnho da amostra\nlibrary(caret)\nsqrt(nrow(conj_treino)) ## ~90\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 89.44831\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(23)\n\nt_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)\nt_knn1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 90-nearest neighbor model\n#> Training set outcome distribution:\n#> \n#>  Nao  Sim \n#> 7734  267\n```\n\n\n:::\n:::\n\n\n## Avaliando o modelo\n\n**A acurácia deu um valor alto, mas isto não é suficiente para considerarmos que temos um bom modelo. Veja que a sensibilidade está muito baixa e que o ideal é que tenhamos valores altos de sensibilidade e especificidade.**\n\n**Observar que a prevalência é muito baixa o que está afetando os resultados do modelo**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"class\")\n\n# Matriz de confusão para valiar os resultados\nconfusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1932   50\n#>        Sim    1   16\n#>                                           \n#>                Accuracy : 0.9745          \n#>                  95% CI : (0.9666, 0.9809)\n#>     No Information Rate : 0.967           \n#>     P-Value [Acc > NIR] : 0.03105         \n#>                                           \n#>                   Kappa : 0.3771          \n#>                                           \n#>  Mcnemar's Test P-Value : 1.801e-11       \n#>                                           \n#>             Sensitivity : 0.242424        \n#>             Specificity : 0.999483        \n#>          Pos Pred Value : 0.941176        \n#>          Neg Pred Value : 0.974773        \n#>              Prevalence : 0.033017        \n#>          Detection Rate : 0.008004        \n#>    Detection Prevalence : 0.008504        \n#>       Balanced Accuracy : 0.620953        \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Curva ROC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\n\n# Para a curva ROC preciso das probabilidades e não das classes\np_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nhead(p_chapeu_knn1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            Nao        Sim\n#> [1,] 1.0000000 0.00000000\n#> [2,] 0.9777778 0.02222222\n#> [3,] 1.0000000 0.00000000\n#> [4,] 1.0000000 0.00000000\n#> [5,] 1.0000000 0.00000000\n#> [6,] 0.9888889 0.01111111\n```\n\n\n:::\n\n```{.r .cell-code}\n# Aqui gera o curva e salvo numa variável\nroc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nlegend(\"bottomright\",legend=c(\"KNN1\"), \n       col=c(\"black\"),lwd=4)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/ROC-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n# Area abaixo da Curva (AUC)\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9468286\n```\n\n\n:::\n:::\n\n\n## Variando K\n\n**Anteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a função train da biblioteca caret**\n\n**Observe que a otimização de k é feita através de acurácia**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(23)\n\n# Usando validação cruzada para obter o valor de k através da função train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.\nctrl <- trainControl(method = \"repeatedcv\", \n                     number = 10,\n                     repeats = 5)\nt_knn2 <- train(inadimplente ~ balanco + receita + estudante,\n                method = \"knn\", \n                trControl= ctrl,\n                tuneGrid = data.frame(k = seq(5,100, by=5)),\n                data = conj_treino)\n## Resultados do treino\nt_knn2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> k-Nearest Neighbors \n#> \n#> 8001 samples\n#>    3 predictor\n#>    2 classes: 'Nao', 'Sim' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold, repeated 5 times) \n#> Summary of sample sizes: 7201, 7202, 7202, 7200, 7201, 7201, ... \n#> Resampling results across tuning parameters:\n#> \n#>   k    Accuracy   Kappa    \n#>     5  0.9687288  0.3765173\n#>    10  0.9712788  0.4168775\n#>    15  0.9715291  0.3850309\n#>    20  0.9716289  0.3721385\n#>    25  0.9717038  0.3589464\n#>    30  0.9715790  0.3548330\n#>    35  0.9715790  0.3491665\n#>    40  0.9714289  0.3406805\n#>    45  0.9716040  0.3406811\n#>    50  0.9713290  0.3246231\n#>    55  0.9710542  0.3128433\n#>    60  0.9710041  0.3001469\n#>    65  0.9706041  0.2807185\n#>    70  0.9704544  0.2692037\n#>    75  0.9701544  0.2485740\n#>    80  0.9697046  0.2246645\n#>    85  0.9694044  0.2037268\n#>    90  0.9689544  0.1678243\n#>    95  0.9686547  0.1429906\n#>   100  0.9684796  0.1203337\n#> \n#> Accuracy was used to select the optimal model using the largest value.\n#> The final value used for the model was k = 25.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(t_knn2)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/K1-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n## Previsões com o resultaddos do treino\nprev_knn2 <- predict(t_knn2, conj_teste)\nconfusionMatrix(prev_knn2, conj_teste$inadimplente,  positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1928   43\n#>        Sim    5   23\n#>                                           \n#>                Accuracy : 0.976           \n#>                  95% CI : (0.9683, 0.9822)\n#>     No Information Rate : 0.967           \n#>     P-Value [Acc > NIR] : 0.01143         \n#>                                           \n#>                   Kappa : 0.4791          \n#>                                           \n#>  Mcnemar's Test P-Value : 9.27e-08        \n#>                                           \n#>             Sensitivity : 0.34848         \n#>             Specificity : 0.99741         \n#>          Pos Pred Value : 0.82143         \n#>          Neg Pred Value : 0.97818         \n#>              Prevalence : 0.03302         \n#>          Detection Rate : 0.01151         \n#>    Detection Prevalence : 0.01401         \n#>       Balanced Accuracy : 0.67295         \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Curva ROC dos 2 melhores modelos k=90 e k=25\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprev_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nprev_knn2 <- predict(t_knn2, conj_teste, type = \"prob\")\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Setting levels: control = Nao, case = Sim\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Setting direction: controls < cases\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Setting levels: control = Nao, case = Sim\n#> Setting direction: controls < cases\n```\n\n\n:::\n\n```{.r .cell-code}\nlegend(\"bottomright\",legend=c(\"KNN1\", \"KNN2\"), \n       col=c(\"black\",\"green\"),lwd=4)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/ROC2-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n## Area embaixo das curvas\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9468286\n```\n\n\n:::\n\n```{.r .cell-code}\nas.numeric(roc_knn2$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9220281\n```\n\n\n:::\n:::\n\n\n**Observe que os resultados de área abaixo da ROC não são suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!**\n\n**Os resultados encontrados apontam k=25 como a melhor opção**\n",
    "supporting": [
      "Aula08_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}