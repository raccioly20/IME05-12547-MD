{"title":"KNN","markdown":{"yaml":{"title":"KNN","author":"Ricardo Accioly","date":"`r Sys.Date()`","output":{"html_document":{"toc":"yes","code_download":"yes"}}},"headingText":"KNN","containsRefs":false,"markdown":"\n\n\n**O KNN é um algoritmo muito simples no qual cada observação é prevista com base em sua \"semelhança\" com outras observações. Ao contrário da maioria dos métodos, KNN é um algoritmo baseado na memória e não pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento são necessárias no tempo de execução e as previsões são feitas diretamente das relações amostrais. Consequentemente, os KNNs também são conhecidos como aprendizes preguiçosos**\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(fig.width = 9, \n                      fig.height= 7,  \n                      fig.retina = 3,\n                      message = FALSE, \n                      warning = FALSE,\n                      dev=c(\"png\"), \n                      fig.path=\"imagens/Aula08A/\")\n```\n\n## Carregando Bibliotecas\n\n```{r bibliotecas, message=FALSE}\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\nstr(Default)\nhead(Default)\n```\n\n## Manipulando os dados\n\n```{r inadimplente}\ncredito <- tibble(Default)\nsummary(credito)\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\nsummary(credito)\n\n```\n\n## Normalização\n\nAntes de iniciarmos é fundamental fazermos a normalização (padronização) dos dados para que o KNN tenha um melhor desempenho.\n\n```{r normalizar}\ncredito_n <- credito\ncredito_n[,3:4] <- scale(credito_n[,3:4])\n```\n\n## Treino e Teste\n\n```{r conjuntos-treino-teste, message=FALSE}\nset.seed(21)\ny <- credito_n$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito_n %>% slice(-indice_teste)\nconj_teste <- credito_n %>% slice(indice_teste)\n\nsummary(conj_treino)\nsummary(conj_teste)\n```\n\n## Matriz de dispersão\n\nVamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente.\n\n```{r splom, message=FALSE}\nlibrary(psych)\npairs.panels(credito, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )\n\n```\n\n## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\n```{r box-plot}\nggplot(credito, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\nggplot(credito, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\nggplot(credito, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\nggplot(credito, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()\n\n\n```\n\n## Explorando um pouco mais Balanço e Receita\n\n```{r histogramas}\nggplot(credito, aes(x=balanco)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))\nggplot(credito, aes(x=receita)) +\n    geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))\n```\n\n## Balanço vs Receita\n\n```{r dispersao}\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point() \n```\n\n## KNN\n\n**Vamos usar a função knn da biblioteca caret que tem ótimas funcionalidades. Observem que a saída pode ser as classes ou as probabilidades de pertencer a uma classe**\n\n**Como o KNN usa as distancias entre os pontos ele é afetado pela escala dos dados, portanto, é necessário que os dados sejam normalizados (padronizados) para eliminar este efeito.**\n\n**Quando temos diversas variáveis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrão 1**\n\n## 1a Modelo\n\n```{r 1modelo}\n# Vamos usar a regra da raiz quadrada do tamnho da amostra\nsqrt(nrow(conj_treino)) ## ~90\nset.seed(21)\nt_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)\nt_knn1\n```\n\n## Avaliando o modelo\n\n**A acurácia deu um valor alto, mas isto não é suficiente para considerarmo que temos um bom modelo. Veja que a sensibilidade está muito baixa e que o ideal é que tenhamos valores altos de sensibilidade e especificidade.**\n\n**Observar que a prevalência é muito baixa o que está afetando os resultados do modelo**\n\n```{r aval}\n## \ny_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"class\")\n\n# Matriz de confusão para valiar os resultados\nconfusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n## Curva ROC\n\n```{r ROC, fig.width=9, message=FALSE}\nlibrary(pROC)\n\n# Para a curva ROC preciso das probabilidades e não das classes\np_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nhead(p_chapeu_knn1)\n\n# Aqui gera o curva e salvo numa variável\nroc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nlegend(\"bottomright\",legend=c(\"KNN1\"), \n       col=c(\"black\"),lwd=4)\n\n# Area abaixo da Curva (AUC)\nas.numeric(roc_knn1$auc)\n```\n\n## Variando K\n\n**Anteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a função train da biblioteca caret**\n\n**Observe que a otimização de k é feita através de acurácia**\n\n```{r K1}\nset.seed(21)\n\n# Usando validação cruzada para obter o valor de k através da função train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.\nctrl <- trainControl(method = \"cv\")\nt_knn2 <- train(inadimplente ~ balanco + receita + estudante,\n                method = \"knn\", trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                data = conj_treino)\n## Resultados do treino\nt_knn2\nplot(t_knn2)\n\n## Previsões com o resultaddos do treino\nprev_knn2 <- predict(t_knn2, conj_teste)\nconfusionMatrix(prev_knn2, conj_teste$inadimplente,  positive=\"Sim\")\n```\n\n## Variando K de outra forma\n\n**Vamos adicionar mais opções no trainControl**\n\n**Ao colocar classProb = TRUE e summaryFunction ao invés da acurácia a otimização passa a ser através o ROC**\n\n```{r K2}\nset.seed(21)\n# ctrl <- trainControl(method = \"cv\", classProbs=TRUE, summaryFunction = twoClassSummary)\nctrl <- trainControl(method = \"repeatedcv\", \n                     number = 10,\n                     repeats = 5, \n                     classProbs = TRUE,\n                     summaryFunction = twoClassSummary)\n\nt_knn3 <- train(inadimplente ~ balanco + receita + estudante, \n                method = \"knn\", \n                trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                metric = \"ROC\",\n                data = conj_treino)\nt_knn3\nplot(t_knn3)\nprev_knn3 <- predict(t_knn3, conj_teste)\nconfusionMatrix(prev_knn3, conj_teste$inadimplente,  positive=\"Sim\")\n```\n\n**Veja que ao otimizar pela ROC o modelo escolhido tem sensibilidade zero! Isto obviamente não é um bom modelo! Neste caso a opção de otimização do parametro pela acurácia dá melhores resultados.**\n\n## Curva ROC dos 2 melhores modelos k=90 e k=20\n\n```{r ROC2, fig.width=9}\nprev_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nprev_knn2 <- predict(t_knn2, conj_teste, type = \"prob\")\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\nroc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\nlegend(\"bottomright\",legend=c(\"KNN1\", \"KNN2\"), \n       col=c(\"black\",\"green\"),lwd=4)\n\n## Area embaixo das curvas\nas.numeric(roc_knn1$auc)\nas.numeric(roc_knn2$auc)\n```\n\n**Observe que os resultados de área abaixo da ROC não são suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!**\n\n**Os resultados encontrados apontam k=20 como a melhor opção**\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":{"html_document":{"toc":"yes","code_download":"yes"}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"Aula08.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.38","editor":"visual","theme":{"light":["cosmo","../theme.scss"],"dark":["cosmo","../theme-dark.scss"]},"mainfont":"Atkinson Hyperlegible","code-copy":true,"title":"KNN","author":"Ricardo Accioly","date":"`r Sys.Date()`"},"extensions":{"book":{"multiFile":true}}}}}