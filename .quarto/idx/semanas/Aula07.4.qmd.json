{"title":"Regularização de Modelos","markdown":{"yaml":{"title":"Regularização de Modelos","author":"Ricardo Accioly","date":"`r Sys.Date()`","output":{"html_document":{"toc":"yes","code_download":"yes"}}},"headingText":"Regularização de modelos","containsRefs":false,"markdown":"\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(fig.width = 9, \n                      fig.height= 7,  \n                      fig.retina = 3,\n                      message = FALSE, \n                      warning = FALSE,\n                      dev=c(\"png\"), \n                      fig.path=\"imagens/Aula07_4/\")\n```\n\n## Carregando Bibliotecas\n\n```{r bibliotecas, warning=FALSE, message=FALSE}\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(glmnet)\ndata(Boston)\n```\n\n## Carregando os dados\n\nVamos utilizar neste exemplo os dados contidos na biblioteca MASS. A base de dados Boston tem `r nrow(Boston)` de valores preços medianos de casas na região de Boston com 13 outras variáveis explicativas (potencialmente). Vamos explorar os dados e ajustar modelos com penalização o Ridge e o LASSO e depois vamos comparar com os mínimos quadrados.\n\n```{r Dados}\nhead(Boston)\nsummary(Boston)\n```\n\nObservamos acima que todas as variáveis são quantitativas e que não há necessidade de transformações.\n\n## Significado das variáveis\n\n```{r Boston}\n# Boston Database\n# \n#1) crim - taxa de criminalidade per capita por cidade.\n# \n#2) zn - proporção de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n#3) indus - proporção de negócios não comerciais por acres e por cidade.\n# \n#4) chas - variável dummy do Rio Charles(= 1 se próximo do rio; 0 de outra forma).\n# \n#5) nox - concentração de óxido de nitrogênio (partes por 10 milhões).\n# \n#6) rm - número médio de quartos por habitação\n# \n#7) age - proporção da unidade ocupadas pelos proprietários construídas antes 1940.\n# \n#8) dis - média ponderada das distâncias dos 5 pontos de emprego em Boston.\n# \n#9) rad - indice de acessibilidade das avenidas radiais.\n# \n#10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n#11) ptratio - razão aluno-professor por cidade.\n# \n#12) black - 1000(Bk−0.63)21000(Bk−0.63)2 proporção de negros por cidade.\n# \n#13) lstat - percentual de baixo status da população.\n# \n#14) medv - valor mediano das cas ocupadas pelos proprietário em $1000s. (Var. Resposta)\n```\n\n## Conjunto de treino e de teste\n\n```{r treino_teste}\nlibrary(caret)\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_treino <- conj_treino %>% select(-rad)\nconj_teste <- Boston %>% slice(indice_teste)\nconj_teste <- conj_teste %>% select(-rad)\nstr(conj_treino)\nstr(conj_teste)\n\n```\n\n## Métodos de Regularização\n\nO pacote glmnet não usa a linguagem de formula, em particular nós devemos passar $x$ como uma matriz e $y$ como um vetor, pois não se usa a sintaxe $y \\sim x$. Com isso será necessário ajustar x e y. A função model.matrix() é particularmente útil para criar x; não só produz uma matriz correspondente as variáveis explicativas, **mas também transforma automaticamente quaisquer variáveis qualitativas em variáveis dummy. Esta última propriedade é importante porque o glmnet() só pode tomar insumos numéricos e quantitativos.**\n\n```{r preparando_dados}\nx_treino <- model.matrix(medv ~ . , data = conj_treino)[, -1]\ny_treino <- conj_treino$medv\n\nx_teste <- model.matrix(medv ~ . , data = conj_teste)[, -1]\ny_teste = conj_teste$medv\n```\n\n## Regressão Ridge\n\nPrimeiro vamos ajustar um modelo de regressão Ridge. Isso é conseguido chamando `glmnet()` com `alpha=0`, se `alpha=1` então `glmnet()` ajusta um lasso.(veja o arquivo de ajuda).\n\n```{r Ridge}\n## Estabelecendo um grid de valores para lambda\ngrid <- 10^seq(-2, 10, length = 100)\najusreg.ridge <- glmnet(x_treino, y_treino, alpha=0, lambda = grid)\n\n```\n\nPor padrão, a função `glmnet()` executa a regressão ridge automaticamente selecionando a faixa de valores de $\\lambda$. No entanto, aqui nós escolhemos implementar usando uma grade de valores que variam de $\\lambda = 10^{-2}$ a $\\lambda = 10^{10}$, cobrindo toda a gama de cenários do modelo nulo contendo apenas o coeficiente linear até o ajuste dos mínimos quadrados.\n\nTambém podemos calcular o modelo para um valor particular de $\\lambda$ que não é um dos valores de grade. Observe que, por padrão, a função `glmnet()` padroniza as variáveis para que elas estejam na mesma escala. **Esta padronização é muito importante no caso da regressão Ridge, pois ela é afetada pela mudança de escala das variáveis explicativas.**\n\nAssociado a cada valor de $\\lambda$ existe um vetor de coeficientes de regressão de ridge, que é armazenado em uma matriz que pode ser acessada por 'coef()'. Neste caso, é uma matriz $14 \\times 100$, com 14 linhas (uma para cada preditor, mais uma para o coeficiente linear) e 100 colunas (uma para cada valor de $\\lambda$).\n\n```{r r1}\ndim(coef(ajusreg.ridge))\nplot(ajusreg.ridge, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n\n```\n\nQuando $\\lambda$ é grande o esperado é que os coeficentes sejam pequenos e quando $\\lambda$ é pequeno os coeficientes assumem valores maiores.\n\n```{r r2}\najusreg.ridge$lambda[1] # Mostra primeiro valor de lambda\ncoef(ajusreg.ridge)[,1] # Mostra os coeficientes associados com o primeiro valor\najusreg.ridge$lambda[100] # Mostra centésimo valor de lambda\ncoef(ajusreg.ridge)[,100] # Mostra os coeficientes associados com o centésimo valor\n```\n\n```{r r3}\nlibrary(plotmo)\nplot_glmnet(ajusreg.ridge)\n```\n\n## Cross-Validation no Ridge\n\nNós podemos usar o k-fold cross validation para identificar o melhor valor de $\\lambda$\n\nA biblioteca glmnet já tem internamente uma função para uso do crosss validation. O default são 10 envelopes de dados `nfold=10`.\n\n```{r r4}\nset.seed(21)\nridge_cv <- cv.glmnet(x_treino,y_treino, alpha=0) ## por padrão k=10\nplot(ridge_cv)\nm_lamb <- ridge_cv$lambda.min  # Seleciona o lambda que minimiza o MSE (EQM) de treino\nm_lamb\nlog(m_lamb)\ncoef(ridge_cv, s=m_lamb)\n```\n\n## Avaliando com conjunto de teste\n\nEm seguida avaliamos seu MSE no conjunto de teste, usando $\\lambda$ = m_lamb. Observe o uso da função 'predict()': desta vez temos previsões para um conjunto de teste, com o argumento `newx`.\n\n```{r avaliando}\najusreg.ridge2 <- glmnet(x_treino, y_treino, alpha=0, lambda = m_lamb)\ny_prev <- predict(ajusreg.ridge2, s = m_lamb, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n```\n\n\n## LASSO\n\nPrimeiro ajustamos com todos os dados como no caso do Ridge\n\n```{r LASSO}\najusreg.lasso <- glmnet(x_treino,y_treino, alpha = 1)\nplot(ajusreg.lasso, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\nplot_glmnet(ajusreg.lasso)\n```\n\n## Validação Cruzada no LASSO\n\n```{r Lasso2}\nlasso_cv <- cv.glmnet(x_treino,y_treino, alpha = 1)\nplot(lasso_cv)\nm_lamb1 <- lasso_cv$lambda.min  # Seleciona o lambda que minimiza o MSE de treino\nm_lamb1\nlog(m_lamb1)\ncoef(lasso_cv, s=m_lamb1)\n```\n\n## Avaliando com conjunto de teste\n\n```{r lasso2}\najusreg.lasso2 <- glmnet(x_treino, y_treino, alpha=1, lambda = m_lamb1)\ny_prev <- predict(ajusreg.lasso2, s = m_lamb1, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n```\n\n## Comparando com a seleção de modelos usando o Cp\n\n```{r outro}\nlibrary(leaps)\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg <- summary(ajusreg.comp)\n## Os modelos vão ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\npoints(9,sumario.reg$cp[9],pch=20,col=\"red\")\n```\n\n## Ajustando no lm() e vendo o erro no conjunto de teste\n\nObservando so resultados de erro vemos que tanto a regressão Ridge como o LASSO apresentaram valores de erro maiores que o modelo definido através da melhor seleção de modelos (best subset regression). Aqui usamos o Cp de Mallows como critério de deleção de variáveis.\n\n```{r erro_teste}\ncoef(ajusreg.comp,9) \noutro_mod <- lm(medv ~ zn + chas + nox + rm + age + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod)\nsqrt(mean((conj_teste$medv - predict(outro_mod, conj_teste)) ^ 2)) \n```\n\n## E o BIC?\n\nE se escolhessemos o BIC como critério de seleção de variáveis explicativas? Neste caso os resultados foram iguais ao Cp. Entretanto, dá para perceber que o BIC apresentou uma certa estabilidade entre 7 e 9 variáveis. Se quisermos ter um modelo mais enxuto poderiamos optar por 7 variáveis.\n\n```{r BIC}\najusreg.comp1 <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg1 <- summary(ajusreg.comp1)\n## Os modelos vão ser escolhidos com base no menor BIC\nplot(sumario.reg1$bic,xlab=\"Número de Variáveis\",ylab=\"BIC\")\nwhich.min(sumario.reg1$bic)\npoints(7,sumario.reg1$bic[7],pch=20,col=\"red\")\ncoef(ajusreg.comp1,7) \noutro_mod1 <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod1)\nsqrt(mean((conj_teste$medv - predict(outro_mod1, conj_teste)) ^ 2))\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":{"html_document":{"toc":"yes","code_download":"yes"}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"Aula07.4.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","theme":{"light":["cosmo","../theme.scss"],"dark":["cosmo","../theme-dark.scss"]},"mainfont":"Atkinson Hyperlegible","code-copy":true,"title":"Regularização de Modelos","author":"Ricardo Accioly","date":"`r Sys.Date()`"},"extensions":{"book":{"multiFile":true}}}}}