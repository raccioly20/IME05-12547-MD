{
  "hash": "a8c69fbb7495a953774e8bd5fb06a301",
  "result": {
    "markdown": "---\ntitle: \"Análise de Clusters\"\nauthor: \"Ricardo Accioly\"\ndate: \"2022-12-30\"\noutput:\n  html_document:\n    toc: yes\n---\n\n\n\n\n## Bibliotecas\n\nEste conteúdo foi adaptado de: https://mhahsler.github.io/Introduction_to_Data_Mining_R\\_Examples/book/clustering-analysis.html\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(cluster)\n```\n:::\n\n\n## Dados\n\nO conjunto de dados Ruspini, que consiste em 75 pontos dividido em quatro grupos, ele é popular para ilustrar técnicas de agrupamento. É um conjunto de dados muito simples com clusters bem separados. O conjunto de dados original tem os pontos ordenados por grupo. Podemos embaralhar os dados (linhas) usando sample_frac.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(ruspini, package=\"cluster\")\n```\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nruspini <- as_tibble(ruspini) %>% sample_frac()\nruspini\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 75 × 2\n       x     y\n   <int> <int>\n 1    44   156\n 2    54   124\n 3    47   149\n 4    99   119\n 5    28    76\n 6     4    53\n 7   101   115\n 8    32   143\n 9   108   111\n10    33   154\n# … with 65 more rows\n```\n:::\n:::\n\n\n## Explorando os dados\n\nNesta etapa os dados são avaliados, pois eventualmente temos situações de dados ausentes, pontos afastados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ruspini, aes(x = x, y = y)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(ruspini)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       x                y         \n Min.   :  4.00   Min.   :  4.00  \n 1st Qu.: 31.50   1st Qu.: 56.50  \n Median : 52.00   Median : 96.00  \n Mean   : 54.88   Mean   : 92.03  \n 3rd Qu.: 76.50   3rd Qu.:141.50  \n Max.   :117.00   Max.   :156.00  \n```\n:::\n:::\n\n\n## Normalização\n\nComo os algoritmos usam medidas de distância é necessário usarmos a normalização para que os resultados naõ sejam afetados pela escala dos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Aqui vamos essa função para fazer a normalização\nescala_numerica <- function(x) x %>% mutate_if(is.numeric, function(y) as.vector(scale(y)))\n\nruspini_norm <- ruspini %>% escala_numerica()\nsummary(ruspini_norm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       x                  y           \n Min.   :-1.66806   Min.   :-1.80743  \n 1st Qu.:-0.76649   1st Qu.:-0.72946  \n Median :-0.09442   Median : 0.08158  \n Mean   : 0.00000   Mean   : 0.00000  \n 3rd Qu.: 0.70879   3rd Qu.: 1.01582  \n Max.   : 2.03655   Max.   : 1.31355  \n```\n:::\n:::\n\n\n## Métodos para obtenção de Clusters\n\n### K-médias\n\nO algoritmo do k-médias usa a distância Eucliadiana quadrática. Aqui vamos usar k=4 e vamos rodar o algoritmo 10 vezes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm <- kmeans(ruspini_norm, centers = 4, nstart = 10)\nkm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nK-means clustering with 4 clusters of sizes 15, 20, 23, 17\n\nCluster means:\n           x          y\n1  0.4607268 -1.4912271\n2 -1.1385941 -0.5559591\n3 -0.3595425  1.1091151\n4  1.4194387  0.4692907\n\nClustering vector:\n [1] 3 3 3 4 2 2 4 3 4 3 3 4 1 2 1 1 2 3 3 4 2 2 4 1 3 2 2 2 2 1 4 4 3 2 2 3 4 1\n[39] 3 1 4 1 2 2 4 3 1 3 3 2 2 1 3 1 4 2 4 1 3 2 3 4 1 3 1 3 2 2 4 3 3 4 3 1 4\n\nWithin cluster sum of squares by cluster:\n[1] 1.082373 2.705477 2.658679 3.641276\n (between_SS / total_SS =  93.2 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nruspini_clusters <- ruspini_norm %>% add_column(cluster = factor(km$cluster))\nruspini_clusters\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 75 × 3\n         x      y cluster\n     <dbl>  <dbl> <fct>  \n 1 -0.357   1.31  3      \n 2 -0.0289  0.657 3      \n 3 -0.258   1.17  3      \n 4  1.45    0.554 4      \n 5 -0.881  -0.329 2      \n 6 -1.67   -0.801 2      \n 7  1.51    0.472 4      \n 8 -0.750   1.05  3      \n 9  1.74    0.390 4      \n10 -0.717   1.27  3      \n# … with 65 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ruspini_clusters, aes(x = x, y = y, color = cluster)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nAdicionando os centroides aos gráficos\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncentroids <- as_tibble(km$centers, rownames = \"cluster\")\ncentroids\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 3\n  cluster      x      y\n  <chr>    <dbl>  <dbl>\n1 1        0.461 -1.49 \n2 2       -1.14  -0.556\n3 3       -0.360  1.11 \n4 4        1.42   0.469\n```\n:::\n\n```{.r .cell-code}\nggplot(ruspini_clusters, aes(x = x, y = y, color = cluster)) + geom_point() + geom_point(data = centroids, aes(x = x, y = y, color = cluster), shape = 3, size = 10)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nVamos usar a biblioteca factoextra para visualizarmos os clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(factoextra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n```\n:::\n\n```{.r .cell-code}\nfviz_cluster(km, data = ruspini_norm, centroids = TRUE, repel = TRUE, ellipse.type = \"norm\")\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### k-medoides\n\nOs medoides pertencem ao proprio conjunto de dados. Podemos observar que o resultado é semelhante ao obtido no k-médias, mas o algoritmo é mais lento.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library(cluster)\nkmed <- pam(ruspini_norm, k = 4)\nsummary(kmed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMedoids:\n     ID          x          y\n[1,] 49 -0.3566917  1.1698207\n[2,]  4  1.4464374  0.5538374\n[3,] 26 -1.1762959 -0.5549325\n[4,] 54  0.4629124 -1.4583746\nClustering vector:\n [1] 1 1 1 2 3 3 2 1 2 1 1 2 4 3 4 4 3 1 1 2 3 3 2 4 1 3 3 3 3 4 2 2 1 3 3 1 2 4\n[39] 1 4 2 4 3 3 2 1 4 1 1 3 3 4 1 4 2 3 2 4 1 3 1 2 4 1 4 1 3 3 2 1 1 2 1 4 2\nObjective function:\n    build      swap \n0.4422977 0.3187056 \n\nNumerical information per cluster:\n     size  max_diss   av_diss  diameter separation\n[1,]   23 0.6558680 0.2993397 1.1591436   0.767612\n[2,]   17 0.9459253 0.3862345 1.4627043   0.767612\n[3,]   20 0.5755656 0.3401125 1.1192822   1.157682\n[4,]   15 0.4589783 0.2433250 0.8359025   1.157682\n\nIsolated clusters:\n L-clusters: character(0)\n L*-clusters: [1] 3 4\n\nSilhouette plot information:\n   cluster neighbor sil_width\n49       1        3 0.8368407\n48       1        3 0.8305019\n3        1        2 0.8222142\n64       1        3 0.8220686\n11       1        3 0.8158429\n1        1        2 0.8150398\n61       1        3 0.8134280\n59       1        3 0.8064757\n53       1        2 0.7984225\n70       1        3 0.7969057\n71       1        3 0.7841631\n25       1        2 0.7794889\n39       1        2 0.7605512\n10       1        3 0.7591035\n19       1        3 0.7473901\n18       1        2 0.7423529\n36       1        3 0.7402623\n8        1        3 0.7249133\n46       1        2 0.7007372\n66       1        3 0.6739284\n2        1        2 0.5661372\n73       1        2 0.5413082\n33       1        2 0.4673917\n7        2        1 0.7898609\n4        2        1 0.7834341\n45       2        1 0.7822308\n55       2        1 0.7790446\n9        2        1 0.7780891\n57       2        1 0.7694930\n37       2        1 0.7624335\n32       2        1 0.7609359\n72       2        1 0.7400337\n31       2        1 0.7392052\n23       2        1 0.7390493\n12       2        1 0.7234199\n62       2        1 0.5894345\n75       2        4 0.5666610\n69       2        1 0.5114355\n41       2        1 0.4358476\n20       2        1 0.3312348\n26       3        1 0.8094377\n34       3        4 0.8027447\n50       3        1 0.7782513\n60       3        4 0.7704646\n29       3        4 0.7700388\n56       3        1 0.7597906\n21       3        1 0.7530091\n67       3        1 0.7436695\n14       3        4 0.7412965\n51       3        1 0.7270442\n27       3        4 0.7255183\n22       3        4 0.7226938\n6        3        4 0.7042349\n35       3        1 0.7026960\n5        3        1 0.6966533\n43       3        4 0.6921822\n44       3        4 0.6756339\n28       3        4 0.6463656\n17       3        1 0.6005277\n68       3        4 0.6004543\n54       4        3 0.8592059\n24       4        3 0.8553255\n47       4        3 0.8530741\n40       4        3 0.8449473\n42       4        3 0.8361633\n63       4        3 0.8187150\n65       4        3 0.8178795\n58       4        2 0.8087015\n13       4        3 0.8013799\n74       4        3 0.7983516\n16       4        3 0.7918724\n30       4        3 0.7768261\n15       4        3 0.7727269\n52       4        2 0.7425993\n38       4        3 0.7328306\nAverage silhouette width per cluster:\n[1] 0.7454551 0.6812849 0.7211353 0.8073733\nAverage silhouette width of total data set:\n[1] 0.7368082\n\n2775 dissimilarities, summarized :\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.03868 1.16780 1.92500 1.78630 2.47760 3.91720 \nMetric :  euclidean \nNumber of objects : 75\n\nAvailable components:\n [1] \"medoids\"    \"id.med\"     \"clustering\" \"objective\"  \"isolation\" \n [6] \"clusinfo\"   \"silinfo\"    \"diss\"       \"call\"       \"data\"      \n```\n:::\n\n```{.r .cell-code}\nplot(kmed)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n:::\n\n\nOutra forma de visualização\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_cluster(kmed, ruspini_norm,\n             ellipse.type = \"convex\",\n             repel =TRUE,\n             ggtheme =theme_minimal())\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nknitr::kable(kmed$medoids)\n```\n\n::: {.cell-output-display}\n|          x|          y|\n|----------:|----------:|\n| -0.3566917|  1.1698207|\n|  1.4464374|  0.5538374|\n| -1.1762959| -0.5549325|\n|  0.4629124| -1.4583746|\n:::\n\n```{.r .cell-code}\nlibrary(janitor)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'janitor'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n```\n:::\n\n```{.r .cell-code}\ntabyl(kmed$clustering)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n kmed$clustering  n   percent\n               1 23 0.3066667\n               2 17 0.2266667\n               3 20 0.2666667\n               4 15 0.2000000\n```\n:::\n:::\n\n\n### Clusters Hierarquicos\n\nO agrupamento hierárquico começa com uma matriz de distância ´dist()´ e tem como padrão method=\"Euclidiano\". As matrizes de distância tornam-se muito grandes rapidamente (tamanho e complexidade de tempo é O(n2) onde n é o número se pontos de dados. Só é possível calcular e armazenar a matriz para pequenos conjuntos de dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- dist(ruspini_norm)\n```\n:::\n\n\nA função hclust() implementa o HCA, ou seja, o cluster hierarquico aglomerativo. Vamos começar usando o método completo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhc <- hclust(d, method = \"complete\")\n```\n:::\n\n\nO HCA retorna um dendrograma e não uma definiçaõ de clusters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hc)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nSe usarmos a biblioteca factoextra podemos definir o número de clusters que queremos visualizar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_dend(hc, k=4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at <https://github.com/kassambara/factoextra/issues>.\n```\n:::\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nPodemos extrair as atraibuições de cluster cortando o dendrograma em 4 partes e adicionando a identidade aos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclusters <- cutree(hc, k = 4)\ncluster_completo <- ruspini_norm %>%\n  add_column(cluster = factor(clusters))\ncluster_completo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 75 × 3\n         x      y cluster\n     <dbl>  <dbl> <fct>  \n 1 -0.357   1.31  1      \n 2 -0.0289  0.657 1      \n 3 -0.258   1.17  1      \n 4  1.45    0.554 2      \n 5 -0.881  -0.329 3      \n 6 -1.67   -0.801 3      \n 7  1.51    0.472 2      \n 8 -0.750   1.05  1      \n 9  1.74    0.390 2      \n10 -0.717   1.27  1      \n# … with 65 more rows\n```\n:::\n:::\n\n\nPodemos usar o método de Ward para obter o cluster.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhc_w <- hclust(d, method = \"ward.D\")\n```\n:::\n\n\nO HCA retorna um dendrograma e não uma definiçaõ de clusters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hc_w)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nSe usarmos a biblioteca factoextra podemos definir o número de clusters que queremos visualizar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_dend(hc_w, k=4)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_cluster(list(data = ruspini_norm, cluster = cutree(hc_w, k = 4)), geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Validação dos Clusters\n\n### Silhouette\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library(cluster)\nplot(silhouette(kmed$clustering,d))\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_silhouette(silhouette(kmed$clustering, d))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  cluster size ave.sil.width\n1       1   23          0.75\n2       2   17          0.68\n3       3   20          0.72\n4       4   15          0.81\n```\n:::\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Numero ótimo de clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Usando o silhouette\nfviz_nbclust(ruspini_norm, pam, method =\"silhouette\", k.max = 8)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Metodo do cotovelo\nfviz_nbclust(ruspini_norm, kmeans, method =\"wss\", k.max = 8)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n:::\n\n\n## \n",
    "supporting": [
      "Aula13_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}