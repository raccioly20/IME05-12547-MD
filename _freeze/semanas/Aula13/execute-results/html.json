{
  "hash": "d4d84cfb81acacf58e03dcf0c1134641",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Análise de Clusters\"\nauthor: \"Ricardo Accioly\"\ndate: \"2024-03-05\"\nformat:\n html:\n    code-link: true\n---\n\n\n## Bibliotecas\n\nEste conteúdo foi adaptado de: https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/book/clustering-analysis.html\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(cluster)\n```\n:::\n\n\n## Dados\n\nO conjunto de dados Ruspini, que consiste em 75 pontos dividido em quatro grupos, ele é popular para ilustrar técnicas de agrupamento. É um conjunto de dados muito simples com clusters bem separados. O conjunto de dados original tem os pontos ordenados por grupo. Podemos embaralhar os dados (linhas) usando sample_frac.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(ruspini, package=\"cluster\")\n```\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nruspini <- as_tibble(ruspini) %>% sample_frac()\nruspini\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 75 × 2\n       x     y\n   <int> <int>\n 1    70     4\n 2    41   150\n 3    32   149\n 4    44   143\n 5   117   115\n 6    13    69\n 7    44   156\n 8    74    96\n 9    63   139\n10    52   152\n# ℹ 65 more rows\n```\n\n\n:::\n:::\n\n\n## Explorando os dados\n\nNesta etapa os dados são avaliados, pois eventualmente temos situações de dados ausentes, pontos afastados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ruspini, aes(x = x, y = y)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(ruspini)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       x                y         \n Min.   :  4.00   Min.   :  4.00  \n 1st Qu.: 31.50   1st Qu.: 56.50  \n Median : 52.00   Median : 96.00  \n Mean   : 54.88   Mean   : 92.03  \n 3rd Qu.: 76.50   3rd Qu.:141.50  \n Max.   :117.00   Max.   :156.00  \n```\n\n\n:::\n:::\n\n\n## Normalização\n\nComo os algoritmos usam medidas de distância é necessário usarmos a normalização para que os resultados naõ sejam afetados pela escala dos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Aqui vamos essa função para fazer a normalização\nescala_numerica <- function(x) x %>% mutate_if(is.numeric, function(y) as.vector(scale(y)))\n\nruspini_norm <- ruspini %>% escala_numerica()\nsummary(ruspini_norm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       x                  y           \n Min.   :-1.66806   Min.   :-1.80743  \n 1st Qu.:-0.76649   1st Qu.:-0.72946  \n Median :-0.09442   Median : 0.08158  \n Mean   : 0.00000   Mean   : 0.00000  \n 3rd Qu.: 0.70879   3rd Qu.: 1.01582  \n Max.   : 2.03655   Max.   : 1.31355  \n```\n\n\n:::\n:::\n\n\n## Métodos para obtenção de Clusters\n\n### K-médias\n\nO algoritmo do k-médias usa a distância Eucliadiana quadrática. Aqui vamos usar k=4 e vamos rodar o algoritmo 10 vezes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm <- kmeans(ruspini_norm, centers = 4, nstart = 10)\nkm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nK-means clustering with 4 clusters of sizes 23, 20, 17, 15\n\nCluster means:\n           x          y\n1 -0.3595425  1.1091151\n2 -1.1385941 -0.5559591\n3  1.4194387  0.4692907\n4  0.4607268 -1.4912271\n\nClustering vector:\n [1] 4 1 1 1 3 2 1 3 1 1 3 4 1 4 4 1 2 3 4 2 2 3 3 1 3 2 3 4 1 2 4 1 1 1 4 3 2 2\n[39] 3 1 2 2 1 2 4 1 1 4 2 2 1 4 2 2 1 2 1 4 2 2 3 3 3 2 4 4 4 3 1 3 1 3 1 3 2\n\nWithin cluster sum of squares by cluster:\n[1] 2.658679 2.705477 3.641276 1.082373\n (between_SS / total_SS =  93.2 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nruspini_clusters <- ruspini_norm %>% add_column(cluster = factor(km$cluster))\nruspini_clusters\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 75 × 3\n         x       y cluster\n     <dbl>   <dbl> <fct>  \n 1  0.496  -1.81   4      \n 2 -0.455   1.19   1      \n 3 -0.750   1.17   1      \n 4 -0.357   1.05   1      \n 5  2.04    0.472  3      \n 6 -1.37   -0.473  2      \n 7 -0.357   1.31   1      \n 8  0.627   0.0816 3      \n 9  0.266   0.964  1      \n10 -0.0944  1.23   1      \n# ℹ 65 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ruspini_clusters, aes(x = x, y = y, color = cluster)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nAdicionando os centroides aos gráficos\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncentroids <- as_tibble(km$centers, rownames = \"cluster\")\ncentroids\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  cluster      x      y\n  <chr>    <dbl>  <dbl>\n1 1       -0.360  1.11 \n2 2       -1.14  -0.556\n3 3        1.42   0.469\n4 4        0.461 -1.49 \n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(ruspini_clusters, aes(x = x, y = y, color = cluster)) + geom_point() + geom_point(data = centroids, aes(x = x, y = y, color = cluster), shape = 3, size = 10)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nVamos usar a biblioteca factoextra para visualizarmos os clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(factoextra)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n```\n\n\n:::\n\n```{.r .cell-code}\nfviz_cluster(km, data = ruspini_norm, centroids = TRUE, repel = TRUE, ellipse.type = \"norm\")\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### k-medoides\n\nOs medoides pertencem ao proprio conjunto de dados. Podemos observar que o resultado é semelhante ao obtido no k-médias, mas o algoritmo é mais lento.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library(cluster)\nkmed <- pam(ruspini_norm, k = 4)\nsummary(kmed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMedoids:\n     ID          x          y\n[1,] 31  0.4629124 -1.4583746\n[2,] 13 -0.3566917  1.1698207\n[3,] 72  1.4464374  0.5538374\n[4,] 17 -1.1762959 -0.5549325\nClustering vector:\n [1] 1 2 2 2 3 4 2 3 2 2 3 1 2 1 1 2 4 3 1 4 4 3 3 2 3 4 3 1 2 4 1 2 2 2 1 3 4 4\n[39] 3 2 4 4 2 4 1 2 2 1 4 4 2 1 4 4 2 4 2 1 4 4 3 3 3 4 1 1 1 3 2 3 2 3 2 3 4\nObjective function:\n    build      swap \n0.4422977 0.3187056 \n\nNumerical information per cluster:\n     size  max_diss   av_diss  diameter separation\n[1,]   15 0.4589783 0.2433250 0.8359025   1.157682\n[2,]   23 0.6558680 0.2993397 1.1591436   0.767612\n[3,]   17 0.9459253 0.3862345 1.4627043   0.767612\n[4,]   20 0.5755656 0.3401125 1.1192822   1.157682\n\nIsolated clusters:\n L-clusters: character(0)\n L*-clusters: [1] 1 4\n\nSilhouette plot information:\n   cluster neighbor sil_width\n31       1        4 0.8592059\n28       1        4 0.8553255\n45       1        4 0.8530741\n12       1        4 0.8449473\n66       1        4 0.8361633\n58       1        4 0.8187150\n52       1        4 0.8178795\n48       1        3 0.8087015\n14       1        4 0.8013799\n1        1        4 0.7983516\n65       1        4 0.7918724\n15       1        4 0.7768261\n19       1        4 0.7727269\n35       1        3 0.7425993\n67       1        4 0.7328306\n13       2        4 0.8368407\n2        2        4 0.8305019\n16       2        3 0.8222142\n4        2        4 0.8220686\n73       2        4 0.8158429\n7        2        3 0.8150398\n69       2        4 0.8134280\n40       2        4 0.8064757\n43       2        3 0.7984225\n55       2        4 0.7969057\n33       2        4 0.7841631\n24       2        3 0.7794889\n10       2        3 0.7605512\n32       2        4 0.7591035\n3        2        4 0.7473901\n34       2        3 0.7423529\n47       2        4 0.7402623\n51       2        4 0.7249133\n57       2        3 0.7007372\n46       2        4 0.6739284\n71       2        3 0.5661372\n29       2        3 0.5413082\n9        2        3 0.4673917\n61       3        2 0.7898609\n72       3        2 0.7834341\n23       3        2 0.7822308\n18       3        2 0.7790446\n11       3        2 0.7780891\n74       3        2 0.7694930\n70       3        2 0.7624335\n39       3        2 0.7609359\n68       3        2 0.7400337\n62       3        2 0.7392052\n25       3        2 0.7390493\n5        3        2 0.7234199\n27       3        2 0.5894345\n36       3        1 0.5666610\n22       3        2 0.5114355\n63       3        2 0.4358476\n8        3        2 0.3312348\n17       4        2 0.8094377\n44       4        1 0.8027447\n6        4        2 0.7782513\n54       4        1 0.7704646\n26       4        1 0.7700388\n20       4        2 0.7597906\n41       4        2 0.7530091\n75       4        2 0.7436695\n53       4        1 0.7412965\n37       4        2 0.7270442\n21       4        1 0.7255183\n49       4        1 0.7226938\n56       4        1 0.7042349\n59       4        2 0.7026960\n64       4        2 0.6966533\n60       4        1 0.6921822\n38       4        1 0.6756339\n30       4        1 0.6463656\n42       4        2 0.6005277\n50       4        1 0.6004543\nAverage silhouette width per cluster:\n[1] 0.8073733 0.7454551 0.6812849 0.7211353\nAverage silhouette width of total data set:\n[1] 0.7368082\n\n2775 dissimilarities, summarized :\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.03868 1.16780 1.92500 1.78630 2.47760 3.91720 \nMetric :  euclidean \nNumber of objects : 75\n\nAvailable components:\n [1] \"medoids\"    \"id.med\"     \"clustering\" \"objective\"  \"isolation\" \n [6] \"clusinfo\"   \"silinfo\"    \"diss\"       \"call\"       \"data\"      \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(kmed)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n:::\n\n\nOutra forma de visualização\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_cluster(kmed, ruspini_norm,\n             ellipse.type = \"convex\",\n             repel =TRUE,\n             ggtheme =theme_minimal())\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nknitr::kable(kmed$medoids)\n```\n\n::: {.cell-output-display}\n\n\n|          x|          y|\n|----------:|----------:|\n|  0.4629124| -1.4583746|\n| -0.3566917|  1.1698207|\n|  1.4464374|  0.5538374|\n| -1.1762959| -0.5549325|\n\n\n:::\n\n```{.r .cell-code}\nlibrary(janitor)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'janitor'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n```\n\n\n:::\n\n```{.r .cell-code}\ntabyl(kmed$clustering)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n kmed$clustering  n   percent\n               1 15 0.2000000\n               2 23 0.3066667\n               3 17 0.2266667\n               4 20 0.2666667\n```\n\n\n:::\n:::\n\n\n### Clusters Hierarquicos\n\nO agrupamento hierárquico começa com uma matriz de distância ´dist()´ e tem como padrão method=\"Euclidiano\". As matrizes de distância tornam-se muito grandes rapidamente (tamanho e complexidade de tempo é O(n2) onde n é o número se pontos de dados. Só é possível calcular e armazenar a matriz para pequenos conjuntos de dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- dist(ruspini_norm)\n```\n:::\n\n\nA função hclust() implementa o HCA, ou seja, o cluster hierarquico aglomerativo. Vamos começar usando o método completo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhc <- hclust(d, method = \"complete\")\n```\n:::\n\n\nO HCA retorna um dendrograma e não uma definiçaõ de clusters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hc)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nSe usarmos a biblioteca factoextra podemos definir o número de clusters que queremos visualizar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_dend(hc, k=4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at <https://github.com/kassambara/factoextra/issues>.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nPodemos extrair as atraibuições de cluster cortando o dendrograma em 4 partes e adicionando a identidade aos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclusters <- cutree(hc, k = 4)\ncluster_completo <- ruspini_norm %>%\n  add_column(cluster = factor(clusters))\ncluster_completo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 75 × 3\n         x       y cluster\n     <dbl>   <dbl> <fct>  \n 1  0.496  -1.81   1      \n 2 -0.455   1.19   2      \n 3 -0.750   1.17   2      \n 4 -0.357   1.05   2      \n 5  2.04    0.472  3      \n 6 -1.37   -0.473  4      \n 7 -0.357   1.31   2      \n 8  0.627   0.0816 3      \n 9  0.266   0.964  2      \n10 -0.0944  1.23   2      \n# ℹ 65 more rows\n```\n\n\n:::\n:::\n\n\nPodemos usar o método de Ward para obter o cluster.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhc_w <- hclust(d, method = \"ward.D\")\n```\n:::\n\n\nO HCA retorna um dendrograma e não uma definiçaõ de clusters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hc_w)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nSe usarmos a biblioteca factoextra podemos definir o número de clusters que queremos visualizar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_dend(hc_w, k=4)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_cluster(list(data = ruspini_norm, cluster = cutree(hc_w, k = 4)), geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Validação dos Clusters\n\n### Silhouette\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library(cluster)\nplot(silhouette(kmed$clustering,d))\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_silhouette(silhouette(kmed$clustering, d))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  cluster size ave.sil.width\n1       1   15          0.81\n2       2   23          0.75\n3       3   17          0.68\n4       4   20          0.72\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Numero ótimo de clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Usando o silhouette\nfviz_nbclust(ruspini_norm, pam, method =\"silhouette\", k.max = 8)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Metodo do cotovelo\nfviz_nbclust(ruspini_norm, kmeans, method =\"wss\", k.max = 8)\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n:::\n\n\n## \n",
    "supporting": [
      "Aula13_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}