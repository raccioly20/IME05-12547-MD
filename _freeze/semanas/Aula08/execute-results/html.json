{
  "hash": "6fcaed557353c141f1d36e50ded6ec3e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"KNN\"\nauthor: \"Ricardo Accioly\"\ndate: \"2025-10-28\"\nformat:\n html:\n    code-link: true\n    fig-width: 9\n    fig-height: 7\n    fig-dpi: 300\nknitr:\n  opts_chunk: \n    out.width: 90%\n    comment: \"#>\"\nexecute: \n  echo: true\n  warning: false\n  message: false\n  freeze: auto\n---\n\n## KNN\n\n**O KNN é um algoritmo muito simples no qual cada observação é prevista com base em sua \"semelhança\" com outras observações. Ao contrário da maioria dos métodos, KNN é um algoritmo baseado na memória e não pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento são necessárias no tempo de execução e as previsões são feitas diretamente das relações amostrais. Consequentemente, os KNNs também são conhecidos como aprendizes preguiçosos**\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(patchwork)\nlibrary(pROC)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 'data.frame':\t10000 obs. of  4 variables:\n#>  $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n#>  $ balance: num  730 817 1074 529 786 ...\n#>  $ income : num  44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   default student   balance    income\n#> 1      No      No  729.5265 44361.625\n#> 2      No     Yes  817.1804 12106.135\n#> 3      No      No 1073.5492 31767.139\n#> 4      No      No  529.2506 35704.494\n#> 5      No      No  785.6559 38463.496\n#> 6      No     Yes  919.5885  7491.559\n```\n\n\n:::\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncredito <- tibble(Default)\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n\n```{.r .cell-code}\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#>  $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n#>  $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n#>  $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco          receita     \n#>  Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n#>  Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n#>               Median :0.0000   Median : 823.6   Median :34553  \n#>               Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n#>               3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n#>               Max.   :1.0000   Max.   :2654.3   Max.   :73554\n```\n\n\n:::\n:::\n\n\n## Graficos de Densidade\n\nVamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeaturePlot(x = credito[, c(\"balanco\", \"receita\", \"estudante\")], \n            y = credito$inadimplente,\n            plot = \"density\", \n            scales = list(x = list(relation = \"free\"), \n                          y = list(relation = \"free\")), \n            adjust = 1.5, \n            pch = \"|\", \n            layout = c(2, 1), \n            auto.key = list(columns = 2))\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/unnamed-chunk-1-1.png){width=90%}\n:::\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/unnamed-chunk-1-2.png){width=90%}\n:::\n:::\n\n\n## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(credito, aes(x=inadimplente, y=balanco, color=inadimplente)) +\n  geom_boxplot()\np2 <- ggplot(credito, aes(x=inadimplente, y=receita, color=inadimplente)) +\n  geom_boxplot()\np3 <- ggplot(credito, aes(x=as.factor(estudante), y=balanco, color=as.factor(estudante))) +\n  geom_boxplot()\np4 <- ggplot(credito, aes(x=as.factor(estudante), y=receita, color=as.factor(estudante))) +\n  geom_boxplot()\n(p1 + p2) / (p3 + p4)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/box-plot-1.png){width=90%}\n:::\n:::\n\n\n## Balanço vs Receita\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point() \n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/dispersao-1.png){width=90%}\n:::\n:::\n\n\n## KNN\n\nVamos usar a função knn da biblioteca caret que tem ótimas funcionalidades. Observem que a saída pode ser as classes ou as probabilidades de pertencer a uma classe\n\n**Como o KNN usa as distancias entre os pontos ele é afetado pela escala dos dados, portanto, é necessário que os dados sejam normalizados (padronizados) para eliminar este efeito.**\n\nQuando temos diversas variáveis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrão 1\n\n## Criando conjuntos de treino e teste e normalizando variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2025)\ny <- credito$inadimplente\ncredito_split <- createDataPartition(y, times = 1, p = 0.10, list = FALSE)\n\nconj_treino <- credito[-credito_split,]\nconj_treino[,3:4] <- scale(conj_treino[,3:4]) # scale normaliza\nconj_teste <- credito[credito_split,]\nconj_teste[,3:4] <- scale(conj_teste[, 3:4])\n                           \nsummary(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco            receita       \n#>  Nao:8700     Min.   :0.0000   Min.   :-1.73003   Min.   :-2.4534  \n#>  Sim: 299     1st Qu.:0.0000   1st Qu.:-0.72954   1st Qu.:-0.9140  \n#>               Median :0.0000   Median :-0.03104   Median : 0.0764  \n#>               Mean   :0.2946   Mean   : 0.00000   Mean   : 0.0000  \n#>               3rd Qu.:1.0000   3rd Qu.: 0.68437   3rd Qu.: 0.7707  \n#>               Max.   :1.0000   Max.   : 3.76117   Max.   : 2.9933\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  inadimplente   estudante         balanco            receita        \n#>  Nao:967      Min.   :0.0000   Min.   :-1.69940   Min.   :-2.12069  \n#>  Sim: 34      1st Qu.:0.0000   1st Qu.:-0.76771   1st Qu.:-0.90454  \n#>               Median :0.0000   Median : 0.02552   Median : 0.06997  \n#>               Mean   :0.2927   Mean   : 0.00000   Mean   : 0.00000  \n#>               3rd Qu.:1.0000   3rd Qu.: 0.67537   3rd Qu.: 0.73936  \n#>               Max.   :1.0000   Max.   : 2.86197   Max.   : 2.86471\n```\n\n\n:::\n:::\n\n\n## 1a Modelo\n\nVamos usar a regra da raiz quadrada do tamanho da amostra para definir o número de vizinhos do KNN.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- round(sqrt(nrow(conj_treino)),0) # número de vizinhos\nk\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 95\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(2025)\nt_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = k)\nt_knn1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 95-nearest neighbor model\n#> Training set outcome distribution:\n#> \n#>  Nao  Sim \n#> 8700  299\n```\n\n\n:::\n:::\n\n\n## Avaliando o modelo\n\n**Através da função matriz de confusão do pacote caret conseguimos obter as principais medidas de avaliação de um modelo de classificação.**\n\n**Veja que a acurácia deu um valor alto, mas isto não é suficiente para considerarmos que temos um bom modelo. Veja que a sensibilidade está muito baixa e que o ideal é que tenhamos valores altos de sensibilidade e especificidade.**\n\n**Observar que a prevalência é muito baixa o que está afetando os resultados do modelo.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"class\")\n\n\nconfusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction Nao Sim\n#>        Nao 964  28\n#>        Sim   3   6\n#>                                           \n#>                Accuracy : 0.969           \n#>                  95% CI : (0.9563, 0.9789)\n#>     No Information Rate : 0.966           \n#>     P-Value [Acc > NIR] : 0.3395          \n#>                                           \n#>                   Kappa : 0.2687          \n#>                                           \n#>  Mcnemar's Test P-Value : 1.629e-05       \n#>                                           \n#>             Sensitivity : 0.176471        \n#>             Specificity : 0.996898        \n#>          Pos Pred Value : 0.666667        \n#>          Neg Pred Value : 0.971774        \n#>              Prevalence : 0.033966        \n#>          Detection Rate : 0.005994        \n#>    Detection Prevalence : 0.008991        \n#>       Balanced Accuracy : 0.586684        \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Curva ROC\n\nPara a curva ROC é necessário que obtenhamos as probabilidades e não das classes, vejam nos comandos abaixo como se obtem as probabilidades.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \np_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nhead(p_chapeu_knn1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            Nao        Sim\n#> [1,] 0.9894737 0.01052632\n#> [2,] 1.0000000 0.00000000\n#> [3,] 1.0000000 0.00000000\n#> [4,] 1.0000000 0.00000000\n#> [5,] 0.9894737 0.01052632\n#> [6,] 1.0000000 0.00000000\n```\n\n\n:::\n\n```{.r .cell-code}\n# Aqui gera o curva e salvo numa variável\nroc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = FALSE, print.auc=FALSE)\n\n# Visualização com ggroc\nggroc(roc_knn1) +\n  ggplot2::labs(title = \"ROC - KNN\", x = \"1 - Especificidade\", y = \"Sensibilidade\") +\n  ggplot2::theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/ROC-1.png){width=90%}\n:::\n:::\n\n\n## Area embaixo da curva ROC\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Area abaixo da Curva (AUC)\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9191405\n```\n\n\n:::\n:::\n\n\n## Variando K\n\nAnteriormente usamos **k=95** . Este parametro, em geral, deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a função train da biblioteca caret\n\nObserve que a otimização de k, no exemplo abaixo, é feita através de acurácia. O k também pode ser otimizado usando o valor do AUC (área embaixo da curva ROC).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2025)\n\n# Usando validação cruzada para obter o valor de k através da função train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.\nctrl <- trainControl(method = \"repeatedcv\", \n                     number = 5,\n                     repeats = 5)\nt_knn2 <- train(inadimplente ~ balanco + receita + estudante,\n                method = \"knn\", \n                trControl= ctrl,\n                tuneGrid = data.frame(k = seq(5,150, by=5)),\n                metric = \"Accuracy\",\n                data = conj_treino)\n## Resultados do treino\nt_knn2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> k-Nearest Neighbors \n#> \n#> 8999 samples\n#>    3 predictor\n#>    2 classes: 'Nao', 'Sim' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold, repeated 5 times) \n#> Summary of sample sizes: 7199, 7199, 7199, 7199, 7200, 7199, ... \n#> Resampling results across tuning parameters:\n#> \n#>   k    Accuracy   Kappa     \n#>     5  0.9704413  0.42266071\n#>    10  0.9716414  0.41185688\n#>    15  0.9723526  0.41049306\n#>    20  0.9730415  0.41527673\n#>    25  0.9729749  0.39961432\n#>    30  0.9729305  0.39434063\n#>    35  0.9725527  0.37664935\n#>    40  0.9724415  0.36463583\n#>    45  0.9723749  0.35587285\n#>    50  0.9722193  0.34677085\n#>    55  0.9722415  0.34231099\n#>    60  0.9719303  0.32682892\n#>    65  0.9717303  0.31692192\n#>    70  0.9715748  0.30754847\n#>    75  0.9709079  0.27742350\n#>    80  0.9706412  0.25982263\n#>    85  0.9703523  0.24349134\n#>    90  0.9702412  0.23166492\n#>    95  0.9697301  0.20218244\n#>   100  0.9690410  0.16434426\n#>   105  0.9686633  0.13872824\n#>   110  0.9683299  0.11503994\n#>   115  0.9678409  0.07816959\n#>   120  0.9676187  0.05780951\n#>   125  0.9673964  0.04083628\n#>   130  0.9672408  0.02760184\n#>   135  0.9671297  0.02148245\n#>   140  0.9670853  0.01773521\n#>   145  0.9669741  0.01144419\n#>   150  0.9669741  0.01144419\n#> \n#> Accuracy was used to select the optimal model using the largest value.\n#> The final value used for the model was k = 20.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(t_knn2)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/K1-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n## Previsões com o resultaddos do treino\nprev_knn2 <- predict(t_knn2, conj_teste)\nconfusionMatrix(prev_knn2, conj_teste$inadimplente,  positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction Nao Sim\n#>        Nao 961  23\n#>        Sim   6  11\n#>                                           \n#>                Accuracy : 0.971           \n#>                  95% CI : (0.9587, 0.9805)\n#>     No Information Rate : 0.966           \n#>     P-Value [Acc > NIR] : 0.219168        \n#>                                           \n#>                   Kappa : 0.4182          \n#>                                           \n#>  Mcnemar's Test P-Value : 0.002967        \n#>                                           \n#>             Sensitivity : 0.32353         \n#>             Specificity : 0.99380         \n#>          Pos Pred Value : 0.64706         \n#>          Neg Pred Value : 0.97663         \n#>              Prevalence : 0.03397         \n#>          Detection Rate : 0.01099         \n#>    Detection Prevalence : 0.01698         \n#>       Balanced Accuracy : 0.65866         \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n\n\n:::\n:::\n\n\n## Curva ROC dos 2 melhores modelos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprev_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nprev_knn2 <- predict(t_knn2, conj_teste, type = \"prob\")\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = FALSE, print.auc=FALSE)\nroc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = FALSE, print.auc=FALSE)\n\n# Visualização com ggroc\nggroc(list(knn1= roc_knn1, knn2= roc_knn2)) +\n  ggplot2::labs(title = \"ROC - KNN\", x = \"1 - Especificidade\", y = \"Sensibilidade\") +\n  ggplot2::theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/ROC2-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n## Area embaixo das curvas\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9191405\n```\n\n\n:::\n\n```{.r .cell-code}\nas.numeric(roc_knn2$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9041304\n```\n\n\n:::\n:::\n\n\nObserve que os resultados de área abaixo da ROC não são suficientes para a escolha do k, pois precisamos estar atentos ao valores de sensibilidade e especificidade! A depender da importância de cada um destes valores para o problema em questão, podemos escolher um k que nos dê um bom equilíbrio entre estes dois valores.\n\n## Reprodutibilidade\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> R version 4.5.1 (2025-06-13 ucrt)\n#> Platform: x86_64-w64-mingw32/x64\n#> Running under: Windows 11 x64 (build 26200)\n#> \n#> Matrix products: default\n#>   LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] LC_COLLATE=Portuguese_Brazil.utf8  LC_CTYPE=Portuguese_Brazil.utf8   \n#> [3] LC_MONETARY=Portuguese_Brazil.utf8 LC_NUMERIC=C                      \n#> [5] LC_TIME=Portuguese_Brazil.utf8    \n#> \n#> time zone: America/Sao_Paulo\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] ISLR_1.4        pROC_1.19.0.1   patchwork_1.3.1 caret_7.0-1    \n#>  [5] lattice_0.22-7  lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n#>  [9] dplyr_1.1.4     purrr_1.1.0     readr_2.1.5     tidyr_1.3.1    \n#> [13] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gtable_0.3.6         xfun_0.52            htmlwidgets_1.6.4   \n#>  [4] recipes_1.3.1        tzdb_0.5.0           vctrs_0.6.5         \n#>  [7] tools_4.5.1          generics_0.1.4       stats4_4.5.1        \n#> [10] parallel_4.5.1       proxy_0.4-27         ModelMetrics_1.2.2.2\n#> [13] pkgconfig_2.0.3      Matrix_1.7-3         data.table_1.17.8   \n#> [16] RColorBrewer_1.1-3   lifecycle_1.0.4      compiler_4.5.1      \n#> [19] farver_2.1.2         codetools_0.2-20     htmltools_0.5.8.1   \n#> [22] class_7.3-23         yaml_2.3.10          prodlim_2025.04.28  \n#> [25] pillar_1.11.0        MASS_7.3-65          gower_1.0.2         \n#> [28] iterators_1.0.14     rpart_4.1.24         foreach_1.5.2       \n#> [31] nlme_3.1-168         parallelly_1.45.1    lava_1.8.1          \n#> [34] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.7       \n#> [37] future_1.67.0        reshape2_1.4.4       listenv_0.9.1       \n#> [40] labeling_0.4.3       splines_4.5.1        fastmap_1.2.0       \n#> [43] grid_4.5.1           cli_3.6.5            magrittr_2.0.3      \n#> [46] dichromat_2.0-0.1    survival_3.8-3       e1071_1.7-16        \n#> [49] future.apply_1.20.0  withr_3.0.2          scales_1.4.0        \n#> [52] timechange_0.3.0     rmarkdown_2.29       globals_0.18.0      \n#> [55] nnet_7.3-20          timeDate_4041.110    hms_1.1.3           \n#> [58] evaluate_1.0.4       knitr_1.50           hardhat_1.4.1       \n#> [61] rlang_1.1.6          Rcpp_1.1.0           glue_1.8.0          \n#> [64] ipred_0.9-15         rstudioapi_0.17.1    jsonlite_2.0.0      \n#> [67] R6_2.6.1             plyr_1.8.9\n```\n\n\n:::\n:::\n\n",
    "supporting": [
      "Aula08_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}