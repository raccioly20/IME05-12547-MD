{
  "hash": "9740a8a4f8f4e941d23590cac94eb6cd",
  "result": {
    "markdown": "---\ntitle: \"KNN\"\nauthor: \"Ricardo Accioly\"\ndate: \"2023-09-29\"\nformat:\n html:\n    code-link: true\n    fig-width: 9\n    fig-height: 7\n    fig-dpi: 300\nknitr:\n  opts_chunk: \n    out.width: 90%\n    comment: \"#>\"\n---\n\n\n## KNN\n\n**O KNN é um algoritmo muito simples no qual cada observação é prevista com base em sua \"semelhança\" com outras observações. Ao contrário da maioria dos métodos, KNN é um algoritmo baseado na memória e não pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento são necessárias no tempo de execução e as previsões são feitas diretamente das relações amostrais. Consequentemente, os KNNs também são conhecidos como aprendizes preguiçosos**\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n:::\n\n```{.r .cell-code}\nstr(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'data.frame':\t10000 obs. of  4 variables:\n#>  $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n#>  $ balance: num  730 817 1074 529 786 ...\n#>  $ income : num  44362 12106 31767 35704 38463 ...\n```\n:::\n\n```{.r .cell-code}\nhead(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>   default student   balance    income\n#> 1      No      No  729.5265 44361.625\n#> 2      No     Yes  817.1804 12106.135\n#> 3      No      No 1073.5492 31767.139\n#> 4      No      No  529.2506 35704.494\n#> 5      No      No  785.6559 38463.496\n#> 6      No     Yes  919.5885  7491.559\n```\n:::\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncredito <- tibble(Default)\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  default    student       balance           income     \n#>  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#>  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#>                        Median : 823.6   Median :34553  \n#>                        Mean   : 835.4   Mean   :33517  \n#>                        3rd Qu.:1166.3   3rd Qu.:43808  \n#>                        Max.   :2654.3   Max.   :73554\n```\n:::\n\n```{.r .cell-code}\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#>  $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n#>  $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n#>  $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n```\n:::\n\n```{.r .cell-code}\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  inadimplente   estudante         balanco          receita     \n#>  Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n#>  Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n#>               Median :0.0000   Median : 823.6   Median :34553  \n#>               Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n#>               3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n#>               Max.   :1.0000   Max.   :2654.3   Max.   :73554\n```\n:::\n:::\n\n\n## Normalização\n\nAntes de iniciarmos é fundamental fazermos a normalização (padronização) dos dados para que o KNN tenha um melhor desempenho.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncredito_n <- credito\ncredito_n[,3:4] <- scale(credito_n[,3:4])\n```\n:::\n\n\n## Treino e Teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nset.seed(21)\ny <- credito_n$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito_n[-indice_teste, ]\nconj_teste <- credito_n[indice_teste, ]\n\nsummary(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  inadimplente   estudante         balanco             receita         \n#>  Nao:7733     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.455267  \n#>  Sim: 266     1st Qu.:0.0000   1st Qu.:-0.732026   1st Qu.:-0.913102  \n#>               Median :0.0000   Median :-0.033621   Median : 0.076805  \n#>               Mean   :0.2953   Mean   :-0.005588   Mean   : 0.001763  \n#>               3rd Qu.:1.0000   3rd Qu.: 0.685798   3rd Qu.: 0.774041  \n#>               Max.   :1.0000   Max.   : 3.760371   Max.   : 3.002050\n```\n:::\n\n```{.r .cell-code}\nsummary(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  inadimplente   estudante         balanco             receita         \n#>  Nao:1934     Min.   :0.0000   Min.   :-1.726998   Min.   :-2.156595  \n#>  Sim:  67     1st Qu.:0.0000   1st Qu.:-0.727536   1st Qu.:-0.910738  \n#>               Median :0.0000   Median : 0.002479   Median : 0.080508  \n#>               Mean   :0.2909   Mean   : 0.022340   Mean   :-0.007049  \n#>               3rd Qu.:1.0000   3rd Qu.: 0.677484   3rd Qu.: 0.759484  \n#>               Max.   :1.0000   Max.   : 3.361757   Max.   : 2.828416\n```\n:::\n:::\n\n\n## Matriz de dispersão\n\nVamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\npairs.panels(credito, \n             method = \"pearson\", # metodo de correlação\n             hist.col = \"#00AFBB\",\n             density = TRUE,  # mostra graficos de densidade\n             ellipses = FALSE # mostra elipses de correlação\n             )\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/splom-1.png){width=90%}\n:::\n:::\n\n\n## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(credito, aes(x=inadimplente, y=balanco)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/box-plot-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nggplot(credito, aes(x=inadimplente, y=receita)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/box-plot-2.png){width=90%}\n:::\n\n```{.r .cell-code}\nggplot(credito, aes(x=as.factor(estudante), y=balanco)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/box-plot-3.png){width=90%}\n:::\n\n```{.r .cell-code}\nggplot(credito, aes(x=as.factor(estudante), y=receita)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/box-plot-4.png){width=90%}\n:::\n:::\n\n\n## Explorando um pouco mais Balanço e Receita\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(credito, aes(x=balanco)) +\n  geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/histogramas-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nggplot(credito, aes(x=receita)) +\n    geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/histogramas-2.png){width=90%}\n:::\n:::\n\n\n## Balanço vs Receita\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point() \n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/dispersao-1.png){width=90%}\n:::\n:::\n\n\n## KNN\n\n**Vamos usar a função knn da biblioteca caret que tem ótimas funcionalidades. Observem que a saída pode ser as classes ou as probabilidades de pertencer a uma classe**\n\n**Como o KNN usa as distancias entre os pontos ele é afetado pela escala dos dados, portanto, é necessário que os dados sejam normalizados (padronizados) para eliminar este efeito.**\n\n**Quando temos diversas variáveis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrão 1**\n\n## 1a Modelo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Vamos usar a regra da raiz quadrada do tamnho da amostra\nsqrt(nrow(conj_treino)) ## ~90\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 89.43713\n```\n:::\n\n```{.r .cell-code}\nset.seed(21)\nt_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)\nt_knn1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 90-nearest neighbor model\n#> Training set outcome distribution:\n#> \n#>  Nao  Sim \n#> 7733  266\n```\n:::\n:::\n\n\n## Avaliando o modelo\n\n**A acurácia deu um valor alto, mas isto não é suficiente para considerarmos que temos um bom modelo. Veja que a sensibilidade está muito baixa e que o ideal é que tenhamos valores altos de sensibilidade e especificidade.**\n\n**Observar que a prevalência é muito baixa o que está afetando os resultados do modelo**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## \ny_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"class\")\n\n# Matriz de confusão para valiar os resultados\nconfusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1930   51\n#>        Sim    4   16\n#>                                           \n#>                Accuracy : 0.9725          \n#>                  95% CI : (0.9644, 0.9792)\n#>     No Information Rate : 0.9665          \n#>     P-Value [Acc > NIR] : 0.07329         \n#>                                           \n#>                   Kappa : 0.3579          \n#>                                           \n#>  Mcnemar's Test P-Value : 5.552e-10       \n#>                                           \n#>             Sensitivity : 0.238806        \n#>             Specificity : 0.997932        \n#>          Pos Pred Value : 0.800000        \n#>          Neg Pred Value : 0.974255        \n#>              Prevalence : 0.033483        \n#>          Detection Rate : 0.007996        \n#>    Detection Prevalence : 0.009995        \n#>       Balanced Accuracy : 0.618369        \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n:::\n:::\n\n\n## Curva ROC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\n\n# Para a curva ROC preciso das probabilidades e não das classes\np_chapeu_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nhead(p_chapeu_knn1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>            Nao        Sim\n#> [1,] 0.9777778 0.02222222\n#> [2,] 1.0000000 0.00000000\n#> [3,] 1.0000000 0.00000000\n#> [4,] 0.9888889 0.01111111\n#> [5,] 1.0000000 0.00000000\n#> [6,] 1.0000000 0.00000000\n```\n:::\n\n```{.r .cell-code}\n# Aqui gera o curva e salvo numa variável\nroc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n\nlegend(\"bottomright\",legend=c(\"KNN1\"), \n       col=c(\"black\"),lwd=4)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/ROC-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n# Area abaixo da Curva (AUC)\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.9276227\n```\n:::\n:::\n\n\n## Variando K\n\n**Anteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a função train da biblioteca caret**\n\n**Observe que a otimização de k é feita através de acurácia**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(21)\n\n# Usando validação cruzada para obter o valor de k através da função train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.\nctrl <- trainControl(method = \"cv\")\nt_knn2 <- train(inadimplente ~ balanco + receita + estudante,\n                method = \"knn\", trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                data = conj_treino)\n## Resultados do treino\nt_knn2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> k-Nearest Neighbors \n#> \n#> 7999 samples\n#>    3 predictor\n#>    2 classes: 'Nao', 'Sim' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \n#> Resampling results across tuning parameters:\n#> \n#>   k    Accuracy   Kappa     \n#>    10  0.9699953  0.37022050\n#>    20  0.9717451  0.37122371\n#>    30  0.9714948  0.34761685\n#>    40  0.9713698  0.32858918\n#>    50  0.9712448  0.30506559\n#>    60  0.9711200  0.29038841\n#>    70  0.9711204  0.28281374\n#>    80  0.9698700  0.22792293\n#>    90  0.9696197  0.20538564\n#>   100  0.9689948  0.15840977\n#>   110  0.9677454  0.09462220\n#>   120  0.9669959  0.03351642\n#>   130  0.9669961  0.01339042\n#>   140  0.9669961  0.01339042\n#>   150  0.9667464  0.00000000\n#>   160  0.9667464  0.00000000\n#>   170  0.9667464  0.00000000\n#>   180  0.9667464  0.00000000\n#>   190  0.9667464  0.00000000\n#>   200  0.9667464  0.00000000\n#> \n#> Accuracy was used to select the optimal model using the largest value.\n#> The final value used for the model was k = 20.\n```\n:::\n\n```{.r .cell-code}\nplot(t_knn2)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/K1-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n## Previsões com o resultaddos do treino\nprev_knn2 <- predict(t_knn2, conj_teste)\nconfusionMatrix(prev_knn2, conj_teste$inadimplente,  positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1926   40\n#>        Sim    8   27\n#>                                           \n#>                Accuracy : 0.976           \n#>                  95% CI : (0.9683, 0.9823)\n#>     No Information Rate : 0.9665          \n#>     P-Value [Acc > NIR] : 0.008318        \n#>                                           \n#>                   Kappa : 0.5183          \n#>                                           \n#>  Mcnemar's Test P-Value : 7.66e-06        \n#>                                           \n#>             Sensitivity : 0.40299         \n#>             Specificity : 0.99586         \n#>          Pos Pred Value : 0.77143         \n#>          Neg Pred Value : 0.97965         \n#>              Prevalence : 0.03348         \n#>          Detection Rate : 0.01349         \n#>    Detection Prevalence : 0.01749         \n#>       Balanced Accuracy : 0.69942         \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n:::\n:::\n\n\n## Variando K de outra forma\n\n**Vamos adicionar mais opções no trainControl**\n\n**Ao colocar classProb = TRUE e summaryFunction ao invés da acurácia a otimização passa a ser através o ROC**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(21)\n# ctrl <- trainControl(method = \"cv\", classProbs=TRUE, summaryFunction = twoClassSummary)\nctrl <- trainControl(method = \"repeatedcv\", \n                     number = 10,\n                     repeats = 5, \n                     classProbs = TRUE,\n                     summaryFunction = twoClassSummary)\n\nt_knn3 <- train(inadimplente ~ balanco + receita + estudante, \n                method = \"knn\", \n                trControl= ctrl, \n                tuneGrid = data.frame(k = seq(10,200, by=10)),\n                metric = \"ROC\",\n                data = conj_treino)\nt_knn3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> k-Nearest Neighbors \n#> \n#> 7999 samples\n#>    3 predictor\n#>    2 classes: 'Nao', 'Sim' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold, repeated 5 times) \n#> Summary of sample sizes: 7200, 7200, 7199, 7198, 7199, 7200, ... \n#> Resampling results across tuning parameters:\n#> \n#>   k    ROC        Sens       Spec       \n#>    10  0.8532549  0.9936118  0.299230769\n#>    20  0.8962842  0.9957323  0.275897436\n#>    30  0.9129487  0.9965599  0.252507123\n#>    40  0.9223242  0.9972324  0.229401709\n#>    50  0.9260029  0.9976204  0.204558405\n#>    60  0.9275003  0.9978014  0.196239316\n#>    70  0.9283630  0.9979566  0.185014245\n#>    80  0.9324715  0.9981118  0.150284900\n#>    90  0.9335728  0.9986809  0.124643875\n#>   100  0.9390171  0.9991464  0.091566952\n#>   110  0.9401918  0.9994827  0.048062678\n#>   120  0.9405837  0.9998707  0.019515670\n#>   130  0.9416564  1.0000000  0.007492877\n#>   140  0.9429103  1.0000000  0.003703704\n#>   150  0.9434492  1.0000000  0.000000000\n#>   160  0.9432553  1.0000000  0.000000000\n#>   170  0.9444527  1.0000000  0.000000000\n#>   180  0.9452018  1.0000000  0.000000000\n#>   190  0.9450158  1.0000000  0.000000000\n#>   200  0.9447751  1.0000000  0.000000000\n#> \n#> ROC was used to select the optimal model using the largest value.\n#> The final value used for the model was k = 180.\n```\n:::\n\n```{.r .cell-code}\nplot(t_knn3)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/K2-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nprev_knn3 <- predict(t_knn3, conj_teste)\nconfusionMatrix(prev_knn3, conj_teste$inadimplente,  positive=\"Sim\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  Nao  Sim\n#>        Nao 1934   66\n#>        Sim    0    1\n#>                                           \n#>                Accuracy : 0.967           \n#>                  95% CI : (0.9582, 0.9744)\n#>     No Information Rate : 0.9665          \n#>     P-Value [Acc > NIR] : 0.4829          \n#>                                           \n#>                   Kappa : 0.0285          \n#>                                           \n#>  Mcnemar's Test P-Value : 1.235e-15       \n#>                                           \n#>             Sensitivity : 0.0149254       \n#>             Specificity : 1.0000000       \n#>          Pos Pred Value : 1.0000000       \n#>          Neg Pred Value : 0.9670000       \n#>              Prevalence : 0.0334833       \n#>          Detection Rate : 0.0004998       \n#>    Detection Prevalence : 0.0004998       \n#>       Balanced Accuracy : 0.5074627       \n#>                                           \n#>        'Positive' Class : Sim             \n#> \n```\n:::\n:::\n\n\n**Veja que ao otimizar pela ROC o modelo escolhido tem sensibilidade zero! Isto obviamente não é um bom modelo! Neste caso a opção de otimização do parametro pela acurácia dá melhores resultados.**\n\n\n## Curva ROC dos 2 melhores modelos k=90 e k=20\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprev_knn1 <- predict(t_knn1, conj_teste, type = \"prob\")\nprev_knn2 <- predict(t_knn2, conj_teste, type = \"prob\")\nroc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Setting levels: control = Nao, case = Sim\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Setting direction: controls < cases\n```\n:::\n\n```{.r .cell-code}\nroc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col=\"green\", legacy.axes=TRUE, add=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Setting levels: control = Nao, case = Sim\n#> Setting direction: controls < cases\n```\n:::\n\n```{.r .cell-code}\nlegend(\"bottomright\",legend=c(\"KNN1\", \"KNN2\"), \n       col=c(\"black\",\"green\"),lwd=4)\n```\n\n::: {.cell-output-display}\n![](Aula08_files/figure-html/ROC2-1.png){width=90%}\n:::\n\n```{.r .cell-code}\n## Area embaixo das curvas\nas.numeric(roc_knn1$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.9276227\n```\n:::\n\n```{.r .cell-code}\nas.numeric(roc_knn2$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.9032436\n```\n:::\n:::\n\n\n**Observe que os resultados de área abaixo da ROC não são suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!**\n\n**Os resultados encontrados apontam k=20 como a melhor opção**\n",
    "supporting": [
      "Aula08_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}