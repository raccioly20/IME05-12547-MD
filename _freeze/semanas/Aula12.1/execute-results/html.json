{
  "hash": "90bf8fb1ecc1838548626af2a93060b4",
  "result": {
    "markdown": "---\ntitle: \"Arvores de Classificação - Única e GBM\"\nauthor: \"Ricardo Accioly\"\ndate: \"2023-05-23\"\nformat:\n html:\n    code-link: true\n---\n\n\n\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ISLR)\ndata(Default)\nsummary(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n```\n:::\n\n```{.r .cell-code}\nstr(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t10000 obs. of  4 variables:\n $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n $ balance: num  730 817 1074 529 786 ...\n $ income : num  44362 12106 31767 35704 38463 ...\n```\n:::\n\n```{.r .cell-code}\nhead(Default)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559\n```\n:::\n:::\n\n\n## Manipulando os dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncredito <- tibble(Default)\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n default    student       balance           income     \n No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n                       Median : 823.6   Median :34553  \n                       Mean   : 835.4   Mean   :33517  \n                       3rd Qu.:1166.3   3rd Qu.:43808  \n                       Max.   :2654.3   Max.   :73554  \n```\n:::\n\n```{.r .cell-code}\n# renomeando colunas\ncredito <- credito %>% \n                rename( inadimplente = default, estudante = student, balanco = balance,\n                receita = income)\ncredito <- credito %>% mutate( inadimplente =  case_when(\n                           inadimplente == \"No\"  ~ \"Nao\",\n                           inadimplente == \"Yes\" ~ \"Sim\"\n                          )) %>% mutate(inadimplente = factor(inadimplente))\ncredito <- credito %>% mutate( estudante =  case_when(\n                           estudante == \"No\"  ~ 0,\n                           estudante == \"Yes\" ~ 1\n                          )) \n\nstr(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:10000] 0 1 0 0 0 1 0 1 0 0 ...\n $ balanco     : num [1:10000] 730 817 1074 529 786 ...\n $ receita     : num [1:10000] 44362 12106 31767 35704 38463 ...\n```\n:::\n\n```{.r .cell-code}\nsummary(credito)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n inadimplente   estudante         balanco          receita     \n Nao:9667     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 333     1st Qu.:0.0000   1st Qu.: 481.7   1st Qu.:21340  \n              Median :0.0000   Median : 823.6   Median :34553  \n              Mean   :0.2944   Mean   : 835.4   Mean   :33517  \n              3rd Qu.:1.0000   3rd Qu.:1166.3   3rd Qu.:43808  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n```\n:::\n:::\n\n\n## Treino e Teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nset.seed(21)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Slicing with a 1-column matrix was deprecated in dplyr 1.1.0.\n```\n:::\n\n```{.r .cell-code}\nconj_teste <- credito %>% slice(indice_teste)\n\nsummary(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n inadimplente   estudante         balanco          receita     \n Nao:7733     Min.   :0.0000   Min.   :   0.0   Min.   :  772  \n Sim: 266     1st Qu.:0.0000   1st Qu.: 481.3   1st Qu.:21339  \n              Median :0.0000   Median : 819.1   Median :34541  \n              Mean   :0.2953   Mean   : 832.7   Mean   :33541  \n              3rd Qu.:1.0000   3rd Qu.:1167.1   3rd Qu.:43840  \n              Max.   :1.0000   Max.   :2654.3   Max.   :73554  \n```\n:::\n\n```{.r .cell-code}\nsummary(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n inadimplente   estudante         balanco          receita     \n Nao:1934     Min.   :0.0000   Min.   :   0.0   Min.   : 4755  \n Sim:  67     1st Qu.:0.0000   1st Qu.: 483.5   1st Qu.:21371  \n              Median :0.0000   Median : 836.6   Median :34591  \n              Mean   :0.2909   Mean   : 846.2   Mean   :33423  \n              3rd Qu.:1.0000   3rd Qu.:1163.1   3rd Qu.:43646  \n              Max.   :1.0000   Max.   :2461.5   Max.   :71239  \n```\n:::\n:::\n\n\n## Arvore de Classificação\n\nNa biblioteca rpart as arvores de classificação são obtidas usando o método class. Existem alguns controles que podem ser feitos nos parametros da arvore.\n\nNeste exemplo só definimos o menor conjunto de dados numa partição (minsplit) e o parametro de complexidade cp. Posteriormente vamos ampliar este controle. Um valor de cp muito pequeno ocasiona overfitting e um valor muito grande resulta numa arvore muito pequena (underfitting). Nos dois casos se diminui o desempenho do modelo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(inadimplente ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classificação\n                control=rpart.control(minsplit=30,cp=0.02))\nplot(arvcl)\ntext(arvcl,pretty=0)\n```\n\n::: {.cell-output-display}\n![](Aula12.1_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## Regras\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regras de Decisão\narvcl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nn= 7999 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 7999 266 Nao (0.96674584 0.03325416)  \n   2) balanco< 1788.349 7761 136 Nao (0.98247648 0.01752352) *\n   3) balanco>=1788.349 238 108 Sim (0.45378151 0.54621849)  \n     6) balanco< 1971.915 150  63 Nao (0.58000000 0.42000000)  \n      12) receita< 33211.76 105  36 Nao (0.65714286 0.34285714) *\n      13) receita>=33211.76 45  18 Sim (0.40000000 0.60000000) *\n     7) balanco>=1971.915 88  21 Sim (0.23863636 0.76136364) *\n```\n:::\n:::\n\n\n## Desenhando a Árvore de uma forma mais clara\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rattle)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: bitops\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRattle: A free graphical interface for data science with R.\nVersion 5.5.1 Copyright (c) 2006-2021 Togaware Pty Ltd.\nType 'rattle()' to shake, rattle, and roll your data.\n```\n:::\n\n```{.r .cell-code}\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)\n```\n\n::: {.cell-output-display}\n![](Aula12.1_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## Previsões\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fazendo Previsões\ny_chapeu <- predict(arvcl, newdata = conj_teste, type=\"class\")\n\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1922   36\n       Sim   12   31\n                                          \n               Accuracy : 0.976           \n                 95% CI : (0.9683, 0.9823)\n    No Information Rate : 0.9665          \n    P-Value [Acc > NIR] : 0.0083176       \n                                          \n                  Kappa : 0.5519          \n                                          \n Mcnemar's Test P-Value : 0.0009009       \n                                          \n            Sensitivity : 0.46269         \n            Specificity : 0.99380         \n         Pos Pred Value : 0.72093         \n         Neg Pred Value : 0.98161         \n             Prevalence : 0.03348         \n         Detection Rate : 0.01549         \n   Detection Prevalence : 0.02149         \n      Balanced Accuracy : 0.72824         \n                                          \n       'Positive' Class : Sim             \n                                          \n```\n:::\n:::\n\n\n## Arvore de Classificação no caret\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\nset.seed(21)\n## Otimizamos o valor de cp usando um 10-fold cv\n# O parametro tuneLength diz para o algoritmo escolher diferentes valores para cp\n# O parametro tuneGrid permite decidir que valores cp deve assumir enquanto que o\n# tuneLength somente limita o número default de parametros que se usa.\ntgrid <- expand.grid(cp = seq(0.01,0.10,0.001))\nctrl <- trainControl(method = \"cv\", classProbs=TRUE)\narvclass <- train(inadimplente ~ . , data = conj_treino, method = \"rpart\",\n                 trControl = ctrl,\n                 tuneGrid = tgrid\n                 )\n# Mostra a acurácia vs cp (parametro de complexidade)\nplot(arvclass)\n```\n\n::: {.cell-output-display}\n![](Aula12.1_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Indica o melhor valor de cp\narvclass$bestTune\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      cp\n53 0.062\n```\n:::\n:::\n\n\n## Uma forma melhor de ver a Árvore\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## melhorando apresentação da árvore\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvclass$finalModel, caption = NULL)\n```\n\n::: {.cell-output-display}\n![](Aula12.1_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Previsões\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fazendo Previsões\ny_chapeu <- arvclass %>% predict(conj_teste) %>% \n                   factor(levels = levels(conj_teste$inadimplente))\nhead(y_chapeu)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] Nao Nao Nao Nao Nao Nao\nLevels: Nao Sim\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(y_chapeu, conj_teste$inadimplente, positive=\"Sim\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Nao  Sim\n       Nao 1927   44\n       Sim    7   23\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.4631         \n                                         \n Mcnemar's Test P-Value : 4.631e-07      \n                                         \n            Sensitivity : 0.34328        \n            Specificity : 0.99638        \n         Pos Pred Value : 0.76667        \n         Neg Pred Value : 0.97768        \n             Prevalence : 0.03348        \n         Detection Rate : 0.01149        \n   Detection Prevalence : 0.01499        \n      Balanced Accuracy : 0.66983        \n                                         \n       'Positive' Class : Sim            \n                                         \n```\n:::\n:::\n\n\n## Verificando a consistencia dos resultados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(121)\ny <- credito$inadimplente\nindice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)\n\nconj_treino <- credito %>% slice(-indice_teste)\nconj_teste <- credito %>% slice(indice_teste)\n\nstr(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [7,999 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:7999] 0 1 0 0 1 0 1 0 1 1 ...\n $ balanco     : num [1:7999] 730 817 1074 786 920 ...\n $ receita     : num [1:7999] 44362 12106 31767 38463 7492 ...\n```\n:::\n\n```{.r .cell-code}\nprop.table(table(conj_treino$inadimplente))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n       Nao        Sim \n0.96674584 0.03325416 \n```\n:::\n\n```{.r .cell-code}\nstr(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [2,001 × 4] (S3: tbl_df/tbl/data.frame)\n $ inadimplente: Factor w/ 2 levels \"Nao\",\"Sim\": 1 1 1 1 1 1 1 1 1 1 ...\n $ estudante   : num [1:2001] 0 0 0 1 0 0 1 1 0 0 ...\n $ balanco     : num [1:2001] 529 1161 1113 1500 1152 ...\n $ receita     : num [1:2001] 35704 37469 23810 13191 42917 ...\n```\n:::\n\n```{.r .cell-code}\nprop.table(table(conj_teste$inadimplente))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n       Nao        Sim \n0.96651674 0.03348326 \n```\n:::\n:::\n\n\n## Obtendo a arvore\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Usando rpart para desenvolver a arvore  \nlibrary(rpart)\narvcl <- rpart(inadimplente ~ ., \n                data=conj_treino,\n                method=\"class\", #para arvore de classificação\n                control=rpart.control(minsplit=30,cp=0.02))\n```\n:::\n\n\n## Desenhando a Árvore de uma forma mais clara\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nfancyRpartPlot(arvcl, caption = NULL)\n```\n\n::: {.cell-output-display}\n![](Aula12.1_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## GBM\n\n### Criando um grid para avaliar os parametros\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhiper_grid <- expand.grid(\n  shrinkage = c(.001, .01, .1),\n  interaction.depth = c(1, 3, 5),\n  n.minobsinnode = c(5, 10, 15),\n  bag.fraction = c(.65, 1),\n  optimal_trees = 0, # um lugar para guardar resultados\n  min_erro = 0   # um lugar para guardar resultados\n  )\n\n# número total de combinações\nnrow(hiper_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 54\n```\n:::\n:::\n\n\n## Avaliando o grid de parametros\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gbm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoaded gbm 2.1.8.1\n```\n:::\n\n```{.r .cell-code}\nconj_treino$inadimplente <- as.numeric(conj_treino$inadimplente)\nconj_treino <- transform(conj_treino, inadimplente=inadimplente - 1)\n\n#Busca no grid\nfor(i in 1:nrow(hiper_grid)) {\n\n  #\n  set.seed(21)\n\n  # treina o modelo\n  gbm.tune <- gbm(\n    formula = inadimplente ~ .,\n    distribution = \"bernoulli\",\n    data = conj_treino,\n    n.trees = 2000,\n    interaction.depth = hiper_grid$interaction.depth[i],\n    shrinkage = hiper_grid$shrinkage[i],\n    n.minobsinnode = hiper_grid$n.minobsinnode[i],\n    bag.fraction = hiper_grid$bag.fraction[i],\n    train.fraction = .75,\n    n.cores = NULL,\n    verbose = FALSE\n  )\n\n  # adiciona os erros de treino e arvores ao grid\n  hiper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)\n  hiper_grid$min_erro[i] <- min(gbm.tune$valid.error)\n}\n\nhiper_grid %>% dplyr::arrange(min_erro) %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   shrinkage interaction.depth n.minobsinnode bag.fraction optimal_trees\n1       0.10                 1             15         0.65           142\n2       0.10                 1             10         0.65           142\n3       0.10                 1              5         0.65            84\n4       0.10                 1              5         1.00           155\n5       0.01                 1              5         1.00          1592\n6       0.10                 1             10         1.00           136\n7       0.10                 1             15         1.00           136\n8       0.01                 1              5         0.65          1002\n9       0.01                 1             10         1.00           940\n10      0.01                 1             15         1.00           940\n    min_erro\n1  0.1602066\n2  0.1602292\n3  0.1604008\n4  0.1607106\n5  0.1608038\n6  0.1611587\n7  0.1611587\n8  0.1611858\n9  0.1612577\n10 0.1612577\n```\n:::\n:::\n\n\n## Modelo final\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \nset.seed(21)\n\n# treina o modelo GBM\ngbm.fit.final <- gbm(\n  formula = inadimplente ~ .,\n  distribution = \"bernoulli\",\n  data = conj_treino,\n  n.trees = 193,\n  interaction.depth = 1,\n  shrinkage = 0.10,\n  n.minobsinnode = 5,\n  bag.fraction = 1.00, \n  train.fraction = 1,\n  n.cores = NULL, \n  verbose = FALSE\n  )  \n```\n:::\n\n\n## Importância das Variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mai = c(1, 2, 1, 2))\nsummary(\n  gbm.fit.final, \n  cBars = 10,\n  method = relative.influence, # também pode ser usado permutation.test.gbm\n  las = 2\n  )\n```\n\n::: {.cell-output-display}\n![](Aula12.1_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                var    rel.inf\nbalanco     balanco 99.2361652\nestudante estudante  0.4480848\nreceita     receita  0.3157499\n```\n:::\n:::\n\n\n## Previsão\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconj_teste$inadimplente <- as.numeric(conj_teste$inadimplente)\nconj_teste <- transform(conj_teste, inadimplente=inadimplente - 1)\n\n# Fazendo Previsões\nprevisao1 <- predict(gbm.fit.final, \n                     newdata = conj_teste,\n                     n.trees=gbm.fit.final$n.trees,\n                     type = \"response\")\nhead(previsao1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.002456101 0.015887955 0.013762373 0.099006852 0.015887955 0.002456101\n```\n:::\n\n```{.r .cell-code}\ngbm.ychapeu <- as.factor(ifelse(previsao1 < 0.5,0,1))\n \nconfusionMatrix(gbm.ychapeu,as.factor(conj_teste$inadimplente), positive=\"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1933   50\n         1    1   17\n                                         \n               Accuracy : 0.9745         \n                 95% CI : (0.9666, 0.981)\n    No Information Rate : 0.9665         \n    P-Value [Acc > NIR] : 0.02354        \n                                         \n                  Kappa : 0.3914         \n                                         \n Mcnemar's Test P-Value : 1.801e-11      \n                                         \n            Sensitivity : 0.253731       \n            Specificity : 0.999483       \n         Pos Pred Value : 0.944444       \n         Neg Pred Value : 0.974786       \n             Prevalence : 0.033483       \n         Detection Rate : 0.008496       \n   Detection Prevalence : 0.008996       \n      Balanced Accuracy : 0.626607       \n                                         \n       'Positive' Class : 1              \n                                         \n```\n:::\n:::\n\n\n## Curva ROC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nType 'citation(\"pROC\")' for a citation.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'pROC'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n```\n:::\n\n```{.r .cell-code}\np_chapeu_gbm <- previsao1\nroc_gbm <- roc(conj_teste$inadimplente ~ p_chapeu_gbm, plot = TRUE, print.auc=FALSE, col=\"black\", legacy.axes=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = 0, case = 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting direction: controls < cases\n```\n:::\n\n::: {.cell-output-display}\n![](Aula12.1_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\nas.numeric(roc_gbm$auc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9536804\n```\n:::\n:::\n",
    "supporting": [
      "Aula12.1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}