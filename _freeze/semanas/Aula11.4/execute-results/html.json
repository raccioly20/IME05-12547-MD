{
  "hash": "e90bdb0ddaa7b9bbd857d47e9d695f76",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Arvores de Regressão - LIME e SHAP'\nauthor: \"Ricardo Accioly\"\ndate: \"2025-06-02\"\nexecute: \n  echo: true\n  warning: false\n  message: false\n  freeze: auto\nformat:\n html:\n    code-link: true\n    fig-height: 10\n    fig-width: 10\n    fig-align: center\n    fig-dpi: 300\nknitr: \n  opts_chunk: \n    out.width: 90%\n    fig.showtext: true\n    collapese: true\n---\n\n## Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)        # Base de dados\nlibrary(ranger)      # Random Forest\nlibrary(lime)        # LIME\nlibrary(iml)         # SHAP\nlibrary(ggplot2)     # Gráficos\nlibrary(dplyr)       # Manipulação\nlibrary(caret)       # Partição dos dados\nlibrary(tidyr)       # Para pivotar\nlibrary(fastshap)\nlibrary(shapviz)\n```\n:::\n\n\n## Avaliando, selecionando dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"Boston\")\nnames(Boston)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n```\n\n\n:::\n\n```{.r .cell-code}\ndados <- Boston \n```\n:::\n\n\n## Treino e Teste com todas as variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Vamos criar os conjuntos de treino teste e desenvolver a arvore \n## com todas as variáveis.\nlibrary(caret)\nset.seed(21)\nindice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)\nconj_treino <- dados[indice,]\nconj_teste <- dados[-indice,]\nhead(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18.0  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n3 0.02729  0.0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0.0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0.0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0.0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n7 0.08829 12.5  7.87    0 0.524 6.012 66.6 5.5605   5 311    15.2 395.60 12.43\n  medv\n1 24.0\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n7 22.9\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      crim   zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n2  0.02731  0.0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n10 0.17004 12.5  7.87    0 0.524 6.004 85.9 6.5921   5 311    15.2 386.71 17.10\n12 0.11747 12.5  7.87    0 0.524 6.009 82.9 6.2267   5 311    15.2 396.90 13.27\n16 0.62739  0.0  8.14    0 0.538 5.834 56.5 4.4986   4 307    21.0 395.62  8.47\n19 0.80271  0.0  8.14    0 0.538 5.456 36.6 3.7965   4 307    21.0 288.99 11.69\n23 1.23247  0.0  8.14    0 0.538 6.142 91.7 3.9769   4 307    21.0 396.90 18.72\n   medv\n2  21.6\n10 18.9\n12 18.9\n16 19.9\n19 20.2\n23 15.2\n```\n\n\n:::\n:::\n\n\n## Treinamento do modelo Random Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_rf <- ranger(\n  formula = medv ~ .,\n  data = conj_treino,\n  num.trees = 500\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrapper para predições\nmodel_type.ranger <- function(x, ...) {\n  \"regression\"\n}\n\npredict_model.ranger <- function(x, newdata, ...) {\n  data.frame(Response = predict(x, data = newdata)$predictions)\n}\n\n# Criando explicador LIME\nexplainer_lime <- lime(\n  x = conj_treino[, setdiff(names(conj_treino), \"medv\")],\n  model = modelo_rf\n)\n\n# Explicação para a primeira observação do teste\nexplanation_lime <- lime::explain(\n  x = conj_teste[1, setdiff(names(conj_teste),\"medv\"), drop=FALSE],\n  explainer = explainer_lime,\n  n_features = 5\n)\n\n# Gráfico LIME\nlime::plot_features(explanation_lime)\n```\n\n::: {.cell-output-display}\n![](Aula11.4_files/figure-html/unnamed-chunk-2-1.png){width=90%}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Criando objeto predictor para o iml\npredictor_shap <- Predictor$new(\n  model = modelo_rf,\n  data = conj_treino[, -which(names(conj_treino) == \"medv\")],\n  y = conj_treino$medv\n)\n\n# SHAP para a mesma observação\nshap <- Shapley$new(predictor_shap, x.interest = conj_teste[1, -which(names(conj_teste) == \"medv\")])\n\n# Gráfico SHAP\nplot(shap)\n```\n\n::: {.cell-output-display}\n![](Aula11.4_files/figure-html/unnamed-chunk-3-1.png){width=90%}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráfico SHAP com shapviz\n# Matriz de preditores\nX <- conj_treino[, setdiff(names(conj_treino), \"medv\")]\n\n# Função de predição para fastshap\npred_fun <- function(object, newdata) {\n  predict(object, data = newdata)$predictions\n}\n\n# Calculando valores SHAP com fastshap\nshap_values <- fastshap::explain(\n  object = modelo_rf,\n  X = X,\n  pred_wrapper = pred_fun,\n  nsim = 100  # número de permutações (pode ajustar)\n)\n\n# Criando objeto shapviz\nsv_rf <- shapviz(shap_values, X = X)\n\n# Visualizações\nsv_importance(sv_rf, kind=\"bee\")\n```\n\n::: {.cell-output-display}\n![](Aula11.4_files/figure-html/unnamed-chunk-4-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nsv_dependence(sv_rf, v = \"lstat\")\n```\n\n::: {.cell-output-display}\n![](Aula11.4_files/figure-html/unnamed-chunk-4-2.png){width=90%}\n:::\n\n```{.r .cell-code}\nsv_waterfall(sv_rf, row_id = 1)\n```\n\n::: {.cell-output-display}\n![](Aula11.4_files/figure-html/unnamed-chunk-4-3.png){width=90%}\n:::\n:::\n\n\n",
    "supporting": [
      "Aula11.4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}