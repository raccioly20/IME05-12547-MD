---
title: "KNN"
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
output:
 html_document:
    toc: yes
    code_download: yes
---

## KNN

**O KNN é um algoritmo muito simples no qual cada observação é prevista com base em sua "semelhança" com outras observações. Ao contrário da maioria dos métodos, KNN é um algoritmo baseado na memória e não pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento são necessárias no tempo de execução e as previsões são feitas diretamente das relações amostrais. Consequentemente, os KNNs também são conhecidos como aprendizes preguiçosos**

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 9, 
                      fig.height= 7,  
                      fig.retina = 3,
                      message = FALSE, 
                      warning = FALSE,
                      dev=c("png"), 
                      fig.path="imagens/Aula08A/")
```

## Carregando Bibliotecas


```{r bibliotecas, message=FALSE}
library(tidyverse)
library(caret)
library(ISLR)
data(Default)
summary(Default)
str(Default)
head(Default)
```

## Manipulando os dados



```{r inadimplente}
credito <- tibble(Default)
summary(credito)
# renomeando colunas
credito <- credito %>% 
                rename( inadimplente = default, estudante = student, balanco = balance,
                receita = income)
credito <- credito %>% mutate( inadimplente =  case_when(
                           inadimplente == "No"  ~ "Nao",
                           inadimplente == "Yes" ~ "Sim"
                          )) %>% mutate(inadimplente = factor(inadimplente))
credito <- credito %>% mutate( estudante =  case_when(
                           estudante == "No"  ~ 0,
                           estudante == "Yes" ~ 1
                          )) 

str(credito)
summary(credito)

```


## Normalização

Antes de iniciarmos é fundamental fazermos a normalização (padronização) dos dados para que o KNN tenha um melhor desempenho.

```{r normalizar}
credito_n <- credito
credito_n[,3:4] <- scale(credito_n[,3:4])
```


## Treino e Teste


```{r conjuntos-treino-teste, message=FALSE}
set.seed(21)
y <- credito_n$inadimplente
indice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)

conj_treino <- credito_n %>% slice(-indice_teste)
conj_teste <- credito_n %>% slice(indice_teste)

summary(conj_treino)
summary(conj_teste)
```


## Matriz de dispersão

Vamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente. 

```{r splom, message=FALSE}
library(psych)
pairs.panels(credito, 
             method = "pearson", # metodo de correlação
             hist.col = "#00AFBB",
             density = TRUE,  # mostra graficos de densidade
             ellipses = FALSE # mostra elipses de correlação
             )

```


## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)


```{r box-plot}
ggplot(credito, aes(x=inadimplente, y=balanco)) +
  geom_boxplot()
ggplot(credito, aes(x=inadimplente, y=receita)) +
  geom_boxplot()
ggplot(credito, aes(x=as.factor(estudante), y=balanco)) +
  geom_boxplot()
ggplot(credito, aes(x=as.factor(estudante), y=receita)) +
  geom_boxplot()


```


## Explorando um pouco mais Balanço e Receita

```{r histogramas}
ggplot(credito, aes(x=balanco)) +
  geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))
ggplot(credito, aes(x=receita)) +
    geom_histogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))
```


## Balanço vs Receita


```{r dispersao}
ggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point() 
```



## KNN

**Vamos usar a função knn da biblioteca caret que tem ótimas funcionalidades. Observem que a saída pode ser as classes ou as probabilidades de pertencer a uma classe**

**Como o KNN usa as distancias entre os pontos ele é afetado pela escala dos dados, portanto, é necessário que os dados sejam normalizados (padronizados) para eliminar este efeito.**

**Quando temos diversas variáveis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrão 1**


## 1a Modelo

```{r 1modelo}
# Vamos usar a regra da raiz quadrada do tamnho da amostra
sqrt(nrow(conj_treino)) ## ~90
set.seed(21)
t_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)
t_knn1
```


## Avaliando o modelo 

**A acurácia deu um valor alto, mas isto não é suficiente para considerarmo que temos um bom modelo. Veja que a sensibilidade está muito baixa e que o ideal é que tenhamos valores altos de sensibilidade e especificidade.**

**Observar que a prevalência é muito baixa o que está afetando os resultados do modelo**


```{r aval}
## 
y_chapeu_knn1 <- predict(t_knn1, conj_teste, type = "class")

# Matriz de confusão para valiar os resultados
confusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive="Sim") 
```


## Curva ROC

```{r ROC, fig.width=9, message=FALSE}
library(pROC)

# Para a curva ROC preciso das probabilidades e não das classes
p_chapeu_knn1 <- predict(t_knn1, conj_teste, type = "prob")
head(p_chapeu_knn1)

# Aqui gera o curva e salvo numa variável
roc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col="black", legacy.axes=TRUE)

legend("bottomright",legend=c("KNN1"), 
       col=c("black"),lwd=4)

# Area abaixo da Curva (AUC)
as.numeric(roc_knn1$auc)
```


## Variando K 

**Anteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a função train da biblioteca caret **

**Observe que a otimização de k é feita através de acurácia**

```{r K1}
set.seed(21)

# Usando validação cruzada para obter o valor de k através da função train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.
ctrl <- trainControl(method = "cv")
t_knn2 <- train(inadimplente ~ balanco + receita + estudante,
                method = "knn", trControl= ctrl, 
                tuneGrid = data.frame(k = seq(10,200, by=10)),
                data = conj_treino)
## Resultados do treino
t_knn2
plot(t_knn2)

## Previsões com o resultaddos do treino
prev_knn2 <- predict(t_knn2, conj_teste)
confusionMatrix(prev_knn2, conj_teste$inadimplente,  positive="Sim")
```

## Variando K de outra forma

**Vamos adicionar mais opções no trainControl**

**Ao colocar classProb = TRUE e summaryFunction ao invés da acurácia a otimização passa a ser através o ROC**


```{r K2}
set.seed(21)
# ctrl <- trainControl(method = "cv", classProbs=TRUE, summaryFunction = twoClassSummary)
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10,
                     repeats = 5, 
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary)

t_knn3 <- train(inadimplente ~ balanco + receita + estudante, 
                method = "knn", 
                trControl= ctrl, 
                tuneGrid = data.frame(k = seq(10,200, by=10)),
                metric = "ROC",
                data = conj_treino)
t_knn3
plot(t_knn3)
prev_knn3 <- predict(t_knn3, conj_teste)
confusionMatrix(prev_knn3, conj_teste$inadimplente,  positive="Sim")
```


**Veja que ao otimizar pela ROC o modelo escolhido tem sensibilidade zero! Isto obviamente não é um bom modelo! Neste caso a opção de otimização do parametro pela acurácia dá melhores resultados.**

## Curva ROC dos 2 melhores modelos k=90 e k=20 

```{r ROC2, fig.width=9}
prev_knn1 <- predict(t_knn1, conj_teste, type = "prob")
prev_knn2 <- predict(t_knn2, conj_teste, type = "prob")
roc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col="black", legacy.axes=TRUE)
roc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col="green", legacy.axes=TRUE, add=TRUE)
legend("bottomright",legend=c("KNN1", "KNN2"), 
       col=c("black","green"),lwd=4)

## Area embaixo das curvas
as.numeric(roc_knn1$auc)
as.numeric(roc_knn2$auc)
```

**Observe que os resultados de área abaixo da ROC não são suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!**

**Os resultados encontrados apontam k=20 como a melhor opção**


