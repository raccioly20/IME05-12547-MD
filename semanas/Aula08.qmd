---
title: "KNN"
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
format:
 html:
    code-link: true
    fig-width: 9
    fig-height: 7
    fig-dpi: 300
knitr:
  opts_chunk: 
    out.width: 90%
    comment: "#>"
---

## KNN

**O KNN é um algoritmo muito simples no qual cada observação é prevista com base em sua "semelhança" com outras observações. Ao contrário da maioria dos métodos, KNN é um algoritmo baseado na memória e não pode ser resumido por um modelo de forma fechada. Isso significa que as amostras de treinamento são necessárias no tempo de execução e as previsões são feitas diretamente das relações amostrais. Consequentemente, os KNNs também são conhecidos como aprendizes preguiçosos**

## Carregando Bibliotecas

```{r bibliotecas, message=FALSE}
library(tidyverse)
library(ISLR)
data(Default)
summary(Default)
str(Default)
head(Default)
```

## Manipulando os dados

```{r inadimplente}
credito <- tibble(Default)
summary(credito)
# renomeando colunas
credito <- credito %>% 
                rename( inadimplente = default, estudante = student, balanco = balance,
                receita = income)
credito <- credito %>% mutate( inadimplente =  case_when(
                           inadimplente == "No"  ~ "Nao",
                           inadimplente == "Yes" ~ "Sim"
                          )) %>% mutate(inadimplente = factor(inadimplente))
credito <- credito %>% mutate( estudante =  case_when(
                           estudante == "No"  ~ 0,
                           estudante == "Yes" ~ 1
                          )) 

str(credito)
summary(credito)

```

## Matriz de dispersão

Vamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente.

```{r splom, message=FALSE}
library(psych)
pairs.panels(credito, 
             method = "pearson", # metodo de correlação
             hist.col = "#00AFBB",
             density = TRUE,  # mostra graficos de densidade
             ellipses = FALSE # mostra elipses de correlação
             )

```

## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)

```{r box-plot}
library(patchwork)
p1 <- ggplot(credito, aes(x=inadimplente, y=balanco, color=inadimplente)) +
  geom_boxplot()
p2 <- ggplot(credito, aes(x=inadimplente, y=receita, color=inadimplente)) +
  geom_boxplot()
p3 <- ggplot(credito, aes(x=as.factor(estudante), y=balanco, color=as.factor(estudante))) +
  geom_boxplot()
p4 <- ggplot(credito, aes(x=as.factor(estudante), y=receita, color=as.factor(estudante))) +
  geom_boxplot()
(p1 + p2) / (p3 + p4)

```

## Explorando um pouco mais Balanço e Receita

```{r histogramas}
p5 <- ggplot(credito, aes(x=balanco)) +
  geom_histogram(bins = round(1+3.322*log10(nrow(credito)),0))
p6 <- ggplot(credito, aes(x=receita)) +
    geom_histogram(bins = round(1+3.322*log10(nrow(credito)),0))
p5 + p6
```

## Balanço vs Receita

```{r dispersao}
ggplot(data = credito, aes(x=balanco,  y = receita, col = inadimplente)) + geom_point() 
```

## KNN

Vamos usar a função knn da biblioteca caret que tem ótimas funcionalidades. Observem que a saída pode ser as classes ou as probabilidades de pertencer a uma classe

**Como o KNN usa as distancias entre os pontos ele é afetado pela escala dos dados, portanto, é necessário que os dados sejam normalizados (padronizados) para eliminar este efeito.**

Quando temos diversas variáveis explicativas em diferentes escalas, em geral, elas devem ser transformadas para ter media zero e desvio padrão 1

## Criando conjuntos de treino e teste e normalizando variáveis

```{r conjuntos-treino-teste, message=FALSE}
library(caret)
set.seed(2024)
y <- credito$inadimplente
credito_split <- createDataPartition(y, times = 1, p = 0.80, list = FALSE)

conj_treino <- credito[credito_split,]
conj_treino[,3:4] <- scale(conj_treino[,3:4]) # scale normaliza
conj_teste <- credito[-credito_split,]
conj_teste[,3:4] <- scale(conj_teste[, 3:4])
                           
summary(conj_treino)
summary(conj_teste)
```

## 1a Modelo

Vamos usar a regra da raiz quadrada do tamanho da amostra para definir o número de vizinhos do KNN.

```{r 1modelo}

library(caret)
sqrt(nrow(conj_treino)) ## ~90
set.seed(23)

t_knn1 <- knn3(inadimplente ~ balanco + receita + estudante, data = conj_treino, k = 90)
t_knn1
```

## Avaliando o modelo

**Através da função matriz de confusão do pacote caret conseguimos obter as principais medidas de avaliação de um modelo de classificação.**

**Veja que a acurácia deu um valor alto, mas isto não é suficiente para considerarmos que temos um bom modelo. Veja que a sensibilidade está muito baixa e que o ideal é que tenhamos valores altos de sensibilidade e especificidade.**

**Observar que a prevalência é muito baixa o que está afetando os resultados do modelo.**

```{r aval}
y_chapeu_knn1 <- predict(t_knn1, conj_teste, type = "class")


confusionMatrix(y_chapeu_knn1, conj_teste$inadimplente, positive="Sim") 
```

## Curva ROC

Para a curva ROC é necessário que obtenhamos as probabilidades e não das classes, vejam nos comandos abaixo como se obtem as probabilidades.

```{r ROC, fig.width=9, message=FALSE}
library(pROC)

# 
p_chapeu_knn1 <- predict(t_knn1, conj_teste, type = "prob")
head(p_chapeu_knn1)

# Aqui gera o curva e salvo numa variável
roc_knn1 <- roc(conj_teste$inadimplente ~ p_chapeu_knn1[,2], plot = TRUE, print.auc=FALSE, col="black", legacy.axes=TRUE)

legend("bottomright",legend=c("KNN1"), 
       col=c("black"),lwd=4)

```

## Area embaixo da curva ROC

```{r}
# Area abaixo da Curva (AUC)
as.numeric(roc_knn1$auc)
```

## Variando K

**Anteriormente usamos k=90. Este parametro deve ser ajustado para melhoramos os modelo KNN. Para isto vamos usar a função train da biblioteca caret**

**Observe que a otimização de k é feita através de acurácia.**

```{r K1}
set.seed(2024)

# Usando validação cruzada para obter o valor de k através da função train da biblioteca caret e o controle do treino e fazendo um gride de valores para k.
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10,
                     repeats = 5)
t_knn2 <- train(inadimplente ~ balanco + receita + estudante,
                method = "knn", 
                trControl= ctrl,
                tuneGrid = data.frame(k = seq(5,100, by=5)),
                metric = "Accuracy",
                data = conj_treino)
## Resultados do treino
t_knn2
plot(t_knn2)

## Previsões com o resultaddos do treino
prev_knn2 <- predict(t_knn2, conj_teste)
confusionMatrix(prev_knn2, conj_teste$inadimplente,  positive="Sim")
```

## Curva ROC dos 2 melhores modelos k=90 e k=15

```{r ROC2, fig.width=9}
prev_knn1 <- predict(t_knn1, conj_teste, type = "prob")
prev_knn2 <- predict(t_knn2, conj_teste, type = "prob")
roc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn1[,2], plot = TRUE, print.auc=FALSE, col="black", legacy.axes=TRUE)
roc_knn2 <- roc(conj_teste$inadimplente ~ prev_knn2[,2], plot = TRUE, print.auc=FALSE, col="green", legacy.axes=TRUE, add=TRUE)
legend("bottomright",legend=c("KNN1", "KNN2"), 
       col=c("black","green"),lwd=4)

## Area embaixo das curvas
as.numeric(roc_knn1$auc)
as.numeric(roc_knn2$auc)
```

**Observe que os resultados de área abaixo da ROC não são suficientes para a escolha do k, pois precisamos estar atentos a sensibilidade e especificidade!**
