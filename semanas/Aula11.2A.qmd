---
title: 'Arvores de Regressão - Random Forest '
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
execute: 
  echo: true
  warning: false
  message: false
  freeze: auto
format:
 html:
    code-link: true
    fig-height: 10
    fig-width: 10
    fig-align: center
    fig-dpi: 300
knitr: 
  opts_chunk: 
    out.width: 90%
    fig.showtext: true
    collapese: true
---

## Bibliotecas

```{r}
library(ranger)
library(dplyr)
library(purrr)
library(rsample)
library(yardstick)
library(tibble)
library(ggplot2)
library(MASS)
```

## Avaliando, selecionando dados

```{r}
data("Boston")
names(Boston)
dados <- Boston 
```

## Treino e Teste com todas as variáveis

```{r}
## Vamos criar os conjuntos de treino teste e desenvolver a arvore 
## com todas as variáveis.
library(caret)
set.seed(21)
indice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)
conj_treino <- dados[indice,]
conj_teste <- dados[-indice,]
head(conj_treino)
head(conj_teste)
```

## Criando um grid de parametros

```{r}
grid_params <- expand.grid(
  mtry = c(2, 4, 6),
  min.node.size = c(1, 5),
  splitrule = c("variance", "extratrees"),
  num.trees = c(100)
)
nrow(grid_params)
head(grid_params)
```

## Validação cruzada com `rsample`

```{r}
set.seed(2025)
folds <- vfold_cv(Boston, v = 5)

```

## Ajuste do modelo Random Forest com cada combinação

```{r}
avaliacoes <- grid_params %>%
  mutate(
    media_rmse = pmap_dbl(list(mtry, min.node.size, splitrule, num.trees), 
      function(mtry, min.node.size, splitrule, num.trees) {
        rmse_fold <- map_dbl(folds$splits, function(split) {
          treino <- analysis(split)
          teste  <- assessment(split)
          modelo <- ranger(
            medv ~ ., 
            data = treino,
            mtry = mtry,
            min.node.size = min.node.size,
            splitrule = splitrule,
            num.trees = num.trees,
            seed = 123
          )
          pred <- predict(modelo, data = teste)$predictions
          metric <- yardstick::rmse_vec(truth = teste$medv, estimate = pred)
          return(metric)
        })
        mean(rmse_fold)
      }
    )
  )
avaliacoes %>% arrange(media_rmse) %>% head()


```

## Melhor combinação de parâmetros

```{r}
melhor_param <- avaliacoes %>% arrange(media_rmse) %>% slice(1)
melhor_param


```

## Ajuste do modelo final

```{r}
modelo_final <- ranger(
  medv ~ ., 
  data = conj_treino,
  mtry = melhor_param$mtry,
  min.node.size = melhor_param$min.node.size,
  splitrule = melhor_param$splitrule,
  num.trees = melhor_param$num.trees,
  seed = 2025,
  importance = "permutation"
)

modelo_final

```

## Avaliação no conjunto de teste

```{r}
pred <- predict(modelo_final, data = conj_teste)$predictions

# Métricas de desempenho
postResample(pred, conj_teste$medv)
```

## Importância das variáveis

```{r}
# Converter a importância em tibble ordenada
df_importancia <- importance(modelo_final) %>% 
  enframe(name = "Variável", value = "Importância") %>% 
  arrange(desc(Importância))

# Gráfico de barras da importância das variáveis
ggplot(df_importancia, aes(x = reorder(Variável, Importância), y = Importância)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Importância das Variáveis (Permutação)",
       x = "Variável",
       y = "Importância") +
  theme_minimal()
```

## Comparação com outro modelo (Regressão Linear)

```{r}
ctrl <- trainControl(method = "cv", number = 5)

model_lm <- train(
  medv ~ ., data = conj_treino,
  method = "lm",
  trControl = ctrl
)

pred_lm <- predict(model_lm, newdata = conj_teste)
postResample(pred_lm, conj_teste$medv)
```

## Grafico de comparação

```{r}
# Gráfico de comparação
graf_comparacao <- ggplot() +
  geom_point(aes(x = conj_teste$medv, y = pred), color = "blue", alpha = 0.5) +
  geom_point(aes(x = conj_teste$medv, y = pred_lm), color = "red", alpha = 0.5) +
  labs(title = "Comparação de Previsões: Random Forest vs Regressão Linear",
       x = "Valores Reais (medv)", y = "Previsões") +
  theme_minimal()
graf_comparacao

```

## Analisando com o LIME

```{r}
# Treinamento com ranger precisa ser refeito em formato compatível com lime
library(lime)

# Treinando modelo com train() + ranger para compatibilidade com LIME
set.seed(2025)
tune_grid <- data.frame(
  mtry = melhor_param$mtry,
  splitrule = as.character(melhor_param$splitrule),
  min.node.size = melhor_param$min.node.size
)
modelo_caret <- train(
  medv ~ ., 
  data = conj_treino,
  method = "ranger",
  trControl = trainControl(method = "none"),
  tuneGrid = tune_grid
)

# Preparar explicador LIME
explainer <- lime(conj_treino, modelo_caret, bin_continuous = FALSE)

# Aplicar LIME a 3 observações novas
explicacoes <- explain(
  conj_teste[1:3, ],
  explainer = explainer,
  n_features = 5,
  n_labels = 1
)

# Dados Analisados
conj_teste[1:3, c("medv", "rm", "ptratio", "nox", "dis", "lstat", "tax")]
# Visualizar explicações
plot_features(explicacoes)
```
