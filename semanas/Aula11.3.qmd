---
title: 'Arvores de Regressão - XGBoost'
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
execute: 
  echo: true
  warning: false
  message: false
  freeze: auto
format:
 html:
    code-link: true
    fig-height: 10
    fig-width: 10
    fig-align: center
    fig-dpi: 300
knitr: 
  opts_chunk: 
    out.width: 90%
    fig.showtext: true
    collapese: true
---

## Bibliotecas

```{r}
library(MASS)         # Dados Boston
library(xgboost)      # Modelo XGBoost
library(dplyr)        # Manipulação de dados
library(rsample)      # Separação treino/teste
library(Metrics)      # Cálculo de RMSE
library(ggplot2)      # Gráficos
```

## Avaliando, selecionando dados

```{r}
data("Boston")
names(Boston)
dados <- Boston 
```

## Treino e Teste com todas as variáveis

```{r}
## Vamos criar os conjuntos de treino teste e desenvolver a arvore 
## com todas as variáveis.
library(caret)
set.seed(21)
indice <- createDataPartition(dados$medv, times=1, p=0.75, list=FALSE)
conj_treino <- dados[indice,]
conj_teste <- dados[-indice,] 
str(conj_treino)
str(conj_teste)
```

## Preparando os dados

```{r}
x_treino <- model.matrix(medv ~ . , data = conj_treino)[, -1]
y_treino <- conj_treino$medv

x_teste <- model.matrix(medv ~ . , data = conj_teste)[, -1]
y_teste = conj_teste$medv

dtrain <- xgb.DMatrix(data = x_treino, label = y_treino)
dtest <- xgb.DMatrix(data = x_teste, label = y_teste)
```

## Treinamento com validação cruzada e grid de parâmetros

```{r}
set.seed(21)
# Grid de hiperparâmetros
grid <- expand.grid(
  eta = c(0.01, 0.1),
  max_depth = c(3, 6),
  nrounds = c(100, 200)
)

# Avaliar cada combinação com CV
resultados_cv <- list()

for (i in 1:nrow(grid)) {
  params <- list(
    objective = "reg:squarederror",
    eta = grid$eta[i],
    max_depth = grid$max_depth[i],
    verbosity = 0
  )
  
  cv <- xgb.cv(
    params = params,
    data = dtrain,
    nrounds = grid$nrounds[i],
    nfold = 5,
    metrics = "rmse",
    early_stopping_rounds = 10,
    verbose = 0
  )
  
  resultados_cv[[i]] <- list(
    rmse = min(cv$evaluation_log$test_rmse_mean),
    best_nrounds = cv$best_iteration,
    params = grid[i, ]
  )
}

# Melhor modelo
rmses <- sapply(resultados_cv, function(x) x$rmse)
melhor_indice <- which.min(rmses)
melhor_param <- resultados_cv[[melhor_indice]]$params
melhor_nrounds <- resultados_cv[[melhor_indice]]$best_nrounds

melhor_param
```

## Modelo Final

```{r}
# Treino final com os melhores parâmetros
final_model <- xgb.train(
  params = list(
    objective = "reg:squarederror",
    eta = melhor_param$eta,
    max_depth = melhor_param$max_depth
  ),
  data = dtrain,
  nrounds = melhor_nrounds,
  verbose = 0
)
```


## Importancia das variáveis

```{r}
# Importância das variáveis
importance_matrix <- xgb.importance(model = final_model)

# Gráfico
xgb.plot.importance(importance_matrix)

```


## Previsões

```{r}
conj_teste$prev <- predict(final_model, dtest)


ggplot(conj_teste, aes(x = prev, y = medv)) + 
  geom_point() + 
  geom_abline()
```

## Calculando o RMSE

```{r}
rmse_final <- rmse(y_teste, conj_teste$prev)
cat("RMSE no conjunto de teste:", rmse_final)
caret::postResample(conj_teste$prev, conj_teste$medv)
```

## Comparação com outro modelo (Regressão Linear)

```{r}
ctrl <- trainControl(method = "cv", number = 5)

model_lm <- train(
  medv ~ ., data = conj_treino,
  method = "lm",
  trControl = ctrl
)

pred_lm <- predict(model_lm, newdata = conj_teste)
postResample(pred_lm, conj_teste$medv)
```
