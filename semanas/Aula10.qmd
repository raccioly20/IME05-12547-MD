---
title: "LDA e QDA"
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
format:
 html:
    code-link: true
    fig-height: 8
    fig-width: 12
    fig-align: center
knitr: 
   opts_chunk: 
    out.width: 90%
    comment: "#>"
execute: 
  echo: true
  warning: false
  message: false
  freeze: auto
---

## LDA e QDA

## Carregando Bibliotecas

```{r}
library(tidyverse)
library(caret)
library(patchwork)
library(pROC)
library(ISLR)
data(Default)
summary(Default)
str(Default)
head(Default)
```

## Manipulando os dados

```{r}
credito <- tibble(Default)
summary(credito)
# renomeando colunas
credito <- credito %>% 
                rename( inadimplente = default, estudante = student, balanco = balance,
                receita = income)
credito <- credito %>% mutate( inadimplente =  case_when(
                           inadimplente == "No"  ~ "Nao",
                           inadimplente == "Yes" ~ "Sim"
                          )) %>% mutate(inadimplente = factor(inadimplente))
credito <- credito %>% mutate( estudante =  case_when(
                           estudante == "No"  ~ 0,
                           estudante == "Yes" ~ 1
                          )) 

str(credito)
summary(credito)

```

## Treino e Teste

```{r}

set.seed(2025)
y <- credito$inadimplente
indice_teste <- createDataPartition(y, times = 1, p = 0.1, list = FALSE)

conj_treino <- credito[-indice_teste,]
conj_teste <- credito[indice_teste,]

summary(conj_treino)
summary(conj_teste)

```

## Graficos de Densidade

Vamos agora explorar os dados originais para termos algum visão do comportamento das variáveis explicativas e a variável dependente.

```{r}
featurePlot(x = conj_treino[, c("balanco", "receita", "estudante")], 
            y = conj_treino$inadimplente,
            plot = "density", 
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")), 
            adjust = 1.5, 
            pch = "|", 
            layout = c(2, 1), 
            auto.key = list(columns = 2))


```

## Avaliando o comportamento das variáveis em função do status (inadimplente / estudante)

```{r}

p1 <- ggplot(credito, aes(x=inadimplente, y=balanco, color=inadimplente)) +
  geom_boxplot()
p2 <- ggplot(credito, aes(x=inadimplente, y=receita, color=inadimplente)) +
  geom_boxplot()
p3 <- ggplot(credito, aes(x=as.factor(estudante), y=balanco, color=as.factor(estudante))) +
  geom_boxplot()
p4 <- ggplot(credito, aes(x=as.factor(estudante), y=receita, color=as.factor(estudante))) +
  geom_boxplot()
(p1 + p2) / (p3 + p4)


```

## Calcula Erro

```{r}
# Este valor é igual a 1 - Accuracy da matriz de confusão
calc_erro_class <- function(real, previsto) {
  mean(real != previsto)
}
```

## Treino e Teste Normalizado

```{r}
set.seed(2025)
# Normalizando os dados
credito <- credito %>% mutate(balanco = scale(balanco), receita = scale(receita))

y <- credito$inadimplente
indice_teste <- createDataPartition(y, times = 1, p = 0.1, list = FALSE)

conj_treino <- credito[-indice_teste,]
conj_teste <- credito[indice_teste,]

summary(conj_treino)
summary(conj_teste)

```

## LDA

```{r LDA}
library(MASS)

treina_lda <- lda(inadimplente ~ balanco + estudante + receita, data = conj_treino)
treina_lda
plot(treina_lda)
names(predict(treina_lda, conj_treino))
y_chapeu <- predict(treina_lda, conj_teste)$class %>% 
             factor(levels = levels(conj_teste$inadimplente))
confusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive="Sim")


# Este valor é igual a 1 - Accuracy da matriz de confusão
calc_erro_class(conj_teste$inadimplente, y_chapeu)
```

## LDA - Ajustando probabilidade limite

```{r LDA2}
p_chapeu <- predict(treina_lda, conj_teste)$posterior
head(p_chapeu)
y_chapeu <- ifelse(p_chapeu[, 2] > 0.11, "Sim", "Nao") %>% 
             factor(levels = levels(conj_teste$inadimplente))
confusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive="Sim") 


# Este valor é igual a 1 - Accuracy da matriz de confusão
calc_erro_class(conj_teste$inadimplente, y_chapeu)
```

## Seleção de variáveis

No LDA, a seleção de variáveis pode ser feita com o RFE (Recursive Feature Elimination). O RFE é um método de seleção de variáveis que utiliza a validação cruzada para avaliar o desempenho do modelo com diferentes subconjuntos de variáveis. O RFE é implementado na função `rfe()` do pacote `caret`.

```{r}
# Usar o RFE para selecionar as variáveis
# Definir controle para RFE
control <- rfeControl(functions = ldaFuncs, method = "cv", number = 10)

# Aplicar o RFE
set.seed(2025)
result <- rfe(conj_treino[, 2:4], conj_treino$inadimplente, sizes = c(1:3), rfeControl = control)

# Resultados
print(result)
```

## Outra Opção

Podemos usar os gráfico exploratórios iniciais e também o resultado da regressão logística como ponto de partida para a seleção de variáveis.

```{r}
treina_lda2 <- lda(inadimplente ~ balanco + estudante, data = conj_treino)
treina_lda2
plot(treina_lda2)
y_chapeu <- predict(treina_lda2, conj_teste)$class %>% 
             factor(levels = levels(conj_teste$inadimplente))
confusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive="Sim")


# Este valor é igual a 1 - Accuracy da matriz de confusão
calc_erro_class(conj_teste$inadimplente, y_chapeu)
```

Podemos observar que não houve mudança nos resultados ao retirar a variável receita.

## QDA

```{r QDA}
treina_qda <- qda(inadimplente ~ balanco + estudante + receita, data = conj_treino)
treina_qda
y_chapeu <- predict(treina_qda, conj_teste)$class %>% 
             factor(levels = levels(conj_teste$inadimplente))
confusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive="Sim") 
```

## QDA - Ajustando probabilidade limite

```{r QDA2}
p_chapeu <- predict(treina_qda, conj_teste)$posterior
head(p_chapeu)
y_chapeu <- ifelse(p_chapeu[, 2] > 0.11, "Sim", "Nao") %>% 
             factor(levels = levels(conj_teste$inadimplente))
confusionMatrix(data = y_chapeu, reference = conj_teste$inadimplente,  positive="Sim") 
```

## Curva ROC

```{r ROC, fig.width=9}
#| warning: false


# KNN
set.seed(2025)
ctrl <- trainControl(method = "cv")
treina_knn <- train(inadimplente ~ balanco + estudante, method = "knn", trControl= ctrl, preProcess=c("center", "scale"), tuneGrid = data.frame(k = seq(21,140, by=4)), data = conj_treino)
prev_knn <- predict(treina_knn, conj_teste,type = "prob")

# Reg Log
mod2 <- glm(inadimplente ~ balanco + estudante,data=conj_treino,family=binomial)
p_chapeu_log <- predict(mod2, newdata = conj_teste, type = "response")

# LDA e QDA
p_chapeu_lda <- predict(treina_lda, conj_teste)$posterior
p_chapeu_qda <- predict(treina_qda, conj_teste)$posterior

roc_log <- roc(conj_teste$inadimplente ~ p_chapeu_log, print.auc=FALSE)
roc_lda <- roc(conj_teste$inadimplente ~ p_chapeu_lda[,2],  print.auc=FALSE)
roc_qda <- roc(conj_teste$inadimplente ~ p_chapeu_qda[,2], print.auc=FALSE)
roc_knn1 <- roc(conj_teste$inadimplente ~ prev_knn[,2], print.auc=FALSE)


# Visualização com ggroc
ggroc(list(KNN= roc_knn1, RegLog= roc_log, LDA=roc_lda, QDA=roc_qda)) +
  ggplot2::labs(title = "ROC - KNN vs Reg Logística vs LDA vs QDA", x = "1 - Especificidade", y = "Sensibilidade") +
  ggplot2::theme_minimal()

as.numeric(roc_log$auc)
as.numeric(roc_lda$auc)
as.numeric(roc_qda$auc)
as.numeric(roc_knn1$auc)
```

## Reprodutibilidade

```{r}
sessionInfo()
```
