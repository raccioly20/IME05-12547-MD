---
title: "Regressão Linear"
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
format:
 html:
    code-link: true
    fig-width: 9
    fig-height: 7
    fig-dpi: 300
knitr:
  opts_chunk: 
    out.width: 90%
    comment: "#>"
execute:
  freeze: auto
---

## Carregando bibliotecas

```{r}
library(tidyverse)
```

## Dados de propaganda

O conjunto de dados contém estatísticas sobre as vendas de um produto em 200 diferentes mercados, juntamente com orçamentos publicitários em cada um desses mercados, para diferentes canais de mídia: TV, rádio e jornal. As vendas estão em milhares de unidades e o orçamento está em milhares de dólares.

```{r carrega-dados}
library(readxl)
propaganda <- read_excel("Propaganda.xlsx")
summary(propaganda)
```

## Renomeando

```{r renomeando}
propaganda <- propaganda %>% rename(Jornal = Newspaper, Vendas = Sales)

```

## Sumario

```{r sumario}
library(summarytools)
dfSummary(propaganda) |> stview(method = "render")
```

## Linhas inicias

```{r head}
library(gt)
gt(head(propaganda, 10)) %>% 
  tab_header(title = "Propaganda")
```

## Criando amostra de treino e teste

```{r treino_teste, message=FALSE}
library(caret)
set.seed(21)
y <- propaganda$Vendas
indice_teste <- createDataPartition(y, times = 1, p = 0.40, list = FALSE)

conj_treino <- propaganda[-indice_teste, ]
conj_teste <- propaganda[indice_teste, ]

str(conj_treino)
str(conj_teste)
gt::gt(head(conj_treino, 10))   %>% 
  tab_header(title = "Propaganda")
```

## Primeira visualização dos dados

Aqui estou usando uma função do pacote caret que de uma maneira simples apresenta a relação entre a variável resposta e suas possíveis variáveis explicativas

```{r caret}
featurePlot(x = conj_treino[ , c("TV", "Radio", "Jornal")], y = conj_treino$Vendas)
```

## Usando o ggplot

```{r ggplot}
gt(head(conj_treino, 10))
c_treino_pivot <- conj_treino %>% pivot_longer(!Vendas, names_to="Tipo", values_to="Orçamento" ) 
gt(head(c_treino_pivot, 10))
conj_treino %>% pivot_longer(!Vendas, names_to="Tipo", values_to="Orçamento" ) %>%
            ggplot() + 
            geom_point(aes(x=Orçamento, y=Vendas)) +
            facet_wrap( ~ Tipo, scales = "free_x") +
            labs(x = "Orçamento (1000 US$)", 
                 y = "Vendas (em 1000 unidades vendidas)", 
                 title = "Vendas vs Propaganda"
                 ) 
```

## Matriz de dispersão

```{r splom, message=FALSE}
library(psych)
pairs.panels(conj_treino, 
             method = "pearson", # metodo de correlação
             hist.col = "#00AFBB",
             density = TRUE,  # mostra graficos de densidade
             ellipses = FALSE # mostra elipses de correlação
             )

```

## Matriz de Correlações

```{r}
library(corrplot)
mat_corr <- cor(conj_treino)
corrplot(mat_corr, method = "number", col = "black", cl.pos = "n")
```

## Outra Matriz de Disersão

```{r}
library(GGally)
ggpairs(conj_treino)
```

## 1o Mod Regressão

```{r 1a_regressão, message=FALSE}
mod1 <- lm( Vendas ~ TV, data = conj_treino)
names(mod1)
coeflinear <- mod1$coefficients[1]
coefang <- mod1$coefficients[2]
summary(mod1)
ggplot(conj_treino, aes(x=TV, y=Vendas)) +
    geom_point() +
    geom_abline(slope = coefang,intercept = coeflinear, color="blue" ) + 
    geom_hline(yintercept=coeflinear, linetype="dashed", color = "red")

```

## Outra forma de representação do 1o Modelo

```{r 1areg, message=FALSE}
library(car)
scatterplot(Vendas ~ TV, data = conj_treino, smooth=F)
```

## Outra forma de representação do 1o Modelo

```{r}
library(ggside)
ggplot(conj_treino, aes(x=TV, y=Vendas)) +
    geom_point() +
    geom_smooth(method = lm, se = FALSE) + 
    geom_xsidehistogram(bins = round(1+3.322*log10(nrow(conj_treino)),0)) + 
    geom_ysidehistogram(bins = round(1+3.322*log10(nrow(conj_treino)),0))  

```

## Extraindo informações do 1o ajuste

```{r 1areg_info}
summary(mod1)$sigma
summary(mod1)$r.squared
```

## Extraindo usando uma função do pacote car

```{r}
brief(mod1)
```

## Intervalo de Confiança

```{r IC}
summary(mod1)
confint(mod1)
```

## Anova

```{r anova}
anova(mod1)
```

## Previsões

```{r previsoes}
#?predict
predict(mod1, data.frame(TV=c(50, 150, 250)), interval = "prediction")
```

## Calculando o erro padrão do resíduo com amostra de teste

```{r avaliando_TV}
##Erro com conjunto de teste
sqrt(mean((conj_teste$Vendas - predict(mod1, conj_teste)) ^ 2)) 

## Error com conjunto de treino
summary(mod1)$sigma
```

## Análise dos resíduos do 1o modelo

```{r residuos1a, message=FALSE}
plot(mod1)
```

-   Gráfico de Resíduos vs valor ajustado (fitted): Os resíduos estão igualmente espalhados em torno de uma linha horizontal sem padrões distintos? (isso é uma boa indicação de que você não tem relações não lineares)
-   Gráfico de quantis normais (Normal QQ). Os resíduos seguem bem a linha reta ou se desviam severamente? (isso é uma indicação que os resíduos se distribuem como a normal)
-   Gráfico de Dispersão-Localização. Você está vendo uma linha horizontal com pontos espalhados aleatoriamente ao longo dela? (Isto indica que a variância é constante)\
-   Gráfico de Resíduos vs influência (leverage). A distância de Cook tem valor alto? ( isto indica que o dado tem influência para os resultados obtidos na regressão)

## Outros testes

Teste de normalidade Teste de heterocedasticidade (Bresch-Pagan) Teste de autocorrelação (Durbin-Watson)

```{r}
library(lmtest)
mod1_sum <- summary(mod1)
# Teste de normalidade
shapiro.test(mod1_sum$residuals)
# Teste de hetrocedasticidade
bptest(mod1)
# Teste de autocorrelação
dwtest(mod1)
```

## 2o Modelo de Regressão

```{r 2modelo-regressão, fig.height= 5}
mod2 <- lm( Vendas ~ Radio, data = conj_treino)
coeflinear <- mod2$coefficients[1]
coefang <- mod2$coefficients[2]
summary(mod2)
ggplot(propaganda, aes(x=Radio, y=Vendas)) +
    geom_point() +
    geom_abline(slope = coefang,intercept = coeflinear, color="blue" ) + 
    geom_hline(yintercept=coeflinear, linetype="dashed", color = "red")
```

## Outra forma de representação do 2o Modelo

```{r 2areg, message=FALSE}
scatterplot(Vendas ~ Radio, data = conj_treino, smooth=F)
```

## Calculando o erro padrão do resíduo com amostra de teste

```{r avaliando_Radio}
## Erro com conjunto de teste
sqrt(mean((conj_teste$Vendas - predict(mod2, conj_teste)) ^ 2)) 

## Error com conjunto de treino
summary(mod2)$sigma
```

## Análise dos resíduos do 2o modelo

```{r}
plot(mod2)
```

## 3o Modelo de Regressão

```{r 3omodelo-regressao, fig.height= 5}
mod3 <- lm( Vendas ~ Jornal, data = conj_treino)
coeflinear <- mod3$coefficients[1]
coefang <- mod3$coefficients[2]
summary(mod3)
ggplot(propaganda, aes(x=Jornal, y=Vendas)) +
    geom_point() +
    geom_abline(slope = coefang,intercept = coeflinear, color="blue" ) + 
    geom_hline(yintercept=coeflinear, linetype="dashed", color = "red")
```

## Outra forma de representação do 3o Modelo

```{r 3areg, message=FALSE}
scatterplot(Vendas ~ Jornal, data = conj_treino, smooth=F)
```

## Calculando o erro padrão do resíduo com amostra de teste

```{r avaliando_mod3}
## Erro com conjunto de teste
sqrt(mean((conj_teste$Vendas - predict(mod3, conj_teste)) ^ 2)) 

## Error com conjunto de treino
summary(mod3)$sigma

```

## Análise dos resíduos do 3o modelo

```{r}
plot(mod3)
```
