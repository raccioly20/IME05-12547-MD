---
title: "Regularização de Modelos"
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
format:
 html:
    code-link: true
---

## Regularização de modelos

## Carregando Bibliotecas

```{r bibliotecas, warning=FALSE, message=FALSE}
library(MASS)
library(tidyverse)
library(glmnet)
data(Boston)
```

## Carregando os dados

Vamos utilizar neste exemplo os dados contidos na biblioteca MASS. A base de dados Boston tem `r nrow(Boston)` de valores preços medianos de casas na região de Boston com 13 outras variáveis explicativas (potencialmente). Vamos explorar os dados e ajustar modelos com penalização o Ridge e o LASSO e depois vamos comparar com os mínimos quadrados.

```{r Dados}
head(Boston)
summary(Boston)
```

Observamos acima que todas as variáveis são quantitativas e que não há necessidade de transformações.

## Significado das variáveis

```{r Boston}
# Boston Database
# 
#1) crim - taxa de criminalidade per capita por cidade.
# 
#2) zn - proporção de terrenos residenciais para lotes acima de 25,000 sq.ft.
# 
#3) indus - proporção de negócios não comerciais por acres e por cidade.
# 
#4) chas - variável dummy do Rio Charles(= 1 se próximo do rio; 0 de outra forma).
# 
#5) nox - concentração de óxido de nitrogênio (partes por 10 milhões).
# 
#6) rm - número médio de quartos por habitação
# 
#7) age - proporção da unidade ocupadas pelos proprietários construídas antes 1940.
# 
#8) dis - média ponderada das distâncias dos 5 pontos de emprego em Boston.
# 
#9) rad - indice de acessibilidade das avenidas radiais.
# 
#10) tax - valor cheio da taxa de propriedade por $10,000.
# 
#11) ptratio - razão aluno-professor por cidade.
# 
#12) black - 1000(Bk−0.63)21000(Bk−0.63)2 proporção de negros por cidade.
# 
#13) lstat - percentual de baixo status da população.
# 
#14) medv - valor mediano das cas ocupadas pelos proprietário em $1000s. (Var. Resposta)
```

## Conjunto de treino e de teste

Observar que retiramos a variável **rad**

```{r treino_teste}
library(caret)
set.seed(21)
y <- Boston$medv
indice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)


conj_treino <- Boston[-indice_teste, ]
conj_teste <- Boston[indice_teste, ]

str(conj_treino)
str(conj_teste)

```

## Métodos de Regularização com o caret

Usando o caret para selecionar o melhor modelo

```{r preparando_dados}
train_control <- trainControl(
  method = "repeatedcv",
  number = 10,  # validação cruzada com 10 folds
  repeats = 5,  # 5 repetições
  savePredictions = "final"  # salva os resultados do modelo final
)
```

## Cross-Validation no caret

Nós podemos usar o k-fold cross validation para identificar o melhor valor de $\lambda$

```{r r4}
set.seed(21)
mdl_ridge <- train(
  medv ~ .,
  data = conj_treino,
  method = "glmnet",
  metric = "RMSE",  
  preProcess = c("center", "scale"),
  tuneGrid = expand.grid(
    .alpha = 0,  # regressão ridge
    .lambda = seq(0, 5, length.out = 201)
  ),
  trControl = train_control
  )
mdl_ridge
ggplot(mdl_ridge) +
  labs(title = "Regressão Ridge Ajuste do Parametro", x = "lambda")
plot(varImp(mdl_ridge))
```

## Avaliando o modelo com o conjunto de teste

Aqui usamos a reamostragem com os dados de teste para avaliar o modelo

```{r avaliando}
# Metricas de desempenho
pr_ridge <- postResample(pred = predict(mdl_ridge, newdata = conj_teste), obs = conj_teste$medv)
pr_ridge
```

## Modelo Final Ridge

```{r}
set.seed(21)
mdl_final_ridge <- train(
  medv ~ .,
  data = conj_treino,
  method = "glmnet",
  metric = "RMSE",
  preProcess = c("center", "scale"),
  tuneGrid = data.frame(
    .alpha = mdl_ridge$bestTune$alpha,  # hiperparametro otimizado
    .lambda = mdl_ridge$bestTune$lambda),  # hiperparametro otimizado
  trControl = train_control
  )
mdl_final_ridge

sqrt(mean((conj_teste$medv - predict(mdl_final_ridge, newdata = conj_teste)) ^ 2))
```

## LASSO

## Validação Cruzada no LASSO

```{r Lasso2}
set.seed(21)
mdl_lasso <- train(
  medv ~ .,
  data = conj_treino,
  method = "glmnet",
  metric = "RMSE",
  preProcess = c("center", "scale"),
  tuneGrid = expand.grid(
    .alpha = 1,  # regressão lasso
    .lambda = seq(0, 5, length.out = 201)
  ),
  trControl = train_control
  )
mdl_lasso$bestTune
ggplot(mdl_lasso) +
  labs(title = "Regressão Lasso - Ajuste de parametro", x = "lambda")
```

## Avaliando com conjunto de teste

```{r lasso2}
# Metricas de desempenho
pr_lasso <- postResample(pred = predict(mdl_lasso, newdata = conj_teste), obs = conj_teste$medv)
pr_lasso
```

## Modelo Final Lasso

```{r}
set.seed(21)
mdl_final_lasso <- train(
  medv ~ .,
  data = conj_treino,
  method = "glmnet",
  metric = "RMSE",
  preProcess = c("center", "scale"),
  tuneGrid = data.frame(
    .alpha = mdl_lasso$bestTune$alpha,  # hiperparametro otimizado
    .lambda = mdl_lasso$bestTune$lambda),  # hiperparametro otimizado
  trControl = train_control
  )
mdl_final_lasso

sqrt(mean((conj_teste$medv - predict(mdl_final_lasso, newdata = conj_teste)) ^ 2))
```
