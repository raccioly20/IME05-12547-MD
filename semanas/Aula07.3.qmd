---
title: "Seleção de Modelos"
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
format:
 html:
    code-link: true
    fig-width: 9
    fig-height: 7
    fig-dpi: 300
knitr:
  opts_chunk: 
    out.width: 90%
    comment: "#>"
execute:
  freeze: auto
  message: false
  warning: false
---

## Carregando Bibliotecas

```{r bibliotecas, message=FALSE}
library(tidyverse)
library(leaps)
```

## Carregando os dados

Vendas de casas em Seattle entre 2015 e 2016

```{r}
vendas_casa <- readRDS("home_sales.rds")
head(vendas_casa)
vendas_casa <- vendas_casa %>% rename(preco=selling_price,
                                      idade=home_age,
                                      quartos=bedrooms,
                                      banheiros= bathrooms,
                                      m2_princ=sqft_living,
                                      m2_tot=sqft_lot,
                                      m2_porao=sqft_basement,
                                      andares=floors
                                      )
summary(vendas_casa)
vendas_casa <- vendas_casa %>% mutate(preco_m=preco/1000) %>% select(-preco)
```

## Análise Exploratória

```{r}
library(summarytools)
dfSummary(vendas_casa) |> stview(method = "render")
vendas_casa %>% select(where(is.numeric)) %>% 
          summarize(
            across(
              everything(),
              ~ var(., na.rm = TRUE))) %>% 
  pivot_longer(everything(),
    names_to = "variavel", 
    values_to = "variancia")
```

## Conjunto de teste e treino

```{r}
library(caret)
set.seed(21)
nrow(vendas_casa)
y <- vendas_casa$preco_m
indice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)

conj_treino <- vendas_casa[-indice_teste,]
conj_teste <- vendas_casa[indice_teste,]

str(conj_treino)
str(conj_teste)
gt::gt(head(conj_treino, 10))
```

## Matriz de correlação

```{r}
library(corrplot)
mat_corr <- cor(conj_treino)
corrplot(mat_corr, method = "number")
```

## Matriz de dispersão

```{r}
library(psych)
pairs.panels(conj_treino,
             method = "pearson", # metodo de correlação
             hist.col = "#00AFBB",
             density = TRUE,  # mostra graficos de densidade
             ellipses = FALSE # mostra elipses de correlação
             )
```

## Métodos de seleção de modelo

```{r}
## Best Subset sem definir o número máx de subsets a ser avaliado
ajusreg.comp <- regsubsets(preco_m ~ ., data=conj_treino)
summary(ajusreg.comp)
```

## Parametros adicionais

Na função `regsubsets` use adicionalmente os parametros nvmax, que define o número máximo de variáveis explicativas analisadas, e method, que define qual método de seleção de variáveis deverá ser usado.

```{r}
ajusreg.comp <- regsubsets(preco_m ~ ., data=conj_treino, nvmax=13, method=c("exhaustive"))
sumario.reg <- summary(ajusreg.comp)
sumario.reg
names(sumario.reg)
```

## Avaliando os modelos com o Cp

```{r}
## Os modelos vão ser escolhidos com base no menor Cp
plot(sumario.reg$cp,xlab="Número de Variáveis",ylab="Cp")
points(which.min(sumario.reg$cp),sumario.reg$cp[which.min(sumario.reg$cp)],pch=20,col="red")
```

## Como extrair detalhes do ajuste

```{r}
coef(ajusreg.comp,which.min(sumario.reg$cp))  
```

## Forward Stepwise (passo a passo à frente)

```{r}
ajusreg.fwd <- regsubsets(preco_m ~ . , data=conj_treino,nvmax=13, method="forward")
sumario.reg.fwd <- summary(ajusreg.fwd)
sumario.reg.fwd 
plot(sumario.reg.fwd$cp,xlab="Número de Variáveis",ylab="Cp")
points(which.min(sumario.reg.fwd$cp),sumario.reg.fwd$cp[which.min(sumario.reg.fwd$cp)],pch=20,col="red")
```

## Como extrair detalhes do ajuste

```{r}
coef(ajusreg.fwd,which.min(sumario.reg.fwd$cp))  
```

## Backward Stepwise (passo a passo atrás)

```{r}
ajusreg.bwd <- regsubsets(preco_m ~ . , data=conj_treino,nvmax=13, method="backward")
sumario.reg.bwd <- summary(ajusreg.bwd)
plot(sumario.reg.bwd$cp,xlab="Número de Variáveis",ylab="Cp")
points(which.min(sumario.reg.bwd$cp),sumario.reg.bwd$cp[which.min(sumario.reg.bwd$cp)],pch=20,col="red")
```

## Como extrair detalhes do ajuste

```{r}
coef(ajusreg.bwd,which.min(sumario.reg.bwd$cp))  
```

## Usando o BIC para seleção de variáveis

Aqui voltamos a usar o método exaustivo (**best subset selection**) que é o mais completo

```{r}
ajusreg.comp <- regsubsets(preco_m ~ ., data=conj_treino, nvmax=13, method=c("exhaustive"))
sumario.reg <- summary(ajusreg.comp)
sumario.reg
names(sumario.reg)
plot(sumario.reg$bic,xlab="Número de Variáveis",ylab="BIC")
points(which.min(sumario.reg$bic),sumario.reg$bic[which.min(sumario.reg$bic)],pch=20,col="red")
coef(ajusreg.comp,which.min(sumario.reg$bic))  
```

Veja que o BIC apresentou um modelo mais enxuto

## Revendo o resultado com o Cp

```{r}
plot(sumario.reg$cp,xlab="Número de Variáveis",ylab="Cp")
points(which.min(sumario.reg$cp),sumario.reg$cp[which.min(sumario.reg$cp)],pch=20,col="red")
coef(ajusreg.comp,which.min(sumario.reg$cp))
```

## Comparando os dois modelos com o lm()

```{r comparando}
## Usando o lm para ajustar o modelo com as variáveis selecionadas pelo BIC
mod_bic <- lm(preco_m ~ idade + quartos + m2_princ + andares, data=conj_treino)
summary(mod_bic)
mod_cp <- lm(preco_m ~ idade + quartos + banheiros + m2_princ + m2_tot + andares, data=conj_treino)
summary(mod_cp)
```

**Em termos de ajuste praticamente não há diferença nos resultados, sendo que o modelo obtido usando o BIC é bem mais enxuto. A parcimoniosidade é sempre bem vinda, mas é necessário ver como ficam os resultados com o conjunto de testes.**

## Avaliando Colinearidade

Uma investigação minuciosa da multicollinearidade envolverá a análise do valor do $R^2$ que resulta da regressão de cada uma das variáveis explicativas contra todas as outras. A relação entre as variáveis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacionário da variância (FIV) ou Variance Inflation Factor (VIF). Seja $Rj~^{2}$ o quadrado do coeficiente de correlação múltipla que resulta quando a variável explicativa $Xj~$ é ajustada contra todas as outras variáveis explicativas. Então o vif para $Xj~$ é $VIFj = 1 / (1-Rj~^{2})$

**A regra geral é que vifs superiores a 4 justificam novas investigações, enquanto VIFs superiores a 10 são sinais de multicollinearidade grave que requerem correção.**

```{r}
library(car)
vif(mod_bic)
vif(mod_cp)
```

## Testando os dois modelos com o conjunto de teste

```{r}
# Modelo com base no Cp
summary(mod_cp)$sigma
summary(mod_cp)$adj.r.squared
## Erro com conjunto de teste
sqrt(mean((conj_teste$preco_m - predict(mod_cp, conj_teste)) ^ 2))

# Modelo com base no BIC
summary(mod_bic)$sigma
summary(mod_bic)$adj.r.squared
## Erro com conjunto de teste
sqrt(mean((conj_teste$preco_m - predict(mod_bic, conj_teste)) ^ 2))
```

**Aqui vemos que as diferença de resultados entre os dois modelos é muito pequena, mas o modelo com base no BIC é mais parcimonioso, então vamos usá-lo para fazer a previsão.**

## Comparando valor real vs previsão (conjunto de treino)

```{r}
conj_treino$Previsoes <- predict(mod_bic, conj_treino)
ggplot(conj_treino, aes(x=Previsoes, y=preco_m)) + 
  geom_point() +
  geom_abline(color = "darkblue") +
  ggtitle("Preço da Casa vs. Previsões do modelo linear")
```

O modelo está tendendo dar previsões mais altas nas casas com menor preço e previsões mais baixas nas casas com maior preço. Tem duas previsões estão mais afastadas da reta Y = X. Vamos identificar estes pontos.

```{r}
conj_treino$Previsoes <- predict(mod_bic, conj_treino)
ggplot(conj_treino, aes(x=Previsoes, y=preco_m)) + 
  geom_point() +
  geom_abline(color = "darkblue") +
  ggtitle("Preço da Casa vs. Previsões do modelo linear") +
  geom_text(aes(label=ifelse(Previsoes > 670, rownames(conj_treino), '')), hjust=0, vjust=-0.5)
```

```{r}
conj_treino[c(3, 704), ]
```

## Comparando valor real vs previsão (conjunto de teste)

```{r}
conj_teste$Previsoes <- predict(mod_bic, conj_teste)
ggplot(conj_teste, aes(x=Previsoes, y=preco_m)) + 
  geom_point() +
  geom_abline(color = "darkblue") +
  ggtitle("Preço da Casa vs. Previsões do modelo linear")
```

## Avaliando os resíduos

```{r}
#| warning: false
residualPlots(mod_bic)
influencePlot(mod_bic)
```
