---
title: "Seleção de Modelos"
author: "Ricardo Accioly"
date: "`r Sys.Date()`"
format:
 html:
    code-link: true
---

```{r}
#| label: setup
#| echo: false
#| message: false
#| warning: false
```

## Carregando Bibliotecas

```{r bibliotecas, message=FALSE}
library(tidyverse)
library(leaps)
```

## Carregando os dados

Vendas de casas em Seattle entre 2015 e 2016

```{r Dados }
vendas_casa <- readRDS("home_sales.rds")
head(vendas_casa)
vendas_casa <- vendas_casa %>% rename(preco=selling_price,
                                      idade=home_age,
                                      quartos=bedrooms,
                                      banheiros= bathrooms,
                                      m2_princ=sqft_living,
                                      m2_tot=sqft_lot,
                                      m2_porao=sqft_basement,
                                      andares=floors
                                      )
summary(vendas_casa)
vendas_casa <- vendas_casa %>% mutate(preco_m=preco/1000) %>% select(-preco)
```

## Conjunto de teste e treino

```{r treino_teste}
library(caret)
set.seed(21)
nrow(vendas_casa)
y <- vendas_casa$preco_m
indice_teste <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)

conj_treino <- vendas_casa[-indice_teste,]
conj_teste <- vendas_casa[indice_teste,]

str(conj_treino)
str(conj_teste)
gt::gt(head(conj_treino, 10))
```

## Matriz de correlação

```{r corrplot1, fig.height=4.5, figure.width=8, message=FALSE}
library(corrplot)
mat_corr <- cor(conj_treino)
corrplot(mat_corr)
```

## Matriz de dispersão

```{r splom2}
library(psych)
pairs.panels(conj_treino,
             method = "pearson", # metodo de correlação
             hist.col = "#00AFBB",
             density = TRUE,  # mostra graficos de densidade
             ellipses = FALSE # mostra elipses de correlação
             )
```

## Métodos de seleção de modelo

```{r melhor_modelo}
## Best Subset sem definir o número máx de subsets a ser avaliado
ajusreg.comp <- regsubsets(preco_m ~ ., data=conj_treino)
summary(ajusreg.comp)
```

## nvmax=13

```{r modelo_completo}
ajusreg.comp <- regsubsets(preco_m ~ ., data=conj_treino, nvmax=13)
sumario.reg <- summary(ajusreg.comp)
sumario.reg
names(sumario.reg)
```

## Avaliando os modelos

```{r avaliando}
## Os modelos vão ser escolhidos com base no menor Cp
plot(sumario.reg$cp,xlab="Número de Variáveis",ylab="Cp")
which.min(sumario.reg$cp)
points(6,sumario.reg$cp[6],pch=20,col="red")
```

## Como extrair detalhes do ajuste

```{r detalhes}
coef(ajusreg.comp,6)  
```

## Forward Stepwise (passo a passo à frente)

```{r FR}
ajusreg.fwd <- regsubsets(preco_m ~ . , data=conj_treino,nvmax=13, method="forward")
sumario.reg.fwd <- summary(ajusreg.fwd)
sumario.reg.fwd 
which.min(sumario.reg.fwd$cp)
plot(sumario.reg.fwd$cp,xlab="Número de Variáveis",ylab="Cp")
points(6,sumario.reg.fwd$cp[6],pch=20,col="red")
```

## Como extrair detalhes do ajuste

```{r detalhes2}
coef(ajusreg.fwd,6)  
```

## Backward Stepwise (passo a passo atrás)

```{r BR, fig.height=4.5, figure.width=6.5}
ajusreg.bwd <- regsubsets(preco_m ~ . , data=conj_treino,nvmax=13, method="backward")
sumario.reg.bwd <- summary(ajusreg.bwd)
sumario.reg.bwd
which.min(sumario.reg.bwd$cp)
plot(sumario.reg.bwd$cp,xlab="Número de Variáveis",ylab="Cp")
points(6,sumario.reg.bwd$cp[6],pch=20,col="red")
```

## Como extrair detalhes do ajuste

```{r detalhes3}
coef(ajusreg.bwd,6)  
```

## Testando outra estatística de seleção de modelos - BIC

```{r BIC}
ajusreg.fwd1 <- regsubsets(preco_m ~ . , data=conj_treino,nvmax=13, method="forward")
sumario.reg.fwd1 <- summary(ajusreg.fwd1)
names(sumario.reg.fwd1)

which.min(sumario.reg.fwd1$bic)
plot(sumario.reg.fwd1$bic,xlab="Número de Variáveis",ylab="BIC")
points(4,sumario.reg.fwd1$bic[4],pch=20,col="red")
coef(ajusreg.fwd1,4)  


```

## Usando o Cp novamente

```{r cp_denovo}
which.min(sumario.reg.fwd1$cp)
plot(sumario.reg.fwd1$cp,xlab="Número de Variáveis",ylab="Cp")
points(6,sumario.reg.fwd1$cp[6],pch=20,col="red")
coef(ajusreg.fwd1,6)
```

## Comparando os dois modelos com o lm()

```{r comparando}
## Usando o lm para ajustar o modelo com as variáveis selecionadas pelo BIC
mod_bic <- lm(preco_m ~ idade + quartos + m2_princ + andares, data=conj_treino)
summary(mod_bic)
mod_cp <- lm(preco_m ~ idade + quartos + banheiros + m2_princ + m2_tot + andares, data=conj_treino)
summary(mod_cp)
```

## Avaliando Colinearidade

Uma investigação minuciosa da multicollinearidade envolverá a análise do valor do $R^2$ que resulta da regressão de cada uma das variáveis explicativas contra todas as outras. A relação entre as variáveis explicativas pode ser julgada examinando uma quantidade chamada fator de inflacionário da variância (FIV) ou Variance Inflation Factor (VIF). Seja $Rj~^{2}$ o quadrado do coeficiente de correlação múltipla que resulta quando a variável explicativa $Xj~$ é ajustada contra todas as outras variáveis explicativas. Então o vif para $Xj~$ é $VIFj = 1 / (1-Rj~^{2})$

**A regra geral é que vifs superiores a 4 justificam novas investigações, enquanto VIFs superiores a 10 são sinais de multicollinearidade grave que requerem correção.**

```{r car, message=FALSE}
library(car)
vif(mod_bic)
vif(mod_cp)
```

## Testando os dois modelos com o conjunto de teste

```{r C_teste}
# Modelo com base no Cp
summary(mod_cp)$sigma
summary(mod_cp)$adj.r.squared
sqrt(mean((conj_teste$preco_m - predict(mod_cp, conj_teste)) ^ 2))

# Modelo com base no BIC
summary(mod_bic)$sigma
summary(mod_bic)$adj.r.squared
sqrt(mean((conj_teste$preco_m - predict(mod_bic, conj_teste)) ^ 2))
```

## Comparando valor real vs previsão

```{r}
conj_treino$Previsoes <- predict(mod_bic, data=conj_treino)
ggplot(conj_treino, aes(x=Previsoes, y=preco_m)) + 
  geom_point() +
  geom_abline(color = "darkblue") +
  ggtitle("Preço da Casa vs. Previsões do modelo linear")
```
